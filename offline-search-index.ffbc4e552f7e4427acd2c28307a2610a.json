























































































































































































































































































































































































































































































































































[{"body":"kitex is a command line tool for code generation provided by the RPC framework Kitex. At present, kitex accepts both thrift and protobuf IDLs, and supports generating a skeleton of a server side project.\nInstallation  At present, the Kitex command-line tool does not support the Windows environment.\n Kitex code generation relies on thriftgo and protoc compilers. You need to install the corresponding compilers first: thriftgo or protoc.\nAfter installing the aforementioned tools, you can install the Kitex command-line tool itself using the following go command:\ngo install github.com/cloudwego/kitex/tool/cmd/kitex@latest Alternatively, you can download the Kitex source code and navigate to the tool/cmd/kitex directory. From there, you can execute go install to install the Kitex command-line tool:\nAfter installation, you can check the version of the tool by executing kitex -version or view the usage help by executing kitex -help.\nGenerate Code Generating code involves two parts: one is the serialization and deserialization code for struct, which is generated by the underlying compilers, thriftgo or protoc. The other part is the stub code used for creating and initiating RPC calls, which is built on the top of the former by the Kitex tool. Users only need to run the Kitex code generation tool, and all the code generation process will be automatically completed by the underlying tools.\nThe syntax for generating code with the Kitex tool is kitex [options] xx.thrift/xxx.proto. For information about the usage of options, please refer to the end of this document.\nTaking the thrift scenario as an example, there are two IDL files as follows:\n// File1：example.thrift namespacegotestinclude\"base.thrift\"structMyReq{1:requiredstringinput2:requiredbase.BaseReqbaseReq}serviceMyService{stringHello(1:requiredMyReqreq)}// File2：base.thrift structBaseReq{1:requiredstringname}If the current directory is under Go Path, execute the following command:\nkitex example.thrift If an error message Outside of $GOPATH. Please specify a module name with the '-module' flag. is displayed, it means that the current directory is not under Go Path, and a new go mod needs to be created. Use the -module flag to specify the go mod and execute the following command:\nkitex -module xxx example.thrift After execution, a directory named kitex_gen will be generated in the current directory with the following contents:\nkitex_gen/ ├── base\t// The generated content of base.thrift, using lowercase IDL file name as the package name when there is no 'go namespace' │ ├── base.go\t// Go code generated by thriftgo, containing the definitions from base.thrift │ ├── k-base.go\t// Generated by Kitex and includes additional serialization optimization implementations provided by Kitex │ └── k-consts.go\t// Avoiding placeholder files for 'import not used' └── test\t// The generated content of example.thrift, use go namespace as package name ├── example.go\t// The Go code generated by Thriftgo, which includes the content defined in example.thrift ├── k-consts.go\t// Placeholder file to avoid 'import not used' ├── k-example.go\t// Generated by Kitex, which includes additional serialization optimization implementations provided by Kitex └── myservice\t// The code generated by kitex for the myservice defined in example.thrift ├── client.go\t// Provide NewClient API ├── invoker.go\t// Provide API in the form of a Server SDK. ├── myservice.go\t// Provide some definitions that are shared by both client.go and server.go └── server.go\t// Provide NewServer API Generate Code with Scaffolding The code example mentioned earlier cannot be directly executed and requires building NewClient and NewServer on your own. The kitex command-line tool provides the -service parameter to generate scaffolded code directly. Execute the following command:\nkitex -service mydemoservice demo.thrift The generated results are as follows:\n├── build.sh\t// Script for quickly building services ├── handler.go\t// Generate a handler scaffold for the server ├── kitex_info.yaml // Record meta information for integration with cwgo tools ├── main.go\t// Quickly start the main function of the server └── script\t// Build service related scripts │ └── bootstrap.sh ├── kitex_gen └── ....\tAfter filling in the business code in the generated function of handler. go, execute the main function of main. go to quickly start the Kitex Server.\nLibrary Dependencies The codes generated by kitex may depends on certain Go libraries:\n For thrift IDLs, it is github.com/apache/thrift v0.13.0 For protobuf IDLs, it is google.golang.org/protobuf v1.26.0  It is important to note that, from v0.14.0, the APIs in github.com/apache/thrift/lib/go/thrift are incompatible with previous versions. If you specify the -u flag when using go get to update dependencies, this library will be updated to the incompatible version and cause compilation failure. Usually, there are errors like this: Like ‘not enough arguments in call to iprot.ReadStructBegin’\nYou can solve this problem by executing an extra command to choose the appropriate version:\ngo get github.com/apache/thrift@v0.13.0 or force the version with a replace command:\ngo mod edit -replace github.com/apache/thrift=github.com/apache/thrift@v0.13.0 After v0.4.5, the tool will automatically add this constraint to go mod.\nNotes for Using Protobuf IDLs The kitex only supports the proto3 version of the protocol buffers language.\nThe go_package option in the IDL is required. Its value is a package name sequence separated by dots (.) or by slashes (/). It determines the suffix of the result import path. For instance,\noption go_package = \"hello.world\"; // or hello/world will generates an import path ${imoprt path of the current directory}/kitex_gen/hello/world.\nIf you assign a complete import path to go_package, then kitex will generate codes for this IDL only when the import path matches the kitex_gen directory. For example:\n go_package=\"${import path of current module}/kitex_gen/hello/world\";: OK. Kitex will generate codes for this IDL; go_package=\"${import path of current module}/hello/world\";: Kitex will not generate codes for this IDL; go_package=\"any.other.domain/some/module/kitex_gen/hello/world\";: Kitex will not generate codes for this IDL;  You can overwrite the go_package value in a proto file with a command line option --protobuf Msome.proto=your.package.name/kitex_gen/wherever/you/like. For the usage of the option, please refer to the official document of Protocol Buffers.\nOptions The option description here may be outdated. Run kitex -h or kitex --help to get all usable options of kitex.\n-service service_name When this option is specified, kitex will generate a scaffold to build a server. Parameter service_name gives the name of the server itself when launched. Its value is usually up to the service registry and service disccovery components when using the Kitex framework.\n-module module_name This option is used to specify the Go module the generated codes belongs to. It affects import paths.\n  If the current directory is a child path of $GOPATH/src, this option can be omitted; kitex will use a path relative to $GOPATH/src as the prefix of import path in generated codes. For example, if you run kitex under $GOPATH/src/example.com/hello/world, the import path of kitex_gen/example_package/example_package.go for other package will be example.com/hello/world/kitex_gen/example_package.\n  If the current directory is not a child path of $GOPATH/src, this option must be specified.\n  If -module is specified, then kitex searches for go.mod from the current directory to the root.\n If go.mod is not found, kitex will generated one with go mod init. If go.mod is found, then kitex will check if the module name in go.mod is identical with the argument of -module; if they diffs, kitex will report an error and exit. Finally, the position of go.mod and its module names determines the import path in generated codes.    -I path Add a search path for IDL. Support adding multiple files. When searching for IDL (including other files included in IDL), it will search in the order of the added path.\nPath input can also support git pull. When the current suffix is git @, http://, https://, the remote git repository will be pulled to the local location and included in the search path. The usage method is as follows:\nkitex -module xx -I xxx.git abc/xxx.thrift Or use @ xxx to specify branch pull:\nkitex -module xx -I xxx.git@branch abc/xxx.thrift During execution, the git repository will be pulled first and stored in~/. kitex/cache/xxx/xxx/ xxx@branch Directory, then search for abc/xxx.thrift in this directory and generate code\n-v or -verbose Output more logs.\n-use path When generating server codes (with -service), the -use option stops kitex from generating the kitex_gen and uses the import path given by the argument instead.\n-combine-service For thrift IDLs, when generating codes for a server, kitex only generates methods for the last service definition in the IDL. If there are multiple services in the IDL and you want to export all their abilities, the -combine-service option is for that.\nThis option creates a CombineService that assembles all methods of services in the target IDL and uses it in the main package. Notice that no two methods of services can have the same name.\n-protobuf value Pass an argument to protoc. The argument will be appended to the -go_out for protoc. See the documentation of protoc for available values.\n-thrift value Pass an argument to thriftgo. The argument will be appended to the -g go: for thriftgo. See the documentation of thriftgo for available values.\nKitex by default passes naming_style=golint,ignore_initialisms,gen_setter,gen_deep_equal to thriftgo and it can be overridden if you specify the same parameter in addition.\n-record In some scenarios, it may be necessary to run the Kitex command multiple times to generate code for multiple IDLs. -record parameter is used to automatically record each Kitex command executed and generate a script file for batch re execution during updates.\nUsage:\nkitex -module xxx -service xxx -record xxx.thrift After executing with the - record parameter, generate the kitex-all.sh file in the execution directory and record the current command If the - record parameter is used multiple times, it will be recorded multiple times The content of kitex-all.sh is as follows:\n#!/bin/bash kitex -module xxx -service xxx xxx.thrift kitex -module xxx xxxa.thrift kitex -module xxx xxxb.thrift kitex -module xxx xxxc.thrift kitex -module xxx xxxd.thrift ....Continue Recording newly executed commands Command records are not always appended backwards, as follows:\n Only one command with - service will be recorded If the idl path of the recorded command is new, append the record at the end If the idl path already exists, overwrite the original record  To regenerate the code, execute kitex-all.sh. If you want to manually adjust, simply open the script file and edit the command directly\n-gen-path  Currently, it only takes effect in the Thrift scenario, and the protobuf side needs to be further improved and implemented.\n Default scenario, kitex will generate code in kitex_ Under the gen directory, adjustments can be made through - gen path\n-protobuf-plugin Plugins that support extending protocs can be integrated into a rich protoc plugin ecosystem, providing convenience for expanding code generation\nThe usage method is as follows:\nkitex -protobuf-plugin {plugin_name:options:out_dir} idl/myservice.proto Among them:\n plugin_name: Indicates the name of the plugin to be executed; For example, ‘protoc gen go’, then its plugin name is ‘go’ options: Represents the options passed to the plugin; Usually, some information such as ‘go module’ is passed on out_dir: Represents the path where the plugin generates code; If there are no special needs, it is generally specified as “.”  The above three options can be mapped to the following protoc commands, which can be automatically concatenated and executed by kitex:\nprotoc --{$plugin_name}_out={$out_dir} --{$plugin_name}_opt={$options} idl/myservice.proto For example, if you want to use protoc-gen-validator plugin, you can execute the following command:\nkitex -protobuf-plugin=validator:module=toutiao/middleware/kitex,recurse=true:. idl/myservice.proto ","categories":"","description":"","excerpt":"kitex is a command line tool for code generation provided by the RPC …","ref":"/docs/kitex/tutorials/code-gen/code_generation/","tags":"","title":"Code Generation Tool"},{"body":" 本篇文档及示例所使用的 Kitex 代码生成工具版本为 v0.5.0\n kitex 是 Kitex 框架提供的用于生成代码的一个命令行工具。目前，kitex 支持 thrift 和 protobuf 的 IDL，并支持生成一个服务端项目的骨架。\n安装  目前 Kitex 命令行工具暂不支持 Windows 环境\n Kitex 代码生成依赖于 thriftgo 和 protoc，需要先安装相应的编译器：thriftgo 或 protoc。\n安装完上述工具后，通过 go 命令安装命令行工具本身\ngo install github.com/cloudwego/kitex/tool/cmd/kitex@latest 你也可以自己下载 Kitex 源码后，进入 tool/cmd/kitex 目录执行 go install 进行安装\n完成后，可以通过执行 kitex -version 查看工具版本，或者 kitex -help 查看使用帮助。\n生成代码 生成代码分两部分，一部分是结构体的编解码序列化代码，由底层编译器 thriftgo 或 protoc 生成；另一部分由 kitex 工具在前者产物上叠加，生成用于创建和发起 RPC 调用的桩代码。用户只需要执行 Kitex 代码生成工具，底层会自动完成所有代码的生成。\nkitex 工具生成代码的语法为 kitex [options] xx.thrfit/xxx.proto ，option 用法可参考文末。\n以 thrift 场景为例，有如下两个 IDL 文件：\n// 文件1：example.thrift namespacegotestinclude\"base.thrift\"structMyReq{1:requiredstringinput2:requiredbase.BaseReqbaseReq}serviceMyService{stringHello(1:requiredMyReqreq)}// 文件2：base.thrift structBaseReq{1:requiredstringname}如果当前目录在 Go Path 下，执行如下命令：\nkitex example.thrift 若报错 Outside of $GOPATH. Please specify a module name with the '-module' flag. ，说明当前目录没在 Go Path 下，需要创建 go mod，并通过 -module 指定 go mod 并执行如下命令：\nkitex -module xxx example.thrift 执行后，在当前目录下会生成一个名为 kitex_gen 目录，内容如下：\nkitex_gen/ ├── base\t// base.thrift 的生成内容，没有 go namespace 时，以 idl 文件名小写作为包名 │ ├── base.go\t// thriftgo 生成，包含 base.thrift 定义的内容的 go 代码 │ ├── k-base.go\t// kitex 生成，包含 kitex 提供的额外序列化优化实现 │ └── k-consts.go\t// 避免 import not used 的占位符文件 └── test\t// example.thrift 的生成内容，用 go namespace 为包名 ├── example.go\t// thriftgo 生成，包含 example.thrift 定义的内容的 go 代码 ├── k-consts.go\t// 避免 import not used 的占位符文件 ├── k-example.go\t// kitex 生成，包含 kitex 提供的额外序列化优化实现 └── myservice\t// kitex 为 example.thrift 里定义的 myservice 生成的代码 ├── client.go\t// 提供了 NewClient API ├── invoker.go\t// 提供了 Server SDK 化的 API ├── myservice.go\t// 提供了 client.go 和 server.go 共用的一些定义 └── server.go\t// 提供了 NewServer API 生成带有脚手架的代码 上文的案例代码并不能直接运行，需要自己完成 NewClient 和 NewServer 的构建。kitex 命令行工具提供了 -service 参数能直接生成带有脚手架的代码，执行如下命令：\nkitex -service mydemoservice demo.thrift 生成结果如下：\n├── build.sh\t// 快速构建服务的脚本 ├── handler.go\t// 为 server 生成 handler 脚手架 ├── kitex_info.yaml // 记录元信息，用于与 cwgo 工具的集成 ├── main.go\t// 快速启动 server 的主函数 └── script\t// 构建服务相关脚本 │ └── bootstrap.sh ├── kitex_gen └── ....\t在 handler.go 的接口中填充业务代码后，执行 main.go 的主函数即可快速启动 Kitex Server。\n库依赖 kitex 生成的代码会依赖相应的 Go 语言代码库：\n 对于 thrift IDL，是 github.com/apache/thrift v0.13.0 对于 protobuf IDL，是  google.golang.org/protobuf v1.26.0  要注意的一个地方是，github.com/apache/thrift/lib/go/thrift 的 v0.14.0 版本开始提供的 API 和之前的版本是不兼容的，如果在更新依赖的时候给 go get 命令增加了 -u 选项，会导致该库更新到不兼容的版本造成编译失败。通常会有这样的报错： 如 not enough arguments in call to iprot.ReadStructBegin\n你可以通过额外执行一个命令来指定正确的版本：\ngo get github.com/apache/thrift@v0.13.0 或用 replace 指令强制固定该版本：\ngo mod edit -replace github.com/apache/thrift=github.com/apache/thrift@v0.13.0 在 v0.4.5 后，工具会对 go mod 自动添加该约束\n使用 protobuf IDL 的注意事项 kitex 仅支持 protocol buffers 的 proto3 版本的语法。\nIDL 里的 go_package 是必需的，其值可以是一个用点（.）或斜线（/）分隔的包名序列，决定了生成的 import path 的后缀。例如\noption go_package = \"hello.world\"; // or hello/world 生成的 import path 会是 ${当前目录的 import path}/kitex_gen/hello/world。\n如果你给 go_package 赋值一个完整的导入路径（import path），那么该路径必须匹配到当前模块的 kitex_gen 才会生成代码。即：\n go_package=\"${当前模块的 import path}/kitex_gen/hello/world\";：OK，kitex 会为该 IDL 生成代码； go_package=\"${当前模块的 import path}/hello/world\";：kitex 不会为该 IDL 生成代码； go_package=\"any.other.domain/some/module/kitex_gen/hello/world\";：kitex 不会为该 IDL 生成代码；  你可以通过命令行参数 --protobuf Msome.proto=your.package.name/kitex_gen/wherever/you/like 来覆盖某个 proto 文件的 go_package 值。具体用法说明可以参考 Protocol Buffers 的官方文档。\n选项 本文描述的选项可能会过时，可以用 kitex -h 或 kitex --help 来查看 kitex 的所有可用的选项。\n-service service_name 使用该选项时，kitex 会生成构建一个服务的脚手架代码，参数 service_name 给出启动时服务自身的名字，通常其值取决于使用 Kitex 框架时搭配的服务注册和服务发现功能。\n-module module_name 该参数用于指定生成代码所属的 Go 模块，会影响生成代码里的 import path。\n  如果当前目录是在 $GOPATH/src 下的一个目录，那么可以不指定该参数；kitex 会使用 $GOPATH/src 开始的相对路径作为 import path 前缀。例如，在 $GOPATH/src/example.com/hello/world 下执行 kitex，那么 kitex_gen/example_package/example_package.go 在其他代码代码里的 import path 会是 example.com/hello/world/kitex_gen/example_package。\n  如果当前目录不在 $GOPATH/src 下，那么必须指定该参数。\n  如果指定了 -module 参数，那么 kitex 会从当前目录开始往上层搜索 go.mod 文件\n 如果不存在 go.mod 文件，那么 kitex 会调用 go mod init 生成 go.mod； 如果存在 go.mod 文件，那么 kitex 会检查 -module 的参数和 go.mod 里的模块名字是否一致，如果不一致则会报错退出； 最后，go.mod 的位置及其模块名字会决定生成代码里的 import path。    -I path 添加一个 IDL 的搜索路径。支持添加多个，搜索 IDL（包括 IDL 里 include 的其他文件）时，会按照添加的路径顺序搜索。\npath 输入也可以支持 git 拉取，当前缀为 git@，http://，https:// 时，会拉取远程 git 仓库到本地，并将其列入搜索路径。使用方式如下：\nkitex -module xx -I xxx.git abc/xxx.thrift 或使用 @xxx 指定分支拉取：\nkitex -module xx -I xxx.git@branch abc/xxx.thrift 执行时会先拉取 git 仓库，存放于 ~/.kitex/cache/xxx/xxx/xxx@branch 目录下，然后再在此目录下搜索 abc/xxx.thrift 并生成代码\n-v 或 -verbose 输出更多日志。\n-use path 在生成服务端代码（使用了 -service）时，可以用 -use 选项来让 kitex 不生成 kitex_gen 目录，而使用该选项给出的 import path。\n-combine-service 对于 thrift IDL，kitex 在生成服务端代码脚手架时，只会针对最后一个 service 生成相关的定义。如果你的 IDL 里定义了多个 service 定义并且希望在一个服务里同时提供这些 service 定义的能力时，可以使用 -combine-service 选项，详见 Combine Service.\n该选项会生成一个合并了目标 IDL 文件中所有 service 方法的 CombineService，并将其用作 main 包里使用的 service 定义。注意这个模式下，被合并的 service 之间不能有冲突的方法名。\n-protobuf value 传递给 protoc 的参数。会拼接在 -go_out 的参数后面。可用的值参考 protoc 的帮助文档。\n-thrift value 传递给 thriftgo 的参数。会拼接在 -g go: 的参数后面。可用的值参考 thriftgo 的帮助文档。kitex 默认传递了 naming_style=golint,ignore_initialisms,gen_setter,gen_deep_equal，可以被覆盖。\n-record 有的场景下，可能需要多次运行 Kitex 命令，为多个 IDL 生成代码。 -record 参数用于自动记录每次执行的 Kitex 命令并生成脚本文件，以便更新时批量重新执行。\n使用方式：\nkitex -module xxx -service xxx -record xxx.thrift 带上 -record 参数执行后，在执行目录下生成 kitex-all.sh 文件，记录本次命令 若多次带有 -record 参数则多次进行记录 kitex-all.sh 内容如下:\n#!/bin/bash kitex -module xxx -service xxx xxx.thrift kitex -module xxx xxxa.thrift kitex -module xxx xxxb.thrift kitex -module xxx xxxc.thrift kitex -module xxx xxxd.thrift ....新执行的命令继续记录 命令记录并不是每次都只往后追加，规则如下：\n 只会记录一条带有 -service 的命令 记录的命令的 idl path 如果是新的，则在末尾追加记录 如果 idl path 是已存在的，则对原记录覆盖  想重新生成代码，执行 kitex-all.sh 即可。若想手动调整，打开脚本文件直接编辑命令即可\n-gen-path  目前只在 thrift 场景生效，protobuf 侧待后续完善实现。\n 默认场景，kitex 会将代码生成在 kitex_gen 目录下，可以通过 -gen-path 进行调整\n-protobuf-plugin 支持拓展 protoc 的插件，可接入丰富的 protoc 插件生态，为拓展生成代码提供方便\n使用方法如下：\nkitex -protobuf-plugin {plugin_name:options:out_dir} idl/myservice.proto 其中：\n plugin_name: 表示要执行的插件名；例如\"protoc-gen-go\"，那么他的插件名就为 “go” options: 表示传递给插件的选项；通常会传递一些类似 “go module” 等信息 out_dir: 表示插件生成代码的路径；如无特殊需求，一般指定为 “.” 即可  以上 3 个选项可映射为如下的 protoc 命令，可被 kitex 自动拼接\u0026执行:\nprotoc --{$plugin_name}_out={$out_dir} --{$plugin_name}_opt={$options} idl/myservice.proto 例如希望使用 protoc-gen-validator 插件，可以执行如下命令：\nkitex -protobuf-plugin=validator:module=toutiao/middleware/kitex,recurse=true:. idl/myservice.proto ","categories":"","description":"","excerpt":" 本篇文档及示例所使用的 Kitex 代码生成工具版本为 v0.5.0\n kitex 是 Kitex 框架提供的用于生成代码的一个命令行工 …","ref":"/zh/docs/kitex/tutorials/code-gen/code_generation/","tags":"","title":"代码生成工具"},{"body":"hz is a tool provided by the Hertz framework for generating code. Currently, hz can generate scaffolding for Hertz projects based on thrift and protobuf’s IDL.\nInstall  Make sure the GOPATH environment variable has been defined correctly (eg export GOPATH=~/go) and add $GOPATH/bin to the PATH environment (eg export PATH=$GOPATH/bin:$PATH); do not set GOPATH to a directory that the current user does not have read/write access to. Install hz:  go install github.com/cloudwego/hertz/cmd/hz@latest Verify that the installation was successful hz -v, if the following version message is displayed, the installation was successful  hz version v0.1.0 Note，Since hz creates soft links to its own binary, make sure that the installation path of hz has writable permissions.\nOperating mode To generate code using thrift or protobuf IDL, The corresponding compiler needs to be installed: thriftgo or protoc.\nThe code generated by hz, part of it is generated by the underlying compiler (usually about the struct defined in IDL), and the other part is the user-defined routing, method and other information in IDL. The user can run the code directly.\nIn terms of execution flow, when hz uses thrift IDL to generate code, hz calls thriftgo to generate the go struct code and executes itself as a plugin to thriftgo (named thrift-gen-hertz) to generate the rest of the code. This is also true when used with the protobuf IDL.\n$\u003e hz ... --idl=IDL | | thrift-IDL |---------\u003e thriftgo --gen go:... -plugin=hertz:... IDL | | protobuf-IDL ---------\u003e protoc --hertz_out=... --hertz_opt=... IDL How to install thriftgo/protoc:\nthriftgo:\n$ GO111MODULE=on go install github.com/cloudwego/thriftgo@latest protoc:\n// brew installation $ brew install protobuf // Official image installation, using macos as an example $ wget https://github.com/protocolbuffers/protobuf/releases/download/v3.19.4/protoc-3.19.4-osx-x86_64.zip $ unzip protoc-3.19.4-osx-x86_64.zip $ cp bin/protoc /usr/local/bin/protoc // Make sure include/google goes under /usr/local/include $ cp -r include/google /usr/local/include/google ","categories":"","description":"","excerpt":"hz is a tool provided by the Hertz framework for generating code. …","ref":"/docs/hertz/tutorials/toolkit/usage/install/","tags":"","title":"hz install"},{"body":"hz 是 Hertz 框架提供的一个用于生成代码的命令行工具。目前，hz 可以基于 thrift 和 protobuf 的 IDL 生成 Hertz 项目的脚手架。\n安装  确保 GOPATH 环境变量已经被正确地定义（例如 export GOPATH=~/go）并且将$GOPATH/bin添加到 PATH 环境变量之中（例如 export PATH=$GOPATH/bin:$PATH）；请勿将 GOPATH 设置为当前用户没有读写权限的目录 安装 hz：  go install github.com/cloudwego/hertz/cmd/hz@latest 验证是否安装成功 hz -v, 如果显示如下版本的信息，则说明安装成功  hz version v0.1.0 注意，由于 hz 会为自身的二进制文件创建软链接，因此请确保 hz 的安装路径具有可写权限。\n运行模式 要使用 thrift 或 protobuf 的 IDL 生成代码，需要安装相应的编译器：thriftgo 或 protoc 。\nhz 生成的代码里，一部分是底层的编译器生成的（通常是关于 IDL 里定义的结构体），另一部分是 IDL 中用户定义的路由、method 等信息。用户可直接运行该代码。\n从执行流上来说，当 hz 使用 thrift IDL 生成代码时，hz 会调用 thriftgo 来生成 go 结构体代码，并将自身作为 thriftgo 的一个插件（名为 thrift-gen-hertz）来执行来生成其他代码。当用于 protobuf IDL 时亦是如此。\n$\u003e hz ... --idl=IDL | | thrift-IDL |---------\u003e thriftgo --gen go:... -plugin=hertz:... IDL | | protobuf-IDL ---------\u003e protoc --hertz_out=... --hertz_opt=... IDL 如何安装 thriftgo/protoc:\nthriftgo:\n$ GO111MODULE=on go install github.com/cloudwego/thriftgo@latest protoc:\n// brew 安装 $ brew install protobuf // 官方镜像安装，以 macos 为例 $ wget https://github.com/protocolbuffers/protobuf/releases/download/v3.19.4/protoc-3.19.4-osx-x86_64.zip $ unzip protoc-3.19.4-osx-x86_64.zip $ cp bin/protoc /usr/local/bin/protoc // 确保 include/google 放入 /usr/local/include下 $ cp -r include/google /usr/local/include/google ","categories":"","description":"","excerpt":"hz 是 Hertz 框架提供的一个用于生成代码的命令行工具。目前，hz 可以基于 thrift 和 protobuf 的 IDL …","ref":"/zh/docs/hertz/tutorials/toolkit/usage/install/","tags":"","title":"hz 安装"},{"body":"The service discovery extensions currently supported in the open source version of Hertz are stored in the registry. You are welcomed to join us in contributing and maintaining for this project.\nAs of now, the supported service discovery extensions are\n nacos consul etcd eureka polaris servicecomb zookeeper redis  Configuration Some optional configurations are provided to users when using service discovery.\n   Configuration Description     WithSD Set isSD to true , required to use service discovery.   WithTag Set tag for requestOptions.   WithCustomizedAddrs Customize the address of the target instance.   WithLoadBalanceOptions Configure load balancing options.    WithSD requestOptions provides WithSD configuration item, when the incoming parameter is true, isSD will be set to true. The WithSD configuration item must be used when using service discovery requests.\nSample code:\nstatus, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) WithTag requestOptions provides WithTag configuration item, using this configuration will set tag for requestOptions.\nSample code:\nstatus, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithTag(\"foo\", \"var\")) WithCustomizedAddrs This configuration item specifies the target instance address during service discovery. It will overwrite the result from Resolver. Resolver is a service discovery center for service discovery.\nSample code:\ncli.Use(sd.Discovery(r, sd.WithCustomizedAddrs(\"127.0.0.1:8088\"))) WithLoadBalanceOptions This configuration item can configure the load balancing algorithm and load balancing parameters for the client.\nSample code:\ncli.Use(sd.Discovery(r, sd.WithLoadBalanceOptions(loadbalance.NewWeightedBalancer(), loadbalance.Options{ RefreshInterval: 5 * time. Second, ExpireInterval: 15 * time. Second, }))) Nacos Install go get github.com/hertz-contrib/registry/nacos Service Registry Option Nacos extension provides option configuration in the service registry section.\nWithRegistryCluster Nacos extension provides WithRegistryCluster to help users configure custom clusters. Defaults to “DEFAULT” .\nFunction signature:\nfunc WithRegistryCluster(cluster string) RegistryOption Example:\nfunc main() { // ...  r, err := nacos.NewDefaultNacosRegistry( nacos.WithRegistryCluster(\"Cluster123\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithRegistryGroup Nacos extension provides WithRegistryGroup to help users configure custom clusters. Defaults to “DEFAULT_GROUP” .\nFunction signature:\nfunc WithRegistryGroup(group string) RegistryOption Example:\nfunc main() { // ...  r, err := nacos.NewDefaultNacosRegistry( nacos.WithRegistryGroup(\"Group1\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewDefaultNacosRegistry NewDefaultNacosRegistry creates a default service registry using nacos. NewDefaultNacosConfig will be called to use the default client. By default, the RegionID is cn-hangzhou, the address is 127.0.0.1, the port number is 8848, and the cache will not be loaded at the beginning. Service registry configuration can be customized.\nFunction signature:\nfunc NewDefaultNacosRegistry(opts ...RegistryOption) (registry.Registry, error) Example:\nfunc main() { // ...  r, err := nacos.NewDefaultNacosRegistry() if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewNacosRegistry NewNacosRegistry uses nacos to create a service registry that can configure clients, and needs to pass in self-configured clients. Customizable service registry configuration.\nFunction signature：\nfunc NewNacosRegistry(client naming_client.INamingClient, opts ...RegistryOption) registry.Registry Example：\nfunc main() { // ...  cli, err := clients.NewNamingClient( vo.NacosClientParam{ ClientConfig: \u0026cc, ServerConfigs: sc, }, ) // ...  r := nacos.NewNacosRegistry(cli) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } Service Discovery Option Nacos extension provides option configuration in the service discovery section.\nWithRegistryCluster Nacos extension provides WithRegistryCluster to help users configure custom clusters. Defaults to “DEFAULT” .\nFunction signature:\nfunc WithRegistryCluster(cluster string) RegistryOption Example:\nfunc main() { client, err := client.NewClient() if err != nil { panic(err) } r, err := nacos.NewDefaultNacosResolver( nacos.WithRegistryCluster(\"Cluster123\"), ) if err != nil { log.Fatal(err) return } client.Use(sd.Discovery(r)) // ... } WithRegistryGroup Nacos extension provides WithRegistryGroup to help users configure custom clusters. Defaults to “DEFAULT_GROUP” .\nFunction signature:\nfunc WithRegistryGroup(group string) RegistryOption Example:\nfunc main() { client, err := client.NewClient() if err != nil { panic(err) } r, err := nacos.NewDefaultNacosResolver( nacos.WithRegistryGroup(\"Group1\"), ) if err != nil { log.Fatal(err) return } client.Use(sd.Discovery(r)) // ... } NewDefaultNacosResolver NewDefaultNacosResolver creates a default service discovery center using nacos. NewDefaultNacosConfig will be called to use the default client. By default, the RegionID is cn-hangzhou, the address is 127.0.0.1, the port number is 8848, and the cache will not be loaded at the beginning. Service registry configuration can be customized.\nFunction signature：\nfunc NewDefaultNacosResolver(opts ...ResolverOption) (discovery.Resolver, error) Example:\nfunc main() { client, err := client.NewClient() if err != nil { panic(err) } r, err := nacos.NewDefaultNacosResolver() if err != nil { log.Fatal(err) return } client.Use(sd.Discovery(r)) // ... } NewNacosResolver NewNacosResolver uses nacos to create a service discovery center with a configurable client, which needs to be passed in a self-configured client. Customizable Service Discovery Center configuration.\nFunction signature:\nfunc NewNacosResolver(cli naming_client.INamingClient, opts ...ResolverOption) discovery.Resolver Example:\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } // ...  nacosCli, err := clients.NewNamingClient( vo.NacosClientParam{ ClientConfig: \u0026cc, ServerConfigs: sc, }) if err != nil { panic(err) } r := nacos.NewNacosResolver(nacosCli) cli.Use(sd.Discovery(r)) // ... } How to use Server  Use server.WithRegistry to set up registration extensions and registration information.  import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/nacos\" ) func main() { addr := \"127.0.0.1:8888\" r, err := nacos.NewDefaultNacosRegistry() if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } Client  Use the sd.Discovery built-in middleware to support incoming custom service discovery extensions as well as load balance extensions. When using service discovery, replace Host with the service name and use config.WithSD to confirm that this request uses service registration.  import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/nacos\" ) func main() { client, err := client.NewClient() if err != nil { panic(err) } r, err := nacos.NewDefaultNacosResolver() if err != nil { log.Fatal(err) return } client.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := client.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\\n\", status, string(body)) } } Configuration The configuration of Nacos client and server can be customized, refer to the configuration of nacos-sdk-go .\nComplete Example For more, see example .\nConsul Install go get github.com/hertz-contrib/registry/consul Service Registry Option Consul extension provides option configuration in the service registry section.\nWithRegistryGroup Consul extension provides WithCheck to help users configure the AgentServiceCheck option in Consul. defaultCheck() is called by default.\nFunction signature:\nfunc WithCheck(check *api.AgentServiceCheck) Option Example:\nfunc main() { // ...  consulClient, err := consulapi.NewClient(config) // ...  check := \u0026consulapi.AgentServiceCheck{ // ...  } r := consul.NewConsulRegister(consulClient, consul.WithCheck(check)) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewConsulRegister NewConsulRegister uses consul to create a new service registry, which needs to be passed in a client, which is created with NewClient. The service registry configuration can be customized. If no configuration is passed in, set check.Timeout to 5 seconds, check.Internal to 5 seconds, and check.DeregisterCriticalServiceAfter to 1 minute.\nFunction signature:\nfunc NewConsulRegister(consulClient *api.Client, opts ...Option) registry.Registry Example:\nfunc main() { // ...  consulClient, err := consulapi.NewClient(config) // ...  r := consul.NewConsulRegister(consulClient) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } Service Discovery Option Consul extension provides option configuration in the service discovery section.\nWithRegistryGroup Consul extension provides WithCheck to help users configure the AgentServiceCheck option in Consul. defaultCheck() is called by default.\nFunction signature:\nfunc WithCheck(check *api.AgentServiceCheck) Option Example:\nfunc main() { // ...  consulClient, err := consulapi.NewClient(consulConfig) if err != nil { log.Fatal(err) return } check := \u0026consulapi.AgentServiceCheck{ // ...  } r := consul.NewConsulResolver(consulClient, consul.WithCheck(check)) cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) } NewConsulResolver NewConsulResolver uses consul to create a new service discovery center, you need to pass in the client. The client is created using NewClient. The service discovery center configuration can be customized.\nFunction signature:\nfunc NewConsulResolver(consulClient *api.Client, opts ...Option) discovery.Resolver Example:\nfunc main() { // ...  consulClient, err := consulapi.NewClient(consulConfig) if err != nil { log.Fatal(err) return } r := consul.NewConsulResolver(consulClient) cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) } How to use Server import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" consulapi \"github.com/hashicorp/consul/api\" \"github.com/hertz-contrib/registry/consul\" ) func main() { // build a consul client  config := consulapi.DefaultConfig() config.Address = \"127.0.0.1:8500\" consulClient, err := consulapi.NewClient(config) if err != nil { log.Fatal(err) return } // build a consul register with the consul client  r := consul.NewConsulRegister(consulClient) // run Hertz with the consul register  addr := \"127.0.0.1:8888\" h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong1\"}) }) h.Spin() } Client import ( \"log\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" consulapi \"github.com/hashicorp/consul/api\" \"github.com/hertz-contrib/registry/consul\" ) func main() { // build a consul client  consulConfig := consulapi.DefaultConfig() consulConfig.Address = \"127.0.0.1:8500\" consulClient, err := consulapi.NewClient(consulConfig) if err != nil { log.Fatal(err) return } // build a consul resolver with the consul client  r := consul.NewConsulResolver(consulClient) // build a hertz client with the consul resolver  cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) } Configuration The configuration of Consul client and server can be customized, refer to the configuration of consul.\nComplete Example For more, see example .\nEtcd Install go get github.com/hertz-contrib/registry/etcd Service Registry Option Etcd extension provides option configuration in the service registry section.\nWithTLSOpt Etcd extension provides WithTLSOpt to help users configure an option to authenticate via tls/ssl.\nFunction signature:\nfunc WithTLSOpt(certFile, keyFile, caFile string) Option Example:\nfunc main() { r, err := etcd.NewEtcdRegistry([]string{\"127.0.0.1:2379\"}, etcd.WithTLSOpt(certFile, keyFile, caFile), ) if err != nil { panic(err) } // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } NewEtcdRegistry NewEtcdRegistry uses etcd to create a new service registry, requires passing in the endpoint value. Customizable client configuration and passing in New creates a new client. Customizable service registry configuration.\nFunction signature:\nfunc NewEtcdRegistry(endpoints []string, opts ...Option) (registry.Registry, error) Example:\nfunc main() { r, err := etcd.NewEtcdRegistry([]string{\"127.0.0.1:2379\"}) if err != nil { panic(err) } // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } Service Discovery Option Etcd extension provides option configuration in the service discovery section.\nWithTLSOpt Etcd extension provides WithTLSOpt to help users configure an option to authenticate via tls/ssl.\nFunction signature:\nfunc WithTLSOpt(certFile, keyFile, caFile string) Option Example:\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := etcd.NewEtcdRegistry([]string{\"127.0.0.1:2379\"}, etcd.WithTLSOpt(certFile, keyFile, caFile), ) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } NewEtcdResolver NewEtcdResolver uses etcd to create a new service discovery center, needs to pass in the endpoint value. You can customize the client configuration and pass New to create a new client. Customize the service discovery center configuration.\nFunction signature:\nfunc NewEtcdResolver(endpoints []string, opts ...Option) (discovery.Resolver, error) Example:\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := etcd.NewEtcdResolver([]string{\"127.0.0.1:2379\"}) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } How to use Server import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/etcd\" ) func main() { r, err := etcd.NewEtcdRegistry([]string{\"127.0.0.1:2379\"}) if err != nil { panic(err) } addr := \"127.0.0.1:8888\" h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) h.GET(\"/ping\", func(_ context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong2\"}) }) h.Spin() } Client import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/etcd\" ) func main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := etcd.NewEtcdResolver([]string{\"127.0.0.1:2379\"}) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"HERTZ: code=%d,body=%s\", status, string(body)) } } Configuration The configuration of Etcd client and server can be customized, refer to the configuration of etcd-client.\nComplete Example For more, see example .\nEureka Install go get github.com/hertz-contrib/eureka Service Registry NewEurekaRegistry NewEurekaRegistry uses eureka to create a new service registry, you need to pass the service Url into NewConn through a string slice, and also pass in the heartbeat interval.\nFunction signature:\nfunc NewEurekaRegistry(servers []string, heatBeatInterval time.Duration) *eurekaRegistry Example:\nfunc main() { // ...  r := eureka.NewEurekaRegistry([]string{\"http://127.0.0.1:8761/eureka\"}, 40*time.Second) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.discovery.eureka\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) //... } NewEurekaRegistryFromConfig NewEurekaRegistryFromConfig uses eureka to create a new service registry, you need to pass in the configuration and call NewConnFromConfig , and also need to pass in the heartbeat interval.\nFunction signature:\nfunc NewEurekaRegistryFromConfig(config fargo.Config, heatBeatInterval time.Duration) *eurekaRegistry Example:\nfunc main() { // ...  config := fargo.Config{ // ...  } r := eureka.NewEurekaRegistryFromConfig(config, 40*time.Second) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.discovery.eureka\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) //... } NewEurekaRegistryFromConn NewEurekaRegistryFromConn uses eureka to create a new service registry, you need to pass in conn directly, and also need to pass in the heartbeat interval.\nFunction signature:\nfunc NewEurekaRegistryFromConn(conn fargo.EurekaConnection, heatBeatInterval time.Duration) *eurekaRegistry Example:\nfunc main() { // ...  conn := fargo.EurekaConnection{ // ...  } r := eureka.NewEurekaRegistryFromConn(conn, 40*time.Second) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.discovery.eureka\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) //... } Service Discovery NewEurekaResolver NewEurekaResolver uses eureka to create a new service discovery center, you need to pass the service Url through a string slice to NewConn.\nFunction signature:\nfunc NewEurekaResolver(servers []string) *eurekaResolver Example:\nfunc main() { cli, err := client.NewClient() if err != nil { hlog.Fatal(err) return } r := eureka.NewEurekaResolver([]string{\"http://127.0.0.1:8761/eureka\"}) cli.Use(sd.Discovery(r)) // ... } NewEurekaResolverFromConfig NewEurekaResolverFromConfig uses eureka to create a new service discovery center, requires passing in the configuration and calling NewConnFromConfig.\nFunction signature:\nfunc NewEurekaResolverFromConfig(config fargo.Config) *eurekaResolver Example:\nfunc main() { // ...  config := fargo.Config{ // ...  } cli, err := client.NewClient() if err != nil { hlog.Fatal(err) return } r := eureka.NewEurekaResolverFromConfig(config) cli.Use(sd.Discovery(r)) // ... } NewEurekaResolverFromConn NewEurekaResolverFromConn uses eureka to create a new service discovery center, which needs to be passed directly to conn.\nFunction signature:\nfunc NewEurekaResolverFromConn(conn fargo.EurekaConnection) *eurekaResolver Example:\nfunc main() { // ...  conn := fargo.EurekaConnection{ // ...  } cli, err := client.NewClient() if err != nil { hlog.Fatal(err) return } r := eureka.NewEurekaResolverFromConn(conn) cli.Use(sd.Discovery(r)) // ... } How to use Server import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/eureka\" ) func main() { addr := \"127.0.0.1:8888\" r := eureka.NewEurekaRegistry([]string{\"http://127.0.0.1:8761/eureka\"}, 40*time.Second) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.discovery.eureka\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong2\"}) }) h.Spin() } Client import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/eureka\" ) func main() { cli, err := client.NewClient() if err != nil { hlog.Fatal(err) return } r := eureka.NewEurekaResolver([]string{\"http://127.0.0.1:8761/eureka\"}) cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.discovery.eureka/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\", status, string(body)) } } Configuration This project uses fargo as eureka client. You should refer to fargo documentation for advanced configuration.\nComplete Example For more, see example .\nPolaris Install go get github.com/hertz-contrib/registry/polaris Service Registry NewPolarisRegistry NewPolarisRegistry creates a new service registry using polaris, passing in a configuration file and calling GetPolarisConfig , using the default configuration if not passed in.\nFunction signature:\nfunc NewPolarisRegistry(configFile ...string) (Registry, error) Example:\nfunc main() { r, err := polaris.NewPolarisRegistry(confPath) if err != nil { log.Fatal(err) } Info := \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", \"127.0.0.1:8888\"), Tags: map[string]string{ \"namespace\": Namespace, }, } h := server.Default(server.WithRegistry(r, Info), server.WithExitWaitTime(10*time.Second)) // ... } Service Discovery NewPolarisResolver NewPolarisResolver uses polaris to create a new service discovery center, passing in a configuration file and calling GetPolarisConfig , using the default configuration if not passed in.\nFunction signature:\nfunc NewPolarisResolver(configFile ...string) (Resolver, error) Example:\nfunc main() { r, err := polaris.NewPolarisResolver(confPath) if err != nil { log.Fatal(err) } client, err := hclient.NewClient() client.Use(sd.Discovery(r)) //... } How to use Server import ( \"context\" \"log\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/polaris\" ) const ( confPath = \"polaris.yaml\" Namespace = \"Polaris\" // At present,polaris server tag is v1.4.0，can't support auto create namespace,  // If you want to use a namespace other than default,Polaris ,before you register an instance,  // you should create the namespace at polaris console first. ) func main() { r, err := polaris.NewPolarisRegistry(confPath) if err != nil { log.Fatal(err) } Info := \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", \"127.0.0.1:8888\"), Tags: map[string]string{ \"namespace\": Namespace, }, } h := server.Default(server.WithRegistry(r, Info), server.WithExitWaitTime(10*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"Hello,Hertz!\") }) h.Spin() } Client import ( \"context\" \"log\" hclient \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/polaris\" ) const ( confPath = \"polaris.yaml\" Namespace = \"Polaris\" // At present,polaris server tag is v1.4.0，can't support auto create namespace,  // if you want to use a namespace other than default,Polaris ,before you register an instance,  // you should create the namespace at polaris console first. ) func main() { r, err := polaris.NewPolarisResolver(confPath) if err != nil { log.Fatal(err) } client, err := hclient.NewClient() client.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { // config.WithTag sets the namespace tag for service discovery  status, body, err := client.Get(context.TODO(), nil, \"http://hertz.test.demo/hello\", config.WithSD(true), config.WithTag(\"namespace\", Namespace)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\\n\", status, body) } } Configuration The configuration of Polaris client and server can be customized, refer to the configuration of polaris-go.\nComplete Example For more, see example .\nServicecomb Install go get github.com/hertz-contrib/registry/servicecomb Service Registry Option Servicecomb extension provides option configuration in the service registry section.\nWithAppId Servicecomb extension provides WithAppId to help users configure the AppId of Servicecomb. Defaults to “DEFAULT” .\nFunction signature:\nfunc WithAppId(appId string) RegistryOption Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithAppId(\"appID\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithRegistryVersionRule Servicecomb extension provides WithRegistryVersionRule to help users configure the version requirements of Servicecomb. Defaults to 1.0.0 .\nFunction signature:\nfunc WithRegistryVersionRule(versionRule string) RegistryOption Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithRegistryVersionRule(\"1.1.0\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithRegistryHostName Servicecomb extension provides WithRegistryHostName to help users configure Servicecomb’s hostname. Defaults to “DEFAULT” .\nFunction signature:\nfunc WithRegistryHostName(hostName string) RegistryOption Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithRegistryHostName(\"hostName\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithRegistryHeartbeatInterval Servicecomb extension provides WithRegistryHeartbeatInterval to help users configure the interval for sending heartbeat packets. Default is 5.\nFunction signature:\nfunc WithRegistryHeartbeatInterval(second int32) RegistryOption Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithRegistryHeartbeatInterval(10), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewDefaultSCRegistry NewDefaultSCRegistry uses service-comb to create a default service registry, which needs to pass in the endpoint value. The service registry configuration can be customized.\nFunction signature:\nfunc NewDefaultSCRegistry(endPoints []string, opts ...RegistryOption) (registry.Registry, error) Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewSCRegistry NewSCRegistry uses service-comb to create a new service registry. It needs to pass in a custom client. Customizable service registry configuration.\nFunction signature:\nfunc NewSCRegistry(client *sc.Client, opts ...RegistryOption) registry.Registry Example:\nfunc main() { client := \u0026sc.Client{ // ...  } // ...  r, err := servicecomb.NewSCRegistry(config) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } Service Discovery Option Servicecomb extension provides option configuration in the service discovery section.\nWithAppId Servicecomb extension provides WithAppId to help users configure the AppId of Servicecomb. Defaults to “DEFAULT” .\nFunction signature:\nfunc WithResolverAppId(appId string) ResolverOption Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithAppId(\"appID\"), ) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } WithResolverVersionRule Servicecomb extension provides WithResolverVersionRule to help users configure Servicecomb’s version requirements. Defaults to latest .\nFunction signature:\nfunc WithResolverVersionRule(versionRule string) ResolverOption Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithResolverVersionRule(\"1.0.0\"), ) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } WithResolverConsumerId Servicecomb extension provides WithResolverConsumerId to help users configure Servicecomb’s ConsumerId . Default is empty .\nFunction signature:\nfunc WithResolverConsumerId(consumerId string) ResolverOption Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithResolverConsumerId(\"1\"), ) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } NewDefaultSCResolver NewDefaultSCResolver uses service-comb to create a default service discovery center, which needs to pass in the endpoint value. Service discovery center configuration can be customized.\nFunction signature:\nfunc NewDefaultSCResolver(endPoints []string, opts ...ResolverOption) (discovery.Resolver, error) Example:\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCResolver([]string{scAddr}) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } NewSCResolver NewSCReslover uses service-comb to create a new service discovery center. It needs to pass in a custom client. The configuration of the service discovery center can be customized.\nFunction signature:\nfunc NewSCResolver(cli *sc.Client, opts ...ResolverOption) discovery.Resolver Example:\nfunc main() { client := \u0026sc.Client{ // ...  } // ...  r, err := servicecomb.NewSCResolver(client) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } How to use Server import ( \"context\" \"log\" \"sync\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/servicecomb\" ) func main() { const scAddr = \"127.0.0.1:30100\" const addr = \"127.0.0.1:8701\" r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong1\"}) }) h.Spin() } Client import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/servicecomb\" ) func main() { const scAddr = \"127.0.0.1:30100\" // build a servicecomb resolver  r, err := servicecomb.NewDefaultSCResolver([]string{scAddr}) if err != nil { panic(err) } // build a hertz client with the servicecomb resolver  cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.servicecomb.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\", status, string(body)) } } Configuration The configuration of Servicecomb client and server can be customized, refer to the configuration of go-chassis/sc-client.\nComplete Example For more, see example .\nZookeeper Install go get github.com/hertz-contrib/registry/zookeeper Service Registry NewZookeeperRegistry NewZookeeperRegistry uses zookeeper to create a service registry. You need to pass the service to Connect through a string slice together with the session timeout.\nFunction signature:\nfunc NewZookeeperRegistry(servers []string, sessionTimeout time.Duration) (registry.Registry, error) Example:\nfunc main() { // ...  r, err := zookeeper.NewZookeeperRegistry([]string{\"127.0.0.1:2181\"}, 40*time.Second) if err != nil { panic(err) } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } NewZookeeperRegistryWithAuth NewZookeeperRegistryWithAuth uses zookeeper to create a service registry. You need to pass the service into Connect through a string slice and session timeout time. In addition, you need to pass in the user and password to call AddAuth, the user and password Can not be empty.\nFunction signature:\nfunc NewZookeeperRegistryWithAuth(servers []string, sessionTimeout time.Duration, user, password string) Example:\nfunc main() { // ...  r, err := zookeeper.NewZookeeperRegistryWithAuth([]string{\"127.0.0.1:2181\"}, 20*time.Second, \"hertzuser\", \"hertzpass\") if err != nil { panic(err) } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } Service Discovery NewZookeeperResolver NewZookeeperResolver uses zookeeper to create a service discovery center, which needs to pass a string slice and session timeout to Connect.\nFunction signature:\nfunc NewZookeeperResolver(servers []string, sessionTimeout time.Duration) (discovery.Resolver, error) Example:\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := zookeeper.NewZookeeperResolver([]string{\"127.0.0.1:2181\"}, 40*time.Second) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } NewZookeeperResolverWithAuth NewZookeeperResolverWithAuth uses zookeeper to create a service discovery center. You need to pass the service into Connect through a string slice and session timeout. In addition, you need to pass in the user and password to call AddAuth, the user and password Can not be empty.\nFunction signature:\nfunc NewZookeeperResolverWithAuth(servers []string, sessionTimeout time.Duration, user, password string) Example:\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := zookeeper.NewZookeeperResolverWithAuth([]string{\"127.0.0.1:2181\"}, 40*time.Second, \"hertzuser\", \"hertzpass\") if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } How to use Server import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/zookeeper\" ) func main() { addr := \"127.0.0.1:8888\" r, err := zookeeper.NewZookeeperRegistry([]string{\"127.0.0.1:2181\"}, 40*time.Second) if err != nil { panic(err) } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong2\"}) }) h.Spin() } Client import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/zookeeper\" ) func main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := zookeeper.NewZookeeperResolver([]string{\"127.0.0.1:2181\"}, 40*time.Second) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\", status, string(body)) } } Configuration The configuration of Zookeeper client and server can be customized, refer to the configuration of go-zookeeper/zk.\nComplete Example For more, see example .\nRedis Install go get github.com/hertz-contrib/registry/redis Service Registry Option The Redis extension provides option configuration in the service registry section.\nWithPassword The Redis extension provides WithPassword to configure the redis password, which must match the password specified in the server configuration options.\nFunction signature:\nfunc WithPassword(password string) Option Sample code:\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithPassword(\"123456\")) //...  h := server. Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils. NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) //... } WithDB The Redis extension provides WithDB to configure the database to choose after connecting to the server.\nFunction signature:\nfunc WithDB(db int) Option Sample code:\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithDB(1)) //...  h := server. Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils. NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) //... } WithTLSConfig The Redis extension provides WithTLSConfig configuration items for configuring TLS.\nFunction signature:\nfunc WithTLSConfig(t *tls.Config) Option Sample code:\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithTLSConfig(\u0026tls.Config{ //...  })) //...  h := server. Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils. NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) //... } WithDialer The Redis extension provides WithDialer to configure Dialer, Dialer will create a new network connection and take precedence over Network and Addr options.\nFunction signature:\nfunc WithDialer(dialer func(ctx context.Context, network, addr string) (net.Conn, error)) Option Sample code:\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithDialer( //...  )) //...  h := server. Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils. NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) //... } WithReadTimeout The Redis extension provides WithReadTimeout to configure the read socket timeout time, the default is 3 seconds.\nFunction signature:\nfunc WithReadTimeout(t time.Duration) Option Sample code:\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithReadTimeout(5*time.Second)) //...  h := server. Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils. NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) //... } WithWriteTimeout The Redis extension provides WithWriteTimeout to configure the write socket timeout time, the default is equivalent to ReadTimeout.\nFunction signature:\nfunc WithWriteTimeout(t time.Duration) Option Sample code:\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithWriteTimeout(5*time.Second)) // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewRedisRegistry NewRedisRegistry uses redis to create a new service registry and needs to pass in the target address. You can customize the client configuration and pass in NewClient to create a new client.\nFunction signature:\nfunc NewRedisRegistry(addr string, opts...Option) registry.Registry Sample code:\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\") //...  h := server. Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils. NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) //... } Service Discovery Option Redis extension provides option configuration in the service discovery section.\nWithPassword The Redis extension provides WithPassword to configure the redis password, which must match the password specified in the server configuration options.\nFunction signature:\nfunc WithPassword(password string) Option Sample code:\nfunc main() { cli, err := client. NewClient() //...  r := redis.NewRedisResolver(\"127.0.0.1:6379\", redis.WithPassword(\"123456\")) cli. Use(sd. Discovery(r)) //... } WithDB The Redis extension provides WithDB to configure the database to choose after connecting to the server.\nFunction signature:\nfunc WithDB(db int) Option Sample code:\nfunc main() { cli, err := client. NewClient() //...  r := redis.NewRedisResolver(\"127.0.0.1:6379\", redis.WithDB(1)) cli. Use(sd. Discovery(r)) //... } WithTLSConfig The Redis extension provides WithTLSConfig configuration items for configuring TLS.\nFunction signature:\nfunc WithTLSConfig(t *tls.Config) Option Sample code:\nfunc main() { cli, err := client. NewClient() //...  r := redis.NewRedisResolver(\"127.0.0.1:6379\", redis.WithTLSConfig(\u0026tls.Config{ //...  })) cli. Use(sd. Discovery(r)) //... } WithDialer The Redis extension provides WithDialer to configure Dialer, Dialer will create a new network connection and take precedence over Network and Addr options.\nFunction signature:\nfunc WithDialer(dialer func(ctx context.Context, network, addr string) (net.Conn, error)) Option Sample code:\nfunc main() { cli, err := client. NewClient() //...  r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithDialer( //...  )) cli. Use(sd. Discovery(r)) //... } WithReadTimeout The Redis extension provides WithReadTimeout to configure the read socket timeout time, the default is 3 seconds.\nFunction signature:\nfunc WithReadTimeout(t time.Duration) Option Sample code:\nfunc main() { cli, err := client. NewClient() //...  r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithReadTimeout(5*time.Second)) //...  )) cli. Use(sd. Discovery(r)) //... } WithWriteTimeout The Redis extension provides WithWriteTimeout to configure the write socket timeout time, the default is equivalent to ReadTimeout.\nFunction signature:\nfunc WithWriteTimeout(t time.Duration) Option Sample code:\nfunc main() { cli, err := client. NewClient() //...  r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithWriteTimeout(5*time.Second)) //...  )) cli. Use(sd. Discovery(r)) //... } NewRedisResolver NewRedisResolver uses redis to create a new service discovery center, and needs to pass in the target address. You can customize the client configuration and pass in NewClient to create a new client.\nFunction signature:\nfunc NewRedisResolver(addr string, opts ...Option) discovery.Resolver Sample code:\nfunc main() { cli, err := client. NewClient() //...  r := redis.NewRedisResolver(\"127.0.0.1:6379\") cli. Use(sd. Discovery(r)) //... } How to use Server package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/redis\" ) func main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\") addr := \"127.0.0.1:8888\" h := server. Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils. NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) h.GET(\"/ping\", func(_ context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h. Spin() } Client package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/redis\" ) func main() { cli, err := client. NewClient() if err != nil { panic(err) } r := redis.NewRedisResolver(\"127.0.0.1:6379\") cli. Use(sd. Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) if err != nil { hlog. Fatal(err) } hlog.Infof(\"HERTZ: code=%d, body=%s\", status, string(body)) } } Configuration You can customize the configuration of redis client and server, refer to go-redis configuration.\nComplete Example For more, see example.\n","categories":"","description":"","excerpt":"The service discovery extensions currently supported in the open …","ref":"/docs/hertz/tutorials/service-governance/service_discovery/","tags":"","title":"Service Registration and Discovery"},{"body":"目前在 Hertz 的开源版本支持的服务发现拓展都存放在 registry 中，欢迎大家参与项目贡献与维护。\n到现在为止，支持的服务发现拓展有\n nacos consul etcd eureka polaris servicecomb zookeeper redis  配置 使用服务发现时会提供一些可选配置给用户。\n   配置 描述     WithSD 设置 isSD 为 true ，使用服务发现必选。   WithTag 为 requestOptions 设置 tag 。   WithCustomizedAddrs 自定义目标实例地址。   WithLoadBalanceOptions 配置负载均衡选项。    WithSD requestOptions 提供 WithSD 配置项，传入参数为 true 时将会设置 isSD 为 true。使用服务发现请求时必须使用 WithSD 配置项。\n示例代码：\nstatus, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) WithTag requestOptions 提供 WithTag 配置项，使用此配置会为 requestOptions 设置 tag。\n示例代码：\nstatus, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithTag(\"foo\", \"var\")) WithCustomizedAddrs 此配置项指定服务发现时的目标实例地址。它将会覆盖来自 Resolver 的结果。Resolver 是服务发现中心，用于服务发现。\n示例代码：\ncli.Use(sd.Discovery(r, sd.WithCustomizedAddrs(\"127.0.0.1:8088\"))) WithLoadBalanceOptions 此配置项可为客户端配置负载均衡算法和负载均衡参数。\n示例代码：\ncli.Use(sd.Discovery(r, sd.WithLoadBalanceOptions(loadbalance.NewWeightedBalancer(), loadbalance.Options{ RefreshInterval: 5 * time.Second, ExpireInterval: 15 * time.Second, }))) Nacos 安装 go get github.com/hertz-contrib/registry/nacos 服务注册 Option Nacos 拓展在服务注册部分中提供了 option 配置。\nWithRegistryCluster Nacos 扩展提供了 WithRegistryCluster 用于帮助用户配置自定义的集群。默认为 “DEFAULT” 。\n函数签名：\nfunc WithRegistryCluster(cluster string) RegistryOption 示例代码：\nfunc main() { // ...  r, err := nacos.NewDefaultNacosRegistry( nacos.WithRegistryCluster(\"Cluster123\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithRegistryGroup Nacos 扩展提供了 WithRegistryGroup 用于帮助用户配置自定义的集群。默认为 “DEFAULT_GROUP” 。\n函数签名：\nfunc WithRegistryGroup(group string) RegistryOption 示例代码：\nfunc main() { // ...  r, err := nacos.NewDefaultNacosRegistry( nacos.WithRegistryGroup(\"Group1\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewDefaultNacosRegistry NewDefaultNacosRegistry 使用 nacos 创建一个默认的服务注册中心。会调用 NewDefaultNacosConfig 使用默认的客户端，默认设置 RegionID 为 cn-hangzhou、地址为 127.0.0.1、端口号为8848，且不会在开始时加载缓存。可自定义服务注册中心配置。\n函数签名：\nfunc NewDefaultNacosRegistry(opts ...RegistryOption) (registry.Registry, error) 示例代码：\nfunc main() { // ...  r, err := nacos.NewDefaultNacosRegistry() if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewNacosRegistry NewNacosRegistry使用 nacos 创建一个可配置客户端的服务注册中心，需要传入自行配置的客户端。可自定义服务注册中心配置。\n函数签名：\nfunc NewNacosRegistry(client naming_client.INamingClient, opts ...RegistryOption) registry.Registry 示例代码：\nfunc main() { // ...  cli, err := clients.NewNamingClient( vo.NacosClientParam{ ClientConfig: \u0026cc, ServerConfigs: sc, }, ) // ...  r := nacos.NewNacosRegistry(cli) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } 服务发现 Option Nacos 拓展在服务发现部分中提供了 option 配置。\nWithRegistryCluster Nacos 扩展提供了 WithRegistryCluster 用于帮助用户配置自定义的集群。默认为 “DEFAULT” 。\n函数签名：\nfunc WithRegistryCluster(cluster string) RegistryOption 示例代码：\nfunc main() { client, err := client.NewClient() if err != nil { panic(err) } r, err := nacos.NewDefaultNacosResolver( nacos.WithRegistryCluster(\"Cluster123\"), ) if err != nil { log.Fatal(err) return } client.Use(sd.Discovery(r)) // ... } WithRegistryGroup Nacos 扩展提供了 WithRegistryGroup 用于帮助用户配置自定义的集群。默认为 “DEFAULT_GROUP” 。\n函数签名：\nfunc WithRegistryGroup(group string) RegistryOption 示例代码：\nfunc main() { client, err := client.NewClient() if err != nil { panic(err) } r, err := nacos.NewDefaultNacosResolver( nacos.WithRegistryGroup(\"Group1\"), ) if err != nil { log.Fatal(err) return } client.Use(sd.Discovery(r)) // ... } NewDefaultNacosResolver NewDefaultNacosResolver 使用 nacos 创建一个默认的服务发现中心。会调用 NewDefaultNacosConfig 使用默认的客户端，默认设置 RegionID 为 cn-hangzhou、地址为 127.0.0.1、端口号为8848，且不会在开始时加载缓存。可自定义服务注册中心配置。\n函数签名：\nfunc NewDefaultNacosResolver(opts ...ResolverOption) (discovery.Resolver, error) 示例代码：\nfunc main() { client, err := client.NewClient() if err != nil { panic(err) } r, err := nacos.NewDefaultNacosResolver() if err != nil { log.Fatal(err) return } client.Use(sd.Discovery(r)) // ... } NewNacosResolver NewNacosResolver 使用 nacos 创建一个可配置客户端的服务发现中心，需要传入自行配置的客户端。可自定义服务发现中心配置。\n函数签名：\nfunc NewNacosResolver(cli naming_client.INamingClient, opts ...ResolverOption) discovery.Resolver 示例代码：\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } // ...  nacosCli, err := clients.NewNamingClient( vo.NacosClientParam{ ClientConfig: \u0026cc, ServerConfigs: sc, }) if err != nil { panic(err) } r := nacos.NewNacosResolver(nacosCli) cli.Use(sd.Discovery(r)) // ... } 使用示例 服务端  使用 server.WithRegistry 设置注册扩展以及注册信息。  import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/nacos\" ) func main() { addr := \"127.0.0.1:8888\" r, err := nacos.NewDefaultNacosRegistry() if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 客户端  使用内置的 sd.Discovery 中间件，支持传入自定义的服务发现扩展以及负载均衡扩展。 使用服务发现时需要将 Host 替换为服务名，并使用 config.WithSD 确定本次请求使用服务注册。  import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/nacos\" ) func main() { client, err := client.NewClient() if err != nil { panic(err) } r, err := nacos.NewDefaultNacosResolver() if err != nil { log.Fatal(err) return } client.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := client.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\\n\", status, string(body)) } } 配置 可自定义 Nacos 客户端以及服务端的配置，参考 nacos-sdk-go 配置。\n完整示例 完整用法示例详见 example 。\nConsul 安装 go get github.com/hertz-contrib/registry/consul 服务注册 Option Consul 拓展在服务注册部分中提供了 option 配置。\nWithRegistryGroup Consul 扩展提供了 WithCheck 用于帮助用户配置 Consul 中的 AgentServiceCheck 选项。默认调用 defaultCheck() 。\n函数签名：\nfunc WithCheck(check *api.AgentServiceCheck) Option 示例代码：\nfunc main() { // ...  consulClient, err := consulapi.NewClient(config) // ...  check := \u0026consulapi.AgentServiceCheck{ // ...  } r := consul.NewConsulRegister(consulClient, consul.WithCheck(check)) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewConsulRegister NewConsulRegister 使用 consul 创建一个新的服务注册中心，需要传入客户端，其中客户端使用 NewClient 创建。可自定义服务注册中心配置，若不传入配置则设置 check.Timeout 为5秒，check.Internal 为5秒，check.DeregisterCriticalServiceAfter 为 1分钟。\n函数签名：\nfunc NewConsulRegister(consulClient *api.Client, opts ...Option) registry.Registry 示例代码：\nfunc main() { // ...  consulClient, err := consulapi.NewClient(config) // ...  r := consul.NewConsulRegister(consulClient) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } 服务发现 Option Consul 拓展在服务发现部分中提供了 option 配置。\nWithRegistryGroup Consul 扩展提供了 WithCheck 用于帮助用户配置 Consul 中的 AgentServiceCheck 选项。默认调用 defaultCheck() 。\n函数签名：\nfunc WithCheck(check *api.AgentServiceCheck) Option 示例代码：\nfunc main() { // ...  consulClient, err := consulapi.NewClient(consulConfig) if err != nil { log.Fatal(err) return } check := \u0026consulapi.AgentServiceCheck{ // ...  } r := consul.NewConsulResolver(consulClient, consul.WithCheck(check)) cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) } NewConsulResolver NewConsulResolver 使用 consul 创建一个新的服务发现中心，需要传入客户端，其中客户端使用 NewClient 创建。可自定义服务发现中心配置。\n函数签名：\nfunc NewConsulResolver(consulClient *api.Client, opts ...Option) discovery.Resolver 示例代码：\nfunc main() { // ...  consulClient, err := consulapi.NewClient(consulConfig) if err != nil { log.Fatal(err) return } r := consul.NewConsulResolver(consulClient) cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) } 使用示例 服务端 import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" consulapi \"github.com/hashicorp/consul/api\" \"github.com/hertz-contrib/registry/consul\" ) func main() { // build a consul client  config := consulapi.DefaultConfig() config.Address = \"127.0.0.1:8500\" consulClient, err := consulapi.NewClient(config) if err != nil { log.Fatal(err) return } // build a consul register with the consul client  r := consul.NewConsulRegister(consulClient) // run Hertz with the consul register  addr := \"127.0.0.1:8888\" h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong1\"}) }) h.Spin() } 客户端 import ( \"log\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" consulapi \"github.com/hashicorp/consul/api\" \"github.com/hertz-contrib/registry/consul\" ) func main() { // build a consul client  consulConfig := consulapi.DefaultConfig() consulConfig.Address = \"127.0.0.1:8500\" consulClient, err := consulapi.NewClient(consulConfig) if err != nil { log.Fatal(err) return } // build a consul resolver with the consul client  r := consul.NewConsulResolver(consulClient) // build a hertz client with the consul resolver  cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) } 配置 可自定义 Nacos 客户端以及服务端的配置，参考 consul 配置。\n完整实例 完整用法示例详见 example 。\nEtcd 安装 go get github.com/hertz-contrib/registry/etcd 服务注册 Option Etcd 拓展在服务注册部分中提供了 option 配置。\nWithTLSOpt Etcd 扩展提供了 WithTLSOpt 用于帮助用户配置一个通过 tls/ssl 进行身份验证的选项。\n函数签名：\nfunc WithTLSOpt(certFile, keyFile, caFile string) Option 示例代码：\nfunc main() { r, err := etcd.NewEtcdRegistry([]string{\"127.0.0.1:2379\"}, etcd.WithTLSOpt(certFile, keyFile, caFile), ) if err != nil { panic(err) } // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } NewEtcdRegistry NewEtcdRegistry 使用 etcd 创建一个新的服务注册中心，需要传入端点值。可自定义客户端配置并传入 New 创建一个新的客户端。可自定义服务注册中心配置。\n函数签名：\nfunc NewEtcdRegistry(endpoints []string, opts ...Option) (registry.Registry, error) 示例代码：\nfunc main() { r, err := etcd.NewEtcdRegistry([]string{\"127.0.0.1:2379\"}) if err != nil { panic(err) } // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } 服务发现 Option Etcd 拓展在服务发现部分中提供了 option 配置。\nWithTLSOpt Etcd 扩展提供了 WithTLSOpt 用于帮助用户配置一个通过 tls/ssl 进行身份验证的选项。\n函数签名：\nfunc WithTLSOpt(certFile, keyFile, caFile string) Option 示例代码：\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := etcd.NewEtcdRegistry([]string{\"127.0.0.1:2379\"}, etcd.WithTLSOpt(certFile, keyFile, caFile), ) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } NewEtcdResolver NewEtcdResolver 使用 etcd 创建一个新的服务发现中心，需要传入端点值。可自定义客户端配置并传入 New 创建一个新的客户端。可自定义服务发现中心配置。\n函数签名：\nfunc NewEtcdResolver(endpoints []string, opts ...Option) (discovery.Resolver, error) 示例代码：\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := etcd.NewEtcdResolver([]string{\"127.0.0.1:2379\"}) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } 使用示例 服务端 import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/etcd\" ) func main() { r, err := etcd.NewEtcdRegistry([]string{\"127.0.0.1:2379\"}) if err != nil { panic(err) } addr := \"127.0.0.1:8888\" h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) h.GET(\"/ping\", func(_ context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong2\"}) }) h.Spin() } 客户端 import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/etcd\" ) func main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := etcd.NewEtcdResolver([]string{\"127.0.0.1:2379\"}) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"HERTZ: code=%d,body=%s\", status, string(body)) } } 配置 可自定义 Etcd 客户端以及服务端的配置，参考 etcd-client 配置。\n完整示例 完整用法示例详见 example 。\nEureka 安装 go get github.com/hertz-contrib/eureka 服务注册 NewEurekaRegistry NewEurekaRegistry 使用 eureka 创建一个新的服务注册中心，需要将服务 Url 通过一个字符串切片传入 NewConn ，并同时传入心跳间隔时长。\n函数签名：\nfunc NewEurekaRegistry(servers []string, heatBeatInterval time.Duration) *eurekaRegistry 示例代码：\nfunc main() { // ...  r := eureka.NewEurekaRegistry([]string{\"http://127.0.0.1:8761/eureka\"}, 40*time.Second) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.discovery.eureka\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) //... } NewEurekaRegistryFromConfig NewEurekaRegistryFromConfig 使用 eureka 创建一个新的服务注册中心，需要传入配置并调用 NewConnFromConfig ，也需要传入心跳间隔时长。\n函数签名：\nfunc NewEurekaRegistryFromConfig(config fargo.Config, heatBeatInterval time.Duration) *eurekaRegistry 示例代码：\nfunc main() { // ...  config := fargo.Config{ // ...  } r := eureka.NewEurekaRegistryFromConfig(config, 40*time.Second) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.discovery.eureka\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) //... } NewEurekaRegistryFromConn NewEurekaRegistryFromConn 使用 eureka 创建一个新的服务注册中心，需要直接传入 conn ，也需要传入心跳间隔时长。\n函数签名：\nfunc NewEurekaRegistryFromConn(conn fargo.EurekaConnection, heatBeatInterval time.Duration) *eurekaRegistry 示例代码：\nfunc main() { // ...  conn := fargo.EurekaConnection{ // ...  } r := eureka.NewEurekaRegistryFromConn(conn, 40*time.Second) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.discovery.eureka\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) //... } 服务发现 NewEurekaResolver NewEurekaResolver 使用 eureka 创建一个新的服务发现中心，需要将服务 Url 通过一个字符串切片传入 NewConn 。\n函数签名：\nfunc NewEurekaResolver(servers []string) *eurekaResolver 示例代码：\nfunc main() { cli, err := client.NewClient() if err != nil { hlog.Fatal(err) return } r := eureka.NewEurekaResolver([]string{\"http://127.0.0.1:8761/eureka\"}) cli.Use(sd.Discovery(r)) // ... } NewEurekaResolverFromConfig NewEurekaResolverFromConfig 使用 eureka 创建一个新的服务发现中心，需要传入配置并调用 NewConnFromConfig 。\n函数签名：\nfunc NewEurekaResolverFromConfig(config fargo.Config) *eurekaResolver 示例代码：\nfunc main() { // ...  config := fargo.Config{ // ...  } cli, err := client.NewClient() if err != nil { hlog.Fatal(err) return } r := eureka.NewEurekaResolverFromConfig(config) cli.Use(sd.Discovery(r)) // ... } NewEurekaResolverFromConn NewEurekaResolverFromConn 使用 eureka 创建一个新的服务发现中心，需要直接传入 conn 。\n函数签名：\nfunc NewEurekaResolverFromConn(conn fargo.EurekaConnection) *eurekaResolver 示例代码：\nfunc main() { // ...  conn := fargo.EurekaConnection{ // ...  } cli, err := client.NewClient() if err != nil { hlog.Fatal(err) return } r := eureka.NewEurekaResolverFromConn(conn) cli.Use(sd.Discovery(r)) // ... } 使用示例 服务端 import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/eureka\" ) func main() { addr := \"127.0.0.1:8888\" r := eureka.NewEurekaRegistry([]string{\"http://127.0.0.1:8761/eureka\"}, 40*time.Second) h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.discovery.eureka\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong2\"}) }) h.Spin() } 客户端 import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/eureka\" ) func main() { cli, err := client.NewClient() if err != nil { hlog.Fatal(err) return } r := eureka.NewEurekaResolver([]string{\"http://127.0.0.1:8761/eureka\"}) cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.discovery.eureka/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\", status, string(body)) } } 配置 本项目使用 fargo 作为 eureka 客户端。 您应该参考 fargo 文档以了解高级配置。\n完整示例 完整用法示例详见 example 。\nPolaris 安装 go get github.com/hertz-contrib/registry/polaris 服务注册 NewPolarisRegistry NewPolarisRegistry 使用 polaris 创建一个新的服务注册中心，可传入配置文件并调用 GetPolarisConfig ，若不传入则使用默认配置。\n函数签名：\nfunc NewPolarisRegistry(configFile ...string) (Registry, error) 示例代码：\nfunc main() { r, err := polaris.NewPolarisRegistry(confPath) if err != nil { log.Fatal(err) } Info := \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", \"127.0.0.1:8888\"), Tags: map[string]string{ \"namespace\": Namespace, }, } h := server.Default(server.WithRegistry(r, Info), server.WithExitWaitTime(10*time.Second)) // ... } 服务发现 NewPolarisResolver NewPolarisResolver 使用 polaris 创建一个新的服务发现中心，可传入配置文件并调用 GetPolarisConfig ，若不传入则使用默认配置。\n函数签名：\nfunc NewPolarisResolver(configFile ...string) (Resolver, error) 示例代码：\nfunc main() { r, err := polaris.NewPolarisResolver(confPath) if err != nil { log.Fatal(err) } client, err := hclient.NewClient() client.Use(sd.Discovery(r)) //... } 使用示例 服务端 import ( \"context\" \"log\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/polaris\" ) const ( confPath = \"polaris.yaml\" Namespace = \"Polaris\" // At present,polaris server tag is v1.4.0，can't support auto create namespace,  // If you want to use a namespace other than default,Polaris ,before you register an instance,  // you should create the namespace at polaris console first. ) func main() { r, err := polaris.NewPolarisRegistry(confPath) if err != nil { log.Fatal(err) } Info := \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", \"127.0.0.1:8888\"), Tags: map[string]string{ \"namespace\": Namespace, }, } h := server.Default(server.WithRegistry(r, Info), server.WithExitWaitTime(10*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"Hello,Hertz!\") }) h.Spin() } 客户端 import ( \"context\" \"log\" hclient \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/polaris\" ) const ( confPath = \"polaris.yaml\" Namespace = \"Polaris\" // At present,polaris server tag is v1.4.0，can't support auto create namespace,  // if you want to use a namespace other than default,Polaris ,before you register an instance,  // you should create the namespace at polaris console first. ) func main() { r, err := polaris.NewPolarisResolver(confPath) if err != nil { log.Fatal(err) } client, err := hclient.NewClient() client.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { // config.WithTag sets the namespace tag for service discovery  status, body, err := client.Get(context.TODO(), nil, \"http://hertz.test.demo/hello\", config.WithSD(true), config.WithTag(\"namespace\", Namespace)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\\n\", status, body) } } 配置 可自定义 polaris 客户端以及服务端的配置，参考 polaris-go 配置。\n完整示例 完整用法示例详见 example 。\nServicecomb 安装 go get github.com/hertz-contrib/registry/servicecomb 服务注册 Option Servicecomb 拓展在服务注册部分中提供了 option 配置。\nWithAppId Servicecomb 扩展提供了 WithAppId 用于帮助用户配置 Servicecomb 的 AppId 。默认为 “DEFAULT\" 。\n函数签名：\nfunc WithAppId(appId string) RegistryOption 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithAppId(\"appID\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithRegistryVersionRule Servicecomb 扩展提供了 WithRegistryVersionRule 用于帮助用户配置 Servicecomb 的版本要求 。默认为 1.0.0 。\n函数签名：\nfunc WithRegistryVersionRule(versionRule string) RegistryOption 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithRegistryVersionRule(\"1.1.0\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithRegistryHostName Servicecomb 扩展提供了 WithRegistryHostName 用于帮助用户配置 Servicecomb 的主机名 。默认为 ”DEFAULT\" 。\n函数签名：\nfunc WithRegistryHostName(hostName string) RegistryOption 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithRegistryHostName(\"hostName\"), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithRegistryHeartbeatInterval Servicecomb 扩展提供了 WithRegistryHeartbeatInterval 用于帮助用户配置发送心跳包的间隔时长 。默认为5。\n函数签名：\nfunc WithRegistryHeartbeatInterval(second int32) RegistryOption 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithRegistryHeartbeatInterval(10), ) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewDefaultSCRegistry NewDefaultSCRegistry 使用 service-comb 创建一个默认服务注册中心，需要传入端点值。可自定义服务注册中心配置。\n函数签名：\nfunc NewDefaultSCRegistry(endPoints []string, opts ...RegistryOption) (registry.Registry, error) 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewSCRegistry NewSCRegistry 使用 service-comb 创建一个新的服务注册中心。需要传入自定义客户端。可自定义服务注册中心配置。\n函数签名：\nfunc NewSCRegistry(client *sc.Client, opts ...RegistryOption) registry.Registry 示例代码：\nfunc main() { client := \u0026sc.Client{ // ...  } // ...  r, err := servicecomb.NewSCRegistry(config) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } 服务发现 Option Servicecomb 拓展在服务发现部分中提供了 option 配置。\nWithAppId Servicecomb 扩展提供了 WithAppId 用于帮助用户配置 Servicecomb 的 AppId 。默认为 “DEFAULT\" 。\n函数签名：\nfunc WithResolverAppId(appId string) ResolverOption 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithAppId(\"appID\"), ) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } WithResolverVersionRule Servicecomb 扩展提供了 WithResolverVersionRule 用于帮助用户配置 Servicecomb 的版本要求 。默认为 latest 。\n函数签名：\nfunc WithResolverVersionRule(versionRule string) ResolverOption 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithResolverVersionRule(\"1.0.0\"), ) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } WithResolverConsumerId Servicecomb 扩展提供了 WithResolverConsumerId 用于帮助用户配置 Servicecomb 的 ConsumerId 。默认为空 。\n函数签名：\nfunc WithResolverConsumerId(consumerId string) ResolverOption 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}, servicecomb.WithResolverConsumerId(\"1\"), ) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } NewDefaultSCResolver NewDefaultSCResolver 使用 service-comb 创建一个默认服务发现中心，需要传入端点值。可自定义服务发现中心配置。\n函数签名：\nfunc NewDefaultSCResolver(endPoints []string, opts ...ResolverOption) (discovery.Resolver, error) 示例代码：\nfunc main() { // ...  r, err := servicecomb.NewDefaultSCResolver([]string{scAddr}) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } NewSCResolver NewSCReslover 使用 service-comb 创建一个新的服务发现中心。需要传入自定义客户端。可自定义服务发现中心配置。\n函数签名：\nfunc NewSCResolver(cli *sc.Client, opts ...ResolverOption) discovery.Resolver 示例代码：\nfunc main() { client := \u0026sc.Client{ // ...  } // ...  r, err := servicecomb.NewSCResolver(client) if err != nil { panic(err) } cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } 使用示例 服务端 import ( \"context\" \"log\" \"sync\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/servicecomb\" ) func main() { const scAddr = \"127.0.0.1:30100\" const addr = \"127.0.0.1:8701\" r, err := servicecomb.NewDefaultSCRegistry([]string{scAddr}) if err != nil { log.Fatal(err) return } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.servicecomb.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong1\"}) }) h.Spin() } 客户端 import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/servicecomb\" ) func main() { const scAddr = \"127.0.0.1:30100\" // build a servicecomb resolver  r, err := servicecomb.NewDefaultSCResolver([]string{scAddr}) if err != nil { panic(err) } // build a hertz client with the servicecomb resolver  cli, err := client.NewClient() if err != nil { panic(err) } cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.servicecomb.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\", status, string(body)) } } 配置 可自定义 Servicecomb 客户端以及服务端的配置，参考 go-chassis/sc-client 配置\n完整示例 完整用法示例详见 example 。\nZookeeper 安装 go get github.com/hertz-contrib/registry/zookeeper 服务注册 NewZookeeperRegistry NewZookeeperRegistry 使用 zookeeper 创建一个服务注册中心，需要将服务通过一个字符串切片与会话超时时间共同传入 Connect 。\n函数签名：\nfunc NewZookeeperRegistry(servers []string, sessionTimeout time.Duration) (registry.Registry, error) 示例代码：\nfunc main() { // ...  r, err := zookeeper.NewZookeeperRegistry([]string{\"127.0.0.1:2181\"}, 40*time.Second) if err != nil { panic(err) } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } NewZookeeperRegistryWithAuth NewZookeeperRegistryWithAuth 使用 zookeeper 创建一个服务注册中心，需要将服务通过一个字符串切片与会话超时时间共同传入 Connect 。除此之外还需要传入用户与密码来调用 AddAuth ，用户与密码不能为空。\n函数签名：\nfunc NewZookeeperRegistryWithAuth(servers []string, sessionTimeout time.Duration, user, password string) 示例代码：\nfunc main() { // ...  r, err := zookeeper.NewZookeeperRegistryWithAuth([]string{\"127.0.0.1:2181\"}, 20*time.Second, \"hertzuser\", \"hertzpass\") if err != nil { panic(err) } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) // ... } 服务发现 NewZookeeperResolver NewZookeeperResolver 使用 zookeeper 创建一个服务发现中心，需要将服务通过一个字符串切片与会话超时时间共同传入 Connect 。\n函数签名：\nfunc NewZookeeperResolver(servers []string, sessionTimeout time.Duration) (discovery.Resolver, error) 示例代码：\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := zookeeper.NewZookeeperResolver([]string{\"127.0.0.1:2181\"}, 40*time.Second) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } NewZookeeperResolverWithAuth NewZookeeperResolverWithAuth 使用 zookeeper 创建一个服务发现中心，需要将服务通过一个字符串切片与会话超时时间共同传入 Connect 。除此之外还需要传入用户与密码来调用 AddAuth ，用户与密码不能为空。\n函数签名：\nfunc NewZookeeperResolverWithAuth(servers []string, sessionTimeout time.Duration, user, password string) 示例代码：\nfunc main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := zookeeper.NewZookeeperResolverWithAuth([]string{\"127.0.0.1:2181\"}, 40*time.Second, \"hertzuser\", \"hertzpass\") if err != nil { panic(err) } cli.Use(sd.Discovery(r)) // ... } 使用示例 服务端 import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/zookeeper\" ) func main() { addr := \"127.0.0.1:8888\" r, err := zookeeper.NewZookeeperRegistry([]string{\"127.0.0.1:2181\"}, 40*time.Second) if err != nil { panic(err) } h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong2\"}) }) h.Spin() } 客户端 import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/zookeeper\" ) func main() { cli, err := client.NewClient() if err != nil { panic(err) } r, err := zookeeper.NewZookeeperResolver([]string{\"127.0.0.1:2181\"}, 40*time.Second) if err != nil { panic(err) } cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"code=%d,body=%s\", status, string(body)) } } 配置 可自定义 zookeeper 客户端以及服务端的配置，参考 go-zookeeper/zk 配置。\n完整示例 完整用法示例详见 example 。\nRedis 安装 go get github.com/hertz-contrib/registry/redis 服务注册 Option Redis 拓展在服务注册部分中提供了 option 配置。\nWithPassword Redis 扩展提供了 WithPassword 配置 redis 的密码，此密码必须匹配服务器配置选项中指定的密码。\n函数签名：\nfunc WithPassword(password string) Option 示例代码：\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithPassword(\"123456\")) // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithDB Redis 扩展提供了 WithDB 配置连接到服务器后要选择的数据库。\n函数签名：\nfunc WithDB(db int) Option 示例代码：\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithDB(1)) // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithTLSConfig Redis 扩展提供了 WithTLSConfig 配置 TLS 的配置项。\n函数签名：\nfunc WithTLSConfig(t *tls.Config) Option 示例代码：\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithTLSConfig(\u0026tls.Config{ // ...  })) // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithDialer Redis 扩展提供了 WithDialer 配置 Dialer，Dialer 将会创建新的网络连接并优先于 Network 和 Addr 选项。\n函数签名：\nfunc WithDialer(dialer func(ctx context.Context, network, addr string) (net.Conn, error)) Option 示例代码：\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithDialer( // ...  )) // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithReadTimeout Redis 扩展提供了 WithReadTimeout 配置读取 socket 超时的时间，默认为 3 秒。\n函数签名：\nfunc WithReadTimeout(t time.Duration) Option 示例代码：\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithReadTimeout(5*time.Second)) // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } WithWriteTimeout Redis 扩展提供了 WithWriteTimeout 配置写入 socket 超时的时间，默认等同于 ReadTimeout 。\n函数签名：\nfunc WithWriteTimeout(t time.Duration) Option 示例代码：\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithWriteTimeout(5*time.Second)) // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } NewRedisRegistry NewRedisRegistry 使用 redis 创建一个新的服务注册中心，需要传入目标地址。可自定义客户端配置并传入 NewClient 创建一个新的客户端。\n函数签名：\nfunc NewRedisRegistry(addr string, opts ...Option) registry.Registry 示例代码：\nfunc main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\") // ...  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) // ... } 服务发现 Option Redis 拓展在服务发现部分中提供了 option 配置。\nWithPassword Redis 扩展提供了 WithPassword 配置 redis 的密码，此密码必须匹配服务器配置选项中指定的密码。\n函数签名：\nfunc WithPassword(password string) Option 示例代码：\nfunc main() { cli, err := client.NewClient() // ...  r := redis.NewRedisResolver(\"127.0.0.1:6379\", redis.WithPassword(\"123456\")) cli.Use(sd.Discovery(r)) // ... } WithDB Redis 扩展提供了 WithDB 配置连接到服务器后要选择的数据库。\n函数签名：\nfunc WithDB(db int) Option 示例代码：\nfunc main() { cli, err := client.NewClient() // ...  r := redis.NewRedisResolver(\"127.0.0.1:6379\", redis.WithDB(1)) cli.Use(sd.Discovery(r)) // ... } WithTLSConfig Redis 扩展提供了 WithTLSConfig 配置 TLS 的配置项。\n函数签名：\nfunc WithTLSConfig(t *tls.Config) Option 示例代码：\nfunc main() { cli, err := client.NewClient() // ...  r := redis.NewRedisResolver(\"127.0.0.1:6379\", redis.WithTLSConfig(\u0026tls.Config{ // ...  })) cli.Use(sd.Discovery(r)) // ... } WithDialer Redis 扩展提供了 WithDialer 配置 Dialer，Dialer 将会创建新的网络连接并优先于 Network 和 Addr 选项。\n函数签名：\nfunc WithDialer(dialer func(ctx context.Context, network, addr string) (net.Conn, error)) Option 示例代码：\nfunc main() { cli, err := client.NewClient() // ...  r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithDialer( // ...  )) cli.Use(sd.Discovery(r)) // ... } WithReadTimeout Redis 扩展提供了 WithReadTimeout 配置读取 socket 超时的时间，默认为 3 秒。\n函数签名：\nfunc WithReadTimeout(t time.Duration) Option 示例代码：\nfunc main() { cli, err := client.NewClient() // ...  r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithReadTimeout(5*time.Second)) // ...  )) cli.Use(sd.Discovery(r)) // ... } WithWriteTimeout Redis 扩展提供了 WithWriteTimeout 配置写入 socket 超时的时间，默认等同于 ReadTimeout 。\n函数签名：\nfunc WithWriteTimeout(t time.Duration) Option 示例代码：\nfunc main() { cli, err := client.NewClient() // ...  r := redis.NewRedisRegistry(\"127.0.0.1:6379\", redis.WithWriteTimeout(5*time.Second)) // ...  )) cli.Use(sd.Discovery(r)) // ... } NewRedisResolver NewRedisResolver 使用 redis 创建一个新的服务发现中心，需要传入目标地址。可自定义客户端配置并传入 NewClient 创建一个新的客户端。\n函数签名：\nfunc NewRedisResolver(addr string, opts ...Option) discovery.Resolver 示例代码：\nfunc main() { cli, err := client.NewClient() // ...  r := redis.NewRedisResolver(\"127.0.0.1:6379\") cli.Use(sd.Discovery(r)) // ... } 使用示例 服务端 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/app/server/registry\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/registry/redis\" ) func main() { r := redis.NewRedisRegistry(\"127.0.0.1:6379\") addr := \"127.0.0.1:8888\" h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, }), ) h.GET(\"/ping\", func(_ context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 客户端 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/middlewares/client/sd\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/registry/redis\" ) func main() { cli, err := client.NewClient() if err != nil { panic(err) } r := redis.NewRedisResolver(\"127.0.0.1:6379\") cli.Use(sd.Discovery(r)) for i := 0; i \u003c 10; i++ { status, body, err := cli.Get(context.Background(), nil, \"http://hertz.test.demo/ping\", config.WithSD(true)) if err != nil { hlog.Fatal(err) } hlog.Infof(\"HERTZ: code=%d,body=%s\", status, string(body)) } } 配置 可自定义 redis 客户端以及服务端的配置，参考 go-redis 配置。\n完整示例 完整用法示例详见 example 。\n","categories":"","description":"","excerpt":"目前在 Hertz 的开源版本支持的服务发现拓展都存放在 registry 中，欢迎大家参与项目贡献与维护。\n到现在为止，支持的服务发现拓展 …","ref":"/zh/docs/hertz/tutorials/service-governance/service_discovery/","tags":"","title":"服务注册与发现"},{"body":"If you want to get more detailed monitoring data, e.g. message packet size, or want to adopt other data source, e.g. InfluxDB, you can implement the Trace interface according to your requirements and inject it by WithTracer Option.\n// Tracer is executed at the start and finish of an HTTP. type Tracer interface { Start(ctx context.Context, c *app.RequestContext) context.Context Finish(ctx context.Context, c *app.RequestContext) } You can get TraceInfo from ctx. What is more, from TraceInfo you can get request time cost, package size, and error information returned from request, etc. Usage example：\ntype ServerTracer struct{ // contain entities which recording metric } // Start record the beginning of an RPC invocation. func (s *ServerTracer) Start(ctx context.Context, _ *app.RequestContext) context.Context { // do nothing \treturn ctx } // Finish record after receiving the response of server. func (s *ServerTracer) Finish(ctx context.Context, c *app.RequestContext) { ti := c.GetTraceInfo() rpcStart := ti.Stats().GetEvent(stats.HTTPStart) rpcFinish := ti.Stats().GetEvent(stats.HTTPFinish) cost := rpcFinish.Time().Sub(rpcStart.Time()) // TODO: record the cost of request } ","categories":"","description":"","excerpt":"If you want to get more detailed monitoring data, e.g. message packet …","ref":"/docs/hertz/tutorials/framework-exten/monitor/","tags":"","title":"Monitoring Extension"},{"body":"Usage Add some options when creating a client：\nclient, err := echo.NewClient(\"targetService\", client.WithXXXX...) Basic Options WithClientBasicInfo func WithClientBasicInfo(ebi *rpcinfo.EndpointBasicInfo) Option Set the service infos for client, including ServiceName and customized Tags, customized Tag such as Cluster, IDC, Env, and it is no need to set Method field of EndpointBasicInfo. It is strongly recommended to configure this option.\nWithHostPorts func WithHostPorts(hostports ...string) Option Manually specifie one or more targets overrides the results discovered by the service and directly connects to the access.\nWithTransportProtocol func WithTransportProtocol(tp transport.Protocol) Option Set the transport protocol, configure the transport protocol on the message protocol. Thrift/KitexProtobuf can configure TTHeader, TTHeaderFramed, and Framed. In addition, Framed is not strictly a transmission protocol. In order to distinguish it for PurePayload, it is also configured as a transmission protocol. PurePayload means that there is no transmission protocol; if it is configured as GRPC, it means that the GRPC protocol is used. , the transmission protocol of GRPC is HTTP2, but for the convenience of users' understanding, it is directly used as the configuration of the transmission protocol. Note that configuring GRPC needs to use Protobuf to define Service. If GRPC is not configured, KitexProtobuf protocol is used by default.\nWithShortConnection func WithShortConnection() Option Enable short connections. More\nWithLongConnection func WithLongConnection(cfg connpool.IdleConfig) Option Enable long connections. More\nWithMuxConnection func WithMuxConnection(connNum int) Option Enable mux connections. Server side also need to turn on this option, or it won’t work. More\nWithMiddleware func WithMiddleware(mw endpoint.Middleware) Option Add a middleware that executes after service level circuit breaker and timeout middleware. More\nWithInstanceMW func WithInstanceMW(mw endpoint.Middleware) Option Add a middleware that executes after service discovery and load balance. If instance level circuit breaker exists, then it will execute after that. (If proxy is used, it will not be called, such as mesh mode). More\nWithMiddlewareBuilder func WithMiddlewareBuilder(mwb endpoint.MiddlewareBuilder) Option Add middleware depends on the context passed in by the framework that contains runtime configuration information (the context of non-RPC calls), so that the middleware can take advantage of the framework’s information when initializing.\nWithCircuitBreaker func WithCircuitBreaker(s *circuitbreak.CBSuite) Option Set the circuit breaker, which includes service circuit break and instance circuit break by default, using the example:\nvar opts []client.Option cbs := circuitbreak.NewCBSuite(circuitbreak.RPCInfo2Key) opts = append(opts, client.WithCloseCallbacks(func() error { // Circuit Breaker Close method is injected into CloseCallbacks to release circuit breaker related resources when the client is destroyed  return cs.cbs.Close() })) opts = append(opts, client.WithCircuitBreaker(cbs)) // Dynamically updates the circuit breaker configuration cbs.UpdateServiceCBConfig(key, config) cbs.UpdateInstanceCBConfig(key, config) For more details, please visit Circuit Breaker.\nWithFailureRetry func WithFailureRetry(p *retry.FailurePolicy) Option Set timeout retry rules, you can configure the maximum number of retries, the maximum time spent accumulated, the threshold of the retry circuit fault rate, the DDL abort and backoff policy. More\nWithBackupRequest func WithBackupRequest(p *retry.BackupPolicy) Option Set the policy for Backup Request, which can configure the number of requests, circuit breaker abort, and link abort. More\nWithRPCTimeout func WithRPCTimeout(d time.Duration) Option Set RPC timeout. More\nWithConnectTimeout func WithConnectTimeout(d time.Duration) Option Set connect timeout. More\nWithTimeoutProvider func WithTimeoutProvider(p rpcinfo.TimeoutProvider) Option Add a TimeoutProvider to set the RPC timeout, connection timeout, etc. policies as a whole. If You use Both WithRPCTimeout or WithConnectTimeout, the settings here will be overridden.\nWithDestService func WithDestService(svr string) Option Specify the service name of the target side of the call.\nWithTag func WithTag(key, val string) Option Add some meta information to the client, such as idc, cluster, etc., for scenarios such as auxiliary service discovery.\nWithStatsLevel func WithStatsLevel(level stats.Level) Optiong Set the stats level for client. More\ngRPC Options  These options only works for scenarios where the transport protocol uses gRPC, with some parameter adjustments to gRPC transfers.\n WithGRPCConnPoolSize func WithGRPCConnPoolSize(s uint32) Option WithGRPCConnPoolSize sets the value for the client connection pool size. In general, you should not adjust the size of the connection pool, otherwise it may cause performance degradation. You should adjust the size according to the actual situation.\nWithGRPCWriteBufferSize func WithGRPCWriteBufferSize(s uint32) Option WithGRPCWriteBufferSize determines how much data can be batched before doing a write on the wire. The corresponding memory allocation for this buffer will be twice the size to keep syscalls low. The default value for this buffer is 32KB. Zero will disable the write buffer such that each write will be on underlying connection. Note: A Send call may not directly translate to a write. It corresponds to the WriteBufferSize ServerOption of gRPC.\nWithGRPCReadBufferSize func WithGRPCReadBufferSize(s uint32) Option WithGRPCReadBufferSize lets you set the size of read buffer, this determines how much data can be read at most for one read syscall. The default value for this buffer is 32KB. Zero will disable read buffer for a connection so data framer can access the underlying conn directly. It corresponds to the ReadBufferSize ServerOption of gRPC.\nWithGRPCInitialWindowSize func WithGRPCInitialWindowSize(s uint32) Option WithGRPCInitialWindowSize returns a Option that sets window size for stream. The lower bound for window size is 64K and any value smaller than that will be ignored. It corresponds to the InitialWindowSize ServerOption of gRPC.\nWithGRPCInitialConnWindowSize func WithGRPCInitialConnWindowSize(s uint32) Option WithGRPCInitialConnWindowSize returns an Option that sets window size for a connection. The lower bound for window size is 64K and any value smaller than that will be ignored. It corresponds to the InitialConnWindowSize ServerOption of gRPC.\nWithGRPCMaxHeaderListSize func WithGRPCMaxHeaderListSize(s uint32) Option WithGRPCMaxHeaderListSize returns a ServerOption that sets the max (uncompressed) size of header list that the server is prepared to accept. It corresponds to the MaxHeaderListSize ServerOption of gRPC.\nWithGRPCKeepaliveParams func WithGRPCKeepaliveParams(kp grpc.ClientKeepalive) Option WithGRPCKeepaliveParams returns a DialOption that specifies keepalive parameters for the client transport. It corresponds to the WithKeepaliveParams DialOption of gRPC.\nWithGRPCTLSConfig func WithGRPCTLSConfig(tlsConfig *tls.Config) Option WithGRPCTLSConfig sets the TLS config to the connection options for Kitex gRPC client.\nAdvanced Options WithSuite func WithSuite(suite Suite) Option Set up a specific configuration, customize according to the scene, configure multiple options and middlewares combinations and encapsulations in the Suite. More\nWithProxy func WithProxy(p proxy.ForwardProxy) Option For proxy scenarios (such as Mesh Egress), do some configuration processing, return proxy address, configure proxy. After ForwardProxy, the framework does not perform service discovery, circuit breakers, and InstanceMWs.\nWithRetryContainer func WithRetryContainer(rc *retry.Container) Option Manually set up RetryContainer. Used to retry the strategy in combination with circuit breakers. At present, three rapid implementation schemes are available: NewRetryContainer, NewRetryContainerWithCB and NewRetryContainerWithCBStat.\n NewRetryContainerWithCB (recommended)  If you have already configured the circuit breaker, it is recommended to reuse the circuit breaker with RetryContainer to avoid additional statistics, you can use the NewRetryContainerWithCB, such as the example in the example below, enable the circuit breaker scenario, and at the same time pass the circuit breaker to RetryContainer:\ncbs := circuitbreak.NewCBSuite(circuitbreak.RPCInfo2Key) retryC := retry.NewRetryContainerWithCB(cbs.ServiceControl(), cbs.ServicePanel()) var opts []client.Option opts = append(opts, client.WithRetryContainer(retryC)) // enable service circuit breaker  opts = append(opts, client.WithMiddleware(cbs.ServiceCBMW()))  NewRetryContainer  Specifies the default RetryContainer for the retry policy, which has a built-in circuit breaker.   NewRetryContainerWithCBStat  To customize the built-in circuit breaker ServiceCBKeyFunc settings, you can use the NewRetryContainerWithCBStat method:\ncbs := circuitbreak.NewCBSuite(YourGenServiceCBKeyFunc) retry.NewRetryContainerWithCBStat(cbs.ServiceControl(), cbs.ServicePanel()) WithWarmingUp func WithWarmingUp(wuo *warmup.ClientOption) Option Set warming up option. Kitex supports client warm-up, which allows you to pre-initialize the relevant components of service discovery and connection pooling when creating the client, avoiding large delays on the first request.\nWarm up service discovery:\ncli, err := myservice.NewClient(psm, client.WithWarmingUp(\u0026warmup.ClientOption{ ResolverOption: \u0026warmup.ResolverOption{ Dests: []*rpcinfo.EndpointBasicInfo{ \u0026rpcinfo.EndpointBasicInfo{ ServiceName: psm, Method: method, Tags: map[string]string{ \"cluster\": \"default\", }, }, }, }, })) Warm up connection pool:\ncli, err := myservice.NewClient(psm, client.WithWarmingUp(\u0026warmup.ClientOption{ PoolOption: \u0026warmup.PoolOption{ ConnNum: 2, }, })) WithCloseCallbacks func WithCloseCallbacks(callback func() error) Option Set close callback function.\nWithErrorHandler func WithErrorHandler(f func(error) error) Option Set the error handler function, which is executed after the server handler is executed and before the middleware executes.\nWithGeneric func WithGeneric(g generic.Generic) Option Specifie the generalization call type, which needs to be used in conjunction with the generalization Client/Server. More\nWithACLRules func WithACLRules(rules ...acl.RejectFunc) Option Set ACL permission access control, which is executed before service discovery. More\nWithConnReporterEnabled func WithConnReporterEnabled() Option Enable connection pool reporter. More\nWithHTTPConnection func WithHTTPConnection() Option Specifie client use RPC over http.\nExtended Options WithTracer func WithTracer(c stats.Tracer) Option Add an additional Tracer. More\nWithResolver func WithResolver(r discovery.Resolver) Option Specifie a resolver to do service discovery. More\nWithHTTPResolver func WithHTTPResolver(r http.Resolver) Option Set HTTP resolver. More\nWithLoadBalancer func WithLoadBalancer(lb loadbalance.Loadbalancer, opts ...*lbcache.Options) Option Set load balancer. More\nWithBoundHandler func WithBoundHandler(h remote.BoundHandler) Option Add a new IO Bound handler. More\nWithCodec func WithCodec(c remote.Codec) Option Specifie a Codec for scenarios that require custom protocol. More\nWithPayloadCodec func WithPayloadCodec(c remote.PayloadCodec) Option Specifie a PayloadCodec. More\nWithMetaHandler func WithMetaHandler(h remote.MetaHandler) Option Add a meta handler for customizing transparent information in conjunction with the transport protocol, such as service name, invocation method, machine room, cluster, env, tracerInfo. More\nWithFirstMetaHandler func WithFirstMetaHandler(h remote.MetaHandler) Option Add a meta handler at the first position.\nWithTransHandlerFactory func WithTransHandlerFactory(f remote.ClientTransHandlerFactory) Option Set transHandlerFactory. More\nWithDiagnosisService func WithDiagnosisService(ds diagnosis.Service) Option Set diagnosis service. More\nWithDialer func WithDialer(d remote.Dialer) Option Set dialer.\nWithConnPool func WithConnPool(pool remote.ConnPool) Option Set connection pool.\n","categories":"","description":"Kitex Client Option instructions.","excerpt":"Kitex Client Option instructions.","ref":"/docs/kitex/tutorials/options/client_options/","tags":"","title":"Client Option"},{"body":"用法 在创建客户端时，带上 Option 参数即可：\nclient, err := echo.NewClient(\"targetService\", client.WithXXXX...) 基础 Option 基本信息 - WithClientBasicInfo func WithClientBasicInfo(ebi *rpcinfo.EndpointBasicInfo) Option 设置 Client 侧的 Service 信息，包括 ServiceName 和自定义的 Tags，自定义 Tag 如 Cluster、IDC、Env，无需设置 EndpointBasicInfo 的 Method 字段。强烈建议配置该 Option。\nIP 端口 - WithHostPorts func WithHostPorts(hostports ...string) Option 手动指定一个或者多个目标端，会覆盖掉服务发现的结果，直接直连访问。\n传输协议 - WithTransportProtocol func WithTransportProtocol(tp transport.Protocol) Option 设置传输协议，在消息协议上配置传输协议。Thrift/KitexProtobuf 可以配置 TTHeader、TTHeaderFramed、Framed，另外，Framed 严格意义上并不算传输协议，为区分用于 PurePayload 将其也作为传输协议配置，PurePayload 表示没有传输协议；如果配置为 GRPC 表示使用 GRPC 协议，GRPC 的传输协议是 HTTP2，但为便于用户理解，直接作为传输协议的配置，注意配置 GRPC 需要用 Protobuf 定义 Service，如果没有配置 GRPC，默认使用的是 KitexProtobuf 协议。\n短连接 - WithShortConnection func WithShortConnection() Option 是否启用短连接，详见连接类型-短连接。\n长连接 - WithLongConnection func WithLongConnection(cfg connpool.IdleConfig) Option 是否启用长连接，详见连接类型-长连接。\n多路复用 - WithMuxConnection func WithMuxConnection(connNum int) Option 是否启用连接多路复用，需要同时在服务端也开启设置，详见连接类型-连接多路复用。\n中间件扩展 - WithMiddleware func WithMiddleware(mw endpoint.Middleware) Option 添加一个中间件，在 Service 熔断和超时中间件之后执行。用法参考 Middleware 扩展。\n中间件扩展 - WithInstanceMW func WithInstanceMW(mw endpoint.Middleware) Option 用于添加一个中间件，在服务发现和负载均衡之后执行，如果有实例熔断器，会在实例熔断器后执行（如果使用了 Proxy 则不会调用到，如 Mesh 模式下）。用法参考 Middleware 扩展。\n中间件扩展 - WithMiddlewareBuilder func WithMiddlewareBuilder(mwb endpoint.MiddlewareBuilder) Option 用于创建并添加中间件，可以根据 ctx 判断场景并创建中间件。 ctx 是框架传入的包含运行时配置信息的上下文（非 RPC 调用的上下文），以便中间件初始化时能利用框架的信息。\n熔断器 - WithCircuitBreaker func WithCircuitBreaker(s *circuitbreak.CBSuite) Option 设置熔断，默认包含 service 熔断和 instance 熔断，使用示例：\nvar opts []client.Option cbs := circuitbreak.NewCBSuite(circuitbreak.RPCInfo2Key) opts = append(opts, client.WithCloseCallbacks(func() error { // 熔断器的 Close 方法注入到 CloseCallbacks，用于在client销毁时，释放熔断相关资源  return cs.cbs.Close() })) opts = append(opts, client.WithCircuitBreaker(cbs)) // 动态更新熔断配置 cbs.UpdateServiceCBConfig(key, config) cbs.UpdateInstanceCBConfig(key, config) 关于熔断说明，详见熔断器。\n超时重试 - WithFailureRetry func WithFailureRetry(p *retry.FailurePolicy) Option 设置超时重试规则，可以配置最大重试次数，累计最大耗时，重试熔断错误率阈值，DDL 中止和退避策略等，详见请求重试。\n备份请求 - WithBackupRequest func WithBackupRequest(p *retry.BackupPolicy) Option 设置 Backup Request 的策略，可以配置请求次数、熔断中止、链路中止等，详见请求重试。\n超时设置 - WithRPCTimeout func WithRPCTimeout(d time.Duration) Option 进行 RPC 超时设置，详见超时控制。\n超时设置 - WithConnectTimeout func WithConnectTimeout(d time.Duration) Option 设置连接超时，详见超时控制。\n超时设置 - WithTimeoutProvider func WithTimeoutProvider(p rpcinfo.TimeoutProvider) Option 添加一个 TimeoutProvider 来整体设置 RPC 超时，连接超时等策略。若同时使用了 WithRPCTimeout 或 WithConnectTimeout，那么这里的设置会被覆盖。\n指定服务 - WithDestService func WithDestService(svr string) Option 指定调用目标端的服务名称，在 NewClient 中，第一个 string 参数就封装了这个 Option ，服务发现等场景会用到该字段。\n添加标签 - WithTag func WithTag(key, val string) Option 为 Client 添加一些元信息，例如 idc，cluster 等，用于辅助服务发现等场景。\n埋点粒度 - WithStatsLevel func WithStatsLevel(level stats.Level) Optiong 为 Client 设置埋点粒度，详见埋点粒度。\ngRPC 相关配置  这类设置只对传输协议使用 gRPC 的场景生效，对 gRPC 传输进行一些参数调整。\n WithGRPCConnPoolSize func WithGRPCConnPoolSize(s uint32) Option 设置 gRPC 的连接池大小。只对传输协议使用 gRPC 的场景生效。\nWithGRPCWriteBufferSize func WithGRPCWriteBufferSize(s uint32) Option 设置 gRPC 写缓冲大小，写缓冲决定了每次批量调用底层写发送数据的大小。默认值为32KB，如果设置为0，则相当于禁用缓冲区，每次写操作都直接调用底层连接进行发送。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCReadBufferSize func WithGRPCReadBufferSize(s uint32) Option 设置 gRPC 的读缓冲大小，读缓冲决定了每次批量从底层读取多少数据。默认值为32KB，如果设置为0，则相当于禁用缓冲区，每次读操作都直接从底层连接进行读操作。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCInitialWindowSize func WithGRPCInitialWindowSize(s uint32) Option 设置 gRPC 每个 Stream 的初始收发窗口大小，最低为64KB，若设置的值小于最低值，则会被忽略。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCInitialConnWindowSize func WithGRPCInitialConnWindowSize(s uint32) Option 设置 gRPC 单条连接上的初始窗口大小，最低为64KB，若设置的值小于最低值，则会被忽略。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCMaxHeaderListSize func WithGRPCMaxHeaderListSize(s uint32) Option 设置 gRPC MaxHeaderListSize 参数，该参数决定了每次调用允许发送的header的最大条数。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCKeepaliveParams func WithGRPCKeepaliveParams(kp grpc.ClientKeepalive) Option 设置 gRPC 客户端 Keepalive 的各项参数。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCTLSConfig func WithGRPCTLSConfig(tlsConfig *tls.Config) Option 设置 gRPC 客户端的 TLS 配置。 该设置只对传输协议使用 gRPC 的场景生效。\n高级 Option 配套扩展 - WithSuite func WithSuite(suite Suite) Option 设置一套特定配置，可根据场景进行定制，在 Suite 中配置多个 Option 和 Middleware 的组合和封装，详见 Suite 扩展。\n代理 - WithProxy func WithProxy(p proxy.ForwardProxy) Option 用于代理场景（如 Mesh Egress）做一些配置处理、返回代理地址，配置 proxy.ForwardProxy 后，框架不会执行服务发现、熔断、InstanceMWs。\n重试 - WithRetryContainer func WithRetryContainer(rc *retry.Container) Option 手动设置 RetryContainer。用于结合熔断器进行重试策略。目前提供了 NewRetryContainer，NewRetryContainerWithCB 与 NewRetryContainerWithCBStat 三个快速实现方案。\n NewRetryContainerWithCB（建议）  ​ 若在已经配置熔断器的情况下，建议与 RetryContainer 复用熔断器，避免额外的统计，可以使用 NewRetryContainerWithCB ，例如下面的示例中，启用熔断器的场景，同时将熔断器透传给 RetryContainer：\ncbs := circuitbreak.NewCBSuite(circuitbreak.RPCInfo2Key) retryC := retry.NewRetryContainerWithCB(cbs.ServiceControl(), cbs.ServicePanel()) var opts []client.Option opts = append(opts, client.WithRetryContainer(retryC)) // enable service circuit breaker  opts = append(opts, client.WithMiddleware(cbs.ServiceCBMW()))   NewRetryContainer\n 指定重试策略的默认 RetryContainer，其内置了一个熔断器    NewRetryContainerWithCBStat\n  ​ 若想对内置的熔断器进行自定义 ServiceCBKeyFunc 设置，则可以使用 NewRetryContainerWithCBStat 方法：\ncbs := circuitbreak.NewCBSuite(YourGenServiceCBKeyFunc) retry.NewRetryContainerWithCBStat(cbs.ServiceControl(), cbs.ServicePanel()) 预热 - WithWarmingUp func WithWarmingUp(wuo *warmup.ClientOption) Option 设置预热。Kitex 支持了客户端预热，可以在创建客户端的时候预先初始化服务发现和连接池的相关组件，避免在首次请求时产生较大的延迟。\n预热服务发现：\ncli, err := myservice.NewClient(psm, client.WithWarmingUp(\u0026warmup.ClientOption{ ResolverOption: \u0026warmup.ResolverOption{ Dests: []*rpcinfo.EndpointBasicInfo{ \u0026rpcinfo.EndpointBasicInfo{ ServiceName: psm, Method: method, Tags: map[string]string{ \"cluster\": \"default\", }, }, }, }, })) 预热连接池：\ncli, err := myservice.NewClient(psm, client.WithWarmingUp(\u0026warmup.ClientOption{ PoolOption: \u0026warmup.PoolOption{ ConnNum: 2, }, })) 设置关闭时回调 - WithCloseCallbacks func WithCloseCallbacks(callback func() error) Option 设置客户端 Close 时的回调函数。\n异常处理器 - WithErrorHandler func WithErrorHandler(f func(error) error) Option 设置异常处理函数，该函数会在远程调用结束，中间件执行前被执行。\n泛化调用 - WithGeneric func WithGeneric(g generic.Generic) Option 指定泛化调用类型，泛化需要结合泛化 Client/Server 使用。详见 Kitex 泛化调用使用指南。\n权限控制 - WithACLRules func WithACLRules(rules ...acl.RejectFunc) Option 设置 ACL 权限访问控制，该模块会在服务发现之前执行，具体用法详见自定义访问控制。\n连接池监控 - WithConnReporterEnabled func WithConnReporterEnabled() Option 设置连接池状态监控，详见连接类型-状态监控。\n启用 HTTP 连接 - WithHTTPConnection func WithHTTPConnection() Option 指定客户端使用 netpoll 提供的 http 连接进行 RPC 交互。\n扩展 Option 链路监控 - WithTracer func WithTracer(c stats.Tracer) Option 额外添加一个 Tracer 进行链路监控，详见链路跟踪-自定义 tracer。\n服务发现 - WithResolver func WithResolver(r discovery.Resolver) Option 指定一个 Resolver 进行服务发现，用法详见服务发现。\nHTTP 解析器 - WithHTTPResolver func WithHTTPResolver(r http.Resolver) Option 指定HTTP Resolver，详见直连访问-自定义 DNS resolver。\n负载均衡 - WithLoadBalancer func WithLoadBalancer(lb loadbalance.Loadbalancer, opts ...*lbcache.Options) Option 设置负载均衡器，详见负载均衡。\nIO Bound 处理器 - WithBoundHandler func WithBoundHandler(h remote.BoundHandler) Option 自定义 IO Bound，详见 Transport Pipeline-Bound 扩展。\n编解码 - WithCodec func WithCodec(c remote.Codec) Option 指定 Codec，详见编解码协议扩展\nPayload 编解码 - WithPayloadCodec func WithPayloadCodec(c remote.PayloadCodec) Option 指定 PayloadCodec，详见编解码协议扩展\n元信息处理 - WithMetaHandler func WithMetaHandler(h remote.MetaHandler) Option 添加一个元信息处理器，用法详见元信息传递扩展。\n元信息处理 - WithFirstMetaHandler func WithFirstMetaHandler(h remote.MetaHandler) Option 在 MetaHandler 链的最前面添加一个元信息处理器，功能同 WithMetaHandler 类似。\n传输设置 - WithTransHandlerFactory func WithTransHandlerFactory(f remote.ClientTransHandlerFactory) Option 自定义传输模块，详见传输模块扩展。\n诊断扩展 - WithDiagnosisService func WithDiagnosisService(ds diagnosis.Service) Option 添加一个自定义的 Diagnosis Service，用来获取更多的诊断信息，详见诊断模块扩展。\nDialer 扩展 - WithDialer func WithDialer(d remote.Dialer) Option 手动指定 Dialer。通常情况下 Dialer 在其他配置中已经进行了配套实现，一般情况下不建议使用。\n连接池扩展 - WithConnPool func WithConnPool(pool remote.ConnPool) Option 手动设置连接池。通常情况下 ConnPool 在其他配置中已经进行了配套实现，一般情况下不建议使用。\n","categories":"","description":"Kitex Client Option 使用说明。","excerpt":"Kitex Client Option 使用说明。","ref":"/zh/docs/kitex/tutorials/options/client_options/","tags":"","title":"Client Option"},{"body":"Hertz integrated Netpoll and Golang network lib by default. Users can choose the appropriate one according to the actual scenarios to meet the best performance.\nUsage While creating a server, Hertz uses netpoll by default, but this behavior can be modified by configuration:\nserver.New(server.WithTransport(standard.NewTransporter)) server.New(server.WithTransport(netpoll.NewTransporter)) While creating a Client, it can also be modified by configuration:\nclient.NewClient(client.WithDialer(standard.NewDialer())) client.NewClient(client.WithDialer(netpoll.NewDialer())) Choosing appropriate network library  If you need to start a TLS server, Please use go net lib instead. netpoll is now working on it but not ready yet. Due to the different I/O trigger model between the two network libs, go net for ET model and netpoll for LT model, which makes the application scenarios of the two libs somewhat different. Under the ET mode, Read / Write events will be handled by the framework. Under the LT mode, Read / Write events will be handled by the network lib itself instead. So with the small size requests, better schedule strategy provided by netpoll will makes LT model perform better; But under the situation with large size requests, since the Read / Write is not controlled by the framework layer, it may cause memory pressure because large amount of data will be loaded into the memory but can not be handled in time.   Under the situation with large request size ( generally larger than 1M ), go net lib with streaming is recommended. In other situation, netpoll lib is recommended for extreme performance.  ","categories":"","description":"","excerpt":"Hertz integrated Netpoll and Golang network lib by default. Users can …","ref":"/docs/hertz/tutorials/basic-feature/network-lib/","tags":"","title":"Network Lib"},{"body":"Hertz provides a default way to print logs in the standard output. It also provides several global functions, such as hlog.Info, hlog.Errorf, hlog.CtxTracef, etc., which are implemented in pkg/common/hlog, to call the corresponding methods of the default logger.\nHow to print logs Hertz can call the method under the pkg/common/hlog package directly, which will call the corresponding method on the defaultLogger. For example, implement a middleware that prints AccessLog.\nfunc AccessLog() app.HandlerFunc { return func(c context.Context, ctx *app.RequestContext) { start := time.Now() ctx.Next(c) end := time.Now() latency := end.Sub(start).Microseconds hlog.CtxTracef(c, \"status=%d cost=%d method=%s full_path=%s client_ip=%s host=%s\", ctx.Response.StatusCode(), latency, ctx.Request.Header.Method(), ctx.Request.URI().PathOriginal(), ctx.ClientIP(), ctx.Request.Host()) } } Redirects the output of the default logger Hertz can use hlog.SetOutput to redirect the output of the default logger provided by hlog. For example, to redirect the output of the default logger to . /output.log, you may do as follows:\npackage main import ( \"os\" \"github.com/cloudwego/hertz/pkg/common/hlog\" ) func main() { f, err := os.OpenFile(\"./output.log\", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) if err != nil { panic(err) } defer f.Close() hlog.SetOutput(f) ... // continue to set up your server } Set the logLevel Hertz can use hlog.SetLevel to set the log level above which logs will be printed.\nhlog.SetLevel(hlog.LevelInfo) The following log levels are currently supported:\nLevelTrace LevelDebug LevelInfo LevelNotice LevelWarn LevelError LevelFatal Log Extension Currently, hlog supports the extended use of zap and logrus. For details on log extension, see.\n","categories":"","description":"","excerpt":"Hertz provides a default way to print logs in the standard output. It …","ref":"/docs/hertz/tutorials/observability/log/","tags":"","title":"Log"},{"body":"Hertz 提供打印日志的方式，默认打在标准输出。实现在 pkg/common/hlog 中，Hertz 同时也提供了若干全局函数，例如 hlog.Info、hlog.Errorf、hlog.CtxTracef 等，用于调用默认 logger 的相应方法。\n如何打印日志 hertz 中可以直接调用 pkg/common/hlog 包下的方法打日志，该方法会调用 defaultLogger 上对应的方法。如实现一个打印 AccessLog 的中间件。\nfunc AccessLog() app.HandlerFunc { return func(c context.Context, ctx *app.RequestContext) { start := time.Now() ctx.Next(c) end := time.Now() latency := end.Sub(start).Microseconds hlog.CtxTracef(c, \"status=%d cost=%d method=%s full_path=%s client_ip=%s host=%s\", ctx.Response.StatusCode(), latency, ctx.Request.Header.Method(), ctx.Request.URI().PathOriginal(), ctx.ClientIP(), ctx.Request.Host()) } } 重定向默认 logger 的输出 可以使用 hlog.SetOutput 来重定向 hlog 提供的默认 logger 的输出。 例如，要把默认 logger 的输出重定向到启动路径下的 ./output.log，可以这样实现：\npackage main import ( \"os\" \"github.com/cloudwego/hertz/pkg/common/hlog\" ) func main() { f, err := os.OpenFile(\"./output.log\", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) if err != nil { panic(err) } defer f.Close() hlog.SetOutput(f) ... // continue to set up your server } 设置 logLevel 可以使用 hlog.SetLevel 来设置日志等级，高于该日志等级的日志才能够被打印出来。\nhlog.SetLevel(hlog.LevelInfo) 目前支持的日志等级有\nLevelTrace LevelDebug LevelInfo LevelNotice LevelWarn LevelError LevelFatal 日志拓展 目前 hlog 支持 zap 和 logrus 的拓展使用，日志拓展详见。\n","categories":"","description":"","excerpt":"Hertz 提供打印日志的方式，默认打在标准输出。实现在 pkg/common/hlog 中，Hertz 同时也提供了若干全局函数， …","ref":"/zh/docs/hertz/tutorials/observability/log/","tags":"","title":"日志"},{"body":"The CORS (Cross-Origin Resource Sharing) mechanism allows a server to identify any origin other than its own so that browsers can access and load those resources. This mechanism is also used to check whether the server allows the browser to send a real request by sending a “precheck” request through the browser. In the “precheck” request header, there are HTTP methods and headers that the real request will use.\nHertz provides implementation of CORS middleware. The implementation here refers to GIN’s cors.\nInstall go get github.com/hertz-contrib/cors Example package main import ( \"time\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() // CORS for https://foo.com and https://github.com origins, allowing:  // - PUT and PATCH methods  // - Origin header  // - Credentials share  // - Preflight requests cached for 12 hours  h.Use(cors.New(cors.Config{ AllowOrigins: []string{\"https://foo.com\"}, AllowMethods: []string{\"PUT\", \"PATCH\"}, AllowHeaders: []string{\"Origin\"}, ExposeHeaders: []string{\"Content-Length\"}, AllowCredentials: true, AllowOriginFunc: func(origin string) bool { return origin == \"https://github.com\" }, MaxAge: 12 * time.Hour, })) h.Spin() } Preflight request For cross-origin access, in the case of a simple request, this is essentially adding an Origin field to the HTTP request header to describe where the source comes from, and the server can respond directly.\nFor non-simple cross-origin access requests (e.g. request method is PUT or PATCH, Content-Type field type is application/json, etc.), an HTTP preflight request is sent to verify that the client has access to the server before formal communication directly. A preflight request is a browser-initiated action that uses the HTTP Method OPTIONS.\nNote: Some of the hertz-cors configurations will only take effect when a preflight request occurs.\nConfig Hertz allows clients to access resources across origins through the use of cors middleware. You can finely control the extent to which server-side resources are allowed to be accessed across origins by customizing the configuration parameters of the Config structure. And you can also choose the default configuration of hertz-cors to allow clients from any origin to access resources.\nOnly part of the optional parameters are configured in the above Example, the full list of parameters for Config is as follows:\n   Parameter Introduction     AllowAllOrigins The property used to allow clients from any origin to access server-side resources, the default value is false   AllowOrigins The property used to set the list of origins a cross-domain request can be executed from, the default value is []   AllowOriginFunc The property used to set a custom function to validate the origin, if this option is set, the content of AllowOrigins is ignored   AllowMethods The property used to set the list of methods the client is allowed to use with cross-domain requests (takes effect when a preflight request is received)   AllowHeaders The property used to set the list of non-simple headers the client is allowed to use with cross-domain requests, the default value is [] (takes effect when a preflight request is received)   AllowCredentials The property indicates whether the request can include user credentials like cookies, HTTP authentication, or client-side SSL certificates, the default value is false   ExposeHeaders The property used to indicate which headers are safe to expose to the API of a CORS API specification, the default value is []   MaxAge The property used to set how long (in seconds) the results of a preflight request can be cached   AllowWildcard The property used to allow to add of origins like http://some-domain/*, https://api.*, or http://some.*.subdomain.com, the default value is false   AllowBrowserExtensions The property used to allow usage of popular browser extensions schemas, the default value is false   AllowWebSockets The property used to allow usage of WebSocket protocol, the default value is false   AllowFiles The property used to allow usage of file:// schema (dangerous!) use it only when you 100% sure it’s needed, the default value is false    AllowAllOrigins If the property value is true, all cross-domain requests will be allowed.\nWhen AllowAllOrigins is true, AllowOriginFunc and AllowOrigins must not be used, otherwise, conflicts will occur.\nAllowOrigins The property set a list of origins that can be accessed cross-domain, any cross-domain requests that satisfies the matching logic can access resource (only one * is allowed within each origin).\nConflicts with AllowAllOrigins, only one of which can be configured at a time.\nWhen used together with AllowOriginFunc, AllowOriginFunc takes precedence over AllowOrigins.\nIf you want to use an origin with wildcards, the AllowWildcard parameter must also be set to true.\nSample Code1:\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowOrigins: []string{\"https://foo.com\"}, })) h.Spin() } Sample Code2:\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowWildcard: true, AllowOrigins: []string{\"http://some-domain/*\"}, })) h.Spin() } AllowOriginFunc It takes the origin as an argument and returns true if allowed or false otherwise.\nConflicts with AllowAllOrigins, only one of which can be configured at a time.\nWhen used together with AllowOrigins, AllowOriginFunc takes precedence over AllowOrigins.\nFunction signatures:\nfunc(origin string) bool Sample Code:\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowOriginFunc: func(origin string) bool { return origin == \"https://github.com\" }, })) h.Spin() } AllowMethods This configuration takes effect only when a preflight request is received and is used to set the list of HTTP methods the client is allowed to use with cross-domain requests.\nIf the request is a simple request initiated by GET or POST, no additional settings are required.\nSample Code:\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowWildcard: true, AllowMethods: []string{\"PUT\", \"PATCH\"}, })) h.Spin() } AllowHeaders This configuration takes effect only when a preflight request is received. The Access-Control-Allow-Headers field is required if the browser request includes the Access-Control-Request-Headers field. It is a comma-separated string indicating all the header fields supported by the server.\nSample Code:\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowHeaders: []string{\"Origin\"}, })) h.Spin() } ExposeHeaders The property indicates which headers are safe to expose to the API of a CORS API specification.\nSample Code:\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ ExposeHeaders: []string{\"Content-Length\"}, })) h.Spin() } As for usage, you may refer to hertz cors\n","categories":"","description":"","excerpt":"The CORS (Cross-Origin Resource Sharing) mechanism allows a server to …","ref":"/docs/hertz/tutorials/basic-feature/middleware/cors/","tags":"","title":"CORS"},{"body":"   date version author update content     2022-05-22 v1.0 wangjingpei first version of IDL Definition Specification for Mapping between Thrift and HTTP    This specification is the IDL definition standard for mapping between Thrift and HTTP. It contains definition standards of service, endpoint, request and response parameters. Kitex partially implements the specification, and the parts of annotation description indicate if it is supported.\nSpecification （1）The standards use annotations to describe API details such as API method, path, position and name of request and response parameters and so on\n（2）The annotations mentioned above are in the form of api.{key}={value}, the key is usually used to specify the position occurred of the parameter, such as header，cookie，query，body and so on. The value is used to specify the actual name of fields, some functional annotations like api.none, api.js_conv, api.http_code are exceptions\n（3）The annotations mentioned above must be in lower-case, uppercase or mixed case letters are not supported. for example api.get, api.header and so on.\nStandards for Whole File  A service corresponds to only one thrift main file. The methods in the main file are for the corresponding API of the current service. The main IDL file can refer to other thrift file definitions In principle, each method corresponds to one request and one response definition In principle, response can be reused, while request reuse is not recommended  Standards for Request Restrict  We should specify the name and type of associated HTTP API parameters, such as header, cookie and name by annotations. If not specified, the GET method corresponds to query parameters, while the POST method corresponds to body parameters automatically. The field name is used as parameter key If the HTTP request uses GET method, api.body annotation occurred in request definitions is invalid. Only annotations such as api.query, api.path or api.cookie are supported If one HTTP request uses POST method and the serialization strategy is form, the request field type like object and map is not supported. But Kitex doesn’t support form now, only json format.  Annotation Description    annotation description field restrict is KiteX supported     api.query api.querycorresponds url query parameter for HTTP request Only basic types (except for object, map ） and list split by , are supported ✅   api.path api.query corresponds url path parameter for HTTP request Only basic types are supported ✅   api.header api.header corresponds header parameter for HTTP request Only basic type and list split by , are supported ✅   api.cookie api. cookie corresponds cookie parameter for HTTP request Only basic types are supported ✅    api.body api.body corresponds body parameter for HTTP request\nBoth serialization type like json and form in body are supported Json is supported by default . The api.serializer annotation for method can sepify serialization json or form ✅, but only json format   api.raw_body api.raw_body corresponds raw body for HTTP request, we can get raw binary body  ✅   api.vd Parameter valid, we can refer HTTPs://github.com/bytedance/go-tagexpr/tree/master/validator for details  ❌   api.js_conv api.js_conv indicates the field should be string while the definition is in64, since int64 is not supported by typescript The annotation value should be true, if else will be treated as invalid ✅   api.raw_uri api.raw_uri is used for protocol exchange from HTTP to RPC, the RPC service can get the raw uri by the field Only string type is supported ❌    Example structItem{// For nested structures, if you want to set the serialization key, use gotag, such as `json: \"Id\"` 1:optionali64id(go.tag='json:\"id\"')2:optionalstringtext}typedefstringJsonDictstructBizRequest{// Corresponding to v_int64 in HTTP query, and the value range is (0, 200) 1:optionali64v_int64(api.query='v_int64')2:optionalstringtext(api.body='text')// Corresponding serialization key = text 3:optionali32token(api.header='token')// Corresponding token in HTTP header 4:optionalJsonDictjson_header(api.header='json_header')5:optionalItemsome(api.body='some')// Corresponding first level key = some 6:optionallist\u003cReqItem\u003ereq_items(api.query='req_items')// api.query Only list split by are supported,Other complex types are not supported 7:optionali32api_version(api.path='action')// Corresponding path in uri 8:optionali64uid(api.path='biz')// Corresponding path in uri 9:optionallist\u003ci64\u003ecids(api.query='cids')// Corresponding to comma separated numbers in query, for example: cids=1,2,3,4 Only supported list\u003ci64\u003e、list\u003ci32\u003e 10:optionallist\u003cstring\u003evids(api.query='vids')}Standards for Response Restrict  Only basic type like int64, string, bool and list split by , are supported for header value Response is defined directly by the business itself. The default JSON is serialized to the body, the key is the field name, and the annotation can be empty  Annotation Description    annotation description field restrict is KiteX supported     api.header api.header corresponds header parameter for HTTP response Only basic types and list split by , are supported ✅   api.http_code api.http_code corresponds HTTP code for HTTP response，such as 200, 500 and so on The annotation value should be true, if else will be treated as invalid ✅   api.body api.body corresponds body parameter for HTTP response  ✅   api.none api.body indicates the field will be ignored for HTTP response The annotation value should be true, if else will be treated as invalid ✅   api.js_conv api.js_conv indicates the field should be trans to string in response since it is int64 The annotation value should be true, if else will be treated as invalid ✅   api.raw_body api.raw_body indicates the field will be treated as raw body for response  ✅   api.cookie api.cookie indicates the field will be treated as cookie for HTTP response  ✅    Example // Finally, BizResponse json will be serialized as a return package to the client structRspItem{1:optionali64item_id// By default, it is serialized with the field name as key, which is equivalent to using gotag `json:\"item_id\"` 2:optionalstringtext}structBizResponse{// This field will be filled in the header returned to the client 1:optionalstringT (api.header='T')// first level key = 'rsp_items' 2:optionalmap\u003ci64,RspItem\u003ersp_items (api.body='rsp_items')3:optionali32v_enum (api.none='true')// Ignore current parameter 4:optionallist\u003cRspItem\u003ersp_item_list (api.body='rsp_item_list')// The business specifies the HTTP Code itself. If not specified, baseResp.StatusCode=0 -\u003e HTTPCode=200, other HTTPCode=500 5:optionali32http_code (api.http_code='true')6:optionallist\u003ci64\u003eitem_count (api.header='item_count')// Comma separated list when setting header 7:optionalstringtoken (api.cookie='token')// 对应 response Cookie 字段 }Standards for Method Restrict  The serialization specified by the api.serializer is valid for GET request Each URI corresponds one method in IDL by annotation, the annotation must be written  Annotation Description    annotation type description example is KiteX supported     api.get string api.get corresponds GET method, the value is the HTTP path, the uri syntex is in accord with gin( we can refer httprouter for detail) api.get = '/life/client/favorite/collect' ✅   api.post string api.post corresponds POST method, the uri syntex is in accord with gin( we can refer httprouter for detail) api.post='/life/client/favorite/collect' ✅   api.put string api.put corresponds PUT method, the uri syntex is in accord with gin( we can refer httprouter for detail) api.put='/life/client/favorite/collect' ✅   api.delete string api.delete corresponds DELETE method, the uri syntex is in accord with gin( we can refer httprouter for detail) api.delete='/life/client/favorite/collect' ✅   api.patch string api.delete corresponds DELETE method, the uri syntex is in accord with gin( we can refer httprouter for detail) api.patch='/life/client/favorite/collect' ✅   api.serializer string Request serialization type of client request Such as form, json, thrift or pb ❌    Example serviceBizService{// Example 1: get request BizResponseBizMethod1(1:biz.BizRequestreq)(api.get='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true',api.category='demo')// Example 2: post request BizResponseBizMethod2(1:biz.BizRequestreq)(api.post='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true',api.serializer='form')// Example 3: delete request BizResponseBizMethod3(1:biz.BizRequestreq)(api.post='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true',api.serializer='json')}","categories":"","description":"","excerpt":"   date version author update content     2022-05-22 v1.0 wangjingpei …","ref":"/docs/kitex/tutorials/advanced-feature/generic-call/thrift_idl_annotation_standards/","tags":"","title":"IDL Definition Specification for Mapping between Thrift and HTTP"},{"body":"   日期 版本 作者 变更内容     2022-05-22 v1.0 王景佩 第一版 Thrift-HTTP 映射的 IDL 规范    本规范是 Thrift 与 HTTP 接口映射的 IDL 定义标准，包括服务、接口以及请求 request、response 参数定义规范和错误码定义规范。Kitex 部分实现了该规范，注解说明有标注支持情况。\n规范说明 （1）本规范采用注解方式来描述接口信息，包括接口的 method, path 以及接口请求参数，返回参数位置（如 header，cookie )、名称等信息\n（2）本规范所述注解采用 api.{key}={value} 的形式，其中key通常用于指定该字段出现的位置如（header，cookie，query，body 等), value 用于指定该字段在对应位置的实际名称, 一些功能性注解（如api.none, api.js_conv, api.http_code) 除外\n（3）本规范中定义的IDL注解如 api.get, api.header 等，只支持小写，不支持大写或者大小写混用如api.GET, api.Header\n文件整体规范  一个服务 service 对应一个 thrift 主文件，主文件里的 method 都是针对当前服务对应接口，主文件可以引用其它 thrift 文件定义 每个 Method 原则上对应一个 Request 和 Response 定义 原则上不建议 Request 复用，可以复用 Response  Request 规范 约束  接口请求字段需要使用注解关联到 HTTP 的某类参数和参数名称。如果无注解，GET 方法接口关联query 参数, POST 方法关联 body 参数, 字段名对应参数key 如果 HTTP 请求是采用 GET 方式的，那么 request 定义中出现的 api.body 注解无效，只有api.query, api.path, api.cookie 有效。 如果 HTTP 请求是采用 POST 方式且序列化方式是 form 的，那么 request 的字段不能有复杂结构如map，object，否则该字段无效。Kitex 目前暂未支持 form 格式，只支持 json 格式。  注解说明    注解 说明 字段约束 Kitex 支持情况     api.query api.query 对应 HTTP 请求的 url query 参数 只支持基本类型(object, map 以外）和逗号分隔的 list 支持   api.path api.path 对应 HTTP 请求的 url path 参数 支持基本类型 支持   api.header api.header 对应 HTTP 请求的 header 参数 只支持基本类型和逗号分隔的list 支持   api.cookie api.cookie 对应 HTTP 的 cookie 参数 支持基本类型 支持   api.body api.body 对应 HTTP 的 body 参数\n支持 body 为 json 和 form 两种格式 在未指定接口序列化方式下默认json格式，也可以在method注解中使用api.serializer来指定json/form 支持，但目前仅支持 JSON 格式   api.raw_body api.raw_body HTTP 原始 body，少数接口 body 加密了，可以拿到原始的 body（二进制数组)  支持   api.vd 参数校验，使用了HTTPs://github.com/bytedance/go-tagexpr/tree/master/validator库，检验表达式语法参见包内readme文件  暂未支持   api.js_conv api.js_conv 标识该字段传入参数需要进行 string to int64 转换，来解决前端 js 不支持 int64 的场景 value通常写true，其它情况与不写该注解等价 支持   api.raw_uri api.raw_uri 用于 HTTP to RPC 协议转换，RPC 服务获取 HTTP接口对应的原始 uri 只支持 string 类型 暂未支持    举例 structItem{1:optionali64id(go.tag='json:\"id\"')// 对于嵌套结构体，如果要设置序列化key,使用gotag 如 `json:\"id\"` 2:optionalstringtext}typedefstringJsonDictstructBizRequest{1:optionali64v_int64(api.query='v_int64')// 对应HTTP query中的v_int64, 且值范围为(0,200) 2:optionalstringtext(api.body='text')// 对应序列化key = text 3:optionali32token(api.header='token')// 对应HTTP header中的token 4:optionalJsonDictjson_header(api.header='json_header')5:optionalItemsome(api.body='some')// 对应一级key = some 6:optionallist\u003cReqItem\u003ereq_items(api.query='req_items')// api.query仅支持逗号相隔的list,其他复杂类型不支持 7:optionali32api_version(api.path='action')// 对应uri的path参数 8:optionali64uid(api.path='biz')// 对应uri的path参数 9:optionallist\u003ci64\u003ecids(api.query='cids')// 对应query里面逗号隔开的数字, 如 cids=1,2,3,4仅支持list\u003ci64\u003e、list\u003ci32\u003e 10:optionallist\u003cstring\u003evids(api.query='vids')}Response 规范 约束  header 不支持除逗号相隔并且 value 为基本类型的 list 以外的复杂类型 直接按照业务自己定义的 response。默认 json 序列化到 body，key为字段名，注解可为空  注解说明    注解 说明 字段约束 Kitex 支持情况     api.header api.header 设置HTTP 请求回复中的header 只支持基本类型和逗号分隔的list 支持   api.http_code api.http_code 对应HTTP 回复中的status code，200/500等 value通常写true，其它情况与不写该注解等价 支持   api.body api.body 对应HTTP 回复中的body参数  支持   api.none 标识该字段在 response中将会被忽略 value通常写true，其它情况与不写该注解等价 支持   api.js_conv 兼容js int64问题，response时需要将int64表示为string value通常写true，其它情况与不写该注解等价 支持   api.raw_body api.raw_body 设置该字段content作为HTTP response的完整body  支持   api.cookie api.cookie 设置HTTP 回复中的cookie （string类型，后端自行拼接）  支持    举例 // 最终将把BizResponse json序列化之后作为给客户端的返包 structRspItem{1:optionali64item_id// 默认被以字段名作key序列化，等价于使用gotag `json:\"item_id\"` 2:optionalstringtext}structBizResponse{1:optionalstringT (api.header='T')// 该字段将填入给客户端返回的header中 2:optionalmap\u003ci64,RspItem\u003ersp_items (api.body='rsp_items')// 一级key = 'rsp_items' 3:optionali32v_enum (api.none='true')// 该注解value通常写true，其它情况与不写该注解等价 4:optionallist\u003cRspItem\u003ersp_item_list (api.body='rsp_item_list')// 业务自己指定了HTTPCode, 如果没有指定, baseResp.StatusCode=0 -\u003e HTTPCode=200, 其他 HTTPCode=500 5:optionali32http_code (api.http_code='true')//对应 response HTTP Code 6:optionallist\u003ci64\u003eitem_count (api.header='item_count')// 当设置header时以逗号相隔的列表 7:optionalstringtoken (api.cookie='token')// 对应 response Cookie 字段 }Method 规范 约束  如果是GET请求，api.serializer定义的序列化方式是无效的 每个URI对应IDL的一个method，通过注解关联，注解不可为空  注解说明    注解 类型 说明 举例 Kitex 支持情况     api.get string get请求，值为HTTP path，uri的语法与gin一致(参考 httprouter) 例如 api.get = '/life/client/favorite/collect' 支持   api.post string post请求，值为HTTP path，uri的语法与gin一致(参考 httprouter) 例如 api.post='/life/client/favorite/collect' 支持   api.put string put请求，值为HTTP path，uri的语法与gin一致(参考 httprouter) 例如 api.put='/life/client/favorite/collect' 支持   api.delete string delete请求，值为HTTP path，uri的语法与gin一致(参考 httprouter) api.delete='/life/client/favorite/collect' 支持   api.patch string delete请求，值为HTTP path，uri的语法与gin一致(参考 httprouter) api.patch='/life/client/favorite/collect' 支持   api.serializer string 客户端请求体序列化方式 如form, json, thrift, pb等 暂未支持    举例 serviceBizService{// 例子1： get请求 BizResponseBizMethod1(1:biz.BizRequestreq)(api.get='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true',api.category='demo')// 例子2: post请求 BizResponseBizMethod2(1:biz.BizRequestreq)(api.post='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true',api.serializer='form')// 例子3: delete请求 BizResponseBizMethod3(1:biz.BizRequestreq)(api.post='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true',api.serializer='json')}","categories":"","description":"","excerpt":"   日期 版本 作者 变更内容     2022-05-22 v1.0 王景佩 第一版 Thrift-HTTP 映射的 IDL …","ref":"/zh/docs/kitex/tutorials/advanced-feature/generic-call/thrift_idl_annotation_standards/","tags":"","title":"Thrift-HTTP 映射的 IDL 规范"},{"body":"跨源资源共享（CORS）机制允许服务器标识除了它自己的其它 origin，使得浏览器可以访问加载这些资源； 该机制也用来检查服务器是否允许浏览器发送真实的请求，通过浏览器发送\"预检\"请求实现，在预检请求头部中有 HTTP 方法和真实请求会用到的头。\nhertz 提供 cors 跨域中间件的实现 ，这里的实现参考了 gin 的 cors。\n安装 go get github.com/hertz-contrib/cors 示例代码 package main import ( \"time\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() // CORS for https://foo.com and https://github.com origins, allowing:  // - PUT and PATCH methods  // - Origin header  // - Credentials share  // - Preflight requests cached for 12 hours  h.Use(cors.New(cors.Config{ AllowOrigins: []string{\"https://foo.com\"}, AllowMethods: []string{\"PUT\", \"PATCH\"}, AllowHeaders: []string{\"Origin\"}, ExposeHeaders: []string{\"Content-Length\"}, AllowCredentials: true, AllowOriginFunc: func(origin string) bool { return origin == \"https://github.com\" }, MaxAge: 12 * time.Hour, })) h.Spin() } 预检请求 对于跨源访问来说，如果是简单请求，本质上就是在 HTTP 请求头信息中添加一个 Origin 字段，用于描述本次请求来自哪个源，服务端可以直接响应。\n而对于非简单跨源访问请求来说（比如请求方法是 PUT 或 PATCH，Content-Type 字段类型是 application/json 等），会在正式通信之前，发送一次 HTTP 预检请求（preflight），用于校验客户端是否有跨源资源访问权限，预检请求使用的方法是 OPTIONS，且这是浏览器自发的行为。\n注意：部分 hertz-cors 的配置只有在预检请求发生时才会生效。\n配置 Hertz 通过使用 cors 中间件，为客户端提供了跨源资源访问的能力。用户可以通过自定义 Config 结构的配置参数，精细控制服务端资源允许跨源访问的范围，亦或选择 hertz-cors 的默认配置，允许来自任意 origin 的客户端访问资源。\n上述示例代码中只配置了部分可选参数，Config 的完整参数列表如下：\n   参数 介绍     AllowAllOrigins 用于设置允许来自任意 origin 的客户端访问服务端资源，默认为 false   AllowOrigins 用于设置允许跨源访问的 origin 列表，默认为 []   AllowOriginFunc 用于设置校验客户端 origin 的函数，当启用这个配置时，AllowOrigins 的内容将被忽略   AllowMethods 用于设置允许客户端跨源访问所使用的 HTTP 方法列表（在接收到预检请求时生效）   AllowHeaders 用于设置客户端发起非简单的跨源资源访问请求时，允许使用的头信息字段列表，默认为 []（在接收到预检请求时生效）   AllowCredentials 用于设置允许客户端请求携带用户凭证，如：cookies，token，SSL 凭证，默认为 false   ExposeHeaders 用于设置允许暴露给客户端的响应头列表，默认为 []   MaxAge 用于设置预检请求的有效期（有效期内不会发起重复的预检请求）   AllowWildcard 用于设置允许含通配符的 origin 访问资源，默认为 false   AllowBrowserExtensions 用于设置允许使用流行的浏览器扩展模式，默认为 false   AllowWebSockets 用于设置允许使用 WebSocket 协议，默认为 false   AllowFiles 用于设置允许使用 file:// 协议（危险）除非你能确保 100% 的安全，才可以使用它，默认为 false    AllowAllOrigins 该参数设置为 true 之后，将允许来自任意 origin 的客户端跨源访问服务端资源。\nAllowAllOrigins 配置为 true 时， AllowOriginFunc 以及 AllowOrigins 配置不可以使用，否则将发生冲突。\nAllowOrigins 描述了可以跨源访问的 origin 列表，如果列表中的任何 origin 携带通配符 * （每个 origin 内只允许使用一个通配符 *），则允许任何满足匹配逻辑的 origin 访问。\n与 AllowAllOrigins 配置冲突，同时只能配置一项。\n与 AllowOriginFunc 配置同时使用时，AllowOriginFunc 的优先级高于 AllowOrigins。\n若需要使用携带通配符的 origin，则 AllowWildcard 参数需同时设置为 true。\n示例代码1：\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowOrigins: []string{\"https://foo.com\"}, })) h.Spin() } 示例代码2：\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowWildcard: true, AllowOrigins: []string{\"http://some-domain/*\"}, })) h.Spin() } AllowOriginFunc 以 origin 为形参，用于自定义 origin 的校验逻辑，返回 true 表示校验通过。\n与 AllowAllOrigins 配置冲突，同时只能配置一项。\n与 AllowOrigins 配置同时使用时，AllowOriginFunc 的优先级高于 AllowOrigins。\n函数签名：\nfunc(origin string) bool 示例代码：\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowOriginFunc: func(origin string) bool { return origin == \"https://github.com\" }, })) h.Spin() } AllowMethods 该配置只有在接收到预检请求时才会生效，用于设置允许客户端跨源访问所使用的 HTTP 方法列表。\n如果是由 GET 或者 POST 发起的简单请求，则无需额外设置。\n示例代码：\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowWildcard: true, AllowMethods: []string{\"PUT\", \"PATCH\"}, })) h.Spin() } AllowHeaders 该配置只有在接收到预检请求时才会生效，如果浏览器请求包括 Access-Control-Request-Headers 字段，则 Access-Control-Allow-Headers 字段是必需的。它是一个逗号分隔的字符串，表明服务器支持的所有头信息字段。\n示例代码：\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ AllowHeaders: []string{\"Origin\"}, })) h.Spin() } ExposeHeaders 用于设置允许客户端从 HTTP Response 的 Header 中获取的自定义头信息字段名称。\n示例代码：\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/cors\" ) func main() { h := server.Default() h.Use(cors.New(cors.Config{ ExposeHeaders: []string{\"Content-Length\"}, })) h.Spin() } 更多用法示例详见 cors\n","categories":"","description":"","excerpt":"跨源资源共享（CORS）机制允许服务器标识除了它自己的其它 origin，使得浏览器可以访问加载这些资源； 该机制也用来检查服务器是否允许浏 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/cors/","tags":"","title":"跨源资源共享"},{"body":"Hertz 默认集成了 Netpoll 和 Golang 原生网络库 两个网络库，用户可以根据自己的场景选择合适的网络库以达到最佳性能。\n使用方式 对于 Server 来说，默认使用 netpoll ，可以通过配置项进行更改：\nserver.New(server.WithTransport(standard.NewTransporter)) server.New(server.WithTransport(netpoll.NewTransporter)) 对于 Client 来说，可以通过配置项进行更改：\nclient.NewClient(client.WithDialer(standard.NewDialer())) client.NewClient(client.WithDialer(netpoll.NewDialer())) 网络库选择  如果有启动 TLS Server 的需求，请使用 go net 网络库。netpoll 正在实现对 TLS 的支持。 由于网络库触发模式的不同：go net 为 ET 模型，netpoll 为 LT 模型，使得两个网络库的适用场景有一些不同。 在 ET 模型下，由框架处理 Read / Write 事件；在 LT 模型下，由网络库处理 Read / Write 事件。 使得在小包场景下，由于更优的调度策略使得 LT 性能更好；在大包场景下，由于读 / 写不受框架层控制，使得大量数据被读入内存而不能及时处理，可能会造成内存压力。   在较大 request size 下（ request size \u003e 1M ），推荐使用 go net 网络库加流式。 在其他场景下，推荐使用 netpoll 网络库，会获得极致的性能。  ","categories":"","description":"","excerpt":"Hertz 默认集成了 Netpoll 和 Golang 原生网络库 两个网络库，用户可以根据自己的场景选择合适的网络库以达到最佳性能。\n使 …","ref":"/zh/docs/hertz/tutorials/basic-feature/network-lib/","tags":"","title":"网络库"},{"body":"会议主题： CloudWeGo 社区会议 2.25\n参会人员： Joway, YangruiEmma, liu-song, AshleeT, li-jin-gou, Hchenn, PureWhiteWu, GuangmingLuo, baiyutang, yccpt, horizonzy.\n会前必读： http://www.cloudwego.io/; https://github.com/cloudwego\n议程 1 ：自我介绍+历史贡献介绍 内容：参会人员轮流开展了自我介绍，包含个人基本情况、历史贡献、个人未来规划、相关建议。\n议程 2 ：社区规划介绍和后续安排 社区介绍（@罗广明 负责介绍）：\n 对CloudWeGo官网进行了简要介绍，并欢迎社区成员对官网内容进行提问，发表看法。 向参会人员介绍 kitex-contrib 库。 提出与其它开源项目合作，吸引更多用户。 介绍 kitex 框架的扩展性，可支持很多能力的扩展，提出未来框架能和更多开源项目做一些对接。  Action Items\n 在官网 Community 部分，后期计划征得大家同意之后，公开各位Contributor 的信息，比如 GitHub 的一些 ID 头像。 在渠道推广方面，后期会考虑与社区其他开源项目合作与对接，包括框架接入、宣传推广等方面。 在 Kitex 框架对接方面，安排 Kitex 框架后期与更多的开源项目（有一定的用户量和知名度的开源项目）进行对接。 在官网优化方面，后期进行网站文档的建设与优化。 在宣传方面，欢迎源码分析方面的文章投稿，同时我们也会加大对 Kitex example 的对外分享与宣传。 在用户案例收集方面，正在逐步沟通与接洽。 确定双周例会时间：暂定双周五晚7:30  议程 3：社区建议  收集外部用户案例：Kitex 除了字节之外也有其他的用户，建议可以收集外部用户案例。@刘嵩 共享代码变更设计文档：关于核心库的变更，内部同学改动的设计文档可以及时放在 Issue 或者群里面，便于感兴趣的同学可以参与进来。@赵延 共享源码分析：源码分析内容可以放到 Issue 中置顶，让大家快速了解整个框架，后期输出的源码分析文档也可以向外部同学同步出来@赵延 ；同时，源码分析文档的框架核心介绍，有助于外部同学对框架做一个深刻的认知，做出更多的 PR @clark(王伟超) 。 丰富宣传方式：建议换一些新颖的方式进行推广和宣传，例如B站和某些有影响力的技术圈之类的。@clark(王伟超) 文章输出：建议@李龙 将之前写的Example 中的 Easy demo ，整理为一篇文章，对项目做一下介绍，之后会对它进行对外发布。  ","categories":"","description":"","excerpt":"会议主题： CloudWeGo 社区会议 2.25\n参会人员： Joway, YangruiEmma, liu-song, AshleeT, …","ref":"/zh/community/meeting_notes/2022-02-25/","tags":"","title":"CloudWeGo 社区会议 2.25"},{"body":"Kitex has completed ETCD, ZooKeeper, Eureka, Consul, Nacos, Polaris multiple service discovery component through the support of community developers. Of course, it also supports DNS resolution and Static IP direct access mode. A strong and complete community ecology has been established for users to choose flexibly according to their needs.\nFor example, DNS Resolver is suitable for the clusters where DNS is used as a service discovery, commonly used for Kubernetes clusters.\nMore service discovery components in extended repository: registry-etcd、registry-nacos、registry-zookeeper、polaris、registry-eureka、registry-consul、registry-servicecomb .\nUsage In the case of DNS Resolver\nimport ( ... dns \"github.com/kitex-contrib/resolver-dns\" \"github.com/cloudwego/kitex/client\" ... ) func main() { ... client, err := echo.NewClient(\"echo\", client.WithResolver(dns.NewDNSResolver())) if err != nil { log.Fatal(err) } ... } ","categories":"","description":"Kitex provides extensions for service registration and discovery, and already supports many popular registries.","excerpt":"Kitex provides extensions for service registration and discovery, and …","ref":"/docs/kitex/tutorials/service-governance/discovery/","tags":"","title":"Service Discovery"},{"body":"Kitex 已经通过社区开发者的支持，完成了 ETCD、ZooKeeper、Eureka、Consul、Nacos、Polaris 多种服务发现模式，当然也支持 DNS 解析以及 Static IP 直连访问模式，建立起了强大且完备的社区生态，供用户按需灵活选用。\n比如 DNS Resolver, 适合使用 DNS 作为服务发现的场景， 常见的用于 Kubernetes 集群。\n更多服务发现组件参看扩展仓库：registry-etcd、registry-nacos、registry-zookeeper、polaris、registry-eureka、registry-consul、registry-servicecomb 。\n使用方式 以 DNS Resolver 为例\nimport ( ... dns \"github.com/kitex-contrib/resolver-dns\" \"github.com/cloudwego/kitex/client\" ... ) func main() { ... client, err := echo.NewClient(\"echo\", client.WithResolver(dns.NewDNSResolver())) if err != nil { log.Fatal(err) } ... } ","categories":"","description":"Kitex 框架提供服务注册与发现的扩展，目前已经支持与业界主流注册中心对接。","excerpt":"Kitex 框架提供服务注册与发现的扩展，目前已经支持与业界主流注册中心对接。","ref":"/zh/docs/kitex/tutorials/service-governance/discovery/","tags":"","title":"服务发现"},{"body":"Supported Scenarios  Binary Generic Call: for traffic transit scenario HTTP Mapping Generic Call: for API Gateway scenario Map Mapping Generic Call JSON Mapping Generic Call  Example of Usage 1. Binary Generic Client Usage Application scenario: mid-platform services can forward the received original Thrift protocol packets to the target miscoservice through Binary Forwarding.\n  Client Initialization\nimport ( \"github.com/cloudwego/kitex/client/genericclient\" \"github.com/cloudwego/kitex/pkg/generic\" ) func NewGenericClient(destServiceName string) genericclient.Client { genericCli := genericclient.NewClient(destServiceName, generic.BinaryThriftGeneric()) return genericCli }   Generic Call\nIf you encode by yourself, you have to use Thrift serialization protocol thrift/thrift-binary-protocol.md. Note that you shouldn’t encode original function parameter, but the XXXArgs which wraps function parameters. You can refer to github.com/cloudwego/kitex/generic/generic_test.go.\nKitex provides a thrift codec package github.com/cloudwego/kitex/pkg/utils.NewThriftMessageCodec.\nrc := utils.NewThriftMessageCodec() buf, err := rc.Encode(\"Test\", thrift.CALL, 100, args) // generic call resp, err := genericCli.GenericCall(ctx, \"actualMethod\", buf)   Server Usage It is not necessary to use Client and Server of Binary Generic Call together. Binary Generic Client can access normal Thrift Server if the correct Thrift encoded binary is passed.\nThe server just supports request with a length header like Framed and TTheader, Bufferd Binary is not ok. So the client has to specify the transport protocol with an option, eg: client.WithTransportProtocol(transport.Framed).\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/server/genericserver\" ) func main() { g := generic.BinaryThriftGeneric() svr := genericserver.NewServer(\u0026GenericServiceImpl{}, g) err := svr.Run() if err != nil { panic(err) } } type GenericServiceImpl struct {} // GenericCall ... func (g *GenericServiceImpl) GenericCall(ctx context.Context, method string, request interface{}) (response interface{}, err error) { // request is thrift binary  reqBuf := request.([]byte) // e.g.  fmt.Printf(\"Method: %s\\n\", method)) result := xxx.NewMockTestResult() result.Success = \u0026resp respBuf, err = rc.Encode(mth, thrift.REPLY, seqID, result) return respBuf, nil } 2. HTTP Mapping Generic Call The HTTP Mapping Generic Call is only for the client, and requires Thrift IDL to comply with the interface mapping specification. See the specific specification IDL Definition Specification for Mapping between Thrift and HTTP\nIDL Definition Example namespacegohttpstructReqItem{1:optionali64id(go.tag=\"json:\\\"id\\\"\")2:optionalstringtext}structBizRequest{1:optionali64v_int64(api.query='v_int64',api.vd=\"$\u003e0\u0026\u0026$\u003c200\")2:optionalstringtext(api.body='text')3:optionali32token(api.header='token')4:optionalmap\u003ci64,ReqItem\u003ereq_items_map (api.body='req_items_map')5:optionalReqItemsome(api.body='some')6:optionallist\u003cstring\u003ereq_items(api.query='req_items')7:optionali32api_version(api.path='action')8:optionali64uid(api.path='biz')9:optionallist\u003ci64\u003ecids(api.query='cids')10:optionallist\u003cstring\u003evids(api.query='vids')}structRspItem{1:optionali64item_id2:optionalstringtext}structBizResponse{1:optionalstringT (api.header='T')2:optionalmap\u003ci64,RspItem\u003ersp_items (api.body='rsp_items')3:optionali32v_enum (api.none='')4:optionallist\u003cRspItem\u003ersp_item_list (api.body='rsp_item_list')5:optionali32http_code (api.http_code='')6:optionallist\u003ci64\u003eitem_count (api.header='item_count')}serviceBizService{BizResponseBizMethod1(1:BizRequestreq)(api.get='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true')BizResponseBizMethod2(1:BizRequestreq)(api.post='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true',api.serializer='form')BizResponseBizMethod3(1:BizRequestreq)(api.post='/life/client/:action/:biz/other',api.baseurl='ib.snssdk.com',api.param='true',api.serializer='json')}Generic Call Example  Request  Type: *generic.HTTPRequest\n Response  Type: *generic.HTTPResponse\npackage main import ( \"github.com/cloudwego/kitex/client/genericclient\" \"github.com/cloudwego/kitex/pkg/generic\" ) func main() { // Parse IDL with Local Files \t// YOUR_IDL_PATH thrift file path, eg: ./idl/example.thrift  // includeDirs: specify include path  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } g, err := generic.HTTPThriftGeneric(p) if err != nil { panic(err) } cli, err := genericclient.NewClient(\"destServiceName\", g, opts...) if err != nil { panic(err) } body := map[string]interface{}{ \"text\": \"text\", \"some\": map[string]interface{}{ \"id\": 1, \"text\": \"text\", }, \"req_items_map\": map[string]interface{}{ \"1\": map[string]interface{}{ \"id\": 1, \"text\": \"text\", }, }, } data, err := json.Marshal(body) if err != nil { panic(err) } url := \"http://example.com/1/1?v_int64=1\u0026req_items=item1,item2,itme3\u0026cids=1,2,3\u0026vids=1,2,3\" req, err := http.NewRequest(http.MethodGet, url, bytes.NewBuffer(data)) if err != nil { panic(err) } req.Header.Set(\"token\", \"1\") customReq, err := generic.FromHTTPRequest(req) // customReq *generic.HttpRequest  resp, err := cli.GenericCall(ctx, \"\", customReq) realResp := resp.(*generic.HttpResponse) realResp.Write(w) } Annotation Extension For example, add a xxx.source = 'not_body_struct' annotation to indicate that a certain field itself does not have a mapping to the HTTP request fields, and you need to traverse its subfields to obtain the corresponding value from the HTTP request. The usage is as follows:\nstructRequest{1:optionali64v_int64(api.query='v_int64')2:optionalCommonParamcommon_param (xxx.source='not_body_struct')}structCommonParam{1:optionali64api_version (api.query='api_version')2:optionali32token(api.header='token')}Extension way：\nfunc init() { descriptor.RegisterAnnotation(new(notBodyStruct)) } // Implement descriptor.Annotation type notBodyStruct struct { } func (a * notBodyStruct) Equal(key, value string) bool { return key == \"xxx.source\" \u0026\u0026 value == \"not_body_struct\" } // Support 4 types Handle: HttpMapping, FieldMapping, ValueMapping, Router func (a * notBodyStruct) Handle() interface{} { return newNotBodyStruct } type notBodyStruct struct{} var newNotBodyStruct descriptor.NewHttpMapping = func(value string) descriptor.HttpMapping { return \u0026notBodyStruct{} } // get value from request func (m *notBodyStruct) Request(req *descriptor.HttpRequest, field *descriptor.FieldDescriptor) (interface{}, bool) { return req, true } // set value to response func (m *notBodyStruct) Response(resp *descriptor.HttpResponse, field *descriptor.FieldDescriptor, val interface{}) { } 3. Map Mapping Generic Call Map Mapping Generic Call means that the user can directly construct Map request or response according to the specification, and Kitex will do Thrift codec accordingly.\nBuild Map Kitex will strictly verify the field name and type constructed according to the given IDL. The field name only supports string type corresponding to the Map Key. The type mapping of the field Value is shown in the Type Mapping Table below.\nReturns the Field ID and type that will verify the Response and generate the corresponding Map Key based on the Field Name of the IDL.\nFor response, the Field ID and Type will be verified, and return Map to user corresponding to the IDL.\nType Mapping Table The Mapping between Golang and Thrift:\n   Golang Type Thrift IDL Type     bool bool   int8 i8   int16 i16   int32 i32   int64 i64   float64 double   string string   []byte binary   []interface{} list/set   map[interface{}]interface{} map   map[string]interface{} struct   int32 enum    Example Take the following IDL as an example:\nenumErrorCode{SUCCESS=0FAILURE=1}structInfo{1:map\u003cstring,string\u003eMap2:i64ID}structEchoRequest{1:stringMsg2:i8I83:i16I164:i32I325:i64I646:binaryBinary7:map\u003cstring,string\u003eMap8:set\u003cstring\u003eSet9:list\u003cstring\u003eList10:ErrorCodeErrorCode11:InfoInfo255:optionalBaseBase}The request construction is as follows:\nreq := map[string]interface{}{ \"Msg\": \"hello\", \"I8\": int8(1), \"I16\": int16(1), \"I32\": int32(1), \"I64\": int64(1), \"Binary\": []byte(\"hello\"), \"Map\": map[interface{}]interface{}{ \"hello\": \"world\", }, \"Set\": []interface{}{\"hello\", \"world\"}, \"List\": []interface{}{\"hello\", \"world\"}, \"ErrorCode\": int32(1), \"Info\": map[string]interface{}{ \"Map\": map[interface{}]interface{}{ \"hello\": \"world\", }, \"ID\": int64(232324), }, } Generic Call Example Example IDL:\nbase.thrift\nnamespacepybasenamespacegobasenamespacejavacom.xxx.thrift.basestructTrafficEnv{1:boolOpen=false,2:stringEnv=\"\",}structBase{1:stringLogID=\"\",2:stringCaller=\"\",3:stringAddr=\"\",4:stringClient=\"\",5:optionalTrafficEnvTrafficEnv,6:optionalmap\u003cstring,string\u003eExtra,}structBaseResp{1:stringStatusMessage=\"\",2:i32StatusCode=0,3:optionalmap\u003cstring,string\u003eExtra,}example_service.thrift\ninclude \"base.thrift\" namespace go kitex.test.server struct ExampleReq { 1: required string Msg, 255: base.Base Base, } struct ExampleResp { 1: required string Msg, 255: base.BaseResp BaseResp, } service ExampleService { ExampleResp ExampleMethod(1: ExampleReq req), } Client Usage  Request  Type: map[string]interface{}\n Response  Type: map[string]interface{}\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/client/genericclient\" ) func main() { // Parse IDL with Local Files  // YOUR_IDL_PATH thrift file path, eg:./idl/example.thrift  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } g, err := generic.MapThriftGeneric(p) if err != nil { panic(err) } cli, err := genericclient.NewClient(\"destServiceName\", g, opts...) if err != nil { panic(err) } // 'ExampleMethod' method name must be passed as param  resp, err := cli.GenericCall(ctx, \"ExampleMethod\", map[string]interface{}{ \"Msg\": \"hello\", }) // resp is a map[string]interface{} } Server Usage  Request  Type: map[string]interface{}\n Response  Type: map[string]interface{}\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/server/genericserver\" ) func main() { // Parse IDL with Local Files  // YOUR_IDL_PATH thrift file path,eg: ./idl/example.thrift  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } g, err := generic.MapThriftGeneric(p) if err != nil { panic(err) } svc := genericserver.NewServer(new(GenericServiceImpl), g, opts...) if err != nil { panic(err) } err := svr.Run() if err != nil { panic(err) } // resp is a map[string]interface{} } type GenericServiceImpl struct { } func (g *GenericServiceImpl) GenericCall(ctx context.Context, method string, request interface{}) (response interface{}, err error) { m := request.(map[string]interface{}) fmt.Printf(\"Recv: %v\\n\", m) return map[string]interface{}{ \"Msg\": \"world\", }, nil } 4. JSON Mapping Generic Call JSON Mapping Generic Call means that the user can directly construct JSON string request or response according to the specification, and Kitex will do Thrift codec accordingly.\nBuild JSON Kitex JSON Mapping Generic Call will convert the request parameters according to the given IDL, will not strictly verify the field name and type constructed.\nThe field name only supports string type corresponding to the JSON Field. The type mapping of the field Value is shown in the Type Mapping Table below.\nReturns the Field ID and type that will verify the Response and generate the corresponding JSON Field based on the Field Name of the IDL.\nFor response, the Field ID and Type will be verified, and return JSON string to user corresponding to the IDL.\nType Mapping Table The Mapping between Golang and Thrift:\n   Golang Type Thrift IDL Type     bool bool   int8 i8   int16 i16   int32 i32   int64 i64   float64 double   string string   []byte binary   []interface{} list/set   map[interface{}]interface{} map   map[string]interface{} struct   int32 enum    Example Take the following IDL as an example：\nenumErrorCode{SUCCESS=0FAILURE=1}structInfo{1:map\u003cstring,string\u003eMap2:i64ID}structEchoRequest{1:stringMsg2:i8I83:i16I164:i32I325:i64I646:map\u003cstring,string\u003eMap7:set\u003cstring\u003eSet8:list\u003cstring\u003eList9:ErrorCodeErrorCode10:InfoInfo255:optionalBaseBase}The request construction is as follows：\nreq := { \"Msg\": \"hello\", \"I8\": 1, \"I16\": 1, \"I32\": 1, \"I64\": 1, \"Map\": \"{\\\"hello\\\":\\\"world\\\"}\", \"Set\": [\"hello\", \"world\"], \"List\": [\"hello\", \"world\"], \"ErrorCode\": 1, \"Info\": \"{\\\"Map\\\":\\\"{\\\"hello\\\":\\\"world\\\"}\\\", \\\"ID\\\":232324}\" } Generic Call Example Example IDL ：\nbase.thrift\nnamespacepybasenamespacegobasenamespacejavacom.xxx.thrift.basestructTrafficEnv{1:boolOpen=false,2:stringEnv=\"\",}structBase{1:stringLogID=\"\",2:stringCaller=\"\",3:stringAddr=\"\",4:stringClient=\"\",5:optionalTrafficEnvTrafficEnv,6:optionalmap\u003cstring,string\u003eExtra,}structBaseResp{1:stringStatusMessage=\"\",2:i32StatusCode=0,3:optionalmap\u003cstring,string\u003eExtra,}example_service.thrift\ninclude \"base.thrift\" namespace go kitex.test.server struct ExampleReq { 1: required string Msg, 255: base.Base Base, } struct ExampleResp { 1: required string Msg, 255: base.BaseResp BaseResp, } service ExampleService { ExampleResp ExampleMethod(1: ExampleReq req), } Client Usage  Request  Type：JSON string\n Response  Type：JSON string\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/client/genericclient\" ) func main() { // Parse IDL with Local Files  // YOUR_IDL_PATH thrift file path, eg:./idl/example.thrift  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } g, err := generic.JSONThriftGeneric(p) if err != nil { panic(err) } cli, err := genericclient.NewClient(\"psm\", g, opts...) if err != nil { panic(err) } // 'ExampleMethod' method name must be passed as param  resp, err := cli.GenericCall(ctx, \"ExampleMethod\", \"{\\\"Msg\\\": \\\"hello\\\"}\") // resp is a JSON string } Server Usage  Request  Type：JSON string\n Response  Type：JSON string\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/server/genericserver\" ) func main() { // Parse IDL with Local Files  // YOUR_IDL_PATH thrift file path,eg: ./idl/example.thrift  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } g, err := generic.JSONThriftGeneric(p) if err != nil { panic(err) } svc := genericserver.NewServer(new(GenericServiceImpl), g, opts...) if err != nil { panic(err) } err := svr.Run() if err != nil { panic(err) } // resp is a JSON string } type GenericServiceImpl struct { } func (g *GenericServiceImpl) GenericCall(ctx context.Context, method string, request interface{}) (response interface{}, err error) { // use jsoniter or other json parse sdk to assert request  m := request.(string) fmt.Printf(\"Recv: %v\\n\", m) return \"{\\\"Msg\\\": \\\"world\\\"}\", nil } IDLProvider Generic Call of HTTP/Map/JSON mapping does not require generated code, but requires IDL which need users to provide.\nAt present, Kitex has two IDLProvider implementations. Users can choose to specify the IDL path or pass in IDL content. Of course, you can also expand the generic.DescriptorProvider according to your needs.\nParse IDL with Local Files p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } Parse IDL with Memory All IDLs need to be constructed into a Map, Key is Path, Value is IDL definition, and the usage is as follows:\np, err := generic.NewThriftContentProvider(\"YOUR_MAIN_IDL_CONTENT\", map[string]string{/*YOUR_INCLUDES_IDL_CONTENT*/}) if err != nil { panic(err) } // dynamic update err = p.UpdateIDL(\"YOUR_MAIN_IDL_CONTENT\", map[string]string{/*YOUR_INCLUDES_IDL_CONTENT*/}) if err != nil { // handle err } Simple example (not real IDL, just for minimizing display Path constructs):\npath := \"a/b/main.thrift\" content := ` namespace go kitex.test.server include \"x.thrift\" include \"../y.thrift\" service InboxService {} ` includes := map[string]string{ path: content, \"x.thrift\": \"namespace go kitex.test.server\", \"../y.thrift\": ` namespace go kitex.test.server include \"z.thrift\" `, } p, err := NewThriftContentProvider(path, includes) Absolute Path including path Addressing If you construct an IDL Map for convenience, you can also use an absolute path as a Key through NewThriftContentWithAbsIncludePathProvider .\np, err := generic.NewThriftContentWithAbsIncludePathProvider(\"YOUR_MAIN_IDL_PATH\", \"YOUR_MAIN_IDL_CONTENT\", map[string]string{\"ABS_INCLUDE_PATH\": \"CONTENT\"}) if err != nil { panic(err) } // dynamic update err = p.UpdateIDL(\"YOUR_MAIN_IDL_PATH\", \"YOUR_MAIN_IDL_CONTENT\", map[string]string{/*YOUR_INCLUDES_IDL_CONTENT*/}) if err != nil { // handle err } Simple example (not real IDL, just for minimizing display Path constructs):\npath := \"a/b/main.thrift\" content := ` namespace go kitex.test.server include \"x.thrift\" include \"../y.thrift\" service InboxService {} ` includes := map[string]string{ path: content, \"a/b/x.thrift\": \"namespace go kitex.test.server\", \"a/y.thrift\": ` namespace go kitex.test.server include \"z.thrift\" `, \"a/z.thrift\": \"namespace go kitex.test.server\", } p, err := NewThriftContentWithAbsIncludePathProvider(path, includes) ","categories":"","description":"Generic call is typically used for mid-platform services that do not need generated code, and only Thrift generic call is supported currently.","excerpt":"Generic call is typically used for mid-platform services that do not …","ref":"/docs/kitex/tutorials/advanced-feature/generic-call/","tags":"","title":"Generic Call"},{"body":"支持场景  二进制泛化调用：用于流量中转场景 HTTP 映射泛化调用：用于 API 网关场景 Map 映射泛化调用 JSON 映射泛化调用  使用方式示例 1. 二进制泛化调用 调用端使用 应用场景：比如中台服务，可以通过二进制流转发将收到的原始 Thrift 协议包发给目标服务。\n  初始化 Client\nimport ( \"github.com/cloudwego/kitex/client/genericclient\" \"github.com/cloudwego/kitex/pkg/generic\" ) func NewGenericClient(destServiceName string) genericclient.Client { genericCli := genericclient.NewClient(destServiceName, generic.BinaryThriftGeneric()) return genericCli }   泛化调用\n若自行编码，需要使用 Thrift 编码格式 thrift/thrift-binary-protocol.md。注意，二进制编码不是对原始的 Thrift 请求参数编码，是 method 参数封装的 XXXArgs。可以参考 github.com/cloudwego/kitex/generic/generic_test.go。\nKitex 提供了 thrift 编解码包github.com/cloudwego/kitex/pkg/utils.NewThriftMessageCodec。\nrc := utils.NewThriftMessageCodec() buf, err := rc.Encode(\"Test\", thrift.CALL, 100, args) // generic call resp, err := genericCli.GenericCall(ctx, \"actualMethod\", buf)   服务端使用 二进制泛化 Client 和 Server 并不是配套使用的，Client 传入正确的 Thrift 编码二进制，可以访问普通的 Thrift Server。\n二进制泛化 Server 只支持 Framed 或 TTHeader 请求，不支持 Bufferd Binary，需要 Client 通过 Option 指定，如：client.WithTransportProtocol(transport.Framed)。\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/server/genericserver\" ) func main() { g := generic.BinaryThriftGeneric() svr := genericserver.NewServer(\u0026GenericServiceImpl{}, g) err := svr.Run() if err != nil { panic(err) } } type GenericServiceImpl struct {} // GenericCall ... func (g *GenericServiceImpl) GenericCall(ctx context.Context, method string, request interface{}) (response interface{}, err error) { // request is thrift binary  reqBuf := request.([]byte) // e.g.  fmt.Printf(\"Method: %s\\n\", method)) result := xxx.NewMockTestResult() result.Success = \u0026resp respBuf, err = rc.Encode(mth, thrift.REPLY, seqID, result) return respBuf, nil } 2. HTTP 映射泛化调用 HTTP 映射泛化调用只针对客户端，要求 Thrift IDL 遵从接口映射规范，具体规范见 Thrift-HTTP 映射的 IDL 规范。\nIDL 定义示例 namespacegohttpstructReqItem{1:optionali64id(go.tag=\"json:\\\"id\\\"\")2:optionalstringtext}structBizRequest{1:optionali64v_int64(api.query='v_int64',api.vd=\"$\u003e0\u0026\u0026$\u003c200\")2:optionalstringtext(api.body='text')3:optionali32token(api.header='token')4:optionalmap\u003ci64,ReqItem\u003ereq_items_map (api.body='req_items_map')5:optionalReqItemsome(api.body='some')6:optionallist\u003cstring\u003ereq_items(api.query='req_items')7:optionali32api_version(api.path='action')8:optionali64uid(api.path='biz')9:optionallist\u003ci64\u003ecids(api.query='cids')10:optionallist\u003cstring\u003evids(api.query='vids')}structRspItem{1:optionali64item_id2:optionalstringtext}structBizResponse{1:optionalstringT (api.header='T')2:optionalmap\u003ci64,RspItem\u003ersp_items (api.body='rsp_items')3:optionali32v_enum (api.none='')4:optionallist\u003cRspItem\u003ersp_item_list (api.body='rsp_item_list')5:optionali32http_code (api.http_code='')6:optionallist\u003ci64\u003eitem_count (api.header='item_count')}serviceBizService{BizResponseBizMethod1(1:BizRequestreq)(api.get='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true')BizResponseBizMethod2(1:BizRequestreq)(api.post='/life/client/:action/:biz',api.baseurl='ib.snssdk.com',api.param='true',api.serializer='form')BizResponseBizMethod3(1:BizRequestreq)(api.post='/life/client/:action/:biz/other',api.baseurl='ib.snssdk.com',api.param='true',api.serializer='json')}泛化调用示例  Request  类型：*generic.HTTPRequest\n Response  类型：*generic.HTTPResponse\npackage main import ( \"github.com/cloudwego/kitex/client/genericclient\" \"github.com/cloudwego/kitex/pkg/generic\" ) func main() { // 本地文件 idl 解析  // YOUR_IDL_PATH thrift 文件路径: 举例 ./idl/example.thrift  // includeDirs: 指定 include 路径，默认用当前文件的相对路径寻找 include  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } // 构造 http 类型的泛化调用  g, err := generic.HTTPThriftGeneric(p) if err != nil { panic(err) } cli, err := genericclient.NewClient(\"destServiceName\", g, opts...) if err != nil { panic(err) } // 构造 request（用于测试），实际应用可以直接使用原始的 HTTP Request  body := map[string]interface{}{ \"text\": \"text\", \"some\": map[string]interface{}{ \"id\": 1, \"text\": \"text\", }, \"req_items_map\": map[string]interface{}{ \"1\": map[string]interface{}{ \"id\": 1, \"text\": \"text\", }, }, } data, err := json.Marshal(body) if err != nil { panic(err) } url := \"http://example.com/life/client/1/1?v_int64=1\u0026req_items=item1,item2,itme3\u0026cids=1,2,3\u0026vids=1,2,3\" req, err := http.NewRequest(http.MethodGet, url, bytes.NewBuffer(data)) if err != nil { panic(err) } req.Header.Set(\"token\", \"1\") customReq, err := generic.FromHTTPRequest(req) // 考虑到业务有可能使用第三方 http request，可以自行构造转换函数  // customReq *generic.HttpRequest  // 由于 http 泛化的 method 是通过 bam 规则从 http request 中获取的，所以填空就行  resp, err := cli.GenericCall(ctx, \"\", customReq) realResp := resp.(*generic.HttpResponse) realResp.Write(w) // 写回 ResponseWriter，用于 http 网关 } 注解扩展 比如增加一个 xxx.source='not_body_struct' 注解，表示某个字段本身没有对 HTTP 请求字段的映射，需要遍历其子字段从 HTTP 请求中获取对应的值。使用方式如下：\nstructRequest{1:optionali64v_int64(api.query='v_int64')2:optionalCommonParamcommon_param (xxx.source='not_body_struct')}structCommonParam{1:optionali64api_version (api.query='api_version')2:optionali32token(api.header='token')}扩展方式如下：\nfunc init() { descriptor.RegisterAnnotation(new(notBodyStruct)) } // 实现 descriptor.Annotation type notBodyStruct struct { } func (a * notBodyStruct) Equal(key, value string) bool { return key == \"xxx.source\" \u0026\u0026 value == \"not_body_struct\" } // Handle 目前支持四种类型：HttpMapping, FieldMapping, ValueMapping, Router func (a * notBodyStruct) Handle() interface{} { return newNotBodyStruct } type notBodyStruct struct{} var newNotBodyStruct descriptor.NewHttpMapping = func(value string) descriptor.HttpMapping { return \u0026notBodyStruct{} } // get value from request func (m *notBodyStruct) Request(req *descriptor.HttpRequest, field *descriptor.FieldDescriptor) (interface{}, bool) { // not_body_struct 注解的作用相当于 step into，所以直接返回 req 本身，让当前 filed 继续从 Request 中查询所需要的值  return req, true } // set value to response func (m *notBodyStruct) Response(resp *descriptor.HttpResponse, field *descriptor.FieldDescriptor, val interface{}) { } 3. Map 映射泛化调用 Map 映射泛化调用是指用户可以直接按照规范构造 Map 请求参数或返回，Kitex 会对应完成 Thrift 编解码。\nMap 构造 Kitex 会根据给出的 IDL 严格校验用户构造的字段名和类型，字段名只支持字符串类型对应 Map Key，字段 Value 的类型映射见类型映射表。\n对于Response会校验 Field ID 和类型，并根据 IDL 的 Field Name 生成相应的 Map Key。\n类型映射 Golang 与 Thrift IDL 类型映射如下：\n   Golang 类型 Thrift IDL 类型     bool bool   int8 i8   int16 i16   int32 i32   int64 i64   float64 double   string string   []byte binary   []interface{} list/set   map[interface{}]interface{} map   map[string]interface{} struct   int32 enum    示例 以下面的 IDL 为例：\nenumErrorCode{SUCCESS=0FAILURE=1}structInfo{1:map\u003cstring,string\u003eMap2:i64ID}structEchoRequest{1:stringMsg2:i8I83:i16I164:i32I325:i64I646:binaryBinary7:map\u003cstring,string\u003eMap8:set\u003cstring\u003eSet9:list\u003cstring\u003eList10:ErrorCodeErrorCode11:InfoInfo255:optionalBaseBase}构造请求如下：\nreq := map[string]interface{}{ \"Msg\": \"hello\", \"I8\": int8(1), \"I16\": int16(1), \"I32\": int32(1), \"I64\": int64(1), \"Binary\": []byte(\"hello\"), \"Map\": map[interface{}]interface{}{ \"hello\": \"world\", }, \"Set\": []interface{}{\"hello\", \"world\"}, \"List\": []interface{}{\"hello\", \"world\"}, \"ErrorCode\": int32(1), \"Info\": map[string]interface{}{ \"Map\": map[interface{}]interface{}{ \"hello\": \"world\", }, \"ID\": int64(232324), }, } 泛化调用示例 示例 IDL ：\nbase.thrift\nnamespacepybasenamespacegobasenamespacejavacom.xxx.thrift.basestructTrafficEnv{1:boolOpen=false,2:stringEnv=\"\",}structBase{1:stringLogID=\"\",2:stringCaller=\"\",3:stringAddr=\"\",4:stringClient=\"\",5:optionalTrafficEnvTrafficEnv,6:optionalmap\u003cstring,string\u003eExtra,}structBaseResp{1:stringStatusMessage=\"\",2:i32StatusCode=0,3:optionalmap\u003cstring,string\u003eExtra,}example_service.thrift\ninclude \"base.thrift\" namespace go kitex.test.server struct ExampleReq { 1: required string Msg, 255: base.Base Base, } struct ExampleResp { 1: required string Msg, 255: base.BaseResp BaseResp, } service ExampleService { ExampleResp ExampleMethod(1: ExampleReq req), } 客户端使用  Request  类型：map[string]interface{}\n Response  类型：map[string]interface{}\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/client/genericclient\" ) func main() { // 本地文件 idl 解析  // YOUR_IDL_PATH thrift 文件路径: 举例 ./idl/example.thrift  // includeDirs: 指定 include 路径，默认用当前文件的相对路径寻找 include  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } // 构造 map 请求和返回类型的泛化调用  g, err := generic.MapThriftGeneric(p) if err != nil { panic(err) } cli, err := genericclient.NewClient(\"destServiceName\", g, opts...) if err != nil { panic(err) } // 'ExampleMethod' 方法名必须包含在 idl 定义中  resp, err := cli.GenericCall(ctx, \"ExampleMethod\", map[string]interface{}{ \"Msg\": \"hello\", }) // resp is a map[string]interface{} } 服务端使用  Request  类型：map[string]interface{}\n Response  类型：map[string]interface{}\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/server/genericserver\" ) func main() { // 本地文件 idl 解析  // YOUR_IDL_PATH thrift 文件路径: e.g. ./idl/example.thrift  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } // 构造 map 请求和返回类型的泛化调用  g, err := generic.MapThriftGeneric(p) if err != nil { panic(err) } svc := genericserver.NewServer(new(GenericServiceImpl), g, opts...) if err != nil { panic(err) } err := svr.Run() if err != nil { panic(err) } // resp is a map[string]interface{} } type GenericServiceImpl struct { } func (g *GenericServiceImpl) GenericCall(ctx context.Context, method string, request interface{}) (response interface{}, err error) { m := request.(map[string]interface{}) fmt.Printf(\"Recv: %v\\n\", m) return map[string]interface{}{ \"Msg\": \"world\", }, nil } 4. JSON 映射泛化调用 JSON 映射泛化调用是指用户可以直接按照规范构造 JSON String 请求参数或返回，Kitex 会对应完成 Thrift 编解码。\nJSON 构造 Kitex 与 MAP 泛化调用严格校验用户构造的字段名和类型不同，JSON 泛化调用会根据给出的 IDL 对用户的请求参数进行转化，无需用户指定明确的类型，如 int32 或 int64。\n对于 Response 会校验 Field ID 和类型，并根据 IDL 的 Field Name 生成相应的 JSON Field。\n类型映射 Golang 与 Thrift IDL 类型映射如下：\n   Golang 类型 Thrift IDL 类型     bool bool   int8 i8   int16 i16   int32 i32   int64 i64   float64 double   string string   []byte binary   []interface{} list/set   map[interface{}]interface{} map   map[string]interface{} struct   int32 enum    示例 以下面的 IDL 为例：\nenumErrorCode{SUCCESS=0FAILURE=1}structInfo{1:map\u003cstring,string\u003eMap2:i64ID}structEchoRequest{1:stringMsg2:i8I83:i16I164:i32I325:i64I646:map\u003cstring,string\u003eMap7:set\u003cstring\u003eSet8:list\u003cstring\u003eList9:ErrorCodeErrorCode10:InfoInfo255:optionalBaseBase}构造请求如下：\nreq := { \"Msg\": \"hello\", \"I8\": 1, \"I16\": 1, \"I32\": 1, \"I64\": 1, \"Map\": \"{\\\"hello\\\":\\\"world\\\"}\", \"Set\": [\"hello\", \"world\"], \"List\": [\"hello\", \"world\"], \"ErrorCode\": 1, \"Info\": \"{\\\"Map\\\":\\\"{\\\"hello\\\":\\\"world\\\"}\\\", \\\"ID\\\":232324}\" } 泛化调用示例 示例 IDL ：\nbase.thrift\nnamespacepybasenamespacegobasenamespacejavacom.xxx.thrift.basestructTrafficEnv{1:boolOpen=false,2:stringEnv=\"\",}structBase{1:stringLogID=\"\",2:stringCaller=\"\",3:stringAddr=\"\",4:stringClient=\"\",5:optionalTrafficEnvTrafficEnv,6:optionalmap\u003cstring,string\u003eExtra,}structBaseResp{1:stringStatusMessage=\"\",2:i32StatusCode=0,3:optionalmap\u003cstring,string\u003eExtra,}example_service.thrift\ninclude \"base.thrift\" namespace go kitex.test.server struct ExampleReq { 1: required string Msg, 255: base.Base Base, } struct ExampleResp { 1: required string Msg, 255: base.BaseResp BaseResp, } service ExampleService { ExampleResp ExampleMethod(1: ExampleReq req), } 客户端使用  Request  类型：JSON string\n Response  类型：JSON string\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/client/genericclient\" ) func main() { // 本地文件 idl 解析  // YOUR_IDL_PATH thrift 文件路径: 举例 ./idl/example.thrift  // includeDirs: 指定 include 路径，默认用当前文件的相对路径寻找 include  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } // 构造 JSON 请求和返回类型的泛化调用  g, err := generic.JSONThriftGeneric(p) if err != nil { panic(err) } cli, err := genericclient.NewClient(\"destServiceName\", g, opts...) if err != nil { panic(err) } // 'ExampleMethod' 方法名必须包含在 idl 定义中  resp, err := cli.GenericCall(ctx, \"ExampleMethod\", \"{\\\"Msg\\\": \\\"hello\\\"}\") // resp is a JSON string } 服务端使用  Request  类型：JSON string\n Response  类型：JSON string\npackage main import ( \"github.com/cloudwego/kitex/pkg/generic\" \"github.com/cloudwego/kitex/server/genericserver\" ) func main() { // 本地文件 idl 解析  // YOUR_IDL_PATH thrift 文件路径: e.g. ./idl/example.thrift  p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } // 构造 JSON 请求和返回类型的泛化调用  g, err := generic.JSONThriftGeneric(p) if err != nil { panic(err) } svc := genericserver.NewServer(new(GenericServiceImpl), g, opts...) if err != nil { panic(err) } err := svr.Run() if err != nil { panic(err) } // resp is a JSON string } type GenericServiceImpl struct { } func (g *GenericServiceImpl) GenericCall(ctx context.Context, method string, request interface{}) (response interface{}, err error) { // use jsoniter or other json parse sdk to assert request  m := request.(string) fmt.Printf(\"Recv: %v\\n\", m) return \"{\\\"Msg\\\": \\\"world\\\"}\", nil } IDLProvider HTTP/Map/JSON 映射的泛化调用虽然不需要生成代码，但需要使用者提供 IDL。\n目前 Kitex 有两种 IDLProvider 实现，使用者可以选择指定 IDL 路径，也可以选择传入 IDL 内容。当然也可以根据需求自行扩展 generci.DescriptorProvider。\n基于本地文件解析 IDL p, err := generic.NewThriftFileProvider(\"./YOUR_IDL_PATH\") if err != nil { panic(err) } 基于内存解析 IDL 所有 IDL 需要构造成 Map ，Key 是 Path，Value 是 IDL 定义，使用方式如下：\np, err := generic.NewThriftContentProvider(\"YOUR_MAIN_IDL_CONTENT\", map[string]string{/*YOUR_INCLUDES_IDL_CONTENT*/}) if err != nil { panic(err) } // dynamic update err = p.UpdateIDL(\"YOUR_MAIN_IDL_CONTENT\", map[string]string{/*YOUR_INCLUDES_IDL_CONTENT*/}) if err != nil { // handle err } 简单实例（为最小化展示 Path 构造，并非真实的 IDL）：\npath := \"a/b/main.thrift\" content := ` namespace go kitex.test.server include \"x.thrift\" include \"../y.thrift\" service InboxService {} ` includes := map[string]string{ path: content, \"x.thrift\": \"namespace go kitex.test.server\", \"../y.thrift\": ` namespace go kitex.test.server include \"z.thrift\" `, } p, err := NewThriftContentProvider(path, includes) 支持绝对路径的 include path 寻址 若为方便构造 IDL Map，也可以通过 NewThriftContentWithAbsIncludePathProvider 使用绝对路径作为 Key。\np, err := generic.NewThriftContentWithAbsIncludePathProvider(\"YOUR_MAIN_IDL_PATH\", \"YOUR_MAIN_IDL_CONTENT\", map[string]string{\"ABS_INCLUDE_PATH\": \"CONTENT\"}) if err != nil { panic(err) } // dynamic update err = p.UpdateIDL(\"YOUR_MAIN_IDL_PATH\", \"YOUR_MAIN_IDL_CONTENT\", map[string]string{/*YOUR_INCLUDES_IDL_CONTENT*/}) if err != nil { // handle err } 简单实例（为最小化展示 Path 构造，并非真实的 IDL）：\npath := \"a/b/main.thrift\" content := ` namespace go kitex.test.server include \"x.thrift\" include \"../y.thrift\" service InboxService {} ` includes := map[string]string{ path: content, \"a/b/x.thrift\": \"namespace go kitex.test.server\", \"a/y.thrift\": ` namespace go kitex.test.server include \"z.thrift\" `, \"a/z.thrift\": \"namespace go kitex.test.server\", } p, err := NewThriftContentWithAbsIncludePathProvider(path, includes) ","categories":"","description":"Kitex 目前仅支持 Thrift 泛化调用，通常用于不需要生成代码的中台服务。","excerpt":"Kitex 目前仅支持 Thrift 泛化调用，通常用于不需要生成代码的中台服务。","ref":"/zh/docs/kitex/tutorials/advanced-feature/generic-call/","tags":"","title":"泛化调用"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/kitex/tutorials/basic-feature/","tags":"","title":"Basic Feature"},{"body":"Introduction Middleware is the major method to extend the Kitex framework. Most of the Kitex-based extensions and secondary development features are based on middleware.\nBefore extending, it is important to remember two principles:\n Middleware and Suit are only allowed to be set before initializing Server and Client, do not allow modified dynamically. Middlewares are executed in the order in which they were added.  Middleware is defined in pkg/endpoint/endpoint.go, the two major types are:\n Endpoint is a function that accepts ctx, req, resp and returns err, see the example below. Middleware (aka MW) is also a function that receives and returns an Endpoint. 3.  In fact, a middleware is a function whose input and output are both Endpoint, which ensures the transparency to the application, and the application itself does not need to know whether it is decorated by the middleware. Due to this feature, middleware can be nested.\nMiddleware should be used in series, by calling the next, you can get the response (if any) and err returned by the latter middleware, and then process accordingly and return the err to the former middleware (be sure to check the err of next function returned, do not swallow the err) or set the response.\nClient-side Middleware There are two ways to add client-side middleware:\n client.WithMiddleware adds a middleware to the current client, executes after service circuit breaker middleware and timeout middleware. client.WithInstanceMW adds a middleware to the current client and executes after service discovery and load balancing. If there has instance circuit breaker, this middleware will execute after instance circuit breaker. (if Proxy is used, it will not be called).  Note that the above functions should all be passed as Options when creating the client.\nThe order of client middleware calls:\n the middleware set by client.WithMiddleware ACLMiddleware (ResolveMW + client.WithInstanceMW + PoolMW / DialerMW) / ProxyMW IOErrorHandleMW  The order in which the calls are returned is reversed.\nThe order of all middleware calls on the client side can be seen in client/client.go.\nContext Middleware Context middleware is also a client-side middleware, but the difference is that it is controlled by ctx whether to inject the middleware or which middleware should be injected.\nThe introduction of Context Middleware is to provide a way to globally or dynamically inject Client Middleware. Typical usage scenario is to count which downstreams are called in this call-chain.\nContext Middleware only exists in the context call-chain, which can avoid problems caused by third-party libraries injecting uncontrollable middleware.\nMiddleware can be injected into ctx with ctx = client.WithContextMiddlewares(ctx, mw) .\nNote: Context Middleware will be executed before Client Middleware.\nServer-side Middleware The server-side middleware is different from the client-side.\nYou can add server-side middleware via server.WithMiddleware, and passing Option when creating the server.\nThe order of server-side middleware calls can be found in server/server.go.\nExample You can see how to use the middleware in the following example.\nIf you have a requirement to print out the request and the response, we can write the following MW:\nfunc PrintRequestResponseMW(next endpoint.Endpoint) endpoint.Endpoint { return func(ctx context.Context, request, response interface{}) error { fmt.Printf(\"request: %v\\n\", request) err := next(ctx, request, response) fmt.Printf(\"response: %v\", response) return err } } Assuming we are at Server side, we can use server.WithMiddleware(PrintRequestResponseMW) to use this MW.\n**The above scenario is only for example, not for production, there will be performance issues. **\nAttention If RPCInfo is used in a custom middleware, please pay attention to that RPCInfo will be recycled after the rpc is finished. If you start a goroutine in the middleware to modify RPCInfo, there will have some problems.\n","categories":"","description":"","excerpt":"Introduction Middleware is the major method to extend the Kitex …","ref":"/docs/kitex/tutorials/framework-exten/middleware/","tags":"","title":"Middleware Extensions"},{"body":"Protocols The table below is message types, codecs and transports supported by Kitex.\n   Message Types Codec Transport     PingPong Thrift / Protobuf TTHeader / HTTP2(gRPC)   Oneway Thrift TTHeader   Streaming Protobuf HTTP2(gRPC)     PingPong: the client always waits for a response after sending a request Oneway: the client does not expect any response after sending a request Streaming: the client can send one or more requests while receiving one or more responses.  Thrift When the codec is thrift, Kitex supports PingPong and Oneway. The streaming on thrift is under development.\nExample Given an IDL:\nnamespacegoechostructRequest{1:stringMsg}structResponse{1:stringMsg}serviceEchoService{ResponseEcho(1:Requestreq);// pingpong method onewayvoidVisitOneway(1:Requestreq);// oneway method }The layout of generated code might be:\n. └── kitex_gen └── echo ├── echo.go ├── echoservice │ ├── client.go │ ├── echoservice.go │ ├── invoker.go │ └── server.go └── k-echo.go The handler code in server side might be:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" ) type handler struct {} func (handler) Echo(ctx context.Context, req *echo.Request) (r *echo.Response, err error) { //...  return \u0026echo.Response{ Msg: \"world\" } } func (handler) VisitOneway(ctx context.Context, req *echo.Request) (err error) { //...  return nil } func main() { svr, err := echoservice.NewServer(handler{}) if err != nil { panic(err) } svr.Run() } PingPong The code in client side might be:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" ) func main() { cli, err := echoservice.NewClient(\"destServiceName\") if err != nil { panic(err) } req := echo.NewRequest() req.Msg = \"hello\" resp, err := cli.Echo(req) if err != nil { panic(err) } // resp.Msg == \"world\" } Oneway The code in client side might be:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" ) func main() { cli, err := echoservice.NewClient(\"destServiceName\") if err != nil { panic(err) } req := echo.NewRequest() req.Msg = \"hello\" err = cli.VisitOneway(req) if err != nil { panic(err) } // no response return } Protobuf Kitex supports two kind of protocols that carries Protobuf payload:\n Kitex Protobuf  Only supports the PingPong type of messages. If any streaming method is defined in the IDL, the protocol will switch to gRPC.   The gRPC Protocol  The protocol that shipped with gRPC.    Example The following is an example showing how to use the streaming types.\nGiven an IDL:\nsyntax = \"proto3\";option go_package = \"echo\";package echo;message Request { string msg = 1;}message Response { string msg = 1;}service EchoService { rpc ClientSideStreaming(stream Request) returns (Response) {} // client streaming  rpc ServerSideStreaming(Request) returns (stream Response) {} // server streaming  rpc BidiSideStreaming(stream Request) returns (stream Response) {} // bidirectional streaming }The generated code might be:\n. └── kitex_gen └── echo ├── echo.pb.go └── echoservice ├── client.go ├── echoservice.go ├── invoker.go └── server.go The handler code in server side:\npackage main import ( \"sync\" \"xx/echo\" \"xx/echo/echoservice\" } type handler struct{} func (handler) ClientSideStreaming(stream echo.EchoService_ClientSideStreamingServer) (err error) { for { req, err := stream.Recv() if err != nil { return err } } } func (handler) ServerSideStreaming(req *echo.Request, stream echo.EchoService_ServerSideStreamingServer) (err error) { _ = req for { resp := \u0026echo.Response{Msg: \"world\"} if err := stream.Send(resp); err != nil { return err } } } func (handler) BidiSideStreaming(stream echo.EchoService_BidiSideStreamingServer) (err error) { var once sync.Once go func() { for { req, err2 := stream.Recv() log.Println(\"received:\", req.GetMsg()) if err2 != nil { once.Do(func() { err = err2 }) break } } }() for { resp := \u0026echo.Response{Msg: \"world\"} if err2 := stream.Send(resp); err2 != nil { once.Do(func() { err = err2 }) return } } return } func main() { svr, err := echoservice.NewServer(handler{}) if err != nil { panic(err) } svr.Run() } Streaming ClientSideStreaming:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" } func main() { cli, err := echoservice.NewClient(\"destServiceName\") if err != nil { panic(err) } cliStream, err := cli.ClientSideStreaming(context.Background()) if err != nil { panic(err) } for { req := \u0026echo.Request{Msg: \"hello\"} if err := cliStream.Send(req); err != nil { panic(err) } } } ServerSideStreaming:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" } func main() { cli, err := echoseervice.NewClient(\"destServiceName\") if err != nil { panic(err) } req := \u0026echo.Request{Msg: \"hello\"} svrStream, err := cli.ServerSideStreaming(context.Background(), req) if err != nil { panic(err) } for { resp, err := svrStream.Recv() if err != nil { panic(err) } // resp.Msg == \"world\"  } } BidiSideStreaming:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" } func main() { cli, err := echoseervice.NewClient(\"destServiceName\") if err != nil { panic(err) } req := \u0026echo.Request{Msg: \"hello\"} bidiStream, err := cli.BidiSideStreaming(context.Background()) if err != nil { panic(err) } go func() { for { req := \u0026echo.Request{Msg: \"hello\"} err := bidiStream.Send(req) if err != nil { panic(err) } } }() for { resp, err := bidiStream.Recv() if err != nil { panic(err) } // resp.Msg == \"world\"  } } ","categories":"","description":"Kitex supports message types of PingPong、Oneway、Streaming.","excerpt":"Kitex supports message types of PingPong、Oneway、Streaming.","ref":"/docs/kitex/tutorials/basic-feature/message_type/","tags":"","title":"Message Types"},{"body":"介绍 Middleware 是扩展 Kitex 框架的一个主要的方法，大部分基于 Kitex 的扩展和二次开发的功能都是基于 middleware 来实现的。\n在扩展过程中，要记得两点原则：\n 中间件和套件都只允许在初始化 Server、Client 的时候设置，不允许动态修改。 Middleware 是按照添加的先后顺序执行的。  Kitex 的中间件定义在 pkg/endpoint/endpoint.go 中，其中最主要的是两个类型：\n Endpoint 是一个函数，接受 ctx、req、resp，返回 err，可参考下方示例； Middleware（下称 MW）也是一个函数，接收同时返回一个 Endpoint。  实际上一个中间件就是一个输入是 Endpoint，输出也是 Endpoint 的函数，这样保证了对应用的透明性，应用本身并不会知道是否被中间件装饰的。由于这个特性，中间件可以嵌套使用。\n中间件是串连使用的，通过调用传入的 next，可以得到后一个中间件返回的 response（如果有）和 err，据此作出相应处理后，向前一个中间件返回 err（务必判断 next err 返回，勿吞了 err）或者设置 response。\n客户端中间件 有两种方法可以添加客户端中间件：\n client.WithMiddleware 对当前 client 增加一个中间件，在 Service 熔断和超时中间件之后执行； client.WithInstanceMW 对当前 client 增加一个中间件，在服务发现、负载均衡之后执行，如果有实例熔断器，会在实例熔断器后执行（如果使用了 Proxy 则不会调用到，如 Mesh 模式下）。  注意，上述函数都应该在创建 client 时作为传入的 Option。\n客户端中间件调用顺序 :\n client.WithMiddleware 设置的中间件 ACLMiddleware (ResolveMW + client.WithInstanceMW + PoolMW / DialerMW) / ProxyMW IOErrorHandleMW  调用返回的顺序则相反。\n客户端所有中间件的调用顺序可以看 client/client.go。\nContext 中间件 Context 中间件本质上也是一种客户端中间件，但是区别是，其由 ctx 来控制是否注入以及注入哪些中间件。\nContext 中间件的引入是为了提供一种能够全局或者动态注入 Client 中间件的方法，典型的使用场景比如统计某个接口调用了哪些下游。但是这种全局性设置只会在 ctx 调用链中存在，可以规避第三方库注入不可控的中间件引起的问题。\n可以通过 ctx = client.WithContextMiddlewares(ctx, mw) 来向 ctx 注入中间件。\n注意：Context 中间件会在 Client 中间件之前执行。\n服务端中间件 服务端的中间件和客户端有一定的区别。\n可以通过 server.WithMiddleware 来增加 server 端的中间件，使用方式和 client 一致，在创建 server 时通过 Option 传入。\n总的服务端中间件的调用顺序可以看 server/server.go。\n示例 我们可以通过以下这个例子来看一下如何使用中间件。\n假如我们现在有需求，需要在请求前打印出 request 内容，再请求后打印出 response 内容，可以编写如下的 MW：\nfunc PrintRequestResponseMW(next endpoint.Endpoint) endpoint.Endpoint { return func(ctx context.Context, request, response interface{}) error { fmt.Printf(\"request: %v\\n\", request) err := next(ctx, request, response) fmt.Printf(\"response: %v\", response) return err } } 假设我们是 Server 端，就可以使用 server.WithMiddleware(PrintRequestResponseMW) 来使用这个 MW 了。\n以上方案仅为示例，不可用于生产，会有性能问题。\n注意事项 如果自定义 middleware 中用到了 RPCInfo，要注意 RPCInfo 在 rpc 结束之后会被回收，所以如果在 middleware 中起了 goroutine 操作 RPCInfo 会出问题，不能这么做。\n","categories":"","description":"","excerpt":"介绍 Middleware 是扩展 Kitex 框架的一个主要的方法，大部分基于 Kitex …","ref":"/zh/docs/kitex/tutorials/framework-exten/middleware/","tags":"","title":"Middleware 扩展"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/kitex/tutorials/basic-feature/","tags":"","title":"基本特性"},{"body":"协议支持 目前 Kitex 支持的消息类型、编解码协议和传输协议\n   消息类型 编码协议 传输协议     PingPong Thrift / Protobuf TTHeader / HTTP2(gRPC)   Oneway Thrift TTHeader   Streaming Protobuf HTTP2(gRPC)     PingPong：客户端发起一个请求后会等待一个响应才可以进行下一次请求 Oneway：客户端发起一个请求后不等待一个响应 Streaming：客户端发起一个或多个请求 , 等待一个或多个响应  Thrift 目前 Thrift 支持 PingPong 和 Oneway。Kitex 计划支持 Thrift Streaming。\nExample IDL 定义 :\nnamespacegoechostructRequest{1:stringMsg}structResponse{1:stringMsg}serviceEchoService{ResponseEcho(1:Requestreq);// pingpong method onewayvoidVisitOneway(1:Requestreq);// oneway method }生成的代码组织结构 :\n. └── kitex_gen └── echo ├── echo.go ├── echoservice │ ├── client.go │ ├── echoservice.go │ ├── invoker.go │ └── server.go └── k-echo.go Server 的处理代码形如 :\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" ) type handler struct {} func (handler) Echo(ctx context.Context, req *echo.Request) (r *echo.Response, err error) { //...  return \u0026echo.Response{ Msg: \"world\" } } func (handler) VisitOneway(ctx context.Context, req *echo.Request) (err error) { //...  return nil } func main() { svr, err := echoservice.NewServer(handler{}) if err != nil { panic(err) } svr.Run() } PingPong Client 侧代码 :\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" ) func main() { cli, err := echoservice.NewClient(\"destServiceName\") if err != nil { panic(err) } req := echo.NewRequest() req.Msg = \"hello\" resp, err := cli.Echo(req) if err != nil { panic(err) } // resp.Msg == \"world\" } Oneway Client 侧代码 :\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" ) func main() { cli, err := echoservice.NewClient(\"destServiceName\") if err != nil { panic(err) } req := echo.NewRequest() req.Msg = \"hello\" err = cli.VisitOneway(req) if err != nil { panic(err) } // no response return } Protobuf Kitex 支持两种承载 Protobuf 负载的协议：\n Kitex Protobuf  只支持 PingPong，若 IDL 定义了 stream 方法，将默认使用 gRPC 协议   gRPC 协议  可以与 gRPC 互通，与 gRPC service 定义相同，支持 Unary(PingPong)、 Streaming 调用    Example 以下给出 Streaming 的使用示例。\nIDL 定义 :\nsyntax = \"proto3\";option go_package = \"echo\";package echo;message Request { string msg = 1;}message Response { string msg = 1;}service EchoService { rpc ClientSideStreaming(stream Request) returns (Response) {} // 客户端侧 streaming  rpc ServerSideStreaming(Request) returns (stream Response) {} // 服务端侧 streaming  rpc BidiSideStreaming(stream Request) returns (stream Response) {} // 双向流 }生成的代码组织结构 :\n. └── kitex_gen └── echo ├── echo.pb.go └── echoservice ├── client.go ├── echoservice.go ├── invoker.go └── server.go Server 侧代码 :\npackage main import ( \"sync\" \"xx/echo\" \"xx/echo/echoservice\" } type handler struct{} func (handler) ClientSideStreaming(stream echo.EchoService_ClientSideStreamingServer) (err error) { for { req, err := stream.Recv() if err != nil { return err } } } func (handler) ServerSideStreaming(req *echo.Request, stream echo.EchoService_ServerSideStreamingServer) (err error) { _ = req for { resp := \u0026echo.Response{Msg: \"world\"} if err := stream.Send(resp); err != nil { return err } } } func (handler) BidiSideStreaming(stream echo.EchoService_BidiSideStreamingServer) (err error) { var once sync.Once go func() { for { req, err2 := stream.Recv() log.Println(\"received:\", req.GetMsg()) if err2 != nil { once.Do(func() { err = err2 }) break } } }() for { resp := \u0026echo.Response{Msg: \"world\"} if err2 := stream.Send(resp); err2 != nil { once.Do(func() { err = err2 }) return } } return } func main() { svr, err := echoservice.NewServer(handler{}) if err != nil { panic(err) } svr.Run() } Streaming ClientSideStreaming:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" } func main() { cli, err := echoservice.NewClient(\"destServiceName\") if err != nil { panic(err) } cliStream, err := cli.ClientSideStreaming(context.Background()) if err != nil { panic(err) } for { req := \u0026echo.Request{Msg: \"hello\"} if err := cliStream.Send(req); err != nil { panic(err) } } } ServerSideStreaming:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" } func main() { cli, err := echoservice.NewClient(\"destServiceName\") if err != nil { panic(err) } req := \u0026echo.Request{Msg: \"hello\"} svrStream, err := cli.ServerSideStreaming(context.Background(), req) if err != nil { panic(err) } for { resp, err := svrStream.Recv() if err != nil { panic(err) } // resp.Msg == \"world\"  } } BidiSideStreaming:\npackage main import ( \"xx/echo\" \"xx/echo/echoservice\" } func main() { cli, err := echoservice.NewClient(\"destServiceName\") if err != nil { panic(err) } req := \u0026echo.Request{Msg: \"hello\"} bidiStream, err := cli.BidiSideStreaming(context.Background()) if err != nil { panic(err) } go func() { for { req := \u0026echo.Request{Msg: \"hello\"} err := bidiStream.Send(req) if err != nil { panic(err) } } }() for { resp, err := bidiStream.Recv() if err != nil { panic(err) } // resp.Msg == \"world\"  } } ","categories":"","description":"Kitex 支持 PingPong、Oneway、Streaming 消息类型。","excerpt":"Kitex 支持 PingPong、Oneway、Streaming 消息类型。","ref":"/zh/docs/kitex/tutorials/basic-feature/message_type/","tags":"","title":"消息类型"},{"body":"cwgo is a command-line tool provided by CloudWeGo for generating code. Currently cwgo supports the IDL of thrift and protobuf, and supports the code generation of MVC Layout, Server, Client and DB.\nDependency and Run Mode The cwgo tool does not directly generate code, but calls the generation function of the corresponding tool after the template is constructed.\ncwgo | | HTTP server/client |-----------\u003e hz | RPC server/client |-----------\u003e kitex | DB ------------\u003e gorm/gen Therefore, the precautions of corresponding tools also need to be followed, such as kitex precautions and generate HTTP code Notes on hz.\nUsing cwgo supports two generation methods of interactive command line and static command line. And weakened the concept of new and update, just input the previous command directly when updating.\nInteractive command line The interactive command line supports one call to generate all codes, such as Server, Client, and DB, which meets the needs of most users. Users only need to enter information according to the prompts.\nSyntax: cwgo init\nAfter executing cwgo init, it will first ask for the type of project that needs to be generated, and multiple choices are supported. As shown in the figure below, server and client are selected\nAfter pressing Enter, the server and client information will be asked in turn. Proceed as follows\n  Select the service type, RPC or HTTP. single choice.\n  Enter a service name. required.\n  Enter the go module name. Required outside GOPATH, not required inside GOPATH.\n  Enter the idl path. required.\n  Whether to use the default configuration to generate the project\n Default configuration: no service discovery component, no other parameters Non-default configuration: select the service discovery component; enter the parameters passed to the generation tool    The questions asked by the client are roughly the same as those asked by the server. The difference is that the number of generated clients will be asked first, and then the information of each client will be input in a loop.\nThe information requested by db is:\n Select the database type. radio Enter the database DSN. required Choose whether to use the default configuration to generate the project. If you choose No, you will be asked to enter the parameters to pass to the build tool  For parameters passed to the tool, refer to documentation for hz and documentation ://www.cloudwego.io/docs/kitex/tutorials/code-gen/code_generation/).\nStatic command line Command description $ cwgo -h NAME: cwgo - All in one tools for CloudWeGo USAGE: cwgo [global options] command [command options] [arguments...] COMMANDS: init interactive command line server generates RPC or HTTP Server client generates RPC or HTTP Client model generate DB Model fallback Fallback to kitex or hz tools GLOBAL OPTIONS: --verbose turn on verbose logging mode --version, -v print tool version Server and Client commands --service specify service name --type specify build type --module specifies the generated module name --idl specify IDL file path --out_dir specify the output path --template specifies the layout template path --registry specifies the service registry component --proto_search_path Add IDL search path, only valid for pb --pass value parameter passed to hz and kitex pass parameter description:\nTo pass the handler_dir' parameter of hz`, you should enter –pass “–handler_dir ./handler”\nParameters passed to the tool hz refer to Documentation, Kitex reference documentation.\nModel commands --dsn specify database DSN --db_type specifies the database type --out_dir specifies the output folder, default biz/dao/query --out_file specifies the output file name, default gen.go --tables specify database table names --unittest Whether to generate a unit test, the default is not generated --only_model Whether to only generate model code, the default is off --model_pkg specify model package name --nullable When the field is null, specify whether to generate a pointer, the default is off --type_tag Whether to generate gorm column type tag for the field, default is not generated --index_tag Whether to generate gorm index tag for the field, default is not generated Common commands Server\ncwgo server --type {{RPC/HTTP}} --idl {{path/to/IDL_file.thrift}} --service {{svc_name}} Client\ncwgo client --type {{RPC/HTTP}} --idl {{path/to/IDL_file.thrift}} --service {{svc_name}} model\ncwgo model --db_type mysql --dsn \"gorm:gorm@tcp(localhost:9910)/gorm?charset=utf8\u0026parseTime=True\u0026loc=Local\" ","categories":"","description":"","excerpt":"cwgo is a command-line tool provided by CloudWeGo for generating code. …","ref":"/docs/cwgo/tutorials/cli/","tags":"","title":"CLI"},{"body":"第5期周报\n","categories":"","description":"","excerpt":"第5期周报\n","ref":"/zh/community/weekly_report/5th/","tags":"","title":"CloudWeGo 第05期周报"},{"body":"第6期周报\n","categories":"","description":"","excerpt":"第6期周报\n","ref":"/zh/community/weekly_report/6th/","tags":"","title":"CloudWeGo 第06期周报"},{"body":"第7期周报\n","categories":"","description":"","excerpt":"第7期周报\n","ref":"/zh/community/weekly_report/7th/","tags":"","title":"CloudWeGo 第07期周报"},{"body":"第8期周报\n","categories":"","description":"","excerpt":"第8期周报\n","ref":"/zh/community/weekly_report/8th/","tags":"","title":"CloudWeGo 第08期周报"},{"body":"第9期周报\n","categories":"","description":"","excerpt":"第9期周报\n","ref":"/zh/community/weekly_report/9th/","tags":"","title":"CloudWeGo 第09期周报"},{"body":"第10期周报\n","categories":"","description":"","excerpt":"第10期周报\n","ref":"/zh/community/weekly_report/10th/","tags":"","title":"CloudWeGo 第10期周报"},{"body":"第11期周报\n","categories":"","description":"","excerpt":"第11期周报\n","ref":"/zh/community/weekly_report/11th/","tags":"","title":"CloudWeGo 第11期周报"},{"body":"第 12 期周报\n","categories":"","description":"","excerpt":"第 12 期周报\n","ref":"/zh/community/weekly_report/12th/","tags":"","title":"CloudWeGo 第12期周报"},{"body":"第 13 期周报\n","categories":"","description":"","excerpt":"第 13 期周报\n","ref":"/zh/community/weekly_report/13th/","tags":"","title":"CloudWeGo 第13期周报"},{"body":"第 14 期周报\n","categories":"","description":"","excerpt":"第 14 期周报\n","ref":"/zh/community/weekly_report/14th/","tags":"","title":"CloudWeGo 第14期周报"},{"body":"第 15 期周报\n","categories":"","description":"","excerpt":"第 15 期周报\n","ref":"/zh/community/weekly_report/15th/","tags":"","title":"CloudWeGo 第15期周报"},{"body":"第 16 期周报\n","categories":"","description":"","excerpt":"第 16 期周报\n","ref":"/zh/community/weekly_report/16th/","tags":"","title":"CloudWeGo 第16期周报"},{"body":"第 17 期周报\n","categories":"","description":"","excerpt":"第 17 期周报\n","ref":"/zh/community/weekly_report/17th/","tags":"","title":"CloudWeGo 第17期周报"},{"body":"第 18 期周报\n","categories":"","description":"","excerpt":"第 18 期周报\n","ref":"/zh/community/weekly_report/18th/","tags":"","title":"CloudWeGo 第18期周报"},{"body":"第 19 期周报\n","categories":"","description":"","excerpt":"第 19 期周报\n","ref":"/zh/community/weekly_report/19th/","tags":"","title":"CloudWeGo 第19期周报"},{"body":"第 20 期周报\n","categories":"","description":"","excerpt":"第 20 期周报\n","ref":"/zh/community/weekly_report/20th/","tags":"","title":"CloudWeGo 第20期周报"},{"body":"第 21 期周报\n","categories":"","description":"","excerpt":"第 21 期周报\n","ref":"/zh/community/weekly_report/21th/","tags":"","title":"CloudWeGo 第21期周报"},{"body":"Server The configuration items on the Server side all use server.xxx when initializing the Server, such as:\npackage main import \"github.com/cloudwego/hertz/pkg/app/server\" func main() { h := server.New(server.WithXXXX()) ... }    Configuration Name Type Description     WithTransport network.NewTransporter Replace the transport. Default：netpoll.NewTransporter   WithHostPorts string Specify the listening address and port   WithKeepAliveTimeout time.Duration Set the keep-alive time of tcp persistent connection, generally no need to modify it, you should more pay attention to idleTimeout rather than modifying it. Default: 1min.   WithReadTimeout time.Duration The timeout of data reading. Default：3min.   WithIdleTimeout time.Duration The free timeout of the request link for persistent connection. Default: 3min.   WithMaxRequestBodySize int Max body size of a request. Default: 4M (the corresponding value of 4M is 4*1024*1024).   WithRedirectTrailingSlash bool Whether to redirect with the / which is at the end of the router automatically. For example： If there is only /foo/ in the router, /foo will be redirected to /foo/. And if there is only /foo in the router, /foo/ will be redirected to /foo. Default: true.   WithRemoveExtraSlash bool RemoveExtraSlash makes the parameter still valid when it contains an extra /. For example, if WithRemoveExtraSlash is true user//xiaoming can match the user/:name router. Default: false.   WithUnescapePathValues bool If true, the request path will be escaped automatically (eg. ‘%2F’ -\u003e ‘/'). If UseRawPath is false (the default), UnescapePathValues is true, because URI().Path() will be used and it is already escaped. To set WithUnescapePathValues to false, you need to set WithUseRawPath to true. Default (true).   WithUseRawPath bool If true, the original path will be used to match the route. Default: false.   WithHandleMethodNotAllowed bool If true when the current path cannot match any method, the server will check whether other methods are registered with the route of the current path, and if exist other methods, it will respond “Method Not Allowed” and return the status code 405; if not, it will use the handler of NotFound to handle it. Default: false.   WithDisablePreParseMultipartForm bool If true, the multipart form will not be preprocessed. The body can be obtained via ctx.Request.Body() and then can be processed by user. Default: false.   WithStreamBody bool If true, the body will be handled by stream processing. Default: false.   WithNetwork string Set the network protocol, optional: tcp，udp，unix(unix domain socket). Default: tcp.   ContinueHandler func(header *RequestHeader) bool Call the ContinueHandler after receiving the Expect 100 Continue header. With ContinueHandler, the server can decide whether to read the potentially large request body based on the header.   PanicHandler HandlerFunc Handle panic used to generate error pages and return error code 500.   NotFound HandlerFunc The handler to be called when the route does not match.   WithExitWaitTime time.Duration Set the graceful exit time. the Server will stop connection establishment for new requests and set the Connection: Close header for each request after closing. When the set time is reached, Server will to be closed. the Server can be closed early when all connections have been closed. Default: 5s.   WithTLS tls.Config Configuring server tls capabilities.   WithListenConfig net.ListenConfig Set the listener configuration. Can be used to set whether to allow reuse ports, etc.   WithALPN bool Whether to enable ALPN. Default: false.   WithTracer tracer.Tracer Inject tracer implementation, if not inject Tracer. Default: close.   WithTraceLevel stats.Level Set trace level, Default: LevelDetailed.   WithWriteTimeout time.Duration The timeout of data writing. Default：infinite.   WithRedirectFixedPath bool If enabled, if the current request path does not match, the server will try to repair the request path and re-match, if the match is successful and the request is a GET request, it will return status code 301 for redirect, other requests will return 308 for redirect. Disabled by default   WithBasePath string Set the base path, which must be prefixed and suffixed with /. The default is /   WithMaxKeepBodySize int Sets the maximum size of the request body and response body to be retained during reclaim. Unit: Byte. Default value: 4 * 1024 * 1024   WithGetOnly bool If enabled, only GET requests are accepted. Disabled by default   WithKeepAlive bool If enabled, use HTTP keepalive. Enabled by default   WithAltTransport network.NewTransporter Set up the alternate transport. Default value: netpoll.NewTransporter   WithH2C bool Sets whether H2C is enabled. Disabled by default   WithReadBufferSize int Set the read buffer size while limiting the HTTP header size. Default value: 4 * 1024   WithRegistry registry.Registry, *registry.Info Setup registry configuration, service registration information. Default value: registry.NoopRegistry, nil   WithAutoReloadRender bool, time.Duration Set up the automatic reload rendering configuration. Default value: false, 0   WithDisablePrintRoute bool Sets whether debugPrintRoute is disabled. Default disable   WithOnAccept func(conn net.Conn) context.Context Set the callback function when a new connection is accepted but cannot receive data in netpoll. In go net, it will be called before converting tls connection. Default value: nil   WithOnConnect func(ctx context.Context, conn network.Conn) context.Context Set the onConnect function. It can received data from connection in netpoll. In go net, it will be called after converting tls connection. Default value: nil    Server Connection limitation:\n If you are using the standard network library, there is no such restriction. If netpoll is used, the maximum number of connections is 10000 (this is the gopool) used at the bottom of netpoll. Yes, the modification method is also very simple, just call the function provided by gopool: gopool.SetCap(xxx) (you can call it once in main.go).  Client The configuration items on the Client side all use server.xxx when initializing the Server, such as:\npackage main import \"github.com/cloudwego/hertz/pkg/app/client\" func main() { c, err := client.NewClient(client.WithXxx()) ... }    Configuration Name Type Description     WithDialTimeout time.Duration Connection establishment timeout. Default: 1s.   WithMaxConnsPerHost int Set the maximum number of connections for every host. Default: 512.   WithMaxIdleConnDuration time.Duration Set the idle connection timeout, which will close the connection after the timeout Default: 10s.   WithMaxConnDuration time.Duration Set the maximum keep-alive time of the connection, when the timeout expired, the connection will be closed after the current request is completed. Default: infinite.   WithMaxConnWaitTimeout time.Duration Set the maximum time to wait for an idle connection. Default: no wait.   WithKeepAlive bool Whether to use persistent connection. Default: true.   WithRetryConfig …retry.Option Set the retry config of client. Hertz version \u003e= v0.4.0.   WithMaxIdempotentCallAttempts int Set the maximum number of calls. If a call fails, it will be retried. Default: 1 (That is no retry). v0.4.0 is obsolete. Only available before v0.4.0. It is recommended to upgrade Hertz version \u003e= v0.4.0 and use WithRetryConfig instead.   WithClientReadTimeout time.Duration Set the maximum time to read the response. Default: infinite.   WithTLSConfig *tls.Config Set the client’s TLS config for mutual TLS authentication.   WithDialer network.Dialer Set the network library used by the client. Default: netpoll.   WithResponseBodyStream bool Set whether to use stream processing. Default: false.   WithDialFunc client.DialFunc Set Dial Function.   WithWriteTimeout time.Duration The timeout of data writing. Default：infinite.    ","categories":"","description":"","excerpt":"Server The configuration items on the Server side all use server.xxx …","ref":"/docs/hertz/reference/config/","tags":"","title":"Configuration instruction"},{"body":"","categories":"","description":"","excerpt":"","ref":"/security/safety-bulletin/detail/","tags":"","title":"detail"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/","tags":"","title":"Documentation"},{"body":"Hertz provides a series of code examples designed to help users get start with Hertz and be familiar with its features. Refer to hertz-examples for more information.\nBizdemo hertz_gorm  hertz_gorm ：Example of using gorm in hertz server  hertz_gorm_gen  hertz_gorm_gen ：Example of using gorm/gen \u0026 proto IDL in hertz server  hertz_jwt  hertz_jwt ：Example of using jwt in hertz server  hertz_session  hertz_session ：Example of using distributed session and csrf in hertz server  Server Run hertz  hello ：Example of launching a hertz “hello world” application  Config  config ：Example of configuring hertz server  Protocol  Protocol ：Example of hertz using protocols such as HTTP1, TLS, etc  Route  Route ：Examples of registering routes, using route groups, and parameter routes  Middleware  basic_auth ：Example of using basic auth middleware CORS ：Example of using the CORS middleware custom ：Example of custom middleware pprof ：Example of using pprof middleware requestid ：Example of using RequestID middleware gzip ：Example of using gzip middleware in hertz server  Parameter binding and validation  binding ：Example of parameter binding and validation  Get Parameters  parameters ：Example of getting query, form, cookie, etc. parameters  Documents  file ：Examples of file upload, file download, and static file services  Render  render ：Example of render body as json, html, protobuf, etc  Redirect  redirect ：Example of a redirect to an internal/external URI  Streaming read/write  streaming ：Example of streaming read/write using hertz server  Graceful shutdown  graceful_shutdown ：Example of hertz server graceful shutdown  Unit test  unit_test ：Example of writing unit tests using the interface provided by hertz without network transmission  Tracing  tracer ：Example of hertz using Jaeger for link tracing  Monitoring  monitoring ：hertz Example of metrics monitoring with Prometheus  Multiple service  multiple_service ：Example of using hertz with multiple services  Adaptor  adaptor ：Example of using adaptor to integrate hertz with package built for http.Handler interface , including a demonstration on using jade as template engine.  Sentinel  sentinel: ：Example of using sentinel-golang in hertz  Reverse proxy  reverseproxy ：Example of using reverse proxy in hertz server  Hlog  hlog: ：Example of using hlog and its log extension  Client Send request  send_request ：Example of sending an http request using the hertz client  Client config  client_config ：Example of configuring the hertz client  TLS  tls ：Example of hertz client sending a tls request  Add parameters  add_parameters ：Example of adding request parameters using the hertz client  Upload file  upload_file ：Example of uploading a file using the hertz client  Middleware  middleware ：Example of using the hertz client middleware  Streaming read  streaming_read ：Example of a streaming read response using the hertz client  Forward proxy  forward_proxy ：Example of configuring a forward proxy using the hertz client  Hz Generate server code based on Thrift  thrift ：Example of using hz with thrift to generate server code  Generate server code based on Protobuf  protobuf ：Example of using hz with protobuf to generate server code  Generate client code  hz_client ：Example of using hz to generate client code  Custom templates  template ：Example of using hz custom templates to generate server code  Three-party plugins  plugin ：Example of using hz to access third-party plugins  ","categories":"","description":"","excerpt":"Hertz provides a series of code examples designed to help users get …","ref":"/docs/hertz/tutorials/example/","tags":"","title":"Example code"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/volo/volo-grpc/getting-started/","tags":"","title":"Getting Started"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/volo/volo-thrift/getting-started/","tags":"","title":"Getting Started"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/pilota/guide/","tags":"","title":"Guide"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/pilota/guide/","tags":"","title":"Guide"},{"body":"Why Plugin is needed Add some customized meta information for Pilota according to IDL generated Struct and other types.\nFor example, in order to add #[derive(serde::Serialize, serde::Deserialize]).\nHow to write a Plugin Plugin Implementation #[derive(Clone, Copy)]struct SerdePlugin;implpilota_build::PluginforSerdePlugin{fn on_item(\u0026mutself,cx: \u0026mutpilota_build::Context,def_id: pilota_build::DefId,// item 的 def_id item: std::sync::Arc\u003cpilota_build::rir::Item\u003e,){match\u0026*item{pilota_build::rir::Item::Message(_)|pilota_build::rir::Item::Enum(_)|pilota_build::rir::Item::NewType(_)=\u003ecx.with_adjust(def_id,|adj|{// Adjust's add_attrs method can add attributes to the Node corresponding to def_id, // which will be used to generate code later in the Codegen phase adj.add_attrs(\u0026[parse_quote!(#[derive(::serde::Serialize, ::serde::Deserialize)])])}),_=\u003e{}};pilota_build::plugin::walk_item(self,cx,def_id,item)}}Plugin Usage Pass the plugin method provided by the Builder.\npilota_build::thrift().plugin(SerdePlugin).write()","categories":"","description":"","excerpt":"Why Plugin is needed Add some customized meta information for Pilota …","ref":"/docs/pilota/guide/plugin/","tags":"","title":"How to write a Plugin？"},{"body":"案例介绍   企业用户如何搭建针对 Kitex 的可观测性系统？如何在 K8s 集群下使用 Kitex ?\n本文将从以下 4 个方面介绍华兴证券基于 Kitex 在多机房 K8s 集群下的实践经验，包括：\n 针对 Kitex 的可观测性系统搭建经验； 服务压力测试中遇到的问题以及解决方案； Kitex 的不同连接类型在 K8s 同集群/跨集群调用下的一些问题和解决方案； 实践中遇到的其他问题以及解决方案；  Kitex 的可观性系统搭建 华兴证券 CloudWeGo-Kitex 使用情况 去年 6 月 1 日，华兴证券相关研发团队成立。Kitex 在 7 月 12 日发布了首个版本，10 天后就引入了 Kitex。\n选择 Kitex 的原因是：团队早期成员比较了解 Kitex，为了快速支撑业务迭代和验证，选择最熟悉的框架，不但使用上比较习惯，对性能和功能方面也比较有把握。\n后来也支撑了华兴证券 APP 的快速上线，大约 4 个月之后就上线了 APP 的第一个版本。\n下图是业务的微服务调用关系图，一共有三十多个微服务，调用链路数超过 70。服务分别部署在两个机房。核心业务比如交易、行情等部署在私有机房。 非核心的业务，比如资讯、股票信息等部署在阿里的金融云，这样能够更好地利用金融云已有的基础设施比如 MySQL、Kafka 等，作为初创团队，能够降低整体的运维压力。 考虑到性能以及安全方面的因素，两个机房之间专门拉了专线。服务之间存在一些跨机房的依赖。跨机房调用会产生很多问题，后文会详细说明。\nTracing 选型 服务数多了之后，我们需要一套链路追踪系统来描绘调用链路每个环节的耗时情况。考虑到 Kitex 原生支持 Opentracing，为减少集成成本，我们调研了符合 Opentracing 规范的产品。\n排除掉收费的、客户端不支持 Go 之后，就剩阿里云的链路追踪产品和 Uber 公司出品的 Jaeger，考虑到私有机房也要部署，最终选择了 Jaeger。\nKitex 接入 Tracing 选定方案之后，开始对 Kitex 的这个功能进行测试，结果发现当时去年 9 月初的 Kitex 版本并不支持跨服务的 Tracing，原因是调用的时候，没有把 Trace 信息发送给下游，如图所示， 这样上下游是两个孤立的 Trace（OpenTracing 规范里称为 Span），于是就无法通过一个 TraceID 去串起整条链路。当时任务比较急，于是我们没有等 Kitex 官方的实现，决定自研。\n为了自研，我们结合 Kitex 的源码，梳理出客户端和服务端的流程。可以看出 Kitex 的上下游都内置了 Tracer 的 Hook。这里我们要解决的问题是，如何把 Span 信息进行跨服务传输？\n经调研，实现透传有三种方案。\n第一种是在消息层搞一个 Thrift 协议的拓展，把 Trace 信息塞进去。原因是 Thrift 本身没有 Header 结构，只能进行协议的拓展。好在 Kitex 支持自定义的协议拓展，因此具备可行性，然而开发成本较高，所以没选择这种方案。\n第二种是在 IDL 里增加通用参数，在字段里存 Trace 信息。缺点是业务无关的字段要在 IDL 里，对性能有一定的影响。毕竟需要通过 Kitex 的中间件，通过反射来提取。\n第三种是利用了 Kitex 提供的传输层透传能力，对业务没有侵入性。最后选择了这一种方案。\n透传方案定了之后，整体的流程就清晰了。首先客户端会在 metaHandler.write 里通过 CTX 获取当前 Span，提取并写入 spanContext 到 TransInfo 中。\n然后服务端，在 metaHandler.Read 里读取 spanContext 并创建 ChildOf 关系的 Span，中间件结束时 span.finish()，最后为了防止产生孤立 Trace，New 服务端时不使用 Kitex 提供的 Tracing 的 Option。\n这里是因为同一个服务可能分别作为 Kitex 上下游，Tracer 如果共用，需要分别加特殊逻辑，实现上有点复杂。\nTracing 基础库 为了充分利用 Tracing 的能力，除了 Kitex，我们在基础库中也增加了 Gin、Gorm、Redis、Kafka 等组件的 Tracing。\n下面展示实际的一条链路。功能是通过短信验证码进行登录。先是作为 HTTP 服务的 API 入口，然后调用了一个短信的 RPC 服务，RPC 服务里面通过 Redis 来检查验证码。 通过之后调用用户服务，里面可能进行一些增加用户的 MySQL 操作。最后把用户登录事件发给 Kafka，然后运营平台进行消费，驱动一些营销活动。可以看出最耗时的部分是关于新增用户的一堆 MySQL 操作。\n对错误的监控 Tracing 一般只关注调用耗时，然而一条链路中可能出现各种错误：\n Kitex   Kitex RPC 返回的 err（Conn Timeout、Read Timeout 等）； IDL 里自定义的业务 Code（111: 用户不存在）。  2.HTTP\n 返回的 HTTP 状态码（404、503）； JSON 里的业务 Code（-1: 内部错误）。  如何对这类错误进行监控？主要有以下三种方案：\n  打日志 + 日志监控，然后通过监控组件，这种方案需要解析日志，所以不方便；\n  写个中间件上报到自定义指标收集服务，这种方案优点是足够通用，但是需要新增中间件。同时自定义指标更关注具体的业务指标；\n  利用 Tracing 的 Tag，这种方案通用且集成成本低。\n  具体实现如下：\n Kitex 的 err、以及 HTTP 的状态码，定义为系统码； IDL 里的 Code 以及 HTTP 返回的 JSON 里的 Code，定义成业务码； Tracing 基础库里提取相应的值，设置到 span.tag 里； Jaeger 的 tag-as-field 配置里加上相应的字段（原始的 Tags，为 es 里的 Nested 对象，无法在 Grafana 里使用 Group By）。  监控告警 在增加错误监控的基础上，我们构建了一套监控告警系统体系。\n这里重点看一下刚才的链路追踪相关的内容。首先每个业务容器会把指标发送到 Jaeger 服务里。Jaeger 最终把数据落盘到 es 中。然后我们在 Grafana 上配置了一堆看板以及对应的告警规则。\n触发报警时，最终会发送到我们自研的 alert-webhook 里。\n自研的部分首先进行告警内容的解析，提取服务名等信息，然后根据服务的业务分类，分发到不同的飞书群里，级别高的报警会打加急电话。这里也是用到了飞书的功能。\nGrafana 里我们配置了各类型服务调用耗时、错误码一体化看板，描述了一个服务的方方面面的指标。包括日志监控、错误码监控、QPS 和调用耗时、容器事件监控、容器资源监控等。\n下图展示了飞书告警卡片。包括 RPC 调用超时、系统码错误、业务码错误。\n这里我们做了两个简单的工作，一个是带上了 TraceID，方便查询链路情况。另一个是把业务码对应的含义也展示出来，研发收到报警之后就不用再去查表了。\n本章小结\n 完成了 Tracing 接入 Kitex，实现跨服务传递； 对 Tracing 基础库扩展了其他类型中间件（Gin、Gorm、Redis、Kafka）的支持； 对 Tracing 基础库增加了系统码、错误码实现对错误的监控； 配置了全方位的服务指标看板； 结合 es、Grafana、飞书以及自研告警服务，搭建了针对微服务的监控告警系统。  这样我们就完成了可观测性体系的搭建。\n服务压力测试中遇到的问题以及解决方案 完成了监控告警体系之后，我们希望对服务进行压测，来找出性能瓶颈。第二部分介绍一下服务压测中遇到的问题和解决方案。\nKitex v0.0.8：连接超时问题 首先我们发现，QPS=150 左右，Kitex 出现连接建立超时的错误。当时我们检查了下 CPU、网络、内存等均没有达到限制。先是怀疑连接池大小不太够，于是测了下 10 和 1000，如上图所示，结果在报错数目上没有区别。 另外观察到的一个现象是，压测期间出现接近 5000 的 Time Wait 状态。\n5000 的限制，是因为达到了 tcp_max_tw_buckets 的设置的值。超过这个值之后，新的处于 Time Wait 状态的连接会被销毁，这样最大值就保持在 5000 了。 于是我们尝试进行排查，但没有思路，于是去翻看 Kitex 的 Issue，发现有人遇到相同的问题。\n原来，v0.0.8 版本的 Kitex，在使用域名的方式来新建 Client 的时候，会导致连接池失效。因为把连接放回连接池时，用的 Key 是解析之后的 IP，而 GET 的时候，用的是解析前的域名，这样根本 Get 不到连接，于是不停创建短连接。 这样的两个后果是：建立连接比较耗时，另一方面请求执行完毕之后都会关闭掉连接，于是导致了大量的 Time Wait。\n为了进行验证，我把测试服务改成了 IP 访问，然后比较了 IP 访问和域名访问以及不同连接池大小的情况。可以看出：IP 访问（连接池有效），但是连接池比较小的情况，出现减少的 Timeout。 连接池 100，Timeout 消失。而中间的域名访问的情况下，出现大量 Timeout。\nKitex v0.1.3：连接池问题修复 看代码得知在 Kitex v0.1.3 修复了这个问题。\n于是我们打算升级 Kitex 的版本，因为当时已经上了生产环境，在升级基础组件之前，需要进行验证，看一下不同连接池大小状态下的表现。还是域名模式，QPS 为 150 的情况下，随着连接池大小的增加，Timeout 的情况逐渐变少到消失。\n继续进行压测，我们发现 QPS=2000 的时候又出现了报错。结合监控，发现原因是连接建立的时候超过了默认的 50ms。\n我们讨论了几种解决方案：\n 修改超时配置。然而，交易日的 9:30-9:35 有⼀堆集中交易请求，突发的流量，耗时长了体验不好，可能会影响 APP 收入，我们希望系统性能保持稳定。 进行连接耗时的优化。然而 Kitex 已经使用了 Epoll 来处理创建连接的事件，作为使用方，进一步优化的难度和成本都太大。 MaxidleTimeout 参数改成无限大？比如先创建一个足够大的池，然后随着用户请求，池变得越来越大，最终稳定下来。但是每次服务升级之后，这个池就空了，需要慢慢恢复。 进行连接预热。  其实连接预热就相当于压测结束之后立马趁热再压一次，如图，可以发现 QPS=2000 的情况下，几乎都走了连接池，没有报错。因此，如果服务启动时能够进行连接预热，就可以省下建立连接的时间，使服务的性能保持稳定。\n当时 CloudWeGo 团队针对我们公司建了企业用户交流群，于是我们就向群里的 Kitex 研发提了连接预热的需求。其开发之后提供了连接预热个数的选项。我们也进行了测试。按照 QPS=2000 进行测试，\n WARM_UP_CONN_NUM=0：大约 1s 报错； WARM_UP_CONN_NUM=100：大约 4s 报错；   WARM_UP_CONN_NUM=1000：大约 4s 报错，但可以看出一开始都无需新建连接； WARM_UP_CONN_NUM=2000：无报错。  本章小结如下：\n Kitex v0.0.8：域名模式下存在连接池失效问题，v0.1.3 中修复； Kitex v0.1.3：可进一步通过连接预热功能提高系统性能。  Kitex 的不同连接类型在 K8s 同集群/跨集群调用下的一些问题和解决方案 长连接的问题：跨集群调用 第三部分我们讨论一下 Kitex 的不同连接类型在 K8s 同集群/跨集群调用下的一些问题和解决方案。\n首先是长连接跨集群调用下的问题。服务在跨集群调用时，其源 IP: 端口为宿主机的，数量有限，而目的 IP: 端口为下游集群的 LB，一般是固定的。\n那么，当长连接池数目比较大（比如数千），且上游较多（各种服务、每个都多副本，加起来可能数十个）的情况下，请求高峰时段可能导致上游宿主机的源端口不够用。同集群内跨机器调用走了 vxlan，因此没有这个问题。\n解决方案有两类：\n 硬件方案：机器； 软件方案：对于下游为 Kitex 服务，改用 Mux 模式（这样少量连接就可以处理大量并发的请求）。下游不是 Kitex 框架，因为 Mux 是私有协议，不支持非 Kitex。此时可考虑增加下游服务的 LB 数量，比如每个 LB 上分配多个端口。  比较起来，改造成 Mux 模式成本最低。\n连接多路复用的问题：滚动升级 但是多路复用模式，在 K8s 场景下，存在一个滚动升级相关的问题。我们先介绍下 Service 模式， K8s 的 Service 模式采用了 IPVS 的 Nat 模式（DR 和隧道模式不支持端口映射），链路为：\n上游容器←→ClusterIP（服务的虚拟 IP）←→下游容器\n然后我们看看滚动升级流程：\n 新容器启动。 新容器 Readiness Check 通过，之后做两件事情：  更新 Endpoints 列表：新增新容器，删除旧容器； 发送 sigTerm 到旧容器的 1 号进程。   由于更新了 Endpoints 列表，Endpoints 列表发生更新事件，立即回调触发规则更新逻辑（syncProxyRules）：  添加新容器到 IPVS 的 rs，权重为 1； 如果此时 IPVS 的旧容器的中 ActiveConn + InactiveConn \u003e 0（即已有连接还在），旧容器的权重会改成 0，但不会删除 rs。    经过步骤 3 之后，已有的连接仍然能够正常工作（因为旧容器 rs 未删），但新建的连接会走到新的容器上（因为旧容器权重 =0）。\n在 Service 模式下，上游通过一个固定的 IP: 端口来访问下游，当下游滚动升级的时候，上游看到的地址并未变化，即无法感知到滚动升级。于是，下游即使有优雅退出，但上游并不知道下游开始优雅退出了。之后可能的情况是：\n 下游发现连接繁忙，一直没有主动关闭，导致 K8s 配置的优雅升级时间超时，强制 Kill 进程，连接关闭，上游报错。 下游发现连接空闲，主动关闭，然而客户端在关闭之前恰好拿到了连接（且认为可用），然后发起请求，实际上由于连接关闭，发起请求失败报错。  针对此问题，解决方案如下：\n 同集群调用：改用 Headless Service 模式（结合 DNSResolver）：通过 DNS 列表的增删来感知下游变动； 跨集群调用：借鉴 HTTP2 的 GOAWAY 机制。  具体，可采用如下方式：\n 收到 sigTerm 的下游直接告诉上游（通过之前建立的 Conn1），同时下游继续处理发来的请求。 上游收到关闭信息之后：  新请求通过新建 Conn2 来发； 已有的请求仍然通过 Conn1，且处理完了之后，等下游优雅关闭 Conn1。    这种方式的优点是同集群跨集群均可使用，缺点是需要 Kitex 框架支持。在我们找 Kitex 团队讨论之后，他们也提供了排期支持本需求。\n连接多路复用的滚动升级测试：Headless Service 模式 在 Kitex 团队开发期间，我们测下 Kitex 已有版本对 Headless Service 模式下的滚动升级功能。\n测试方案如下：\n Kitex 版本 v0.1.3； 上下游均为 Mux 模式； 上游的加了个自定义 DNSResolver，刷新时间为 1s，加日志打印解析结果； 下游的退出信号处理，收到 sigTerm 之后特意 Sleep 10s（用来排除这个 Case：服务端发现连接空闲关闭了，但客户端在关闭之前恰好拿到连接，接着认为未关闭，实际上已经关闭，而客户端发起了请求，于是导致报错）； QPS=100 恒定压上游，然后触发下游滚动升级。  实测报错如下图：\n时序分析如下：\n 旧下游收到 sigTerm，开始 Sleep 10s； 上游解析到旧下游的 IP，向旧下游发起请求； DNS 规则更新：旧上游 IP 解析项消失，新下游解析项出现； 上游请求报错； 旧下游sleep完成，开始退出逻辑。  可见报错时旧下游还未执行退出逻辑，排除旧下游主动关闭连接。请求旧下游期间，且此时解析到新容器 IP（移除了旧容器 IP），报错是因为还没到退出逻辑的时候。因此推测，解析条目变化导致了报错。\n根据推测，结合代码（Kitex 客户端部分）分析，可能出现以下并发问题：\n 【协程1】客户端从 Mux池里取出 conn1，即将发起请求（所以没有机会再检查 conn1 状态了）； 【协程2】DNS 更新，移除了 IP，于是 Clean 方法中关闭了 conn1； 【协程1】客户端用 conn1 发起请求，导致报错 conn closed。  于是我们向 CloudWeGo 提了 Issue，他们很快修复了这个问题。\n连接多路复用的滚动升级测试：Service 模式 同样地，在 Service 模式中，测试方案如下：\n Kitex 版本使用 Feature 分支：mux-graceful-shutdown； 上下游均为 Mux 模式、服务发现使用 Service 模式； 恒定 QPS=200 压上游，20s 触发下游滚动升级； 另外写个服务打印期间的 IPVS 的日志； 下游的退出信号处理，收到 SigTerm 之后特意 sleep 10s（保证 ipvs 规则已更新）。  测试结果如下： 报错：INFO[0050] “{\"code\":-1,\"message\":\"remote or network error: conn closed\"}\"。\n时序分析为：\n 旧下游收到 sigTerm，开始 sleep 10s。 IPVS规则变化：  新下游 weight=1，ac=0，inac=0； 旧下游 weight=0，ac=2，inac=0。   旧下游 sleep 完成，进入最长为 15s（WithExitWaitTime）的优雅退出。 上游请求报错。 旧下游打印了最后一条日志。 IPVS 规则变化：  新下游 weight=1，ac=2，inac=0 =\u003e ac=2 说明上游新建连接到新容器； 旧下游 weight=0，ac=0，inac=2 =\u003e inac=2 表示连接关闭。   IPVS 规则变化：旧下游的规则被移除。  因此我们得出结论，报错发生在优雅退出期间。最后一条日志时刻大于报错时刻，因此，排除 K8s 的问题，确认 Conn Closed 是由 Kitex 导致的。 之后我们和 Kitex 研发团队沟通了分析结果，找到了 Root Cause，是因为假设了新的下游会有一个新的地址（但实际中 Service 模式都是一个地址），导致新请求取到了老请求的连接并进行关闭。对此进行了修复：\n连接多路复用的问题：下游扩容 如果⽤ Service 模式（上游看到的下游就是体现为⼀个 IP），创建的 TCP 连接会在最开始固定的几个下游 POD 上，之后如果扩容增加 POD，新创建的 POD 就不会路由到了，导致扩容实际上无效。\n解决方案如下：\n 同集群调用：可用 Headless Service 模式，由于 DNS 解析能够得到所有 POD，路由没问题。 跨集群调用：不在同集群内， Headless Service 模式无效，考虑如下方案：   方案1：修改服务发现机制。 优点：Kitex 无需改动。 缺点：增加依赖项（服务发现组件）。 方案2：下游先升级，之后上游 Redeploy 一下，让连接分布到下游的各种实例上。 优点：Kitex 无需改动。 缺点：上游可能很多，逐个 Redeploy 非常不优雅。 方案3：上游定期把 Mux 给过期掉，然后新建连接。 优点：彻底解决。 缺点：需要 Kitex 支持。  本章小结如下：\n 首先，针对长连接模式分析了跨集群时上游源端口数问题，希望通过多路复用模式解决； 其次，针对多路复用模式 + K8s Headless Service 模式的优雅升级，实测报错，分析定位了原因，Kitex 研发团队及时解决了相应问题； 再次，针对多路复用模式 + K8s Service 模式下的优雅升级提出了方案，Kitex 团队完成了实现，迭代了一轮，测试通过； 最后，针对多路复用模式 + K8s Service 模式下的下游副本扩容时路由不到的问题分析了原因，提出了方案，目前方案待实现。  实践中遇到的其他问题以及解决方案 RPC Timeout Context Canceled 错误 第四部分我们分析下实践中遇到的其他问题以及解决方案。研发同学发现日志出现 contexe canceled 的错误，分析日志发现出现频率低，一天只有几十条，属于偶发报错。\n我们推测是用户手机因为某种原因关闭了进行中的连接所导致，对此进行本地验证。三个部分：首先Gin 客户端设置了 500ms 超时限制，去请求 Gin 服务端接口； 其次，Gin 服务端收到请求之后，转而去调用 Kitex 服务；最后，Kitex 服务端 sleep 1s 模拟耗时超时，保证 Gin 客户端在请求过程中关闭连接。\n实测能够稳定地复现。\n我们梳理了源码逻辑，客户端关闭连接之后，Gin 读取到 EOF，调用 cancelCtx，被 Kitex 客户端的 rpcTimeoutMW 捕获到，于是返回了 err。\n那么问题就变成，请求未完成时，连接为何会被关闭？我们按照设备的 ID 去分析日志，发现两类情况：一类是报错对应的请求是该设备短期内的最后一条，于是考虑 APP 被手动关闭； 二是报错对应的请求非短期内的最后一条，客户端研发反馈，有些接口例如搜索，上一条请求执行中（未返回），且新的请求来时，会 Close 掉上一次请求的连接。 第二种情况比较确定，关于第一种情况，APP 被关闭时，IOS 和 Android 是否会关闭连接？客户端同学没有给出肯定的答复。\n于是我们考虑实际测试一下，两端分别写一个测试的应用，持续发起请求，但是不释放连接，此时关闭 APP，分析 TCP 包。实测我们在两端上均看到了 4 次挥手的 Fin 包。所以这个问题得到了确认。\n那么如何进行修复呢？我们采取在 GIN 的中间件上拦截掉 Done 方法的方式。\n上线之后，再没有出现这种情况。\n还有一个问题，我们在测试环境发现，跨集群调用的时候，经常出现连接被重置的问题。生产环境搜日志，无此现象。\n我们分析了环境差异：\n 生产环境是专线直连； 测试环境，因为专线比较昂贵，机房之前通过公网访问，中间有个 NAT 设备。  我们找网络同事咨询，得知 NAT 表项的过期时间是 60s。连接过期时，NAT 设备并不会通知上下游。因此，上游调用的时候，如果 NAT 设备发现表项不存在，会认为是一个失效的连接，就返回了 rst。 于是我们的解决方案是 Kitex 上游的 MaxIdleTimeout 改成 30s。实测再未出现报错。\n本章小结如下：\n Rpc Timeout：Tontext Tanceled 问题分析和解决； Rpc Error：Connection Reset 问题分析和解决。  展望 未来我们计划把 Gin 更换为更高性能（QPS/时延）的 CloudWeGo-Hertz。因为我们 K 线服务的 Response Size 比较大（~202KiB），更换后 QPS 预计可达原先的 5 倍。 同时，为回馈开源社区，我们打算贡献 Tracing 基础库的代码到 Kitex-contrib/Tracer-opentracing。欢迎持续关注 CloudWeGo 项目，加入社区一起交流。\n","categories":"","description":"","excerpt":"案例介绍   企业用户如何搭建针对 Kitex 的可观测性系统？如何在 K8s 集群下使用 Kitex ?\n本文将从以下 4 个方面介绍华兴 …","ref":"/cooperation/huaxingsec/","tags":"","title":"华兴证券：混合云原生架构下的 Kitex 实践"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/tutorials/toolkit/usage/","tags":"","title":"hz usages"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/tutorials/toolkit/usage/","tags":"","title":"hz 使用方法"},{"body":"Volo provides CLI tools of the same name for initializing projects, managing IDLs, and more. To install Volo tool, run the following command:\n$ cargo install volo-cli Then run:\n$ volo help You should see something like the following:\nUSAGE: volo [OPTIONS] \u003cSUBCOMMAND\u003e OPTIONS: -h, --help Print help information -n, --entry-name \u003cENTRY_NAME\u003e The entry name, defaults to 'default'. [default: default] -v, --verbose Turn on the verbose mode. -V, --version Print version information SUBCOMMANDS: help Print this message or the help of the given subcommand(s) idl manage your idl init init your project ","categories":"","description":"","excerpt":"Volo provides CLI tools of the same name for initializing projects, …","ref":"/docs/volo/volo-grpc/getting-started/part_1/","tags":"","title":"Part 1. Install the CLI Tool"},{"body":"Volo provides CLI tools of the same name for initializing projects, managing IDLs, and more. To install Volo tool, run the following command:\n$ cargo install volo-cli Then run:\n$ volo help You should see something like the following:\nUSAGE: volo [OPTIONS] \u003cSUBCOMMAND\u003e OPTIONS: -h, --help Print help information -n, --entry-name \u003cENTRY_NAME\u003e The entry name, defaults to 'default'. [default: default] -v, --verbose Turn on the verbose mode. -V, --version Print version information SUBCOMMANDS: help Print this message or the help of the given subcommand(s) idl manage your idl init init your project ","categories":"","description":"","excerpt":"Volo provides CLI tools of the same name for initializing projects, …","ref":"/docs/volo/volo-thrift/getting-started/part_1/","tags":"","title":"Part 1. Install the CLI Tool"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/releases/kitex/","tags":"","title":"Kitex Release"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/kitex/","tags":"","title":"Kitex"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/blog/releases/kitex/","tags":"","title":"Kitex Release"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/kitex/","tags":"","title":"Kitex"},{"body":"Hertz provides the ability to extend the network library. If users need to replace with other network libraries, they can implement the corresponding interfaces according to their needs. Server needs to implement the network.Conn interface, Client needs to implement the network.Dialer interface.\nInterface Definition Interfaces in pkg/network/connection.go\ntype Conn interface { net.Conn Reader Writer SetReadTimeout(t time.Duration) error } // Reader is for buffered Reader type Reader interface { // Peek returns the next n bytes without advancing the reader.  Peek(n int) ([]byte, error) // Skip discards the next n bytes.  Skip(n int) error // Release the memory space occupied by all read slices. This method needs to be executed actively to  // recycle the memory after confirming that the previously read data is no longer in use.  // After invoking Release, the slices obtained by the method such as Peek will  // become an invalid address and cannot be used anymore.  Release() error // Len returns the total length of the readable data in the reader.  Len() int // ReadByte is used to read one byte with advancing the read pointer.  ReadByte() (byte, error) // ReadBinary is used to read next n byte with copy, and the read pointer will be advanced.  ReadBinary(n int) (p []byte, err error) } type Writer interface { // Malloc will provide a n bytes buffer to send data.  Malloc(n int) (buf []byte, err error) // WriteBinary will use the user buffer to flush.  // NOTE: Before flush successfully, the buffer b should be valid.  WriteBinary(b []byte) (n int, err error) // Flush will send data to the peer end.  Flush() error } For Client, you should implement the following interface in order to replace the Client-side network library.\ntype Dialer interface { DialConnection(network, address string, timeout time.Duration, tlsConfig *tls.Config) (conn Conn, err error) DialTimeout(network, address string, timeout time.Duration, tlsConfig *tls.Config) (conn net.Conn, err error) AddTLS(conn Conn, tlsConfig *tls.Config) (Conn, error) } Custom Network Library The Hertz Server and Client provide separate initialization configuration items\nServer\nserver.New(server.WithTransport(YOUR_TRANSPORT)) Client\nclient.NewClient(client.WithDialer(YOUR_DIALER)) ","categories":"","description":"","excerpt":"Hertz provides the ability to extend the network library. If users …","ref":"/docs/hertz/tutorials/framework-exten/advanced-exten/network-lib/","tags":"","title":"Network Library Extensions"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/news/","tags":"","title":"News"},{"body":"cwgo is a CloudWeGo All in one code generation tool, which integrates the advantages of each component to improve the developer experience.\nThe cwgo tool can easily generate engineering templates, and its main features are as follows:\nFeatures   User-friendly way of generating\nThe cwgo tool provides both interactive command line and static command line. The interactive command line can generate code at low cost, no need to care about passing parameters, and no need to execute multiple commands, It is suitable for most users; users who need advanced functions can still use the regular static command line construction to generate commands.\n  Support for generating engineering templates\nThe cwgo tool supports the generation of MVC project layout. Users only need to complete their own business code in the corresponding position according to the functions of different directories, focusing on business logic.\n  Support generating Server and Client code\nThe cwgo tool supports generating Server and Client codes of Kitex and Hertz, and provides an encapsulation of Client. Users can call downstream out of the box, eliminating the cumbersome steps of encapsulating the Client\n  Support for generating database code\nThe cwgo tool supports generating database CURD code. Users no longer need to encapsulate the cumbersome CURD code by themselves, which improves the user’s work efficiency.\n  Support fallback to Kitex, Hz tools\nIf you were a Kitex or Hz user before, you can still use the cwgo tool. The cwgo tool supports the fallback function and can be used as Kitex and Hz, truly realizing a tool to generate all.\n  Install # Go 1.15 and earlier versions GO111MODULE=on GOPROXY=https://goproxy.cn/, direct go get github.com/cloudwego/cwgo@latest # Go 1.16 and later GOPROXY=https://goproxy.cn/, direct go install github.com/cloudwego/cwgo@latest ","categories":"","description":"","excerpt":"cwgo is a CloudWeGo All in one code generation tool, which integrates …","ref":"/docs/cwgo/overview/","tags":"","title":"Overview"},{"body":"CloudWeGo-Hertz Hertz [həːts] is a high-performance, high-usability, extensible HTTP framework for Go. It’s designed to make it easy for developers to build microservices.\nInspired by other open source frameworks such as fasthttp, gin, and echo, combined with the unique challenges faced by ByteDance, Hertz has become production-ready and has powered ByteDance’s internal services over the years.\nToday, as Go gains popularity in microservice development, Hertz is the right choice if you are looking for a customisable, high-performance framework to support a variety of use cases.\nArchitecture Features High usability In modern software engineering, it is agreed that the delivery of high-quality code in a short period of time has become increasingly important in a highly competitive environment. With this in mind, we actively listen to user feedback during the initial interactions with Hertz and strive to refine the framework to improve the user experience and help developers get the job done quickly and correctly.\nHigh performance Hertz uses Netpoll by default, a high performance network library built from scratch. Compared to the go.net implementation, the benchmark shows that in some scenarios Hertz’s performance is better in terms of both QPS and time delay.\nThe following graphs show how Hertz compares to other popular frameworks for echo requests in terms of performance.\nComparison of four frameworks:\nComparison of three frameworks:\nPlease refer to https://github.com/cloudwego/hertz-benchmark for more details about benchmarking.\nHigh extensibility Hertz uses a layered architecture to deliver a “batteries included” experience. Because of its layered design, the framework is highly extensible, while its core functionality remains robust. Hertz comes with default implementations for many modules, but also allows users to extend them to suit their own needs. At present, only stable features have been released to the open source community. For further planning, please refer to the RoadMap.\nMulti-protocol support Hertz framework provides out-of-box support for HTTP 1.1 and ALPN protocol. In addition, due to its layered design, Hertz supports the custom implementation of the protocol layer to adapt to different use cases.\nSwitching Network layer on demand Hertz has the ability to switch between network layer implementations ( Netpoll and go.net ) as required. Users can choose the network library that best suits their needs. Hertz also supports network layer extension in the form of plug-ins.\nPerformance Performance testing can only provide a relative reference. In production, there are many factors that can affect actual performance.\nWe provide the hertz-benchmark project to track and compare the performance of Hertz and other frameworks in different situations for reference.\nRelated Projects  Netpoll: A high-performance network library. Hertz uses it by default. Hertz-Contrib: A collection of Hertz extensions. Example: A repository to host examples for Hertz.  Blogs  ByteDance Practice on Go Network Library  ","categories":"","description":"","excerpt":"CloudWeGo-Hertz Hertz [həːts] is a high-performance, high-usability, …","ref":"/docs/hertz/overview/","tags":"","title":"Overview"},{"body":"CloudWeGo-Kitex Kitex [kaɪt’eks] is a high-performance and strong-extensibility Golang RPC framework that helps developers build microservices. If the performance and extensibility are the main concerns when you develop microservices, Kitex can be a good choice.\nArchitecture Basic Features  High Performance  Kitex integrates Netpoll, a high-performance network library, which offers significant performance advantage over go net.\n Extensibility  Kitex provides many interfaces with default implementation for users to customize. You can extend or inject them into Kitex to fulfill your needs (please refer to the framework extension section below).\n Multi-message Protocol  Kitex is designed to be extensible to support multiple RPC messaging protocols. The initial release contains support for Thrift, Kitex Protobuf and gRPC, in which Kitex Protobuf is a Kitex custom Protobuf messaging protocol with a protocol format similar to Thrift. Kitex also supports developers extending their own messaging protocols.\n Multi-transport Protocol  For service governance, Kitex supports TTHeader and HTTP2. TTHeader can be used in conjunction with Thrift and Kitex Protobuf; HTTP2 is currently mainly used with the gRPC protocol, and it will support Thrift in the future.\n Multi-message Type  Kitex supports PingPong, One-way, and Bidirectional Streaming. Among them, One-way currently only supports Thrift protocol, two-way Streaming only supports gRPC, and Kitex will support Thrift’s two-way Streaming in the future.\n Service Governance  Kitex integrates service governance modules such as service registry, service discovery, load balancing, circuit breaker, rate limiting, retry, monitoring, tracing, logging, diagnosis, etc. Most of these have been provided with default extensions, and users can choose to integrate.\n Code Generation  Kitex has built-in code generation tools that support generating Thrift, Protobuf, and scaffold code.\nPerformance We compared the performance of Kitex with some popular RPC frameworks (test code), such as gRPC and RPCX, both using Protobuf protocol. The test results show that Kitex performs better.\nNote: The performance benchmarks obtained from the experiment are for reference only, because there are many factors that can affect the actual performance in application scenarios.\nTest environment  CPU: Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz, 4 cores Memory: 8GB OS: Debian 5.4.56.bsk.1-amd64 x86_64 GNU/Linux Go: 1.15.4  Concurrency performance Change the concurrency with a fixed packet size 1KB.\n   QPS TP99 TP999           Throughput performance Change packet size with a fixed concurrency of 100.\n   QPS TP99 TP999           Related Projects  Netpoll: A high-performance network library. kitex-contrib: A partial extension library of Kitex, which users can integrate into Kitex through options according to their needs. Example: Use examples of Kitex.  Blogs  Performance Optimization Practice of Go RPC framework Kitex Practice of ByteDance on Go Network Library  ","categories":"","description":"This doc covers architecture design, features and performance of Kitex.","excerpt":"This doc covers architecture design, features and performance of …","ref":"/docs/kitex/overview/","tags":"","title":"Overview"},{"body":"Motore is an async middleware abstraction powered by GAT and TAIT.\nAround Motore, we build modular and reusable components for building robust networking clients and servers.\nMotore is greatly inspired by Tower.\nOverview Motore uses GAT and TAIT to reduce the mental burden of writing asynchronous code, especially to avoid the overhead of Box to make people less anxious.\nThe core abstraciton of Motore is the Service trait:\npubtraitService\u003cCx,Request\u003e{/// Responses given by the service. type Response;/// Errors produced by the service. type Error;/// The future response value. type Future\u003c'cx\u003e: Future\u003cOutput=Result\u003cSelf::Response,Self::Error\u003e\u003e+Send+'cxwhereCx: 'cx,Self: 'cx;/// Process the request and return the response asynchronously. fn call\u003c'cx,'s\u003e(\u0026'smutself,cx: \u0026'cxmutCx,req: Request)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx;}Getting Started Combing GAT and type_alias_impl_trait together, we can write asynchronous code in a very concise and readable way.\npubstruct Timeout\u003cS\u003e{inner: S,duration: Duration,}impl\u003cCx,Req,S\u003eService\u003cCx,Req\u003eforTimeout\u003cS\u003ewhereReq: 'static+Send,S: Service\u003cCx,Req\u003e+'static+Send,Cx: 'static+Send,S::Error: Send +Sync+Into\u003cBoxError\u003e,{type Response=S::Response;type Error=BoxError;type Future\u003c'cx\u003e=implFuture\u003cOutput=Result\u003cS::Response,Self::Error\u003e\u003e+'cx;fn call\u003c'cx,'s\u003e(\u0026'smutself,cx: \u0026'cxmutCx,req: Req)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx,{asyncmove{letsleep=tokio::time::sleep(self.duration);tokio::select!{r=self.inner.call(cx,req)=\u003e{r.map_err(Into::into)},_=sleep=\u003eErr(std::io::Error::new(std::io::ErrorKind::TimedOut,\"service time out\").into()),}}}}We also provided the #[motore::service] macro to make writing a Service more async-native:\nusemotore::service;pubstruct S\u003cI\u003e{inner: I,}#[service]impl\u003cCx,Req,I\u003eService\u003cCx,Req\u003eforS\u003cI\u003ewhereReq: Send +'static,I: Service\u003cCx,Req\u003e+Send+'static,Cx: Send +'static,{asyncfn call(\u0026mutself,cx: \u0026mutCx,req: Req)-\u003e Result\u003cI::Response,I::Error\u003e{self.inner.call(cx,req).await}}","categories":"","description":"","excerpt":"Motore is an async middleware abstraction powered by GAT and TAIT. …","ref":"/docs/motore/overview/","tags":"","title":"Overview"},{"body":"Introduction Netpoll is a high-performance non-blocking I/O networking framework, which focused on RPC scenarios, developed by ByteDance.\nRPC is usually heavy on processing logic and therefore cannot handle I/O serially. But Go’s standard library net is designed for blocking I/O APIs, so that the RPC framework can only follow the One Conn One Goroutine design. It will waste a lot of cost for context switching, due to a large number of goroutines under high concurrency. Besides, net.Conn has no API to check Alive, so it is difficult to make an efficient connection pool for RPC framework, because there may be a large number of failed connections in the pool.\nOn the other hand, the open source community currently lacks Go network libraries that focus on RPC scenarios. Similar repositories such as: evio, gnet, etc., are all focus on scenarios like Redis, HAProxy.\nBut now, Netpoll was born and solved the above problems. It draws inspiration from the design of evio and netty, has excellent Performance, and is more suitable for microservice architecture. Also Netpoll provides a number of Features, and it is recommended to replace net in some RPC scenarios.\nWe developed the RPC framework Kitex and HTTP framework Hertz based on Netpoll, both with industry-leading performance.\nExamples show how to build RPC client and server using Netpoll.\nFeatures   Already\n LinkBuffer provides nocopy API for streaming reading and writing gopool provides high-performance goroutine pool mcache provides efficient memory reuse IsActive supports checking whether the connection is alive Dialer supports building clients EventLoop supports building a server TCP, Unix Domain Socket Linux, macOS (operating system)    Future\n io_uring Shared Memory IPC TLS UDP    Unsupported\n Windows (operating system)    Performance Benchmark should meet the requirements of industrial use. In the RPC scenario, concurrency and timeout are necessary support items.\nWe provide the netpoll-benchmark project to track and compare the performance of Netpoll and other frameworks under different conditions for reference.\nMore benchmarks reference kitex-benchmark and hertz-benchmark\nReference  Official Website Getting Started  ","categories":"","description":"","excerpt":"Introduction Netpoll is a high-performance non-blocking I/O networking …","ref":"/docs/netpoll/overview/","tags":"","title":"Overview"},{"body":"Volo Volo is a high-performance and strong-extensibility Rust RPC framework that helps developers build microservices.\nVolo uses Motore as its middleware abstraction, which is powered by GAT.\nArchitecture Features Powered by GAT Volo uses Motore as its middleware abstraction, which is powered by GAT.\nThrough GAT, we can avoid many unnecessary Box memory allocations, improve ease of use, and provide users with a more friendly programming interface and a more ergonomic programming paradigm.\nHigh Performance Rust is known for its high performance and safety. We always take high performance as our goal in the design and implementation process, reduce the overhead of each place as much as possible, and improve the performance of each implementation.\nFirst of all, it is very unfair to compare the performance with the Go framework, so we will not focus on comparing the performance of Volo and Kitex, and the data we give can only be used as a reference, I hope everyone can view it objectively; at the same time, due to the open source community has not found another mature Rust async version Thrift RPC framework, and performance comparison is always easy to lead to war, so we hope to weaken the comparison of performance data as much as possible, and we’ll only publish our own QPS data.\nUnder the same test conditions as Kitex (limited to 4C), the Volo QPS is 35W; at the same time, we are internally verifying the version based on Monoio (CloudWeGo’s open source Rust async runtime), and the QPS can reach 44W.\nFrom the flame graph of our online business, thanks to Rust’s static distribution and excellent compilation optimization, the overhead of the framework part is basically negligible (excluding syscall overhead).\nEasy to Use Rust is known for being hard to learn and hard to use, and we want to make it as easy as possible for users to use the Volo framework and write microservices in the Rust language, providing the most ergonomic and intuitive coding experience possible. Therefore, we make ease of use one of our most important goals.\nFor example, we provide the volo command line tool for bootstrapping projects and managing idl files; at the same time, we split thrift and gRPC into two independent(but share some components) frameworks to provide programming paradigms that best conform to different protocol semantics and interface.\nWe also provide the #[service] macro (which can be understood as the async_trait that does not require Box) to enable users to write service middleware using async rust without psychological burden.\nStrong Extensibility Benefiting from Rust’s powerful expression and abstraction capabilities, through the flexible middleware Service abstraction, developers can process RPC meta-information, requests and responses in a very unified form.\nFor example, service governance functions such as service discovery and load balancing can be implemented in the form of services without the need to implement Trait independently.\nWe have also created an organization Volo-rs, any contributions are welcome.\nRelated Projects  Volo-rs：The volo ecosystem which contains a lot of useful components. Pilota：A thrift and protobuf implementation in pure rust with high performance and extensibility. Motore：Middleware abstraction layer powered by GAT. Metainfo：Transmissing metainfo across components.  ","categories":"","description":"","excerpt":"Volo Volo is a high-performance and strong-extensibility Rust RPC …","ref":"/docs/volo/overview/","tags":"","title":"Overview"},{"body":" search    All  Low  Mid  High  Danger     year All 2021 2022 2023 2024 2025       Bulletin Digest Level Influence Publish      Previous  1 2  3 Next   Total: 3    ","categories":"","description":"","excerpt":" search    All  Low  Mid  High  Danger     year All 2021 2022 2023 …","ref":"/security/safety-bulletin/","tags":"","title":"safety-bulletin"},{"body":"The cwgo tool also supports passing its own template, and the template syntax is the syntax of go template. cwgo also welcomes users to contribute their own templates. Due to the different concepts of RPC and HTTP, the corresponding template variables also have some differences, please refer to the following for details\nTo pass a custom template, add the -template parameter to the command, such as\ncwgo server -type RPC -service {service name} -idl {idl path} -template {tpl path} RPC  The template file is delivered through the yaml folder, specified by the --template-dir command line parameter of kitex, all yaml files in this folder will be rendered, and if the template parsing fails, it will exit directly. Watch out for unknown hidden files. extensions.yaml in the folder is a specific file, the content of which is Extended Service Code configuration file. If the file exists, there is no need to pass the template-extension parameter  The yaml file is defined as follows:\n# The path and file name of the generated file, which will create a folder in the root directory of the project, and generate a main.go file in the folder, which supports template rendering syntax path: /handler/{{ .Name }}.go update_behavior: type: skip / cover / append # Specify update behavior, if loop_method is true, append is not supported. The default is skip key: Test{{.Name}} # The searched function name, if the rendered function name exists, it is considered that the method does not need to be appended append_tpl: # updated content template import_tpl: # The newly added import content is a list, which can be rendered by template loop_method: true # Whether to enable loop rendering body: template content # template content The data used by the template is PackageInfo. It is considered that this part contains all metadata, such as methodInfo, etc. The user only needs to pass the template file, and the data in the template is PackageInfo data. Commonly used content in PackageInfo can be found in the appendix. cwgo supports circularly rendering files according to methodinfo. There is only one element in the methodInfo list during cyclic rendering, which is the method currently being rendered. When updating, currently supports overwriting, skipping and adding files according to methods, and supports appending in one file. If the loop render file is enabled, only skip and cover are supported.  Best practice rpc example tpl can refer to here\nHTTP  The template file is delivered through the yaml folder, but unlike the RPC layout, the HTTP layout is implemented based on hertz’s custom template. Here we need to specify the yaml file name to be fixed as layout.yaml and package .yaml, for the use of custom templates, please refer to Hz custom template usage documentation.  Best practice http example tpl can refer to here\nAppendix Kitex PackageInfo structure meaning type PackageInfo struct { Namespace string // idl namespace, it is recommended not to use under pb  Dependencies map[string]string // package name =\u003e import path, used for searching imports  *ServiceInfo // the target service  Codec string NoFastAPI bool Version string RealServiceName string Imports map[string]map[string]bool ExternalKitexGen string Features []feature FrugalPretouch bool Module string // go module name } type ServiceInfo struct { PkgInfo ServiceName string RawServiceName string ServiceTypeName func() string Base *ServiceInfo Methods []*MethodInfo CombineServices []*ServiceInfo Has Streaming bool } type PkgInfo struct { PkgName string // last paragraph of namespace  PkgRefName string ImportPath string // import path of req and resp of this method } type MethodInfo struct { PkgInfo ServiceName string // the name of this service  Name string // the name of this method  RawName string // Same as above  Oneway bool void bool Args []*Parameter // Input parameter information, including input parameter name, import path, type  Resp *Parameter // output parameter, including input parameter name, import path, type  Exceptions []*Parameter ArgStructName string ResStructName string IsResponseNeedRedirect bool // int -\u003e int*  GenArgResultStruct bool ClientStreaming bool Server Streaming bool } } ","categories":"","description":"","excerpt":"The cwgo tool also supports passing its own template, and the template …","ref":"/docs/cwgo/tutorials/templete-extension/","tags":"","title":"Template Extension"},{"body":"Referring to the Thrift THeader protocol, we designed the TTheader protocol.\nHeader Format 0 1 2 3 4 5 6 7 8 9 a b c d e f 0 1 2 3 4 5 6 7 8 9 a b c d e f +----------------------------------------------------------------+ | 0| LENGTH | +----------------------------------------------------------------+ | 0| HEADER MAGIC | FLAGS | +----------------------------------------------------------------+ | SEQUENCE NUMBER | +----------------------------------------------------------------+ | 0| HEADER SIZE | ... +--------------------------------- Header is of variable size: (and starts at offset 14) +----------------------------------------------------------------+ | PROTOCOL ID |NUM TRANSFORMS . |TRANSFORM 0 ID (uint8)| +----------------------------------------------------------------+ | TRANSFORM 0 DATA ... +----------------------------------------------------------------+ | ... ... | +----------------------------------------------------------------+ | INFO 0 ID (uint8)| INFO 0 DATA ... +----------------------------------------------------------------+ | ... ... | +----------------------------------------------------------------+ | | | PAYLOAD | | | +----------------------------------------------------------------+  LENGTH: 32bits, including the byte size of the remaining part of the data packet, but does not include itself HEADER MAGIC: 16bits, value: 0x1000, it’s used to identify TTHeaderTransport FLAGS: 16bits, it’s a reserved field, not used yet, default value is 0x0000 SEQUENCE NUMBER: 32bits, it’s the seqId of the message packet, can be used for multiplexing, and ensure it is incremented within a single connection HEADER SIZE: 16bits, it’s equal to the number of bytes divided by 4 of the head length. The header length calculation starts from the 14th byte and continues until before PAYLOAD (Notice: The maximum length of the header is 64K) PROTOCOL ID: uint8 encoding, the values are:  ProtocolIDBinary = 0 ProtocolIDCompact = 2   NUM TRANSFORMS: uint8 encoding, the number of TRANSFORM TRANSFORM ID: uint8 encoding, refer the instructions below INFO ID: uint8 encoding, refer the instructions below PAYLOAD: message content  PADDING Header will be padded out to next 4-byte boundary with 0x00.\nTransform IDs Transform IDs represents the compression way, which is a reserved field and is not supported currently. The values are:\n ZLIB_TRANSFORM = 0x01: the corresponding data is empty, indicating that the data is compressed with zlib SNAPPY_TRANSFORM = 0x03: the corresponding data is empty, indicating that the data is compressed with snappy  Info IDs Info IDs is used to transmit some key/value pair information, the values are:\n INFO_KEYVALUE = 0x01: the corresponding data is a key/value pair, key and value are each composed of the length of uint16 plus no-training-null string, which is generally used to transmit some common meta information, such as tracingId INFO_INTKEYVALUE = 0x10: the corresponding data is a key/value pair, the key is uint16, the value is composed of the length of uint16 plus the no-trading-null string, which is generally used to transmit some internally customized meta information, some keys are required as request:  TRANSPORT_TYPE = 1 (value: framed/unframed) LOG_ID = 2 FROM_SERVICE = 3 FROM_CLUSTER = 4 (default) FROM_IDC = 5 TO_SERVICE = 6 TO_METHOD = 9   ACL_TOKEN_KEYVALUE = 0x11: the corresponding data is a key/value pair, key and value are each composed of the length of uint16 plus no-trading-null string, used to transmit ACL Token  ","categories":"","description":"Kitex protocol design of TTheader.","excerpt":"Kitex protocol design of TTheader.","ref":"/docs/kitex/reference/transport_protocol_ttheader/","tags":"","title":"TTHeader"},{"body":"参考 Thrift THeader 协议 ，我们设计了 TTheader 协议。\n协议编码  0 1 2 3 4 5 6 7 8 9 a b c d e f 0 1 2 3 4 5 6 7 8 9 a b c d e f +----------------------------------------------------------------+ | 0| LENGTH | +----------------------------------------------------------------+ | 0| HEADER MAGIC | FLAGS | +----------------------------------------------------------------+ | SEQUENCE NUMBER | +----------------------------------------------------------------+ | 0| HEADER SIZE | ... +--------------------------------- Header is of variable size: (and starts at offset 14) +----------------------------------------------------------------+ | PROTOCOL ID |NUM TRANSFORMS . |TRANSFORM 0 ID (uint8)| +----------------------------------------------------------------+ | TRANSFORM 0 DATA ... +----------------------------------------------------------------+ | ... ... | +----------------------------------------------------------------+ | INFO 0 ID (uint8)| INFO 0 DATA ... +----------------------------------------------------------------+ | ... ... | +----------------------------------------------------------------+ | | | PAYLOAD | | | +----------------------------------------------------------------+ 其中：\n LENGTH 字段 32bits，包括数据包剩余部分的字节大小，不包含 LENGTH 自身长度 HEADER MAGIC 字段 16bits，值为：0x1000，用于标识 TTHeaderTransport FLAGS 字段 16bits，为预留字段，暂未使用，默认值为 0x0000 SEQUENCE NUMBER 字段 32bits，表示数据包的 seqId，可用于多路复用，最好确保单个连接内递增 HEADER SIZE 字段 16bits，等于头部长度字节数 /4，头部长度计算从第 14 个字节开始计算，一直到 PAYLOAD 前（备注：header 的最大长度为 64K） PROTOCOL ID 字段 uint8 编码，取值有：  ProtocolIDBinary = 0 ProtocolIDCompact = 2   NUM TRANSFORMS 字段 uint8 编码，表示 TRANSFORM 个数 TRANSFORM ID 字段 uint8 编码，具体取值参考下文 INFO ID 字段 uint8 编码，具体取值参考下文 PAYLOAD 消息内容  PADDING 填充 Header 部分长度 bytes 数必须是 4 的倍数，不足部分用 0x00 填充\nTransform IDs 表示压缩方式，为预留字段，暂不支持，取值有：\n ZLIB_TRANSFORM = 0x01，对应的 data 为空，表示用 zlib 压缩数据； SNAPPY_TRANSFORM = 0x03，对应的 data 为空，表示用 snappy 压缩数据；  Info IDs 用于传递一些 kv 对信息，取值有：\n INFO_KEYVALUE = 0x01，对应的 data 为 key/value 对，key 和 value 各自都是由 uint16 的长度加上 no-trailing-null 的字符串组成，一般用于传递一些常见的 meta 信息，例如 tracingId； INFO_INTKEYVALUE = 0x10，对应的 data 为 key/value 对，key 为 uint16，value 由 uint16 的长度加上 no-trailing-null 的字符串组成，一般用于传递一些内部定制的 meta 信息，其中作为 request 有些 key 是必填的：  TRANSPORT_TYPE = 1（取值：framed/unframed） LOG_ID = 2 FROM_SERVICE = 3 FROM_CLUSTER = 4（默认 default） FROM_IDC = 5 TO_SERVICE = 6 TO_METHOD = 9   ACL_TOKEN_KEYVALUE = 0x11，对应的 data 为 key/value 对，key 和 value 各自都是由 uint16 的长度加上 no-trailing-null 的字符串组成，用于传递 ACL Token；  ","categories":"","description":"Kitex TTheader 协议设计。","excerpt":"Kitex TTheader 协议设计。","ref":"/zh/docs/kitex/reference/transport_protocol_ttheader/","tags":"","title":"TTHeader"},{"body":"Hertz 提供了一系列示例代码旨在帮助用户快速上手 Hertz 并了解 Hertz 的特性，参考 hertz-examples 以获取更多信息。\nBizdemo hertz_gorm  hertz_gorm ：在 hertz server 中使用 gorm 的示例  hertz_gorm_gen  hertz_gorm_gen ：在 hertz server 中使用 gorm/gen \u0026 proto IDL 的示例  hertz_jwt  hertz_jwt ：在 hertz server 中使用 jwt 的示例  hertz_session  hertz_session ：在 hertz server 中使用分布式 session 和 csrf 的示例  Server 启动 Hertz  hello ：启动对于 hertz 来说相当于 “hello world” 的示例  配置  config ：配置 hertz server 的示例  协议  Protocol ：hertz 使用 HTTP1、TLS 等协议的示例  路由  Route ：注册路由、使用路由组、参数路由的示例  中间件  basic_auth ：使用 basic auth 中间件的示例 CORS ：使用 CORS 中间件的示例 custom ：自定义中间件的示例 pprof ：使用 pprof 中间件的示例 requestid ：使用 RequestID 中间件的示例 gzip ：在 hertz server 中使用 gzip 中间件的示例  参数绑定及验证  binding ：参数绑定及验证的示例  获取参数  parameters ：获取 query、form、cookie 等参数的示例  文件  file ：关于如何上传，下载文件和搭建静态文件服务的示例  渲染  render ：渲染 json, html, protobuf 的示例  重定向  redirect ：重定向到内部/外部 URI 的示例  流式读/写  streaming ：使用 hertz server 流式读/写的示例  优雅退出  graceful_shutdown ：hertz server 优雅退出的示例  单元测试  unit_test ：使用 hertz 提供的接口不经过网络传输编写单元测试的示例  链路追踪  tracer ：hertz 使用 Jaeger 进行链路追踪的示例  监控  monitoring ：hertz 使用 Prometheus 进行指标监控的示例  多端口服务  multiple_service ：使用 Hertz 启动多端口服务的示例  适配器  adaptor ：使用 adaptor 集成基于 http.Handler 接口开发的工具, 包含使用 jade 作为模版引擎的示例  Sentinel  sentinel: ：sentinel-golang 结合 hertz 使用的示例  反向代理  reverseproxy ：在 hertz server 中使用反向代理的示例  Hlog  hlog: ：使用 hlog 以及其日志拓展的示例  Client 发送请求  send_request ：使用 hertz client 发送 http 请求的示例  配置  client_config ：配置 hertz client 的示例  TLS  tls ：hertz client 发送 tls 请求的示例  添加请求内容  add_parameters ：使用 hertz client 添加请求参数的示例  上传文件  upload_file ：使用 hertz client 上传文件的示例  中间件  middleware ：使用 hertz client middleware 的示例  流式读响应  streaming_read ：使用 hertz client 流式读响应的示例  正向代理  forward_proxy ：使用 hertz client 配置正向代理的示例  Hz 基于 Thrift 生成服务端代码  thrift ：使用 hz 与 thrift 生成服务端代码的示例  基于 Protobuf 生成服务端代码  protobuf ：使用 hz 与 protobuf 生成服务端代码的示例  客户端代码生成  hz_client ：使用 hz 生成客户端代码的示例  自定义模板  template ：使用 hz 自定义模版生成服务端代码的示例  接入第三方插件  plugin ：使用 hz 接入第三方插件的示例  ","categories":"","description":"","excerpt":"Hertz 提供了一系列示例代码旨在帮助用户快速上手 Hertz 并了解 Hertz 的特性，参考 hertz-examples 以获取更多 …","ref":"/zh/docs/hertz/tutorials/example/","tags":"","title":"代码示例"},{"body":"我们先来讲一下，我们为什么要 Context。\ntower 中的 Service 签名如下\npubtraitService\u003cRequest\u003e{type Response;type Error;type Future: Future\u003cOutput=Result\u003cSelf::Response,Self::Error\u003e\u003e;fn poll_ready(\u0026mutself,cx: \u0026mutContext\u003c'_\u003e)-\u003e Poll\u003cResult\u003c(),Self::Error\u003e\u003e;fn call(\u0026mutself,req: Request)-\u003e Self::Future;}在 call 方法中并没有 Context 这个概念，那么为什么我们在 Motore 中引入这个概念呢？\n实现一个 Log 中间件 假设我们的需求是在 call 成功或者失败的时候打印 LogId，首先我们需要考虑 LogId 存放在哪儿？\n我们想要使用 Context 来存放所有与该请求上下文有关的信息，那么 LogId 应该可以存放到 Context 中。\npubstruct Context{log_id: String,}按照 tower 的设计，那么 Context 应该可以被放到 Request 中。\n那么我们可以这么来实现我们的中间件。\npubstruct VoloRequest\u003cReq\u003e{cx: Context,data: Req,}pubstruct LogService\u003cS\u003e{inner: S,}impl\u003cReq,S\u003eService\u003cVoloRequest\u003cReq\u003e\u003eforLogService\u003cS\u003e{// 这里省略 poll_ready 实现 fn call(\u0026mutself,req: VoloRequest\u003cReq\u003e)-\u003e Self::Future{async{letlog_id=req.cx.log_id.clone();letresp=self.inner.call(req).await;matchresp{Ok(_)=\u003e{tracing::info(\"log id: {}\",log_id);},Err(_)=\u003e{tracing::error(\"log id: {}\",log_id);},}resp}}}因为我们需要把 VoloRequest 向之后的 Service 传递所有权，那么这里我们就需要把 log_id clone 一下。\n这里的 clone 会有潜在的开销，这个时候我们可以把 log_id 的类型从 String 改为 Arc\u003cString\u003e 来降低开销。\n但是我们真的需要 clone 嘛？\n我们这里打印 log_id 的这个需求其实只需要使用 Context 的引用。并且我们期望 Context 结构的生命周期在整个请求执行阶段都是有效的， 在 inner service 执行完之后，我们仍然可以访问 Context 中的数据。\n所以我们尝试在 Request 之外引入 Context 这个概念，并且让 call 方法可以使用 \u0026mut Context。\n这样我们可以使用这种方式来实现我们的 LogService:\nimpl\u003cReq,S\u003eService\u003cReq\u003eforLogService\u003cS\u003e{// 这里省略 poll_ready 实现 fn call(\u0026mutself,cx: \u0026mutContext,req: Req)-\u003e Self::Future{async{letresp=self.inner.call(cx,req).await;matchresp{Ok(_)=\u003e{tracing::info(\"log id: {}\",cx.log_id);},Err(_)=\u003e{tracing::error(\"log id: {}\",cx.log_id);},}resp}}}Context 的生命周期 Service 使用的是 \u0026mut Context，那么这个引用的生命周期应该是什么呢？\nContext 里面存放的是一个请求的上下文，那么 Context 的生命周期应该是请求级别的。所以我们引入了生命周期 'cx。\n那么 Service call 方法的 \u0026mut self 的生命周期又应该是什么呢？我们的 Rpc Server 是由一个又一个 Service 组成的。那么 Service 的生命周期其实应该是我们的 Rpc Server 的生命周期。\n因为 call 方法返回的 Future 中可能会依赖 Context 中的数据，那么 Future 的 lifetime 至少也应该是 'cx。\n所以最后我们的 call 方法的签名就会变成:\nfn call\u003c'cx,'s\u003e(\u0026'smutself,cx: \u0026'cxmutContext,req: Request)-\u003e Future\u003c'cx\u003e;那么我们该怎么约束返回的 Future 的 lifetime 为 'cx 呢\n 使用 Pin\u003cBox\u003cdyn Future\u003cOutput = Result\u003cSelf::Response, Self::Error\u003e\u003e + 'cx\u003e\u003e GAT  如果我们使用方案1的话就会存在 overhead，不可避免的需要一大堆 Box::pin。\n因此我们这里选择直接使用 GAT（GAT 马上也会 stable）\n","categories":"","description":"","excerpt":"我们先来讲一下，我们为什么要 Context。\ntower 中的 Service …","ref":"/zh/docs/motore/faq/q1_gat/","tags":"","title":"使用 GAT，解决了什么问题？"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/security/safety-bulletin/detail/","tags":"","title":"公告详情"},{"body":"案例介绍   本文将从以下 4 个方面介绍华兴证券基于 Kitex 在多机房 K8s 集群下的实践经验，包括：\n 针对 Kitex 的可观测性系统搭建经验； 服务压力测试中遇到的问题以及解决方案； Kitex 的不同连接类型在 K8s 同集群/跨集群调用下的一些问题和解决方案； 实践中遇到的其他问题以及解决方案；  Kitex 的可观性系统搭建 华兴证券 CloudWeGo-Kitex 使用情况 去年 6 月 1 日，华兴证券相关研发团队成立。Kitex 在 7 月 12 日发布了首个版本，10 天后就引入了 Kitex。\n选择 Kitex 的原因是：团队早期成员比较了解 Kitex，为了快速支撑业务迭代和验证，选择最熟悉的框架，不但使用上比较习惯，对性能和功能方面也比较有把握。\n后来也支撑了华兴证券 APP 的快速上线，大约 4 个月之后就上线了 APP 的第一个版本。\n下图是业务的微服务调用关系图，一共有三十多个微服务，调用链路数超过 70。服务分别部署在两个机房。核心业务比如交易、行情等部署在私有机房。 非核心的业务，比如资讯、股票信息等部署在阿里的金融云，这样能够更好地利用金融云已有的基础设施比如 MySQL、Kafka 等，作为初创团队，能够降低整体的运维压力。 考虑到性能以及安全方面的因素，两个机房之间专门拉了专线。服务之间存在一些跨机房的依赖。跨机房调用会产生很多问题，后文会详细说明。\nTracing 选型 服务数多了之后，我们需要一套链路追踪系统来描绘调用链路每个环节的耗时情况。考虑到 Kitex 原生支持 Opentracing，为减少集成成本，我们调研了符合 Opentracing 规范的产品。\n排除掉收费的、客户端不支持 Go 之后，就剩阿里云的链路追踪产品和 Uber 公司出品的 Jaeger，考虑到私有机房也要部署，最终选择了 Jaeger。\nKitex 接入 Tracing 选定方案之后，开始对 Kitex 的这个功能进行测试，结果发现当时去年 9 月初的 Kitex 版本并不支持跨服务的 Tracing，原因是调用的时候，没有把 Trace 信息发送给下游，如图所示， 这样上下游是两个孤立的 Trace（OpenTracing 规范里称为 Span），于是就无法通过一个 TraceID 去串起整条链路。当时任务比较急，于是我们没有等 Kitex 官方的实现，决定自研。\n为了自研，我们结合 Kitex 的源码，梳理出客户端和服务端的流程。可以看出 Kitex 的上下游都内置了 Tracer 的 Hook。这里我们要解决的问题是，如何把 Span 信息进行跨服务传输？\n经调研，实现透传有三种方案。\n第一种是在消息层搞一个 Thrift 协议的拓展，把 Trace 信息塞进去。原因是 Thrift 本身没有 Header 结构，只能进行协议的拓展。好在 Kitex 支持自定义的协议拓展，因此具备可行性，然而开发成本较高，所以没选择这种方案。\n第二种是在 IDL 里增加通用参数，在字段里存 Trace 信息。缺点是业务无关的字段要在 IDL 里，对性能有一定的影响。毕竟需要通过 Kitex 的中间件，通过反射来提取。\n第三种是利用了 Kitex 提供的传输层透传能力，对业务没有侵入性。最后选择了这一种方案。\n透传方案定了之后，整体的流程就清晰了。首先客户端会在 metaHandler.write 里通过 CTX 获取当前 Span，提取并写入 spanContext 到 TransInfo 中。\n然后服务端，在 metaHandler.Read 里读取 spanContext 并创建 ChildOf 关系的 Span，中间件结束时 span.finish()，最后为了防止产生孤立 Trace，New 服务端时不使用 Kitex 提供的 Tracing 的 Option。\n这里是因为同一个服务可能分别作为 Kitex 上下游，Tracer 如果共用，需要分别加特殊逻辑，实现上有点复杂。\nTracing 基础库 为了充分利用 Tracing 的能力，除了 Kitex，我们在基础库中也增加了 Gin、Gorm、Redis、Kafka 等组件的 Tracing。\n下面展示实际的一条链路。功能是通过短信验证码进行登录。先是作为 HTTP 服务的 API 入口，然后调用了一个短信的 RPC 服务，RPC 服务里面通过 Redis 来检查验证码。 通过之后调用用户服务，里面可能进行一些增加用户的 MySQL 操作。最后把用户登录事件发给 Kafka，然后运营平台进行消费，驱动一些营销活动。可以看出最耗时的部分是关于新增用户的一堆 MySQL 操作。\n对错误的监控 Tracing 一般只关注调用耗时，然而一条链路中可能出现各种错误：\n Kitex   Kitex RPC 返回的 err（Conn Timeout、Read Timeout 等）； IDL 里自定义的业务 Code（111: 用户不存在）。  2.HTTP\n 返回的 HTTP 状态码（404、503）； JSON 里的业务 Code（-1: 内部错误）。  如何对这类错误进行监控？主要有以下三种方案：\n  打日志 + 日志监控，然后通过监控组件，这种方案需要解析日志，所以不方便；\n  写个中间件上报到自定义指标收集服务，这种方案优点是足够通用，但是需要新增中间件。同时自定义指标更关注具体的业务指标；\n  利用 Tracing 的 Tag，这种方案通用且集成成本低。\n  具体实现如下：\n Kitex 的 err、以及 HTTP 的状态码，定义为系统码； IDL 里的 Code 以及 HTTP 返回的 JSON 里的 Code，定义成业务码； Tracing 基础库里提取相应的值，设置到 span.tag 里； Jaeger 的 tag-as-field 配置里加上相应的字段（原始的 Tags，为 es 里的 Nested 对象，无法在 Grafana 里使用 Group By）。  监控告警 在增加错误监控的基础上，我们构建了一套监控告警系统体系。\n这里重点看一下刚才的链路追踪相关的内容。首先每个业务容器会把指标发送到 Jaeger 服务里。Jaeger 最终把数据落盘到 es 中。然后我们在 Grafana 上配置了一堆看板以及对应的告警规则。\n触发报警时，最终会发送到我们自研的 alert-webhook 里。\n自研的部分首先进行告警内容的解析，提取服务名等信息，然后根据服务的业务分类，分发到不同的飞书群里，级别高的报警会打加急电话。这里也是用到了飞书的功能。\nGrafana 里我们配置了各类型服务调用耗时、错误码一体化看板，描述了一个服务的方方面面的指标。包括日志监控、错误码监控、QPS 和调用耗时、容器事件监控、容器资源监控等。\n下图展示了飞书告警卡片。包括 RPC 调用超时、系统码错误、业务码错误。\n这里我们做了两个简单的工作，一个是带上了 TraceID，方便查询链路情况。另一个是把业务码对应的含义也展示出来，研发收到报警之后就不用再去查表了。\n本章小结\n 完成了 Tracing 接入 Kitex，实现跨服务传递； 对 Tracing 基础库扩展了其他类型中间件（Gin、Gorm、Redis、Kafka）的支持； 对 Tracing 基础库增加了系统码、错误码实现对错误的监控； 配置了全方位的服务指标看板； 结合 es、Grafana、飞书以及自研告警服务，搭建了针对微服务的监控告警系统。  这样我们就完成了可观测性体系的搭建。\n服务压力测试中遇到的问题以及解决方案 完成了监控告警体系之后，我们希望对服务进行压测，来找出性能瓶颈。第二部分介绍一下服务压测中遇到的问题和解决方案。\nKitex v0.0.8：连接超时问题 首先我们发现，QPS=150 左右，Kitex 出现连接建立超时的错误。当时我们检查了下 CPU、网络、内存等均没有达到限制。先是怀疑连接池大小不太够，于是测了下 10 和 1000，如上图所示，结果在报错数目上没有区别。 另外观察到的一个现象是，压测期间出现接近 5000 的 Time Wait 状态。\n5000 的限制，是因为达到了 tcp_max_tw_buckets 的设置的值。超过这个值之后，新的处于 Time Wait 状态的连接会被销毁，这样最大值就保持在 5000 了。 于是我们尝试进行排查，但没有思路，于是去翻看 Kitex 的 Issue，发现有人遇到相同的问题。\n原来，v0.0.8 版本的 Kitex，在使用域名的方式来新建 Client 的时候，会导致连接池失效。因为把连接放回连接池时，用的 Key 是解析之后的 IP，而 GET 的时候，用的是解析前的域名，这样根本 Get 不到连接，于是不停创建短连接。 这样的两个后果是：建立连接比较耗时，另一方面请求执行完毕之后都会关闭掉连接，于是导致了大量的 Time Wait。\n为了进行验证，我把测试服务改成了 IP 访问，然后比较了 IP 访问和域名访问以及不同连接池大小的情况。可以看出：IP 访问（连接池有效），但是连接池比较小的情况，出现减少的 Timeout。 连接池 100，Timeout 消失。而中间的域名访问的情况下，出现大量 Timeout。\nKitex v0.1.3：连接池问题修复 看代码得知在 Kitex v0.1.3 修复了这个问题。\n于是我们打算升级 Kitex 的版本，因为当时已经上了生产环境，在升级基础组件之前，需要进行验证，看一下不同连接池大小状态下的表现。还是域名模式，QPS 为 150 的情况下，随着连接池大小的增加，Timeout 的情况逐渐变少到消失。\n继续进行压测，我们发现 QPS=2000 的时候又出现了报错。结合监控，发现原因是连接建立的时候超过了默认的 50ms。\n我们讨论了几种解决方案：\n 修改超时配置。然而，交易日的 9:30-9:35 有⼀堆集中交易请求，突发的流量，耗时长了体验不好，可能会影响 APP 收入，我们希望系统性能保持稳定。 进行连接耗时的优化。然而 Kitex 已经使用了 Epoll 来处理创建连接的事件，作为使用方，进一步优化的难度和成本都太大。 MaxidleTimeout 参数改成无限大？比如先创建一个足够大的池，然后随着用户请求，池变得越来越大，最终稳定下来。但是每次服务升级之后，这个池就空了，需要慢慢恢复。 进行连接预热。  其实连接预热就相当于压测结束之后立马趁热再压一次，如图，可以发现 QPS=2000 的情况下，几乎都走了连接池，没有报错。因此，如果服务启动时能够进行连接预热，就可以省下建立连接的时间，使服务的性能保持稳定。\n当时 CloudWeGo 团队针对我们公司建了企业用户交流群，于是我们就向群里的 Kitex 研发提了连接预热的需求。其开发之后提供了连接预热个数的选项。我们也进行了测试。按照 QPS=2000 进行测试，\n WARM_UP_CONN_NUM=0：大约 1s 报错； WARM_UP_CONN_NUM=100：大约 4s 报错；   WARM_UP_CONN_NUM=1000：大约 4s 报错，但可以看出一开始都无需新建连接； WARM_UP_CONN_NUM=2000：无报错。  本章小结如下：\n Kitex v0.0.8：域名模式下存在连接池失效问题，v0.1.3 中修复； Kitex v0.1.3：可进一步通过连接预热功能提高系统性能。  Kitex 的不同连接类型在 K8s 同集群/跨集群调用下的一些问题和解决方案 长连接的问题：跨集群调用 第三部分我们讨论一下 Kitex 的不同连接类型在 K8s 同集群/跨集群调用下的一些问题和解决方案。\n首先是长连接跨集群调用下的问题。服务在跨集群调用时，其源 IP: 端口为宿主机的，数量有限，而目的 IP: 端口为下游集群的 LB，一般是固定的。\n那么，当长连接池数目比较大（比如数千），且上游较多（各种服务、每个都多副本，加起来可能数十个）的情况下，请求高峰时段可能导致上游宿主机的源端口不够用。同集群内跨机器调用走了 vxlan，因此没有这个问题。\n解决方案有两类：\n 硬件方案：机器； 软件方案：对于下游为 Kitex 服务，改用 Mux 模式（这样少量连接就可以处理大量并发的请求）。下游不是 Kitex 框架，因为 Mux 是私有协议，不支持非 Kitex。此时可考虑增加下游服务的 LB 数量，比如每个 LB 上分配多个端口。  比较起来，改造成 Mux 模式成本最低。\n连接多路复用的问题：滚动升级 但是多路复用模式，在 K8s 场景下，存在一个滚动升级相关的问题。我们先介绍下 Service 模式， K8s 的 Service 模式采用了 IPVS 的 Nat 模式（DR 和隧道模式不支持端口映射），链路为：\n上游容器←→ClusterIP（服务的虚拟 IP）←→下游容器\n然后我们看看滚动升级流程：\n 新容器启动。 新容器 Readiness Check 通过，之后做两件事情：  更新 Endpoints 列表：新增新容器，删除旧容器； 发送 sigTerm 到旧容器的 1 号进程。   由于更新了 Endpoints 列表，Endpoints 列表发生更新事件，立即回调触发规则更新逻辑（syncProxyRules）：  添加新容器到 IPVS 的 rs，权重为 1； 如果此时 IPVS 的旧容器的中 ActiveConn + InactiveConn \u003e 0（即已有连接还在），旧容器的权重会改成 0，但不会删除 rs。    经过步骤 3 之后，已有的连接仍然能够正常工作（因为旧容器 rs 未删），但新建的连接会走到新的容器上（因为旧容器权重 =0）。\n在 Service 模式下，上游通过一个固定的 IP: 端口来访问下游，当下游滚动升级的时候，上游看到的地址并未变化，即无法感知到滚动升级。于是，下游即使有优雅退出，但上游并不知道下游开始优雅退出了。之后可能的情况是：\n 下游发现连接繁忙，一直没有主动关闭，导致 K8s 配置的优雅升级时间超时，强制 Kill 进程，连接关闭，上游报错。 下游发现连接空闲，主动关闭，然而客户端在关闭之前恰好拿到了连接（且认为可用），然后发起请求，实际上由于连接关闭，发起请求失败报错。  针对此问题，解决方案如下：\n 同集群调用：改用 Headless Service 模式（结合 DNSResolver）：通过 DNS 列表的增删来感知下游变动； 跨集群调用：借鉴 HTTP2 的 GOAWAY 机制。  具体，可采用如下方式：\n 收到 sigTerm 的下游直接告诉上游（通过之前建立的 Conn1），同时下游继续处理发来的请求。 上游收到关闭信息之后：  新请求通过新建 Conn2 来发； 已有的请求仍然通过 Conn1，且处理完了之后，等下游优雅关闭 Conn1。    这种方式的优点是同集群跨集群均可使用，缺点是需要 Kitex 框架支持。在我们找 Kitex 团队讨论之后，他们也提供了排期支持本需求。\n连接多路复用的滚动升级测试：Headless Service 模式 在 Kitex 团队开发期间，我们测下 Kitex 已有版本对 Headless Service 模式下的滚动升级功能。\n测试方案如下：\n Kitex 版本 v0.1.3； 上下游均为 Mux 模式； 上游的加了个自定义 DNSResolver，刷新时间为 1s，加日志打印解析结果； 下游的退出信号处理，收到 sigTerm 之后特意 Sleep 10s（用来排除这个 Case：服务端发现连接空闲关闭了，但客户端在关闭之前恰好拿到连接，接着认为未关闭，实际上已经关闭，而客户端发起了请求，于是导致报错）； QPS=100 恒定压上游，然后触发下游滚动升级。  实测报错如下图：\n时序分析如下：\n 旧下游收到 sigTerm，开始 Sleep 10s； 上游解析到旧下游的 IP，向旧下游发起请求； DNS 规则更新：旧上游 IP 解析项消失，新下游解析项出现； 上游请求报错； 旧下游sleep完成，开始退出逻辑。  可见报错时旧下游还未执行退出逻辑，排除旧下游主动关闭连接。请求旧下游期间，且此时解析到新容器 IP（移除了旧容器 IP），报错是因为还没到退出逻辑的时候。因此推测，解析条目变化导致了报错。\n根据推测，结合代码（Kitex 客户端部分）分析，可能出现以下并发问题：\n 【协程1】客户端从 Mux池里取出 conn1，即将发起请求（所以没有机会再检查 conn1 状态了）； 【协程2】DNS 更新，移除了 IP，于是 Clean 方法中关闭了 conn1； 【协程1】客户端用 conn1 发起请求，导致报错 conn closed。  于是我们向 CloudWeGo 提了 Issue，他们很快修复了这个问题。\n连接多路复用的滚动升级测试：Service 模式 同样地，在 Service 模式中，测试方案如下：\n Kitex 版本使用 Feature 分支：mux-graceful-shutdown； 上下游均为 Mux 模式、服务发现使用 Service 模式； 恒定 QPS=200 压上游，20s 触发下游滚动升级； 另外写个服务打印期间的 IPVS 的日志； 下游的退出信号处理，收到 SigTerm 之后特意 sleep 10s（保证 ipvs 规则已更新）。  测试结果如下： 报错：INFO[0050] “{\"code\":-1,\"message\":\"remote or network error: conn closed\"}\"。\n时序分析为：\n 旧下游收到 sigTerm，开始 sleep 10s。 IPVS规则变化：  新下游 weight=1，ac=0，inac=0； 旧下游 weight=0，ac=2，inac=0。   旧下游 sleep 完成，进入最长为 15s（WithExitWaitTime）的优雅退出。 上游请求报错。 旧下游打印了最后一条日志。 IPVS 规则变化：  新下游 weight=1，ac=2，inac=0 =\u003e ac=2 说明上游新建连接到新容器； 旧下游 weight=0，ac=0，inac=2 =\u003e inac=2 表示连接关闭。   IPVS 规则变化：旧下游的规则被移除。  因此我们得出结论，报错发生在优雅退出期间。最后一条日志时刻大于报错时刻，因此，排除 K8s 的问题，确认 Conn Closed 是由 Kitex 导致的。 之后我们和 Kitex 研发团队沟通了分析结果，找到了 Root Cause，是因为假设了新的下游会有一个新的地址（但实际中 Service 模式都是一个地址），导致新请求取到了老请求的连接并进行关闭。对此进行了修复：\n连接多路复用的问题：下游扩容 如果⽤ Service 模式（上游看到的下游就是体现为⼀个 IP），创建的 TCP 连接会在最开始固定的几个下游 POD 上，之后如果扩容增加 POD，新创建的 POD 就不会路由到了，导致扩容实际上无效。\n解决方案如下：\n 同集群调用：可用 Headless Service 模式，由于 DNS 解析能够得到所有 POD，路由没问题。 跨集群调用：不在同集群内， Headless Service 模式无效，考虑如下方案：   方案1：修改服务发现机制。 优点：Kitex 无需改动。 缺点：增加依赖项（服务发现组件）。 方案2：下游先升级，之后上游 Redeploy 一下，让连接分布到下游的各种实例上。 优点：Kitex 无需改动。 缺点：上游可能很多，逐个 Redeploy 非常不优雅。 方案3：上游定期把 Mux 给过期掉，然后新建连接。 优点：彻底解决。 缺点：需要 Kitex 支持。  本章小结如下：\n 首先，针对长连接模式分析了跨集群时上游源端口数问题，希望通过多路复用模式解决； 其次，针对多路复用模式 + K8s Headless Service 模式的优雅升级，实测报错，分析定位了原因，Kitex 研发团队及时解决了相应问题； 再次，针对多路复用模式 + K8s Service 模式下的优雅升级提出了方案，Kitex 团队完成了实现，迭代了一轮，测试通过； 最后，针对多路复用模式 + K8s Service 模式下的下游副本扩容时路由不到的问题分析了原因，提出了方案，目前方案待实现。  实践中遇到的其他问题以及解决方案 RPC Timeout Context Canceled 错误 第四部分我们分析下实践中遇到的其他问题以及解决方案。研发同学发现日志出现 contexe canceled 的错误，分析日志发现出现频率低，一天只有几十条，属于偶发报错。\n我们推测是用户手机因为某种原因关闭了进行中的连接所导致，对此进行本地验证。三个部分：首先Gin 客户端设置了 500ms 超时限制，去请求 Gin 服务端接口； 其次，Gin 服务端收到请求之后，转而去调用 Kitex 服务；最后，Kitex 服务端 sleep 1s 模拟耗时超时，保证 Gin 客户端在请求过程中关闭连接。\n实测能够稳定地复现。\n我们梳理了源码逻辑，客户端关闭连接之后，Gin 读取到 EOF，调用 cancelCtx，被 Kitex 客户端的 rpcTimeoutMW 捕获到，于是返回了 err。\n那么问题就变成，请求未完成时，连接为何会被关闭？我们按照设备的 ID 去分析日志，发现两类情况：一类是报错对应的请求是该设备短期内的最后一条，于是考虑 APP 被手动关闭； 二是报错对应的请求非短期内的最后一条，客户端研发反馈，有些接口例如搜索，上一条请求执行中（未返回），且新的请求来时，会 Close 掉上一次请求的连接。 第二种情况比较确定，关于第一种情况，APP 被关闭时，IOS 和 Android 是否会关闭连接？客户端同学没有给出肯定的答复。\n于是我们考虑实际测试一下，两端分别写一个测试的应用，持续发起请求，但是不释放连接，此时关闭 APP，分析 TCP 包。实测我们在两端上均看到了 4 次挥手的 Fin 包。所以这个问题得到了确认。\n那么如何进行修复呢？我们采取在 GIN 的中间件上拦截掉 Done 方法的方式。\n上线之后，再没有出现这种情况。\n还有一个问题，我们在测试环境发现，跨集群调用的时候，经常出现连接被重置的问题。生产环境搜日志，无此现象。\n我们分析了环境差异：\n 生产环境是专线直连； 测试环境，因为专线比较昂贵，机房之前通过公网访问，中间有个 NAT 设备。  我们找网络同事咨询，得知 NAT 表项的过期时间是 60s。连接过期时，NAT 设备并不会通知上下游。因此，上游调用的时候，如果 NAT 设备发现表项不存在，会认为是一个失效的连接，就返回了 rst。 于是我们的解决方案是 Kitex 上游的 MaxIdleTimeout 改成 30s。实测再未出现报错。\n本章小结如下：\n Rpc Timeout：Tontext Tanceled 问题分析和解决； Rpc Error：Connection Reset 问题分析和解决。  展望 未来我们计划把 Gin 更换为更高性能（QPS/时延）的 CloudWeGo-Hertz。因为我们 K 线服务的 Response Size 比较大（~202KiB），更换后 QPS 预计可达原先的 5 倍。 同时，为回馈开源社区，我们打算贡献 Tracing 基础库的代码到 Kitex-contrib/Tracer-opentracing。欢迎持续关注 CloudWeGo 项目，加入社区一起交流。\n","categories":"","description":"","excerpt":"案例介绍   本文将从以下 4 个方面介绍华兴证券基于 Kitex 在多机房 K8s 集群下的实践经验，包括：\n 针对 Kitex 的可观测 …","ref":"/zh/cooperation/huaxingsec/","tags":"","title":"华兴证券：混合云原生架构下的 Kitex 实践"},{"body":"cwgo 是 CloudWeGo 提供的用于生成代码的一个命令行工具。目前 cwgo 支持 thrift 和 protobuf 的 IDL，支持生成 MVC Layout、Server、Client 和 DB 的代码。\n依赖与运行模式 cwgo 工具并不直接生成代码，而是构造好模板后调用相应工具的生成函数。\ncwgo | | HTTP server / client |-----------\u003e hz | RPC server / client |-----------\u003e kitex | DB ------------\u003e gorm/gen 所以相对应工具的注意事项也需要遵守， 如生成 RPC 代码时 kitex 的注意事项和生成 HTTP 代码时 hz 的注意事项。\n使用 cwgo 支持交互式命令行和静态命令行两种生成方式。并且弱化了 new 和 update 的概念，更新时直接输入之前的指令即可。\n交互式命令行 交互式命令行支持一次调用生成所有代码，如 Server、Client、DB，满足大部分用户的需求，用户只需要根据提示输入信息即可。\n语法：cwgo init\n执行 cwgo init 后，会首先询问需要生成的项目类型，支持多选，如下图所示，选择了 server 和 client\n敲回车后，会依次询问 server 和 client 的信息。步骤如下\n  选择服务类型，RPC 还是 HTTP。单选。\n  输入服务名称。必填。\n  输入 go module 名称。在 GOPATH 外为必填，在 GOPATH 内不需要填。\n  输入 idl 路径。必填。\n  是否使用默认配置去生成项目\n 默认配置：无服务发现组件，无其他参数 非默认配置：选择服务发现组件；输入传递给生成工具的参数    client 询问的问题和 server 大致相同，区别是会首先询问生成的 client 的数量，之后循环输入每一个 client 的信息。\ndb 询问的信息为：\n 选择数据库类型。单选 输入数据库 DSN。必填 选择是否使用默认配置去生成项目。如选择否，则会要求输入传递给生成工具的参数  对于传递给工具的参数，hz 参考文档，kitex 参考文档。\n静态命令行 命令说明 $ cwgo -h NAME: cwgo - All in one tools for CloudWeGo USAGE: cwgo [global options] command [command options] [arguments...] COMMANDS: init 交互式命令行 server 生成 RPC 或者 HTTP Server client 生成 RPC 或者 HTTP Client model 生成 DB Model fallback 回退到 kitex 或者 hz 工具 GLOBAL OPTIONS: --verbose 打开冗余日志模式 --version, -v 打印工具版本 Server 和 Client 命令 --service 指定服务名称 --type 指定生成类型 --module 指定生成 module 名称 --idl 指定 IDL 文件路径 --out_dir 指定输出路径 --template 指定 layout 模板路径 --registry 指定服务注册组件 --proto_search_path 添加 IDL 搜索路径，只对 pb 生效 --pass value 传递给 hz 和 kitex 的参数 pass 参数说明：\n如传递 hz 的 `handler_dir\" 参数, 则应输入 –pass “–handler_dir ./handler”\n传递给工具的参数 hz 参考文档， kitex 参考文档。\nModel 命令 --dsn 指定数据库 DSN --db_type 指定数据库类型 --out_dir 指定输出文件夹，默认 biz/dao/query --out_file 指定输出文件名，默认 gen.go --tables 指定数据库表名称 --unittest 是否生成单测，默认不生成 --only_model 是否只生成 model 代码，默认关闭 --model_pkg 指定 model package 名 --nullable 当字段为 null 时，指定是否生成指针，默认关闭 --type_tag 是否给字段生成 gorm column type tag，默认不生成 --index_tag 是否给字段生成 gorm index tag，默认不生成 常用命令 Server\ncwgo server --type {{RPC/HTTP}} --idl {{path/to/IDL_file.thrift}} --service {{svc_name}} Client\ncwgo client --type {{RPC/HTTP}} --idl {{path/to/IDL_file.thrift}} --service {{svc_name}} Model\ncwgo model --db_type mysql --dsn \"gorm:gorm@tcp(localhost:9910)/gorm?charset=utf8\u0026parseTime=True\u0026loc=Local\" ","categories":"","description":"","excerpt":"cwgo 是 CloudWeGo 提供的用于生成代码的一个命令行工具。目前 cwgo 支持 thrift 和 protobuf 的 IDL， …","ref":"/zh/docs/cwgo/tutorials/cli/","tags":"","title":"命令行工具"},{"body":"为了增加框架的灵活性和易用性，Volo 允许用户在 Client 端使用 CallOpt 针对单个请求设置一些请求的元信息。\n以 Volo-Thrift 为例，CallOpt 定义如下：\npubstruct CallOpt{/// Sets the callee tags for the call. pubcallee_tags: TypeMap,/// Sets the address for the call. pubaddress: Option\u003cAddress\u003e,pubconfig: Config,/// Sets the caller tags for the call. pubcaller_tags: TypeMap,}其中 callee_tags 指代的是对端的一些元信息，caller_tags 指代的是本地的元信息，这两个 TypeMap 主要是给服务发现、负载均衡、路由等中间件扩展使用的。\naddress 代表下游的地址，如果设置了，原则上就不需要经过服务发现和负载均衡等组件了。\nconfig 中可以设置一些请求的配置，比如 RPC 超时时间等。\n我们可以通过下述方法来在请求时指定 CallOpt：\nlazy_static!{staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example-item\").layer_outer(LogLayer).address(addr).build()};}#[volo::main]asyncfn main(){letcallopt=CallOpt::default();letreq=volo_gen::volo::example::GetItemRequest{id: 1024};letresp=CLIENT.clone().with_callopt(callopt).get_item(req).await;matchresp{Ok(info)=\u003etracing::info!(\"{:?}\",info),Err(e)=\u003etracing::error!(\"{:?}\",e),}}","categories":"","description":"","excerpt":"为了增加框架的灵活性和易用性，Volo 允许用户在 Client 端使用 CallOpt 针对单个请求设置一些请求的元信息。 …","ref":"/zh/docs/volo/guide/with_callopt/","tags":"","title":"在调用时指定 CallOpt"},{"body":"为什么需要 Plugin 为 Pilota 根据 IDL 生成的 Struct 等类型增加一些自定义的 meta 信息。\n比如增加#[derive(serde::Serialize, serde::Deserialize]) 等\n如何写一个 Plugin 实现 Plugin #[derive(Clone, Copy)]struct SerdePlugin;implpilota_build::PluginforSerdePlugin{fn on_item(\u0026mutself,cx: \u0026mutpilota_build::Context,def_id: pilota_build::DefId,// item 的 def_id item: std::sync::Arc\u003cpilota_build::rir::Item\u003e,){match\u0026*item{pilota_build::rir::Item::Message(_)|pilota_build::rir::Item::Enum(_)|pilota_build::rir::Item::NewType(_)=\u003ecx.with_adjust(def_id,|adj|{// Adjust 的 add_attrs 方法可以为 def_id 对应的 Node 增加 Attribute，在之后的 Codegen 阶段会带上这些元信息生成代码 adj.add_attrs(\u0026[parse_quote!(#[derive(::serde::Serialize, ::serde::Deserialize)])])}),_=\u003e{}};pilota_build::plugin::walk_item(self,cx,def_id,item)}}使用 Plugin 通过 Builder 提供的 plugin 方法传入即可\npilota_build::thrift().plugin(SerdePlugin).write()","categories":"","description":"","excerpt":"为什么需要 Plugin 为 Pilota 根据 IDL 生成的 Struct 等类型增加一些自定义的 meta 信息。\n比如增 …","ref":"/zh/docs/pilota/guide/plugin/","tags":"","title":"如何编写 Plugin？"},{"body":" 搜索    全部  低  中  高  致命     年份 请选择 2021 2022 2023 2024 2025       公告 摘要 严重级别 影响组件与版本 发布时间      Previous  1 2  3 Next   Total: 3    ","categories":"","description":"","excerpt":" 搜索    全部  低  中  高  致命     年份 请选择 2021 2022 2023 2024 2025 …","ref":"/zh/security/safety-bulletin/","tags":"","title":"安全公告"},{"body":"Volo 提供了同名的命令行工具，用来初始化项目、管理 IDL 等。我们可以先通过以下命令来安装 Volo：\n$ cargo install volo-cli 随后，我们输入：\n$ volo help 就能看到类似以下输出啦：\nUSAGE: volo [OPTIONS] \u003cSUBCOMMAND\u003e OPTIONS: -h, --help Print help information -n, --entry-name \u003cENTRY_NAME\u003e The entry name, defaults to 'default'. [default: default] -v, --verbose Turn on the verbose mode. -V, --version Print version information SUBCOMMANDS: help Print this message or the help of the given subcommand(s) idl manage your idl init init your project ","categories":"","description":"","excerpt":"Volo 提供了同名的命令行工具，用来初始化项目、管理 IDL 等。我们可以先通过以下命令来安装 Volo：\n$ cargo install …","ref":"/zh/docs/volo/volo-grpc/getting-started/part_1/","tags":"","title":"Part 1. 安装命令行工具"},{"body":"Volo 提供了同名的命令行工具，用来初始化项目、管理 IDL 等。我们可以先通过以下命令来安装 Volo：\n$ cargo install volo-cli 随后，我们输入：\n$ volo help 就能看到类似以下输出啦：\nUSAGE: volo [OPTIONS] \u003cSUBCOMMAND\u003e OPTIONS: -h, --help Print help information -n, --entry-name \u003cENTRY_NAME\u003e The entry name, defaults to 'default'. [default: default] -v, --verbose Turn on the verbose mode. -V, --version Print version information SUBCOMMANDS: help Print this message or the help of the given subcommand(s) idl manage your idl init init your project ","categories":"","description":"","excerpt":"Volo 提供了同名的命令行工具，用来初始化项目、管理 IDL 等。我们可以先通过以下命令来安装 Volo：\n$ cargo install …","ref":"/zh/docs/volo/volo-thrift/getting-started/part_1/","tags":"","title":"Part 1. 安装命令行工具"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/volo/volo-grpc/getting-started/","tags":"","title":"快速开始"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/volo/volo-thrift/getting-started/","tags":"","title":"快速开始"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/","tags":"","title":"文档"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/blog/news/","tags":"","title":"新闻"},{"body":"cwgo 是 CloudWeGo All in one 代码生成工具，整合了各个组件的优势，提高开发者提体验。\ncwgo 工具可以方便生成工程化模版，其主要功能特点如下：\n工具特点   用户友好生成方式\ncwgo 工具同时提供了交互式命令行和静态命令行两种方式。交互式命令行可以低成本生成代码，不用再去关心传递什么参数，也不用执行多次命令， 适合大部分用户；而对高级功能有需求的用户，仍可使用常规的静态命令行构造生成命令。\n  支持生成工程化模板\ncwgo 工具支持生成 MVC 项目 Layout，用户只需要根据不同目录的功能，在相应的位置完成自己的业务代码即可，聚焦业务逻辑。\n  支持生成 Server、Client 代码\ncwgo 工具支持生成 Kitex、Hertz 的 Server 和 Client 代码，提供了对 Client 的封装。用户可以开箱即用的调用下游，免去封装 Client 的繁琐步骤\n  支持生成数据库代码\ncwgo 工具支持生成数据库 CURD 代码。用户无需再自行封装繁琐的 CURD 代码，提高用户的工作效率。\n  支持回退为 Kitex、Hz 工具\n如果之前是 Kitex、Hz 的用户，仍然可以使用 cwgo 工具。cwgo 工具支持回退功能，可以当作 Kitex、Hz 使用，真正实现一个工具生成所有。\n  安装 cwgo 工具 # Go 1.15 及之前版本 GO111MODULE=on GOPROXY=https://goproxy.cn/,direct go get github.com/cloudwego/cwgo@latest # Go 1.16 及以后版本 GOPROXY=https://goproxy.cn/,direct go install github.com/cloudwego/cwgo@latest ","categories":"","description":"","excerpt":"cwgo 是 CloudWeGo All in one 代码生成工具，整合了各个组件的优势，提高开发者提体验。\ncwgo 工具可以方便生成工 …","ref":"/zh/docs/cwgo/overview/","tags":"","title":"概览"},{"body":"CloudWeGo-Hertz Hertz[həːts] 是一个 Golang 微服务 HTTP 框架，在设计之初参考了其他开源框架 fasthttp、gin、echo 的优势， 并结合字节跳动内部的需求，使其具有高易用性、高性能、高扩展性等特点，目前在字节跳动内部已广泛使用。 如今越来越多的微服务选择使用 Golang，如果对微服务性能有要求，又希望框架能够充分满足内部的可定制化需求，Hertz 会是一个不错的选择。\n架构设计 框架特点   高易用性\n在开发过程中，快速写出来正确的代码往往是更重要的。因此，在 Hertz 在迭代过程中，积极听取用户意见，持续打磨框架，希望为用户提供一个更好的使用体验，帮助用户更快的写出正确的代码。\n  高性能\nHertz 默认使用自研的高性能网络库 Netpoll，在一些特殊场景相较于 go net，Hertz 在 QPS、时延上均具有一定优势。关于性能数据，可参考下图 Echo 数据。\n四个框架的对比:\n三个框架的对比:\n关于详细的性能数据，可参考 https://github.com/cloudwego/hertz-benchmark。\n  高扩展性\nHertz 采用了分层设计，提供了较多的接口以及默认的扩展实现，用户也可以自行扩展。同时得益于框架的分层设计，框架的扩展性也会大很多。目前仅将稳定的能力开源给社区，更多的规划参考 RoadMap。\n  多协议支持\nHertz 框架原生提供 HTTP1.1、ALPN 协议支持。除此之外，由于分层设计，Hertz 甚至支持自定义构建协议解析逻辑，以满足协议层扩展的任意需求。\n  网络层切换能力\nHertz 实现了 Netpoll 和 Golang 原生网络库 间按需切换能力，用户可以针对不同的场景选择合适的网络库，同时也支持以插件的方式为 Hertz 扩展网络库实现。\n  框架性能 性能测试只能提供相对参考，工业场景下，有诸多因素可以影响实际的性能表现。\n我们提供了 hertz-benchmark 项目用来长期追踪和比较 Hertz 与其他框架在不同情况下的性能数据以供参考。\n相关项目  Netpoll: 自研高性能网络库，Hertz 默认集成 Hertz-Contrib: Hertz 扩展仓库，提供中间件、tracer 等能力 Example: Hertz 使用例子  相关文章  字节跳动在 Go 网络库上的实践  ","categories":"","description":"","excerpt":"CloudWeGo-Hertz Hertz[həːts] 是一个 Golang 微服务 HTTP 框架， …","ref":"/zh/docs/hertz/overview/","tags":"","title":"概览"},{"body":"CloudWeGo-Kitex Kitex[kaɪt’eks] 字节跳动内部的 Golang 微服务 RPC 框架，具有高性能、强可扩展的特点，在字节内部已广泛使用。如果对微服务性能有要求，又希望定制扩展融入自己的治理体系，Kitex 会是一个不错的选择。\n架构设计 框架特点   高性能\n使用自研的高性能网络库 Netpoll，性能相较 go net 具有显著优势。\n  扩展性\n提供了较多的扩展接口以及默认扩展实现，使用者也可以根据需要自行定制扩展，具体见下面的框架扩展。\n  多消息协议\nRPC 消息协议默认支持 Thrift、Kitex Protobuf、gRPC。Thrift 支持 Buffered 和 Framed 二进制协议；Kitex Protobuf 是 Kitex 自定义的 Protobuf 消息协议，协议格式类似 Thrift；gRPC 是对 gRPC 消息协议的支持，可以与 gRPC 互通。除此之外，使用者也可以扩展自己的消息协议。\n  多传输协议\n传输协议封装消息协议进行 RPC 互通，传输协议可以额外透传元信息，用于服务治理，Kitex 支持的传输协议有 TTHeader、HTTP2。TTHeader 可以和 Thrift、Kitex Protobuf 结合使用；HTTP2 目前主要是结合 gRPC 协议使用，后续也会支持 Thrift。\n  多种消息类型\n支持 PingPong、Oneway、双向 Streaming。其中 Oneway 目前只对 Thrift 协议支持，双向 Streaming 只对 gRPC 支持，后续会考虑支持 Thrift 的双向 Streaming。\n  服务治理\n支持服务注册/发现、负载均衡、熔断、限流、重试、监控、链路跟踪、日志、诊断等服务治理模块，大部分均已提供默认扩展，使用者可选择集成。\n  代码生成\nKitex 内置代码生成工具，可支持生成 Thrift、Protobuf 以及脚手架代码。\n  框架性能 性能测试只能提供相对参考，工业场景下，有诸多因素可以影响实际的性能表现。\n由于开源社区缺少支持 thrift 的优秀 RPC 框架，当前对比项目为 grpc, rpcx, 均使用 protobuf 协议。\n我们通过 测试代码 比较了它们的性能，测试表明 Kitex 具有明显优势。\n测试环境  CPU: Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz, 4 cores Memory: 8GB OS: Debian 5.4.56.bsk.1-amd64 x86_64 GNU/Linux Go: 1.15.4  并发表现 (Echo 1KB, 改变并发量)    QPS TP99 TP999           吞吐表现 (并发 100, 改变包大小)    QPS TP99 TP999           相关项目  Netpoll: 自研的高性能网络库，Kitex 默认集成的。 kitex-contrib：Kitex 的部分扩展库，使用者可以根据需求通过 Option 集成进 Kitex 中。 Example：Kitex 的使用示例。  相关文章  字节跳动 Go RPC 框架 Kitex 性能优化实践 字节跳动在 Go 网络库上的实践  ","categories":"","description":"Kitex 架构设计、框架特点、框架性能。","excerpt":"Kitex 架构设计、框架特点、框架性能。","ref":"/zh/docs/kitex/overview/","tags":"","title":"概览"},{"body":"Motore 是一个使用了 GAT 和 TAIT 特性的中间件抽象层。\n基于 Motore，我们编写了一些模块化并且可复用的，用来编写 client 和 server 的组件。\nMotore 深受Tower 启发。\nMotore 使用 GAT 和 TAIT 来减轻编写异步代码的精神负担，尤其是为了避免 Box 的开销而导致的负担，以减少使用者的焦虑。\nMotore 最核心的抽象是 Service trait：\npubtraitService\u003cCx,Request\u003e{/// Responses given by the service. type Response;/// Errors produced by the service. type Error;/// The future response value. type Future\u003c'cx\u003e: Future\u003cOutput=Result\u003cSelf::Response,Self::Error\u003e\u003e+Send+'cxwhereCx: 'cx,Self: 'cx;/// Process the request and return the response asynchronously. fn call\u003c'cx,'s\u003e(\u0026'smutself,cx: \u0026'cxmutCx,req: Request)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx;}快速上手 通过将 GAT 和 TAIT 组合在一起，我们可以以非常简洁易读的方式编写异步代码：\npubstruct Timeout\u003cS\u003e{inner: S,duration: Duration,}impl\u003cCx,Req,S\u003eService\u003cCx,Req\u003eforTimeout\u003cS\u003ewhereReq: 'static+Send,S: Service\u003cCx,Req\u003e+'static+Send,Cx: 'static+Send,S::Error: Send +Sync+Into\u003cBoxError\u003e,{type Response=S::Response;type Error=BoxError;type Future\u003c'cx\u003e=implFuture\u003cOutput=Result\u003cS::Response,Self::Error\u003e\u003e+'cx;fn call\u003c'cx,'s\u003e(\u0026'smutself,cx: \u0026'cxmutCx,req: Req)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx,{asyncmove{letsleep=tokio::time::sleep(self.duration);tokio::select!{r=self.inner.call(cx,req)=\u003e{r.map_err(Into::into)},_=sleep=\u003eErr(std::io::Error::new(std::io::ErrorKind::TimedOut,\"service time out\").into()),}}}}我们还提供了#[motore::service]宏以使编写 Service 更加像编写原生异步 Rust：\nusemotore::service;pubstruct S\u003cI\u003e{inner: I,}#[service]impl\u003cCx,Req,I\u003eService\u003cCx,Req\u003eforS\u003cI\u003ewhereReq: Send +'static,I: Service\u003cCx,Req\u003e+Send+'static,Cx: Send +'static,{asyncfn call(\u0026mutself,cx: \u0026mutCx,req: Req)-\u003e Result\u003cI::Response,I::Error\u003e{self.inner.call(cx,req).await}}","categories":"","description":"","excerpt":"Motore 是一个使用了 GAT 和 TAIT 特性的中间件抽象层。\n基于 Motore，我们编写了一些模块化并且可复用的， …","ref":"/zh/docs/motore/overview/","tags":"","title":"概览"},{"body":"简介 Netpoll 是由 字节跳动 开发的高性能 NIO(Non-blocking I/O)网络库，专注于 RPC 场景。\nRPC 通常有较重的处理逻辑，因此无法串行处理 I/O。而 Go 的标准库 net 设计了 BIO(Blocking I/O) 模式的 API，使得 RPC 框架设计上只能为每个连接都分配一个 goroutine。 这在高并发下，会产生大量的 goroutine，大幅增加调度开销。此外，net.Conn 没有提供检查连接活性的 API，因此 RPC 框架很难设计出高效的连接池，池中的失效连接无法及时清理。\n另一方面，开源社区目前缺少专注于 RPC 方案的 Go 网络库。类似的项目如：evio, gnet 等，均面向 Redis, HAProxy 这样的场景。\n因此 Netpoll 应运而生，它借鉴了 evio 和 netty 的优秀设计，具有出色的 性能，更适用于微服务架构。 同时，Netpoll 还提供了一些 特性，推荐在 RPC 设计中替代 net 。\n基于 Netpoll 开发的 RPC 框架 Kitex 和 HTTP 框架 Hertz，其性能均业界领先。\n范例 展示了如何使用 Netpoll 构建 RPC Client 和 Server。\n特性   已经支持\n LinkBuffer 提供可以流式读写的 nocopy API gopool 提供高性能的 goroutine 池 mcache 提供高效的内存复用 IsActive 支持检查连接是否存活 Dialer 支持构建 client EventLoop 支持构建 server 支持 TCP，Unix Domain Socket 支持 Linux，macOS（操作系统）    即将开源\n Shared Memory IPC 支持 TLS 支持 UDP    不被支持\n Windows（操作系统）    性能 性能测试应满足工业级使用要求，在 RPC 场景下，并发请求、等待超时是必要的支持项。\n我们提供了 netpoll-benchmark 项目用来长期追踪和比较 Netpoll 与其他框架在不同情况下的性能数据以供参考。\n更多测试参考 kitex-benchmark 和 hertz-benchmark\n参考  官方网站 使用文档  ","categories":"","description":"","excerpt":"简介 Netpoll 是由 字节跳动 开发的高性能 NIO(Non-blocking I/O)网络库，专注于 RPC 场景。\nRPC 通常有 …","ref":"/zh/docs/netpoll/overview/","tags":"","title":"概览"},{"body":"Volo Volo 是字节跳动服务框架团队研发的轻量级、高性能、可扩展性强、易用性好的 Rust RPC 框架，使用了 Rust 最新的 GAT 特性。\nVolo 使用 Motore 作为中间件抽象层，Motore 基于 GAT 设计。\n架构图 特性 基于 GAT 设计 我们热爱并追随最新的技术，Volo 的核心抽象使用了 Rust 最新的 GAT 特性，在这个过程中我们也借鉴了 Tower 的设计。 Tower 是一个非常优秀的抽象层设计，适用于非 GAT 的情况下，非常感谢 Tower 团队。\n通过 GAT，我们可以避免很多不必要的 Box 内存分配，以及提升易用性，给用户提供更友好的编程接口和更符合人体工程学的编程范式。\n高性能 Rust 以高性能和安全著称，我们在设计和实现过程中也时刻以高性能作为我们的目标，尽可能降低每一处的开销，提升每一处实现的性能。\n首先要说明，和 Go 的框架对比性能是极不公平的，因此我们不会着重比较 Volo 和 Kitex 的性能，并且我们给出的数据仅能作为参考，希望大家能够客观看待； 同时，由于在开源社区并没有找到另一款成熟的 Rust 语言的 Async 版本 Thrift RPC 框架，而且性能对比总是容易引战，因此我们希望尽可能弱化性能数据的对比，仅会公布我们自己极限 QPS 的数据。\n在和 Kitex 相同的测试条件（限制 4C）下，Volo 极限 QPS 为 35W；同时，我们内部正在验证基于 Monoio（CloudWeGo 开源的 Rust Async Runtime）的版本，极限 QPS 可以达到 44W。\n从我们线上业务的火焰图来看，得益于 Rust 的静态分发和优秀的编译优化，框架部分的开销基本可以忽略不计（不包含 syscall 开销）。\n易用性好 Rust 以难学难用而闻名，我们希望尽可能降低用户使用 Volo 框架以及使用 Rust 语言编写微服务的难度，提供最符合人体工程学和直觉的编码体验。因此，我们把易用性作为我们重要的目标之一。\n比如，我们提供了 volo 命令行工具，用于初始化项目以及管理 idl；同时，我们将 thrift 及 gRPC 拆分为两个独立（但共用一些组件）的框架，以提供最符合不同协议语义的编程范式及接口。\n我们还提供了#[service]宏（可以理解为不需要 Box 的 async_trait）来使得用户可以无心理负担地使用异步来编写 Service 中间件。\n扩展性强 收益于 Rust 强大的表达和抽象能力，通过灵活的中间件 Service 抽象，开发者可以以非常统一的形式，对 RPC 元信息、请求和响应做处理。\n比如，服务发现、负载均衡等服务治理功能，都可以以 Service 形式进行实现，而不需要独立实现 Trait。\n相关的扩展，我们会放在 volo-rs 组织下，也欢迎大家贡献自己的扩展到 volo-rs～\n相关生态  Volo-rs：Volo 的相关生态 Pilota：Volo 使用的 Thrift 与 Protobuf 编译器及编解码的纯 Rust 实现（不依赖 protoc） Motore：Volo 参考 Tower 设计的，使用了 GAT 的 middleware 抽象层 Metainfo：Volo 用于进行元信息透传的组件，期望定义一套元信息透传的标准  ","categories":"","description":"","excerpt":"Volo Volo 是字节跳动服务框架团队研发的轻量级、高性能、可扩展性强、易用性好的 Rust RPC 框架，使用了 Rust …","ref":"/zh/docs/volo/overview/","tags":"","title":"概览"},{"body":"cwgo 工具也支持传递自己的模板，模版语法为 go template 的语法。cwgo 也欢迎用户贡献自己的模板。由于 RPC 和 HTTP 概念不同，其对应的模版变量也有一些差异，详细请参考下文\n如需传递自定义模板，请给命令添加 -template 参数，如\ncwgo server -type RPC -service {service name} -idl {idl path} -template {tpl path} RPC  模板文件通过 yaml 文件夹传递，通过 kitex 的 --template-dir 命令行参数指定，该文件夹下的所有 yaml 文件都会被渲染，模版解析失败会直接退出。请注意是否存在未知的隐藏文件。 文件夹内的 extensions.yaml 为特定文件，该文件的内容为扩展 Service 代码的配置文件。如果该文件存在的话，则不需要再传递 template-extension 参数  Yaml 文件定义如下：\n# 生成文件的路径及文件名，这会在项目根目录下创建 a 文件夹，并在文件夹内生成 main.go 文件，支持模版渲染语法 path: /handler/{{ .Name }}.go update_behavior: type: skip / cover / append # 指定更新行为，如果 loop_method 为true，则不支持 append。默认是 skip key: Test{{.Name}} # 查找的函数名，如果渲染后的函数名存在，则认为该方法不用追加 append_tpl: # 更新的内容模板 import_tpl: # 新增的 import 内容，是一个 list，可以通过模版渲染 loop_method: true # 是否开启循环渲染 body: template content # 模板内容 模板使用的数据为 PackageInfo，认为这部分内包含所有的元数据，如 methodInfo 等，用户只需要传递模板文件即可，模板内的数据为 PackageInfo 数据。PackageInfo 内常用的内容见附录。 cwgo 支持根据 methodinfo 循环渲染文件。循环渲染时的 methodInfo list 内只有一个元素，为当前正在渲染的 method。 更新时，目前支持覆盖、跳过和根据 methods 增加文件三种，支持在一个文件当中 append。如果开启了循环渲染文件，则只支持 skip 和 cover。  最佳实践的 rpc 示例 tpl 可参考这里\nHTTP  模版文件通过 yaml 文件夹传递，但是与 RPC 的 layout 不同的是 HTTP 的 layout 是基于 hertz 的自定义模版实现的，这里我们需要指定的 yaml 文件名需要固定为 layout.yaml 与 package.yaml ，对于自定义模版的使用可以参考 Hz 自定义模版使用文档。  最佳实践的 http 示例 tpl 可参考这里\n附录 Kitex PackageInfo 结构体含义 type PackageInfo struct { Namespace string // idl namespace，pb 下建议不要使用  Dependencies map[string]string // package name =\u003e import path, used for searching imports  *ServiceInfo // the target service  Codec string NoFastAPI bool Version string RealServiceName string Imports map[string]map[string]bool ExternalKitexGen string Features []feature FrugalPretouch bool Module string // go module 名称 } type ServiceInfo struct { PkgInfo ServiceName string RawServiceName string ServiceTypeName func() string Base *ServiceInfo Methods []*MethodInfo CombineServices []*ServiceInfo HasStreaming bool } type PkgInfo struct { PkgName string // namespace 最后一段  PkgRefName string ImportPath string // 这个方法的 req 和 resp 的 import path } type MethodInfo struct { PkgInfo ServiceName string // 这个 service 的 name  Name string // 这个 method 的 name  RawName string // 同上  Oneway bool Void bool Args []*Parameter // 入参信息，包括入参名称、import 路径、类型  Resp *Parameter // 出参，包括入参名称、import 路径、类型  Exceptions []*Parameter ArgStructName string ResStructName string IsResponseNeedRedirect bool // int -\u003e int*  GenArgResultStruct bool ClientStreaming bool ServerStreaming bool } } ","categories":"","description":"","excerpt":"cwgo 工具也支持传递自己的模板，模版语法为 go template 的语法。cwgo 也欢迎用户贡献自己的模板。由于 RPC …","ref":"/zh/docs/cwgo/tutorials/templete-extension/","tags":"","title":"模板拓展"},{"body":"用户如果需要更详细的打点，例如包大小，或者想要更换其他数据源，例如 influxDB，用户可以根据自己的需求实现 Tracer 接口，并通过 WithTracer Option 来注入。\n// Tracer is executed at the start and finish of an HTTP. type Tracer interface { Start(ctx context.Context, c *app.RequestContext) context.Context Finish(ctx context.Context, c *app.RequestContext) } 从 ctx 中可以获得 TraceInfo，进一步的从 TraceInfo 中获取请求耗时、包大小和请求返回的错误信息等，举例：\ntype ServerTracer struct{ // contain entities which recording metric } // Start record the beginning of an RPC invocation. func (s *ServerTracer) Start(ctx context.Context, _ *app.RequestContext) context.Context { // do nothing \treturn ctx } // Finish record after receiving the response of server. func (s *ServerTracer) Finish(ctx context.Context, c *app.RequestContext) { ti := c.GetTraceInfo() rpcStart := ti.Stats().GetEvent(stats.HTTPStart) rpcFinish := ti.Stats().GetEvent(stats.HTTPFinish) cost := rpcFinish.Time().Sub(rpcStart.Time()) // TODO: record the cost of request } ","categories":"","description":"","excerpt":"用户如果需要更详细的打点，例如包大小，或者想要更换其他数据源，例如 influxDB，用户可以根据自己的需求实现 Tracer 接口， …","ref":"/zh/docs/hertz/tutorials/framework-exten/monitor/","tags":"","title":"监控扩展"},{"body":"Hertz 提供了网络库扩展的能力。用户如果需要更换其他的网络库，可以根据需求实现对应的接口。Server 需要实现 network.Conn 接口，Client 需要实现 network.Dialer 接口。\n接口定义 接口在 pkg/network/connection.go 中\ntype Conn interface { net.Conn Reader Writer SetReadTimeout(t time.Duration) error } // Reader is for buffered Reader type Reader interface { // Peek returns the next n bytes without advancing the reader.  Peek(n int) ([]byte, error) // Skip discards the next n bytes.  Skip(n int) error // Release the memory space occupied by all read slices. This method needs to be executed actively to  // recycle the memory after confirming that the previously read data is no longer in use.  // After invoking Release, the slices obtained by the method such as Peek will  // become an invalid address and cannot be used anymore.  Release() error // Len returns the total length of the readable data in the reader.  Len() int // ReadByte is used to read one byte with advancing the read pointer.  ReadByte() (byte, error) // ReadBinary is used to read next n byte with copy, and the read pointer will be advanced.  ReadBinary(n int) (p []byte, err error) } type Writer interface { // Malloc will provide a n bytes buffer to send data.  Malloc(n int) (buf []byte, err error) // WriteBinary will use the user buffer to flush.  // NOTE: Before flush successfully, the buffer b should be valid.  WriteBinary(b []byte) (n int, err error) // Flush will send data to the peer end.  Flush() error } 对于 Client 来说，实现了以下接口就可以替换 Client 侧的网络库。\ntype Dialer interface { DialConnection(network, address string, timeout time.Duration, tlsConfig *tls.Config) (conn Conn, err error) DialTimeout(network, address string, timeout time.Duration, tlsConfig *tls.Config) (conn net.Conn, err error) AddTLS(conn Conn, tlsConfig *tls.Config) (Conn, error) } 自定义网络库 Hertz 的 Server 和 Client 分别提供了初始化配置项\nServer\nserver.New(server.WithTransport(YOUR_TRANSPORT)) Client\nclient.NewClient(client.WithDialer(YOUR_DIALER)) ","categories":"","description":"","excerpt":"Hertz 提供了网络库扩展的能力。用户如果需要更换其他的网络库，可以根据需求实现对应的接口。Server …","ref":"/zh/docs/hertz/tutorials/framework-exten/advanced-exten/network-lib/","tags":"","title":"网络库扩展"},{"body":"Server Server 侧的配置项均在初始化 Server 时采用 server.xxx 的方式，如\npackage main import \"github.com/cloudwego/hertz/pkg/app/server\" func main() { h := server.New(server.WithXXXX()) ... }    配置名称 类型 说明     WithTransport network.NewTransporter 更换底层 transport，默认值：netpoll.NewTransporter   WithHostPorts string 指定监听的地址和端口   WithKeepAliveTimeout time.Duration tcp 长连接保活时间，一般情况下不用修改，更应该关注 idleTimeout。默认值：1min   WithReadTimeout time.Duration 底层读取数据超时时间。默认值：3min   WithIdleTimeout time.Duration 长连接请求链接空闲超时时间。默认值：3min   WithMaxRequestBodySize int 配置最大的请求体大小，默认4M（4M对应的填的值是4*1024*1024）   WithRedirectTrailingSlash bool 自动根据末尾的 / 转发，例如：如果 router 只有 /foo/，那么 /foo 会重定向到 /foo/ ；如果只有 /foo，那么 /foo/ 会重定向到 /foo。默认开启   WithRemoveExtraSlash bool RemoveExtraSlash 当有额外的 / 时也可以当作参数。如: user/:name，如果开启该选项 user//xiaoming 也可匹配上参数。默认关闭   WithUnescapePathValues bool 如果开启，请求路径会被自动转义（eg. ‘%2F’ -\u003e ‘/'）。如果 UseRawPath 为 false（默认情况），则 UnescapePathValues 实际上为 true，因为 .URI().Path() 将被使用，它已经是转义后的。设置该参数为 false，需要配合 WithUseRawPath(true)。 默认开启(true)   WithUseRawPath bool 如果开启， 会使用原始 path 进行路由匹配。默认关闭   WithHandleMethodNotAllowed bool 如果开启，当当前路径不能被匹配上时，server 会去检查其他方法是否注册了当前路径的路由，如果存在则会响应\"Method Not Allowed\"，并返回状态码405; 如果没有，则会用 NotFound 的 handler 进行处理。默认关闭   WithDisablePreParseMultipartForm bool 如果开启，则不会预处理 multipart form。可以通过 ctx.Request.Body() 获取到 body 后由用户处理。默认关闭   WithStreamBody bool 如果开启，则会使用流式处理 body。默认关闭   WithNetwork string 设置网络协议，可选：tcp，udp，unix（unix domain socket），默认为tcp   ContinueHandler func(header *RequestHeader) bool 在接收到 Expect 100 Continue 头之后调用 ContinueHandler。使用 ContinueHandler，服务器可以决定是否根据标头读取可能很大的请求正文   PanicHandler HandlerFunc 处理 panic，用来生成错误页面并返回500   NotFound HandlerFunc 当路由匹配不上时被调用的 handler   WithExitWaitTime time.Duration 设置优雅退出时间。Server 会停止建立新的连接，并对关闭后的每一个请求设置 Connection: Close 的 header，当到达设定的时间关闭 Server。当所有连接已经关闭时，Server 可以提前关闭。默认 5s   WithTLS tls.Config 配置 server tls 能力   WithListenConfig net.ListenConfig 设置监听器配置，可用于设置是否允许 reuse port 等   WithALPN bool 是否开启 ALPN。默认关闭   WithTracer tracer.Tracer 注入 tracer 实现，如不注入 Tracer 实现，默认关闭   WithTraceLevel stats.Level 设置 trace level，默认 LevelDetailed   WithWriteTimeout time.Duration 写入数据超时时间，默认值：无限长   WithRedirectFixedPath bool 如果开启，当当前请求路径不能匹配上时，server 会尝试修复请求路径并重新进行匹配，如果成功匹配并且为 GET 请求则会返回状态码 301 进行重定向，其他请求方式返回 308 进行重定向。默认关闭   WithBasePath string 设置基本路径，前缀和后缀必须为 /。默认为 /   WithMaxKeepBodySize int 设置回收时保留的请求体和响应体的最大大小。单位:字节。默认值：4 * 1024 * 1024   WithGetOnly bool 如果开启则只接受 GET 请求。默认关闭   WithKeepAlive bool 如果开启则使用 HTTP 长连接。默认开启   WithAltTransport network.NewTransporter 设置备用 transport。默认值：netpoll.NewTransporter   WithH2C bool 设置是否开启 H2C。默认关闭   WithReadBufferSize int 设置读缓冲区大小，同时限制 HTTP header 大小。默认值：4 * 1024   WithRegistry registry.Registry, *registry.Info 设置注册中心配置，服务注册信息。默认值：registry.NoopRegistry, nil   WithAutoReloadRender bool, time.Duration 设置自动重载渲染配置。默认值：false, 0   WithDisablePrintRoute bool 设置是否禁用 debugPrintRoute。默认不禁用   WithOnAccept func(conn net.Conn) context.Context 设置在 netpoll 中当一个连接被接受但不能接收数据时的回调函数，在 go net 中在转换 TLS 连接之前被调用。默认值：nil   WithOnConnect func(ctx context.Context, conn network.Conn) context.Context 设置 onConnect 函数。它可以接收来自 netpoll 连接的数据。在go net中，它将在转换 TLS 连接后被调用。默认值：nil    Server Connection 数量限制:\n 如果是使用标准网络库，无此限制 如果是使用 netpoll，最大连接数为 10000 （这个是netpoll底层使用的 gopool ）控制的，修改方式也很简单，调用 gopool 提供的函数即可：gopool.SetCap(xxx)(main.go 中调用一次即可)。  Client Client 侧的配置项均在初始化 Client 时采用 client.xxx 的方式\npackage main import \"github.com/cloudwego/hertz/pkg/app/client\" func main() { c, err := client.NewClient(client.WithXxx()) ... }    配置名称 类型 说明     WithDialTimeout time.Duration 连接建立超时时间，默认 1s   WithMaxConnsPerHost int 设置为每个 host 建立的最大连接数，默认 512   WithMaxIdleConnDuration time.Duration 设置空闲连接超时时间，当超时后会关闭该连接，默认10s   WithMaxConnDuration time.Duration 设置连接存活的最大时长，超过这个时间的连接在完成当前请求后会被关闭，默认无限长   WithMaxConnWaitTimeout time.Duration 设置等待空闲连接的最大时间，默认不等待   WithKeepAlive bool 是否使用长连接，默认开启   WithRetryConfig …retry.Option 设置 client 的 retry config。Hertz 版本需 \u003e= v0.4.0   WithMaxIdempotentCallAttempts int 设置最大调用次数，调用失败则会重试。默认1次即不重试。v0.4.0版本废止，该版本之前可用，建议升级 Hertz 版本 \u003e= v0.4.0 并使用 WithRetryConfig 替代   WithClientReadTimeout time.Duration 设置读取 response 的最长时间，默认无限长   WithTLSConfig *tls.Config 双向 TLS 认证时，设置 client 的 TLS config   WithDialer network.Dialer 设置 client 使用的网络库，默认 netpoll   WithResponseBodyStream bool 设置是否使用流式处理，默认关闭   WithDialFunc client.DialFunc 设置 Dial Function   WithWriteTimeout time.Duration 写入数据超时时间，默认值：无限长    ","categories":"","description":"","excerpt":"Server Server 侧的配置项均在初始化 Server 时采用 server.xxx 的方式，如\npackage main …","ref":"/zh/docs/hertz/reference/config/","tags":"","title":"配置说明"},{"body":"Basic Usage new: Create a new Hertz project  Create a new project  // Execute under GOPATH, go mod name defaults to the current path relative to GOPATH, or you can specify your own hz new // Execute under non-GOPATH, you need to specify the go mod name hz new -mod hertz/demo // Tidy \u0026 get dependencies go mod tidy After executed, it generates a scaffold for the Hertz project in the current directory.\nCompiling Projects  go build Run the project and test it  Run the project:\n./{{your binary}} Test:\ncurl 127.0.0.1:8888/ping If it returns {\"message\":\"pong\"}, it works.\n","categories":"","description":"","excerpt":"Basic Usage new: Create a new Hertz project  Create a new project  // …","ref":"/docs/hertz/tutorials/toolkit/usage/usage/","tags":"","title":"hz basic usage"},{"body":"基本使用 new: 创建一个 Hertz 新项目  创建新项目  // GOPATH 下执行，go mod 名字默认为当前路径相对GOPATH的路径，也可自己指定 hz new // 非GOPATH 下执行，需要指定 go mod 名 hz new -mod hertz/demo // 整理 \u0026 拉取依赖 go mod tidy 执行后会在当前目录下生成 Hertz 项目的脚手架。\n编译项目  go build 运行项目并测试  运行项目：\n./{{your binary}} 测试：\ncurl 127.0.0.1:8888/ping 如果返回{\"message\":\"pong\"}，说明接口调通。\n","categories":"","description":"","excerpt":"基本使用 new: 创建一个 Hertz 新项目  创建新项目  // GOPATH 下执行，go mod 名字默认为当前路径相 …","ref":"/zh/docs/hertz/tutorials/toolkit/usage/usage/","tags":"","title":"hz 的基本使用"},{"body":"Hertz provides command-line tools (hz) that support custom template features, including:\n Customize the layout template (i.e., the directory structure of the generated code) Custom package templates (i.e. service-related code structures, including handler, router, etc.)  Users can provide their own templates and rendering parameters, combined with the ability of hz, to complete the custom code generation structure.\nCustom layout template  Users can modify or rewrite according to the default template to meet their own needs\n Hz takes advantage of the “go template” capability to support defining templates in “yaml” format and uses “json” format to define rendering data.\nThe so-called layout template refers to the structure of the entire project. These structures have nothing to do with the specific idl definition, and can be directly generated without idl. The default structure is as follows:\n. ├── biz │ ├── handler │ │ └── ping.go │ │ └── ****.go // Set of handlers divided by service, the position can be changed according to handler_dir │ ├── model │ │ └── model.go // idl generated struct, the position can be changed according to model_dir │ └── router //undeveloped custom dir │ └── register.go // Route registration, used to call the specific route registration │ └── route.go // Specific route registration location │ └── middleware.go // Default middleware build location ├── .hz // hz Create code flags ├── go.mod ├── main.go // Start the entrance ├── router.go // User-defined route write location └── router_gen.go // hz generated route registration call IDL // hello.thrift namespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");}structHelloResp{1:stringRespBody;}serviceHelloService{HelloRespHelloMethod(1:HelloReqrequest)(api.get=\"/hello\");}Command hz new --mod=github.com/hertz/hello --idl=./hertzDemo/hello.thrift --customize_layout=template/layout.yaml:template/data.json The meaning of the default layout template  Note: The following bodies are all go templates\n layouts:# The directory of the generated handler will only be generated if there are files in the directory- path:biz/handler/delims:- \"\"- \"\"body:\"\"# The directory of the generated model will only be generated if there are files in the directory- path:biz/model/delims:- \"\"- \"\"body:\"\"# project main file- path:main.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. package main import ( \"github.com/cloudwego/hertz/pkg/app/server\" ) func main() { h := server.Default() register(h) h.Spin() }# go.mod file, need template rendering data {{.GoModule}} to generate- path:go.moddelims:- '{{'- '}}'body:|-module {{.GoModule}} {{- if .UseApacheThrift}} replace github.com/apache/thrift =\u003e github.com/apache/thrift v0.13.0 {{- end}}# .gitignore file- path:.gitignoredelims:- \"\"- \"\"body:\"*.o\\n*.a\\n*.so\\n_obj\\n_test\\n*.[568vq]\\n[568vq].out\\n*.cgo1.go\\n*.cgo2.c\\n_cgo_defun.c\\n_cgo_gotypes.go\\n_cgo_export.*\\n_testmain.go\\n*.exe\\n*.exe~\\n*.test\\n*.prof\\n*.rar\\n*.zip\\n*.gz\\n*.psd\\n*.bmd\\n*.cfg\\n*.pptx\\n*.log\\n*nohup.out\\n*settings.pyc\\n*.sublime-project\\n*.sublime-workspace\\n!.gitkeep\\n.DS_Store\\n/.idea\\n/.vscode\\n/output\\n*.local.yml\\ndumped_hertz_remote_config.json\\n\\t\\t \\ \"# .hz file, containing hz version, is the logo of the project created by hz, no need to transfer rendering data- path:.hzdelims:- '{{'- '}}'body:|-// Code generated by hz. DO NOT EDIT. hz version: {{.hzVersion}}# ping comes with ping handler- path:biz/handler/ping.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. package handler import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/common/utils\" ) // Ping . func Ping(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{ \"message\": \"pong\", }) }# `router_gen.go` is the file that defines the route registration- path:router_gen.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. DO NOT EDIT. package main import ( \"github.com/cloudwego/hertz/pkg/app/server\" router \"{{.RouterPkgPath}}\" ) // register registers all routers. func register(r *server.Hertz) { router.GeneratedRegister(r) customizedRegister(r) }# Custom route registration file- path:router.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. package main import ( \"github.com/cloudwego/hertz/pkg/app/server\" handler \"{{.HandlerPkgPath}}\" ) // customizeRegister registers customize routers. func customizedRegister(r *server.Hertz){ r.GET(\"/ping\", handler.Ping) // your code ... }# Default route registration file, do not modify it- path:biz/router/register.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. DO NOT EDIT. package router import ( \"github.com/cloudwego/hertz/pkg/app/server\" ) // GeneratedRegister registers routers generated by IDL. func GeneratedRegister(r *server.Hertz){ //INSERT_POINT: DO NOT DELETE THIS LINE! }The meaning of template rendering parameter file When a custom template and render data are specified, the options specified on the command line will not be used as render data, so the render data in the template needs to be defined by the user.\nHz uses “json” to specify render data, as described below\n{ // global render parameters \"*\": { \"GoModule\": \"github.com/hz/test\", // must be consistent with the command line, otherwise the subsequent generation of model, handler and other code will use the mod specified by the command line, resulting in inconsistency. \"ServiceName\": \"p.s.m\", // as specified on the command line \"UseApacheThrift\": false // Set \"true\"/\"false\" depending on whether to use \"thrift\" }, // router_gen.go route the registered render data, // \"biz/router\"points to the module of the routing code registered by the default idl, do not modify it \"router_gen.go\": { \"RouterPkgPath\": \"github.com/hz/test/biz/router\" } } Customize a layout template  At present, the project layout generated by hz is already the most basic skeleton of a hertz project, so it is not recommended to delete the files in the existing template.\nHowever, if the user wants a different layout, of course, you can also delete the corresponding file according to your own needs (except “biz/register.go”, the rest can be modified)\nWe welcome users to contribute their own templates\n Assuming that the user only wants “main.go” and “go.mod” files, then we modify the default template as follows:\ntemplate # layout.yamllayouts:# project main file- path:main.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. package main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"{{.GoModule}}/biz/router\" ) func main() { h := server.Default() router.GeneratedRegister(h) // do what you wanted // add some render data: {{.MainData}} h.Spin() }# go.mod file, requires template rendering data {{.GoModule}} to generate- path:go.moddelims:- '{{'- '}}'body:|-module {{.GoModule}} {{- if .UseApacheThrift}} replace github.com/apache/thrift =\u003e github.com/apache/thrift v0.13.0 {{- end}}# Default route registration file, no need to modify- path:biz/router/register.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. DO NOT EDIT. package router import ( \"github.com/cloudwego/hertz/pkg/app/server\" ) // GeneratedRegister registers routers generated by IDL. func GeneratedRegister(r *server.Hertz){ //INSERT_POINT: DO NOT DELETE THIS LINE! }render data { \"*\": { \"GoModule\": \"github.com/hertz/hello\", \"ServiceName\": \"hello\", \"UseApacheThrift\": true }, \"main.go\": { \"MainData\": \"this is customized render data\" } } Command:\nhz new --mod=github.com/hertz/hello --idl=./hertzDemo/hello.thrift --customize_layout=template/layout.yaml:template/data.json Custom package template  The template address of the hz template:\nUsers can modify or rewrite according to the default template to meet their own needs\n  The so-called package template refers to the code related to the idl definition. This part of the code involves the service, go_package/namespace, etc. specified when defining idl. It mainly includes the following parts: handler.go: Handling function logic router.go: the route registration logic of the service defined by the specific idl register.go: logic for calling the content in router.go Model code: generated go struct; however, since the tool that uses plugins to generate model code currently does not have permission to modify the model template, this part of the function is not open for now  Command # After that, the package template rendering data will be provided, so the form of \"k-v\" is retained when entering the command, and \":\" needs to be added after customize_package. hz new --mod=github.com/hertz/hello --handler_dir=handler_test --idl=hertzDemo/hello.thrift --customize_package=template/package.yaml: Default package template Note: The custom package template does not provide the function of rendering data, mainly because the rendering data is generated by the hz tool, so it does not provide the function of writing your own rendering data for now. You can modify the parts of the template that have nothing to do with rendering data to meet your own needs.\nlayouts:# path only indicates the template of handler.go, the specific handler path is determined by the default path and handler_dir- path:handler.godelims:- '{{'- '}}'body:|-// Code generated by hertz generator. package {{.PackageName}} import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" {{- range $k, $v := .Imports}} {{$k}} \"{{$v.Package}}\" {{- end}} ) {{range $_, $MethodInfo := .Methods}} {{$MethodInfo.Comment}} func {{$MethodInfo.Name}}(ctx context.Context, c *app.RequestContext) { var err error {{if ne $MethodInfo.RequestTypeName \"\" -}} var req {{$MethodInfo.RequestTypeName}} err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } {{end}} resp := new({{$MethodInfo.ReturnTypeName}}) c.{{.Serializer}}(200, resp) } {{end}}# path only indicates the router.go template, whose path is fixed at: biz/router/namespace/- path:router.godelims:- '{{'- '}}'body:|-// Code generated by hertz generator. DO NOT EDIT. package {{$.PackageName}} import ( \"github.com/cloudwego/hertz/pkg/app/server\" {{range $k, $v := .HandlerPackages}}{{$k}} \"{{$v}}\"{{end}} ) /* This file will register all the routes of the services in the master idl. And it will update automatically when you use the \"update\" command for the idl. So don't modify the contents of the file, or your code will be deleted when it is updated. */ {{define \"g\"}} {{- if eq .Path \"/\"}}r {{- else}}{{.GroupName}}{{end}} {{- end}} {{define \"G\"}} {{- if ne .Handler \"\"}} {{- .GroupName}}.{{.HttpMethod}}(\"{{.Path}}\", append({{.MiddleWare}}Mw(), {{.Handler}})...) {{- end}} {{- if ne (len .Children) 0}} {{.MiddleWare}} := {{template \"g\" .}}.Group(\"{{.Path}}\", {{.MiddleWare}}Mw()...) {{- end}} {{- range $_, $router := .Children}} {{- if ne .Handler \"\"}} {{template \"G\" $router}} {{- else}} {\t{{template \"G\" $router}} } {{- end}} {{- end}} {{- end}} // Register register routes based on the IDL 'api.${HTTP Method}' annotation. func Register(r *server.Hertz) { {{template \"G\" .Router}} }# path only indicates the template of register.go, the path of register is fixed to biz/router/register.go- path:register.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. DO NOT EDIT. package router import ( \"github.com/cloudwego/hertz/pkg/app/server\" {{$.PkgAlias}} \"{{$.Pkg}}\" ) // GeneratedRegister registers routers generated by IDL. func GeneratedRegister(r *server.Hertz){ //INSERT_POINT: DO NOT DELETE THIS LINE! {{$.PkgAlias}}.Register(r) }- path:model.godelims:- \"\"- \"\"body:\"\"# path only indicates the template of middleware.go, the path of middleware is the same as router.go: biz/router/namespace/- path:middleware.godelims:- '{{'- '}}'body:|-// Code generated by hertz generator. package {{$.PackageName}} import ( \"github.com/cloudwego/hertz/pkg/app\" ) {{define \"M\"}} func {{.MiddleWare}}Mw() []app.HandlerFunc { // your code... return nil } {{range $_, $router := $.Children}}{{template \"M\" $router}}{{end}} {{- end}} {{template \"M\" .Router}}# path only indicates the template of client.go, the path of client code generation is specified by the user \"${client_dir}\"- path:client.godelims:- '{{'- '}}'body:|-// Code generated by hertz generator. package {{$.PackageName}} import ( \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/common/config\" ) type {{.ServiceName}}Client struct { client * client.Client } func New{{.ServiceName}}Client(opt ...config.ClientOption) (*{{.ServiceName}}Client, error) { c, err := client.NewClient(opt...) if err != nil { return nil, err } return \u0026{{.ServiceName}}Client{ client: c, }, nil }# handler_single means a separate handler template, used to update each new handler when updating- path:handler_single.godelims:- '{{'- '}}'body:|+{{.Comment}} func {{.Name}}(ctx context.Context, c *app.RequestContext) { // this my demo var err error {{if ne .RequestTypeName \"\" -}} var req {{.RequestTypeName}} err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } {{end}} resp := new({{.ReturnTypeName}}) c.{{.Serializer}}(200, resp) }# middleware_single means a separate middleware template, which is used to update each new middleware_single when updating- path:middleware_single.godelims:- '{{'- '}}'body:|+func {{.MiddleWare}}Mw() []app.HandlerFunc { // your code... return nil }Customize a package template  Like layout templates, users can also customize package templates.\nAs far as the templates provided by the package are concerned, the average user may only need to customize handler.go templates, because router.go/middleware.go/register.go are generally related to the idl definition and the user does not need to care, so hz currently also fixes the location of these templates, and generally does not need to be modified.\nTherefore, users can customize the generated handler template according to their own needs to speed up development; however, since the default handler template integrates some model information and package information, the hz tool is required to provide rendering data. This part of the user can modify it according to their own situation, and it is generally recommended to leave model information.\n Add a new template Considering that sometimes you may need to add your own implementation for some information of IDL, such as adding a single test for each generated handler. Therefore, the hz templates allow users to customize new templates and provide data sources for the template rendering parameters.\nTemplate format:\n- path:biz/handler/{{$HandlerName}}.go // path+filename, support rendering dataloop_method:bool // Whether to generate multiple files according to the method defined in idl, to be used with path renderingloop_service:bool // whether to generate multiple files according to the service defined in idl, to be used with path renderingupdate_behavior:// The update behavior of the file when using hz updatetype: string // update behavior:skip/cover/appendappend_key:\"method\"/\"service\" // Specify the appended rendering data source, method/service, in the append behaviorinsert_key:string // The \"key\" of the append logic in the append behavior, based on which to determine if appending is neededappend_content_tpl:string // Specify the template for appending content in the append behaviorimport_tpl:[]string // The template to be added to the importbody:string // The template content of the generated fileTemplate Data Source  File path rendering: The following rendering data can be used when specifying a file path  type FilePathRenderInfo struct { MasterIDLName string // master IDL name \tGenPackage string // master IDL generate code package \tHandlerDir string // handler generate dir \tModelDir string // model generate dir \tRouterDir string // router generate dir \tProjectDir string // projectDir \tGoModule string // go module \tServiceName string // service name, changed as services are traversed \tMethodName string // method name, changed as methods are traversed \tHandlerGenPath string // \"api.gen_path\" value }  Single file rendering data: the rendering data used when defining a single file, all IDL information can be extracted according to the definition of “IDLPackageRenderInfo”  type CustomizedFileForIDL struct { *IDLPackageRenderInfo FilePath string FilePackage string }  Method level rendering data: when “loop_method” is specified, the rendering data used will be generated as a file for each method  type CustomizedFileForMethod struct { *HttpMethod // The specific information parsed for each method definition \tFilePath string // When the method file is generated in a loop, the path to the file \tFilePackage string // When the method file is generated in a loop, the go package name of the file \tServiceInfo *Service // The information defined by the service to which the method belongs } type HttpMethod struct { Name string HTTPMethod string Comment string RequestTypeName string ReturnTypeName string Path string Serializer string OutputDir string Models map[string]*model.Model }  Service level rendering data: when “loop_service” is specified, the rendering data will be used and a file will be generated for each service unit  type CustomizedFileForService struct { *Service // specific information about the service, including the service name, information about the method defined in the servide, etc. \tFilePath string // When the service file is generated in a loop, the path to the file \tFilePackage string // When the service file is looped, the go package name of the file \tIDLPackageInfo *IDLPackageRenderInfo // Information about the IDL definition to which the service belongs } type Service struct { Name string Methods []*HttpMethod ClientMethods []*ClientMethod Models []*model.Model // all dependency models \tBaseDomain string // base domain for client code } A simple example of a custom handler template is given below:\nexample  example: https://github.com/cloudwego/hertz-examples/tree/main/hz/template\n   Modify the content of the default handler\n  Add a single test file for handler\n  layouts:- path:handler.gobody:|-{{$OutDirs := GetUniqueHandlerOutDir .Methods}} package {{.PackageName}} import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" {{- range $k, $v := .Imports}} {{$k}} \"{{$v.Package}}\" {{- end}} {{- range $_, $OutDir := $OutDirs}} {{if eq $OutDir \"\" -}} \"{{$.ProjPackage}}/biz/service\" {{- else -}} \"{{$.ProjPackage}}/biz/service/{{$OutDir}}\" {{- end -}} {{- end}} \"{{$.ProjPackage}}/biz/utils\" ) {{range $_, $MethodInfo := .Methods}} {{$MethodInfo.Comment}} func {{$MethodInfo.Name}}(ctx context.Context, c *app.RequestContext) { var err error {{if ne $MethodInfo.RequestTypeName \"\" -}} var req {{$MethodInfo.RequestTypeName}} err = c.BindAndValidate(\u0026req) if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } {{end}} {{if eq $MethodInfo.OutputDir \"\" -}} resp,err := service.New{{$MethodInfo.Name}}Service(ctx, c).Run(\u0026req) if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } {{else}} resp,err := {{$MethodInfo.OutputDir}}.New{{$MethodInfo.Name}}Service(ctx, c).Run(\u0026req) if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } {{end}} utils.SendSuccessResponse(ctx, c, consts.StatusOK, resp) } {{end}}update_behavior:import_tpl:- |-{{$OutDirs := GetUniqueHandlerOutDir .Methods}} {{- range $_, $OutDir := $OutDirs}} {{if eq $OutDir \"\" -}} \"{{$.ProjPackage}}/biz/service\" {{- else -}} \"{{$.ProjPackage}}/biz/service/{{$OutDir}}\" {{end}} {{- end}}- path:handler_single.gobody:|+{{.Comment}} func {{.Name}}(ctx context.Context, c *app.RequestContext) { var err error {{if ne .RequestTypeName \"\" -}} var req {{.RequestTypeName}} err = c.BindAndValidate(\u0026req) if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } {{end}} {{if eq .OutputDir \"\" -}} resp,err := service.New{{.Name}}Service(ctx, c).Run(\u0026req) {{else}} resp,err := {{.OutputDir}}.New{{.Name}}Service(ctx, c).Run(\u0026req) {{end}} if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } utils.SendSuccessResponse(ctx, c, consts.StatusOK, resp) }=- path:\"{{.HandlerDir}}/{{.GenPackage}}/{{ToSnakeCase .ServiceName}}_test.go\"loop_service:trueupdate_behavior:type:\"append\"append_key:\"method\"insert_key:\"Test{{$.Name}}\"append_tpl:|-func Test{{.Name}}(t *testing.T) { h := server.Default() h.GET(\"{{.Path}}\", {{.Name}}) w := ut.PerformRequest(h.Engine, \"{{.HTTPMethod}}\", \"{{.Path}}\", \u0026ut.Body{Body: bytes.NewBufferString(\"\"), Len: 1}, ut.Header{}) resp := w.Result() assert.DeepEqual(t, 201, resp.StatusCode()) assert.DeepEqual(t, \"\", string(resp.Body())) // todo edit your unit test. }body:|-package {{.FilePackage}} import ( \"bytes\" \"testing\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/test/assert\" \"github.com/cloudwego/hertz/pkg/common/ut\" ) {{range $_, $MethodInfo := $.Methods}} func Test{{$MethodInfo.Name}}(t *testing.T) { h := server.Default() h.GET(\"{{$MethodInfo.Path}}\", {{$MethodInfo.Name}}) w := ut.PerformRequest(h.Engine, \"{{$MethodInfo.HTTPMethod}}\", \"{{$MethodInfo.Path}}\", \u0026ut.Body{Body: bytes.NewBufferString(\"\"), Len: 1}, ut.Header{}) resp := w.Result() assert.DeepEqual(t, 201, resp.StatusCode()) assert.DeepEqual(t, \"\", string(resp.Body())) // todo edit your unit test. } {{end}}MVC Template Practice Hertz provides a best practice for customizing templates for MVC, see code for code details.\nPrecautions Precautions for using layout templates When the user uses the layout custom template, the generated layout and rendering data are taken over by the user, so the user needs to provide the rendering data of the defined layout.\nPrecautions for using package templates Generally speaking, when users use package templates, most of them are to modify the default handler template; however, hz does not provide a single handler template at present, so when updating an existing handler file, the default handler template will be used to append a new handler function to the end of the handler file. When the corresponding handler file does not exist, a custom template will be used to generate the handler file.\n","categories":"","description":"","excerpt":"Hertz provides command-line tools (hz) that support custom template …","ref":"/docs/hertz/tutorials/toolkit/template/","tags":"","title":"hz custom template use"},{"body":"Hertz 提供的命令行工具(以下称为\"hz\")支持自定义模板功能，包括:\n 自定义 layout 模板(即生成代码的目录结构) 自定义 package 模板(即与 service 相关的代码结构，包括 handler、router 等)  用户可自己提供模板以及渲染参数，并结合 hz 的能力，来完成自定义的代码生成结构。\n自定义 layout 模板  用户可根据默认模板来修改或重写，从而满足自身需求\n hz 利用了 go template 支持以 “yaml” 的格式定义模板，并使用 “json” 定义模板渲染数据。\n所谓的 layout 模板是指整个项目的结构，这些结构与具体的 idl 定义无关，不需要 idl 也可以直接生成，默认的结构如下:\n. ├── biz │ ├── handler │ │ └── ping.go │ │ └── ****.go // 按照服务划分的 handler 集合，位置可根据 handler_dir 改变 │ ├── model │ │ └── model.go // idl 生成的 struct，位置可根据 model_dir 改变 │ └── router // 未开发自定义 dir │ └── register.go // 路由注册，用来调用具体的路由注册 │ └── route.go // 具体路由注册位置 │ └── middleware.go // 默认 middleware 生成位置 ├── .hz // hz 创建代码标志 ├── go.mod ├── main.go // 启动入口 ├── router.go // 用户自定义路由写入位置 └── router_gen.go // hz 生成的路由注册调用 IDL // hello.thrift namespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");}structHelloResp{1:stringRespBody;}serviceHelloService{HelloRespHelloMethod(1:HelloReqrequest)(api.get=\"/hello\");}命令 hz new --mod=github.com/hertz/hello --idl=./hertzDemo/hello.thrift --customize_layout=template/layout.yaml:template/data.json 默认 layout 模板的含义  注：以下的 body 均为 go template\n layouts:# 生成的 handler 的目录，只有目录下有文件才会生成- path:biz/handler/delims:- \"\"- \"\"body:\"\"# 生成的 model 的目录，只有目录下有文件才会生成- path:biz/model/delims:- \"\"- \"\"body:\"\"# 项目 main 文件，- path:main.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. package main import ( \"github.com/cloudwego/hertz/pkg/app/server\" ) func main() { h := server.Default() register(h) h.Spin() }# go.mod 文件，需要模板渲染数据{{.GoModule}}才能生成- path:go.moddelims:- '{{'- '}}'body:|-module {{.GoModule}} {{- if .UseApacheThrift}} replace github.com/apache/thrift =\u003e github.com/apache/thrift v0.13.0 {{- end}}# .gitignore 文件- path:.gitignoredelims:- \"\"- \"\"body:\"*.o\\n*.a\\n*.so\\n_obj\\n_test\\n*.[568vq]\\n[568vq].out\\n*.cgo1.go\\n*.cgo2.c\\n_cgo_defun.c\\n_cgo_gotypes.go\\n_cgo_export.*\\n_testmain.go\\n*.exe\\n*.exe~\\n*.test\\n*.prof\\n*.rar\\n*.zip\\n*.gz\\n*.psd\\n*.bmd\\n*.cfg\\n*.pptx\\n*.log\\n*nohup.out\\n*settings.pyc\\n*.sublime-project\\n*.sublime-workspace\\n!.gitkeep\\n.DS_Store\\n/.idea\\n/.vscode\\n/output\\n*.local.yml\\ndumped_hertz_remote_config.json\\n\\t\\t \\ \"# .hz 文件，包含 hz 版本，是 hz 创建的项目的标志，不需要传渲染数据- path:.hzdelims:- '{{'- '}}'body:|-// Code generated by hz. DO NOT EDIT. hz version: {{.hzVersion}}# ping 自带 ping 的 handler- path:biz/handler/ping.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. package handler import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/common/utils\" ) // Ping . func Ping(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{ \"message\": \"pong\", }) }# 定义路由注册的文件，需要模板渲染数据{{.RouterPkgPath}}才能生成- path:router_gen.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. DO NOT EDIT. package main import ( \"github.com/cloudwego/hertz/pkg/app/server\" router \"{{.RouterPkgPath}}\" ) // register registers all routers. func register(r *server.Hertz) { router.GeneratedRegister(r) customizedRegister(r) }# 自定义路由注册的文件- path:router.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. package main import ( \"github.com/cloudwego/hertz/pkg/app/server\" handler \"{{.HandlerPkgPath}}\" ) // customizeRegister registers customize routers. func customizedRegister(r *server.Hertz){ r.GET(\"/ping\", handler.Ping) // your code ... }# 默认路由注册文件，不要修改- path:biz/router/register.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. DO NOT EDIT. package router import ( \"github.com/cloudwego/hertz/pkg/app/server\" ) // GeneratedRegister registers routers generated by IDL. func GeneratedRegister(r *server.Hertz){ //INSERT_POINT: DO NOT DELETE THIS LINE! }模板渲染参数文件的含义 当指定了自定义模板以及渲染数据后，此时命令行指定的选项将不会被作为渲染数据，因此，模板中的渲染数据需要用户自己定义。\nhz 使用了\"json\"来指定渲染数据，下面进行介绍\n{ // 全局的渲染参数 \"*\": { \"GoModule\": \"github.com/hz/test\", // 要和命令行指定的一致，否则后续生成model、handler等代码将使用命令行指定的mod，导致出现不一致。 \"ServiceName\": \"p.s.m\", // 要和命令行指定的一致 \"UseApacheThrift\": false // 根据是否使用\"thrift\"设置\"true\"/\"false\" }, // router_gen.go 路由注册的渲染数据， // \"biz/router\"指向默认idl注册的路由代码的module，不要修改 \"router_gen.go\": { \"RouterPkgPath\": \"github.com/hz/test/biz/router\" } } 自定义一个 layout 模板  目前，hz 生成的项目 layout 已经是一个 hertz 项目最最最基础的骨架了，所以不建议删除现有的模板里的文件。\n不过如果用户想要一个别的 layout ，当然也可以根据自身需求来删除相应的文件(除\"biz/register.go\"外，其余都可以动)\n我们十分欢迎用户来贡献自己的模板\n 下面假设用户只想要 “main.go” 以及 “go.mod” 文件，那么我们对默认模板进行修改，如下：\ntemplate // layout.yamllayouts:# 项目 main 文件，- path:main.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. package main import ( \"github.com/cloudwego/hertz/pkg/app/server\" \"{{.GoModule}}/biz/router\" ) func main() { h := server.Default() router.GeneratedRegister(h) // do what you wanted // add some render data: {{.MainData}} h.Spin() }# go.mod 文件，需要模板渲染数据{{.GoModule}}才能生成- path:go.moddelims:- '{{'- '}}'body:|-module {{.GoModule}} {{- if .UseApacheThrift}} replace github.com/apache/thrift =\u003e github.com/apache/thrift v0.13.0 {{- end}}# 默认路由注册文件，没必要修改- path:biz/router/register.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. DO NOT EDIT. package router import ( \"github.com/cloudwego/hertz/pkg/app/server\" ) // GeneratedRegister registers routers generated by IDL. func GeneratedRegister(r *server.Hertz){ //INSERT_POINT: DO NOT DELETE THIS LINE! }render data { \"*\": { \"GoModule\": \"github.com/hertz/hello\", \"ServiceName\": \"hello\", \"UseApacheThrift\": true }, \"main.go\": { \"MainData\": \"this is customized render data\" } } 命令：\nhz new --mod=github.com/hertz/hello --idl=./hertzDemo/hello.thrift --customize_layout=template/layout.yaml:template/data.json 自定义 package 模板  hz 模板的模板地址：\n用户可根据默认模板来修改或重写，从而符合自身需求\n  所谓的 package 模板是指与 idl 定义相关的服务代码，这部分代码涉及到定义 idl 时指定的service、go_package/namespace等，主要包括以下几部分： handler.go： 处理函数逻辑 router.go：具体的 idl 定义的服务的路由注册逻辑 register.go：调用router.go中内容的逻辑 model代码：生成的 go struct；不过由于目前使用插件来生成model代码工具没权限来修改model的模板，所以这部分功能先不开放  命令 # 之后会提供 package 模板渲染数据，所以输入命令的时候先保留了\"k-v\"的形式，customize_package 后需要加\":\" hz new --mod=github.com/hertz/hello --handler_dir=handler_test --idl=hertzDemo/hello.thrift --customize_package=template/package.yaml: 默认 package 模板 注意：自定义 package 模板没有提供渲染数据的功能，这里主要是因为这些渲染数据是 hz 工具解析生成的，所以暂时不提供自己写渲染数据的功能。可以修改下模板里面与渲染数据无关的部分，以满足自身需求。\n# 以下数据都是 yaml marshal 得到的，所以可能看起来比较乱layouts:# path只表示handler.go的模板，具体的handler路径由默认路径和handler_dir决定- path:handler.godelims:- '{{'- '}}'body:|-// Code generated by hertz generator. package {{.PackageName}} import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" {{- range $k, $v := .Imports}} {{$k}} \"{{$v.Package}}\" {{- end}} ) {{range $_, $MethodInfo := .Methods}} {{$MethodInfo.Comment}} func {{$MethodInfo.Name}}(ctx context.Context, c *app.RequestContext) { var err error {{if ne $MethodInfo.RequestTypeName \"\" -}} var req {{$MethodInfo.RequestTypeName}} err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } {{end}} resp := new({{$MethodInfo.ReturnTypeName}}) c.{{.Serializer}}(200, resp) } {{end}}# path只表示router.go的模板，其路径固定在:biz/router/namespace/- path:router.godelims:- '{{'- '}}'body:|-// Code generated by hertz generator. DO NOT EDIT. package {{$.PackageName}} import ( \"github.com/cloudwego/hertz/pkg/app/server\" {{range $k, $v := .HandlerPackages}}{{$k}} \"{{$v}}\"{{end}} ) /* This file will register all the routes of the services in the master idl. And it will update automatically when you use the \"update\" command for the idl. So don't modify the contents of the file, or your code will be deleted when it is updated. */ {{define \"g\"}} {{- if eq .Path \"/\"}}r {{- else}}{{.GroupName}}{{end}} {{- end}} {{define \"G\"}} {{- if ne .Handler \"\"}} {{- .GroupName}}.{{.HttpMethod}}(\"{{.Path}}\", append({{.MiddleWare}}Mw(), {{.Handler}})...) {{- end}} {{- if ne (len .Children) 0}} {{.MiddleWare}} := {{template \"g\" .}}.Group(\"{{.Path}}\", {{.MiddleWare}}Mw()...) {{- end}} {{- range $_, $router := .Children}} {{- if ne .Handler \"\"}} {{template \"G\" $router}} {{- else}} {\t{{template \"G\" $router}} } {{- end}} {{- end}} {{- end}} // Register register routes based on the IDL 'api.${HTTP Method}' annotation. func Register(r *server.Hertz) { {{template \"G\" .Router}} }# path只表示register.go的模板，register的路径固定为biz/router/register.go- path:register.godelims:- \"\"- \"\"body:|-// Code generated by hertz generator. DO NOT EDIT. package router import ( \"github.com/cloudwego/hertz/pkg/app/server\" {{$.PkgAlias}} \"{{$.Pkg}}\" ) // GeneratedRegister registers routers generated by IDL. func GeneratedRegister(r *server.Hertz){ //INSERT_POINT: DO NOT DELETE THIS LINE! {{$.PkgAlias}}.Register(r) }- path:model.godelims:- \"\"- \"\"body:\"\"# path只表示middleware.go的模板，middleware的路径和router.go一样为：biz/router/namespace/- path:middleware.godelims:- '{{'- '}}'body:|-// Code generated by hertz generator. package {{$.PackageName}} import ( \"github.com/cloudwego/hertz/pkg/app\" ) {{define \"M\"}} func {{.MiddleWare}}Mw() []app.HandlerFunc { // your code... return nil } {{range $_, $router := $.Children}}{{template \"M\" $router}}{{end}} {{- end}} {{template \"M\" .Router}}# path只表示client.go的模板，client代码的生成路径由用户指定\"${client_dir}\"- path:client.godelims:- '{{'- '}}'body:|-// Code generated by hertz generator. package {{$.PackageName}} import ( \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/common/config\" ) type {{.ServiceName}}Client struct { client * client.Client } func New{{.ServiceName}}Client(opt ...config.ClientOption) (*{{.ServiceName}}Client, error) { c, err := client.NewClient(opt...) if err != nil { return nil, err } return \u0026{{.ServiceName}}Client{ client: c, }, nil }# handler_single表示单独的handler模板，用于update的时候更新每一个新增的handler- path:handler_single.godelims:- '{{'- '}}'body:|+{{.Comment}} func {{.Name}}(ctx context.Context, c *app.RequestContext) { // this my demo var err error {{if ne .RequestTypeName \"\" -}} var req {{.RequestTypeName}} err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } {{end}} resp := new({{.ReturnTypeName}}) c.{{.Serializer}}(200, resp) }# middleware_single表示单独的middleware模板，用于update的时候更新每一个新增的middleware_single- path:middleware_single.godelims:- '{{'- '}}'body:|+func {{.MiddleWare}}Mw() []app.HandlerFunc { // your code... return nil }自定义一个 package 模板  与 layout 模板一样，用户同样可以自定义 package 模板。\n就 package 提供的模板来说，一般用户可能只有自定义 handler.go 的模板的需求，因为router.go/middleware.go/register.go 一般与 idl 定义相关而用户无需关心，因此 hz 目前也将这些模板生成的位置固定了，一般也无需修改。\n因此，用户可根据自身的需求来自定义生成的 handler 模板，加速开发速度；但是由于默认的 handler 模板集成了一些 model 的信息以及 package 信息，所以需要 hz 工具来提供渲染数据。这部分用户可根据自身情况酌情来修改，一般建议留下 model 信息。\n 覆盖默认模板 目前，hz 本身自带了如下的模板：\n handler.go router.go register.go middleware.go client.go handler_single.go middleware_single.go idl_client.go hertz_client.go  以上这些模板是工具运行最基础的模板，在自定义模板的时候：\n 如果指定了同名模板会覆盖掉默认的内容 如果没指定同名模板会使用默认的模板  因此，大家在自定义模板的时候需要根据自己的实际情况来考虑是否需要覆盖掉这些模板\n添加一个新的模板 考虑到大家有时可能需要针对 IDL 的某些信息新增自己的一些实现，例如为每个生成的handler加一下单测等需求。因此，hz 的模板里允许用户自定义新的模板，并提供模板的渲染参数数据源。\n模板形式：\n- path:biz/Fgy/{{$HandlerName}}.go // 路径+文件名，支持渲染数据loop_method:bool // 是否按照 idl 中定义的 method 生成多个文件，配合 path 渲染使用loop_service:bool // 是否按照 idl 中定义的 service 生成多个文件，配合 path 渲染使用update_behavior:// 在使用 hz update 的时候对于该文件的更新行为type:string // 更新行为:skip/cover/appendappend_key:\"method\"/\"service\" // 在 append 行为的时候，指定追加的渲染数据源，method/serviceinsert_key:string // 在 append 行为的时候追加逻辑的 “key”，根据这个key判断是否需要进行追加append_content_tpl:string // 在 append 行为的时候，指定追加内容的模板import_tpl:[]string // 要新增的import的模板body:string // 生成文件的模板内容模板数据源  文件路径渲染：在指定文件路径的时候可使用如下渲染数据  type FilePathRenderInfo struct { MasterIDLName string // master IDL name \tGenPackage string // master IDL generate code package \tHandlerDir string // handler generate dir \tModelDir string // model generate dir \tRouterDir string // router generate dir \tProjectDir string // projectDir \tGoModule string // go module \tServiceName string // service name, changed as services are traversed \tMethodName string // method name, changed as methods are traversed \tHandlerGenPath string // \"api.gen_path\" value }  单个文件的渲染数据：在单独定义一个文件时使用的渲染数据，可根据 “IDLPackageRenderInfo” 的定义解出所有 IDL 的信息  type CustomizedFileForIDL struct { *IDLPackageRenderInfo FilePath string FilePackage string }  Method 级别的渲染数据：当指定\"loop_method\"时，会使用到的渲染数据，会以每个 method 为单位生成一个文件  type CustomizedFileForMethod struct { *HttpMethod // 每个 method 定义的解析出来的具体信息 \tFilePath string // 当循环生成 method 文件时，该文件路径 \tFilePackage string // 当循环生成 method 文件时，该文件的 go package 名 \tServiceInfo *Service // 该 method 所属的 service 定义的信息 } type HttpMethod struct { Name string HTTPMethod string Comment string RequestTypeName string ReturnTypeName string Path string // 请求路由 \tSerializer string OutputDir string Models map[string]*model.Model }  Service 级别的渲染数据：当指定\"loop_service\"时，会使用到的渲染数据，会以每个 service 为单位生成一个文件  type CustomizedFileForService struct { *Service // 该 service 的具体信息，包括 service 名字，servide 内定义的 method 的信息等 \tFilePath string // 当循环生成 service 文件时，该文件路径 \tFilePackage string // 当循环生成 service 文件时，该文件的 go package 名 \tIDLPackageInfo *IDLPackageRenderInfo // 该 service 所属的 IDL 定义的信息 } type Service struct { Name string Methods []*HttpMethod ClientMethods []*ClientMethod Models []*model.Model // all dependency models \tBaseDomain string // base domain for client code } 下面给出一个简单的自定义 handler 模板的示例：\nexample  example： https://github.com/cloudwego/hertz-examples/tree/main/hz/template\n   修改默认 handler 的内容\n  为 handler 新增一个单测文件\n  layouts:- path:handler.gobody:|-{{$OutDirs := GetUniqueHandlerOutDir .Methods}} package {{.PackageName}} import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" {{- range $k, $v := .Imports}} {{$k}} \"{{$v.Package}}\" {{- end}} {{- range $_, $OutDir := $OutDirs}} {{if eq $OutDir \"\" -}} \"{{$.ProjPackage}}/biz/service\" {{- else -}} \"{{$.ProjPackage}}/biz/service/{{$OutDir}}\" {{- end -}} {{- end}} \"{{$.ProjPackage}}/biz/utils\" ) {{range $_, $MethodInfo := .Methods}} {{$MethodInfo.Comment}} func {{$MethodInfo.Name}}(ctx context.Context, c *app.RequestContext) { var err error {{if ne $MethodInfo.RequestTypeName \"\" -}} var req {{$MethodInfo.RequestTypeName}} err = c.BindAndValidate(\u0026req) if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } {{end}} {{if eq $MethodInfo.OutputDir \"\" -}} resp,err := service.New{{$MethodInfo.Name}}Service(ctx, c).Run(\u0026req) if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } {{else}} resp,err := {{$MethodInfo.OutputDir}}.New{{$MethodInfo.Name}}Service(ctx, c).Run(\u0026req) if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } {{end}} utils.SendSuccessResponse(ctx, c, consts.StatusOK, resp) } {{end}}update_behavior:import_tpl:- |-{{$OutDirs := GetUniqueHandlerOutDir .Methods}} {{- range $_, $OutDir := $OutDirs}} {{if eq $OutDir \"\" -}} \"{{$.ProjPackage}}/biz/service\" {{- else -}} \"{{$.ProjPackage}}/biz/service/{{$OutDir}}\" {{end}} {{- end}}- path:handler_single.gobody:|+{{.Comment}} func {{.Name}}(ctx context.Context, c *app.RequestContext) { var err error {{if ne .RequestTypeName \"\" -}} var req {{.RequestTypeName}} err = c.BindAndValidate(\u0026req) if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } {{end}} {{if eq .OutputDir \"\" -}} resp,err := service.New{{.Name}}Service(ctx, c).Run(\u0026req) {{else}} resp,err := {{.OutputDir}}.New{{.Name}}Service(ctx, c).Run(\u0026req) {{end}} if err != nil { utils.SendErrResponse(ctx, c, consts.StatusOK, err) return } utils.SendSuccessResponse(ctx, c, consts.StatusOK, resp) }=- path:\"{{.HandlerDir}}/{{.GenPackage}}/{{ToSnakeCase .ServiceName}}_test.go\"loop_service:trueupdate_behavior:type:\"append\"append_key:\"method\"insert_key:\"Test{{$.Name}}\"append_tpl:|-func Test{{.Name}}(t *testing.T) { h := server.Default() h.GET(\"{{.Path}}\", {{.Name}}) w := ut.PerformRequest(h.Engine, \"{{.HTTPMethod}}\", \"{{.Path}}\", \u0026ut.Body{Body: bytes.NewBufferString(\"\"), Len: 1}, ut.Header{}) resp := w.Result() assert.DeepEqual(t, 201, resp.StatusCode()) assert.DeepEqual(t, \"\", string(resp.Body())) // todo edit your unit test. }body:|-package {{.FilePackage}} import ( \"bytes\" \"testing\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/test/assert\" \"github.com/cloudwego/hertz/pkg/common/ut\" ) {{range $_, $MethodInfo := $.Methods}} func Test{{$MethodInfo.Name}}(t *testing.T) { h := server.Default() h.GET(\"{{$MethodInfo.Path}}\", {{$MethodInfo.Name}}) w := ut.PerformRequest(h.Engine, \"{{$MethodInfo.HTTPMethod}}\", \"{{$MethodInfo.Path}}\", \u0026ut.Body{Body: bytes.NewBufferString(\"\"), Len: 1}, ut.Header{}) resp := w.Result() assert.DeepEqual(t, 201, resp.StatusCode()) assert.DeepEqual(t, \"\", string(resp.Body())) // todo edit your unit test. } {{end}}MVC 模板实践 Hertz 提供了 一个 MVC 自定义模版的最佳实践，代码详见 code 。\n注意事项 使用 layout 模板的注意事项 当用户使用了 layout 自定义模板后，那么生成的 layout 和渲染数据都由用户接管，所以用户需要提供其定义的 layout 的渲染数据。\n使用 package 模板的注意事项 一般来说，用户使用 package 模板的时候大多数是为了修改默认的 handler 模板；不过，目前 hz 没有提供单个 handler 的模板，所以当 update 已经存在的 handler 文件时，会使用默认 handler 模板在 handler 文件尾追加新的 handler function。当对应的 handler 文件不存在的时候，才会使用自定义模板来生成 handler 文件。\n","categories":"","description":"","excerpt":"Hertz 提供的命令行工具(以下称为\"hz\")支持自定义模板功能，包括:\n 自定义 layout 模板(即生成代码的目录结构) …","ref":"/zh/docs/hertz/tutorials/toolkit/template/","tags":"","title":"hz 自定义模板使用"},{"body":"HTTP/2 is a replacement for how HTTP is expressed “on the wire.” It is not a ground-up rewrite of the protocol; HTTP methods, status codes and semantics are the same, and it should be possible to use the same APIs as HTTP/1.x (possibly with some small additions) to represent the protocol.\nThe focus of the protocol is on performance; specifically, end-user perceived latency, network and server resource usage. One major goal is to allow the use of a single connection from browsers to a Web site.\nHertz supports both h2 and h2c. It uses net/http2 implementation for reference.\nExample h2 package main import ( \"context\" \"crypto/tls\" \"encoding/json\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/network/standard\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/hertz-contrib/http2/config\" \"github.com/hertz-contrib/http2/factory\" ) const ( keyPEM = `\u003cyour key PEM\u003e` certPEM = `\u003cyour cert PEM\u003e` ) func runClient() { cli, _ := client.NewClient() cli.SetClientFactory(factory.NewClientFactory( config.WithDialer(standard.NewDialer()), config.WithTLSConfig(\u0026tls.Config{InsecureSkipVerify: true}))) v, _ := json.Marshal(map[string]string{ \"hello\": \"world\", \"protocol\": \"h2\", }) for { time.Sleep(time.Second * 1) req, rsp := protocol.AcquireRequest(), protocol.AcquireResponse() req.SetMethod(\"POST\") req.SetRequestURI(\"https://127.0.0.1:8888\") req.SetBody(v) err := cli.Do(context.Background(), req, rsp) if err != nil { fmt.Println(err) return } fmt.Printf(\"[client]: received body: %s\\n\", string(rsp.Body())) } } func main() { cfg := \u0026tls.Config{ MinVersion: tls.VersionTLS12, CurvePreferences: []tls.CurveID{tls.X25519, tls.CurveP256}, CipherSuites: []uint16{ tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, }, } cert, err := tls.X509KeyPair([]byte(certPEM), []byte(keyPEM)) if err != nil { fmt.Println(err.Error()) } cfg.Certificates = append(cfg.Certificates, cert) h := server.New(server.WithHostPorts(\":8888\"), server.WithALPN(true), server.WithTLS(cfg)) // register HTTP2 server factory \th.AddProtocol(\"h2\", factory.NewServerFactory( config.WithReadTimeout(time.Minute), config.WithDisableKeepAlive(false))) cfg.NextProtos = append(cfg.NextProtos, \"h2\") h.POST(\"/\", func(c context.Context, ctx *app.RequestContext) { var j map[string]string _ = json.Unmarshal(ctx.Request.Body(), \u0026j) fmt.Printf(\"[server]: received request: %+v\\n\", j) r := map[string]string{ \"msg\": \"hello world\", } for k, v := range j { r[k] = v } ctx.JSON(http.StatusOK, r) }) go runClient() h.Spin() } h2c package main import ( \"context\" \"encoding/json\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/hertz-contrib/http2/config\" \"github.com/hertz-contrib/http2/factory\" ) func runClient() { c, _ := client.NewClient() c.SetClientFactory(factory.NewClientFactory(config.WithAllowHTTP(true))) v, _ := json.Marshal(map[string]string{ \"hello\": \"world\", \"protocol\": \"h2c\", }) for { time.Sleep(time.Second * 1) req, rsp := protocol.AcquireRequest(), protocol.AcquireResponse() req.SetMethod(\"POST\") req.SetRequestURI(\"http://127.0.0.1:8888\") req.SetBody(v) err := c.Do(context.Background(), req, rsp) if err != nil { fmt.Println(err) return } fmt.Printf(\"client received body: %s\\n\", string(rsp.Body())) } } func main() { h := server.New(server.WithHostPorts(\":8888\"), server.WithH2C(true)) // register HTTP2 server factory \th.AddProtocol(\"h2\", factory.NewServerFactory()) h.POST(\"/\", func(c context.Context, ctx *app.RequestContext) { var j map[string]string _ = json.Unmarshal(ctx.Request.Body(), \u0026j) fmt.Printf(\"server çreceived request: %+v\\n\", j) r := map[string]string{ \"msg\": \"hello world\", } for k, v := range j { r[k] = v } ctx.JSON(http.StatusOK, r) }) go runClient() h.Spin() } Config Server    Option Default Description     ReadTimeout 0 The timeout for reading available resources from the server after the connection is established,   DisableKeepAlive false Whether to disable Keep-Alive mode    Sample Code:\npackage main import ( \"context\" \"crypto/tls\" \"encoding/json\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/network/standard\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/hertz-contrib/http2/config\" \"github.com/hertz-contrib/http2/factory\" ) const ( keyPEM = `\u003cyour key PEM\u003e` certPEM = `\u003cyour cert PEM\u003e` ) func runClient() { cli, _ := client.NewClient() cli.SetClientFactory(factory.NewClientFactory( config.WithDialer(standard.NewDialer()), config.WithTLSConfig(\u0026tls.Config{InsecureSkipVerify: true}))) v, _ := json.Marshal(map[string]string{ \"hello\": \"world\", \"protocol\": \"h2\", }) for { time.Sleep(time.Second * 1) req, rsp := protocol.AcquireRequest(), protocol.AcquireResponse() req.SetMethod(\"POST\") req.SetRequestURI(\"https://127.0.0.1:8888\") req.SetBody(v) err := cli.Do(context.Background(), req, rsp) if err != nil { fmt.Println(err) return } fmt.Printf(\"[client]: received body: %s\\n\", string(rsp.Body())) } } func main() { cfg := \u0026tls.Config{ MinVersion: tls.VersionTLS12, CurvePreferences: []tls.CurveID{tls.X25519, tls.CurveP256}, CipherSuites: []uint16{ tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, }, } cert, err := tls.X509KeyPair([]byte(certPEM), []byte(keyPEM)) if err != nil { fmt.Println(err.Error()) } cfg.Certificates = append(cfg.Certificates, cert) h := server.New(server.WithHostPorts(\":8888\"), server.WithALPN(true), server.WithTLS(cfg)) // register HTTP2 server factory \th.AddProtocol(\"h2\", factory.NewServerFactory( config.WithReadTimeout(time.Minute), config.WithDisableKeepAlive(false))) cfg.NextProtos = append(cfg.NextProtos, \"h2\") h.POST(\"/\", func(c context.Context, ctx *app.RequestContext) { var j map[string]string _ = json.Unmarshal(ctx.Request.Body(), \u0026j) fmt.Printf(\"[server]: received request: %+v\\n\", j) r := map[string]string{ \"msg\": \"hello world\", } for k, v := range j { r[k] = v } ctx.JSON(http.StatusOK, r) }) go runClient() h.Spin() } WithReadTimeout Used to set ReadTimeout, the default value is 0.\nFunction Signature:\nfunc WithReadTimeout(t time.Duration) Option WithDisableKeepAlive Used to set whether to disable keep-alive or not, and not to disable it by default.\nFunction Signature:\nfunc WithDisableKeepAlive(disableKeepAlive bool) Option Client    Option Default Description     MaxHeaderListSize 0, means use the default limit (10MB) Refers to SETTINGS_MAX_HEADER_LIST_SIZE in the HTTP2 specification.   AllowHTTP false Set whether to allow HTTP,the h2c switch   ReadIdleTimeout 0,which means no health check If the connection does not receive any frames during this interval, a health check is performed using ping frames.   PingTimeout 15s A timeout period after which the connection will be closed if no response to Ping  is received.   WriteByteTimeout 0 If no data is written during this time interval, the connection will be closed.   StrictMaxConcurrentStreams false Controls whether the server’s SETTINGS_MAX_CONCURRENT_STREAMS should be respected globally.   DialTimeout 1s imeout for establishing new connections to hosts.   MaxIdleConnDuration 0 Idle keep-alive connections are closed after this duration.   DisableKeepAlive false Connection will close after each request when set this to true.   Dialer netpoll.NewDialer() Default Dialer is used if not set.   TLSConfig nil Whether to use TLS (aka SSL or HTTPS) for host connections.   RetryConfig  nil All configurations related to retry    Sample:\npackage main import ( \"context\" \"crypto/tls\" \"encoding/json\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/client/retry\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/network/standard\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/hertz-contrib/http2/config\" \"github.com/hertz-contrib/http2/factory\" ) const ( keyPEM = `\u003cyour key PEM\u003e` certPEM = `\u003cyour cert PEM\u003e` ) func runClient() { cli, _ := client.NewClient() cli.SetClientFactory(factory.NewClientFactory( config.WithDialTimeout(3*time.Second), config.WithReadIdleTimeout(1*time.Second), config.WithWriteByteTimeout(time.Second), config.WithPingTimeout(time.Minute), config.WithMaxIdleConnDuration(2*time.Second), config.WithClientDisableKeepAlive(true), //Close Connection after each request \tconfig.WithStrictMaxConcurrentStreams(true), // Set the server's SETTINGS_MAX_CONCURRENT_STREAMS to be respected globally. \tconfig.WithDialer(standard.NewDialer()), // You can customize dialer here \tconfig.WithMaxHeaderListSize(0xffffffff), // Set SETTINGS_MAX_HEADER_LIST_SIZE to unlimited. \tconfig.WithMaxIdempotentCallAttempts(3), config.WithRetryConfig( retry.WithMaxAttemptTimes(3), retry.WithInitDelay(2*time.Millisecond), retry.WithMaxDelay(200*time.Millisecond), retry.WithMaxJitter(30*time.Millisecond), retry.WithDelayPolicy(retry.FixedDelayPolicy), ), config.WithStrictMaxConcurrentStreams(true), // Set the server's SETTINGS_MAX_CONCURRENT_STREAMS to be respected globally. \tconfig.WithTLSConfig(\u0026tls.Config{ SessionTicketsDisabled: false, InsecureSkipVerify: true, }), )) v, _ := json.Marshal(map[string]string{ \"hello\": \"world\", \"protocol\": \"h2\", }) for { time.Sleep(time.Second * 1) req, rsp := protocol.AcquireRequest(), protocol.AcquireResponse() req.SetMethod(\"POST\") req.SetRequestURI(\"https://127.0.0.1:8888\") req.SetBody(v) err := cli.Do(context.Background(), req, rsp) if err != nil { fmt.Println(err) return } fmt.Printf(\"[client]: received body: %s\\n\", string(rsp.Body())) } } func main() { cfg := \u0026tls.Config{ MinVersion: tls.VersionTLS12, CurvePreferences: []tls.CurveID{tls.X25519, tls.CurveP256}, CipherSuites: []uint16{ tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, }, } cert, err := tls.X509KeyPair([]byte(certPEM), []byte(keyPEM)) if err != nil { fmt.Println(err.Error()) } cfg.Certificates = append(cfg.Certificates, cert) h := server.New(server.WithHostPorts(\":8888\"), server.WithALPN(true), server.WithTLS(cfg)) // register HTTP2 server factory \th.AddProtocol(\"h2\", factory.NewServerFactory( config.WithReadTimeout(time.Minute), config.WithDisableKeepAlive(false))) cfg.NextProtos = append(cfg.NextProtos, \"h2\") h.POST(\"/\", func(c context.Context, ctx *app.RequestContext) { var j map[string]string _ = json.Unmarshal(ctx.Request.Body(), \u0026j) fmt.Printf(\"[server]: received request: %+v\\n\", j) r := map[string]string{ \"msg\": \"hello world\", } for k, v := range j { r[k] = v } ctx.JSON(http.StatusOK, r) }) go runClient() h.Spin() } WithMaxHeaderListSize Used to set SETTINGS_MAX_HEADER_LIST_SIZE.\nUnlike the HTTP2 specification, 0 here indicates that the default limit is used (currently 10MB). If you want to indicate infinity, you can set it to a value as large as possible (0xffffff or 1\u003c\u003c32-1).\nFunction Signature:\nfunc WithMaxHeaderListSize(maxHeaderListSize uint32) ClientOption WithReadIdleTimeout Used to set the read timeout interval, after which a health check will be performed using ping frames.\nNote that a ping response will be treated as a receive frame, so if there is no other traffic on the connection, the health check will be performed at every read timeout interval.\nThe default value of 0 means that no health check will be performed.\nFunction Signature:\nfunc WithReadIdleTimeout(readIdleTimeout time.Duration) ClientOption WithWriteByteTimeout Used to set the write timeout time, after which the connection will be closed. The timing starts when the data is ready to be written and keeps extending as data is written.\nFunction Signature:\nfunc WithWriteByteTimeout(writeByteTimeout time.Duration) ClientOption WithStrictMaxConcurrentStreams Used to set whether the server’s SETTINGS_MAX_CONCURRENT_STREAMS should be used globally.\nFunction Signature:\nfunc WithStrictMaxConcurrentStreams(strictMaxConcurrentStreams bool) ClientOption WithPingTimeout Set the timeout for Ping responses, after which the connection will be closed if no response is received to Ping .The default is 15s.\nFunction Signature:\nfunc WithPingTimeout(pt time.Duration) ClientOption WithAllowHTTP Used to set whether to allow HTTP. if enabled, the client will use h2c mode. Not enabled by default.\nFunction Signature:\nfunc WithAllowHTTP(allow bool) ClientOption WithDialer Support custom dialer, default is netpoll.NewDialer().\nFunction Signature:\nfunc WithDialer(d network.Dialer) ClientOption Interface Definition:\ntype Dialer interface { // DialConnection is used to dial the peer end. \tDialConnection(network, address string, timeout time.Duration, tlsConfig *tls.Config) (conn Conn, err error) // DialTimeout is used to dial the peer end with a timeout. \t// \t// NOTE: Not recommended to use this function. Just for compatibility. \tDialTimeout(network, address string, timeout time.Duration, tlsConfig *tls.Config) (conn net.Conn, err error) // AddTLS will transfer a common connection to a tls connection. \tAddTLS(conn Conn, tlsConfig *tls.Config) (Conn, error) } WithDialTimeout Used to set the timeout for establishing a new connection with the host, default is 1s.\nFunction Signature:\nfunc WithDialTimeout(timeout time.Duration) ClientOption WithTLSConfig Used to customize the TLS configuration.\nFunction Signature:\nfunc WithTLSConfig(tlsConfig *tls.Config) ClientOption WithMaxIdleConnDuration Used to set the maximum idle time for a long connection, after which the connection is closed. The default is 0.\nFunction Signature:\nfunc WithMaxIdleConnDuration(d time.Duration) ClientOption WithMaxIdempotentCallAttempts Sets maximum number of attempts for idempotent calls.\nFunction Signature:\nfunc WithMaxIdempotentCallAttempts(n int) ClientOption WithRetryConfig Used to set the configuration related to retry.\nFunction Signature:\nfunc WithRetryConfig(opts ...retry.Option) ClientOption WithClientDisableKeepAlive Used to set whether to close the connection after each request. The default is false.\nFunction Signature:\nfunc WithClientDisableKeepAlive(disable bool) ClientOption For more usage examples, see hertz-contrib/http2.\n","categories":"","description":"","excerpt":"HTTP/2 is a replacement for how HTTP is expressed “on the wire.” It is …","ref":"/docs/hertz/tutorials/basic-feature/protocol/http2/","tags":"","title":"HTTP2"},{"body":"HTTP/2 是对 HTTP “在线” 表达方式的一种替代。它并不是对协议的彻底重写；HTTP 方法、状态码和语义都是一样的，而且应该可以使用与 HTTP/1.x 相同的 API（可能会有一些小的补充）来表示协议。\n协议的侧重点是性能：缩短用户感知的延迟、减少网络和服务器资源的使用。一个主要目标是允许使用从浏览器到网站的单一连接。\nHertz 同时支持 h2 和 h2c。参考了 net/http2 的实现。\n示例代码 h2 package main import ( \"context\" \"crypto/tls\" \"encoding/json\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/network/standard\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/hertz-contrib/http2/config\" \"github.com/hertz-contrib/http2/factory\" ) const ( keyPEM = `\u003cyour key PEM\u003e` certPEM = `\u003cyour cert PEM\u003e` ) func runClient() { cli, _ := client.NewClient() cli.SetClientFactory(factory.NewClientFactory( config.WithDialer(standard.NewDialer()), config.WithTLSConfig(\u0026tls.Config{InsecureSkipVerify: true}))) v, _ := json.Marshal(map[string]string{ \"hello\": \"world\", \"protocol\": \"h2\", }) for { time.Sleep(time.Second * 1) req, rsp := protocol.AcquireRequest(), protocol.AcquireResponse() req.SetMethod(\"POST\") req.SetRequestURI(\"https://127.0.0.1:8888\") req.SetBody(v) err := cli.Do(context.Background(), req, rsp) if err != nil { fmt.Println(err) return } fmt.Printf(\"[client]: received body: %s\\n\", string(rsp.Body())) } } func main() { cfg := \u0026tls.Config{ MinVersion: tls.VersionTLS12, CurvePreferences: []tls.CurveID{tls.X25519, tls.CurveP256}, CipherSuites: []uint16{ tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, }, } cert, err := tls.X509KeyPair([]byte(certPEM), []byte(keyPEM)) if err != nil { fmt.Println(err.Error()) } cfg.Certificates = append(cfg.Certificates, cert) h := server.New(server.WithHostPorts(\":8888\"), server.WithALPN(true), server.WithTLS(cfg)) // register http2 server factory \th.AddProtocol(\"h2\", factory.NewServerFactory( config.WithReadTimeout(time.Minute), config.WithDisableKeepAlive(false))) cfg.NextProtos = append(cfg.NextProtos, \"h2\") h.POST(\"/\", func(c context.Context, ctx *app.RequestContext) { var j map[string]string _ = json.Unmarshal(ctx.Request.Body(), \u0026j) fmt.Printf(\"[server]: received request: %+v\\n\", j) r := map[string]string{ \"msg\": \"hello world\", } for k, v := range j { r[k] = v } ctx.JSON(http.StatusOK, r) }) go runClient() h.Spin() } h2c package main import ( \"context\" \"encoding/json\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/hertz-contrib/http2/config\" \"github.com/hertz-contrib/http2/factory\" ) func runClient() { c, _ := client.NewClient() c.SetClientFactory(factory.NewClientFactory(config.WithAllowHTTP(true))) v, _ := json.Marshal(map[string]string{ \"hello\": \"world\", \"protocol\": \"h2c\", }) for { time.Sleep(time.Second * 1) req, rsp := protocol.AcquireRequest(), protocol.AcquireResponse() req.SetMethod(\"POST\") req.SetRequestURI(\"http://127.0.0.1:8888\") req.SetBody(v) err := c.Do(context.Background(), req, rsp) if err != nil { fmt.Println(err) return } fmt.Printf(\"client received body: %s\\n\", string(rsp.Body())) } } func main() { h := server.New(server.WithHostPorts(\":8888\"), server.WithH2C(true)) // register http2 server factory \th.AddProtocol(\"h2\", factory.NewServerFactory()) h.POST(\"/\", func(c context.Context, ctx *app.RequestContext) { var j map[string]string _ = json.Unmarshal(ctx.Request.Body(), \u0026j) fmt.Printf(\"server çreceived request: %+v\\n\", j) r := map[string]string{ \"msg\": \"hello world\", } for k, v := range j { r[k] = v } ctx.JSON(http.StatusOK, r) }) go runClient() h.Spin() } 配置 服务端    配置 默认值 介绍     ReadTimeout 0 建立连接后，从服务器读取到可用资源的超时时间   DisableKeepAlive false 是否关闭 Keep-Alive模式    示例代码：\npackage main import ( \"context\" \"crypto/tls\" \"encoding/json\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/network/standard\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/hertz-contrib/http2/config\" \"github.com/hertz-contrib/http2/factory\" ) const ( keyPEM = `\u003cyour key PEM\u003e` certPEM = `\u003cyour cert PEM\u003e` ) func runClient() { cli, _ := client.NewClient() cli.SetClientFactory(factory.NewClientFactory( config.WithDialer(standard.NewDialer()), config.WithTLSConfig(\u0026tls.Config{InsecureSkipVerify: true}))) v, _ := json.Marshal(map[string]string{ \"hello\": \"world\", \"protocol\": \"h2\", }) for { time.Sleep(time.Second * 1) req, rsp := protocol.AcquireRequest(), protocol.AcquireResponse() req.SetMethod(\"POST\") req.SetRequestURI(\"https://127.0.0.1:8888\") req.SetBody(v) err := cli.Do(context.Background(), req, rsp) if err != nil { fmt.Println(err) return } fmt.Printf(\"[client]: received body: %s\\n\", string(rsp.Body())) } } func main() { cfg := \u0026tls.Config{ MinVersion: tls.VersionTLS12, CurvePreferences: []tls.CurveID{tls.X25519, tls.CurveP256}, CipherSuites: []uint16{ tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, }, } cert, err := tls.X509KeyPair([]byte(certPEM), []byte(keyPEM)) if err != nil { fmt.Println(err.Error()) } cfg.Certificates = append(cfg.Certificates, cert) h := server.New(server.WithHostPorts(\":8888\"), server.WithALPN(true), server.WithTLS(cfg)) // register http2 server factory \th.AddProtocol(\"h2\", factory.NewServerFactory( config.WithReadTimeout(time.Minute), config.WithDisableKeepAlive(false))) cfg.NextProtos = append(cfg.NextProtos, \"h2\") h.POST(\"/\", func(c context.Context, ctx *app.RequestContext) { var j map[string]string _ = json.Unmarshal(ctx.Request.Body(), \u0026j) fmt.Printf(\"[server]: received request: %+v\\n\", j) r := map[string]string{ \"msg\": \"hello world\", } for k, v := range j { r[k] = v } ctx.JSON(http.StatusOK, r) }) go runClient() h.Spin() } WithReadTimeout 用于设置 ReadTimeout,默认值为 0。\n函数签名：\nfunc WithReadTimeout(t time.Duration) Option WithDisableKeepAlive 用于设置是否禁用 keep-alive，默认不禁用。\n函数签名:\nfunc WithDisableKeepAlive(disableKeepAlive bool) Option 客户端    配置 默认值 介绍     MaxHeaderListSize 0，指使用默认的限制（10MB） 指 http2 规范中的SETTINGS_MAX_HEADER_LIST_SIZE。   AllowHTTP false 设置是否允许 http，h2c 模式的开关   ReadIdleTimeout 0，即不进行健康检查 若连接在该段时间间隔内未接收到任何帧，将使用ping帧进行健康检查。   PingTimeout 15s 超时时间，如果未收到对 Ping 的响应，连接将在该超时时间后关闭。   WriteByteTimeout 0 若在该段时间间隔内未写入任何数据，将关闭连接。   StrictMaxConcurrentStreams false 设置服务器的SETTINGS_MAX_CONCURRENT_STREAMS是否应该被全局使用。   DialTimeout 1s 与主机建立新连接的超时时间。   MaxIdleConnDuration 0 闲置的长连接在该段时间后关闭。   DisableKeepAlive false 是否在每次请求后关闭连接。   Dialer netpoll.NewDialer() 用于设置拨号器。   TLSConfig nil TLS配置   RetryConfig  nil 所有与重试有关的配置    示例代码：\npackage main import ( \"context\" \"crypto/tls\" \"encoding/json\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app/client/retry\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/network/standard\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/hertz-contrib/http2/config\" \"github.com/hertz-contrib/http2/factory\" ) const ( keyPEM = `\u003cyour key PEM\u003e` certPEM = `\u003cyour cert PEM\u003e` ) func runClient() { cli, _ := client.NewClient() cli.SetClientFactory(factory.NewClientFactory( config.WithDialTimeout(3*time.Second), config.WithReadIdleTimeout(1*time.Second), config.WithWriteByteTimeout(time.Second), config.WithPingTimeout(time.Minute), config.WithMaxIdleConnDuration(2*time.Second), config.WithClientDisableKeepAlive(true), //Close Connection after each request \tconfig.WithStrictMaxConcurrentStreams(true), // Set the server's SETTINGS_MAX_CONCURRENT_STREAMS to be respected globally. \tconfig.WithDialer(standard.NewDialer()), // You can customize dialer here \tconfig.WithMaxHeaderListSize(0xffffffff), // Set SETTINGS_MAX_HEADER_LIST_SIZE to unlimited. \tconfig.WithMaxIdempotentCallAttempts(3), config.WithRetryConfig( retry.WithMaxAttemptTimes(3), retry.WithInitDelay(2*time.Millisecond), retry.WithMaxDelay(200*time.Millisecond), retry.WithMaxJitter(30*time.Millisecond), retry.WithDelayPolicy(retry.FixedDelayPolicy), ), config.WithStrictMaxConcurrentStreams(true), // Set the server's SETTINGS_MAX_CONCURRENT_STREAMS to be respected globally. \tconfig.WithTLSConfig(\u0026tls.Config{ SessionTicketsDisabled: false, InsecureSkipVerify: true, }), )) v, _ := json.Marshal(map[string]string{ \"hello\": \"world\", \"protocol\": \"h2\", }) for { time.Sleep(time.Second * 1) req, rsp := protocol.AcquireRequest(), protocol.AcquireResponse() req.SetMethod(\"POST\") req.SetRequestURI(\"https://127.0.0.1:8888\") req.SetBody(v) err := cli.Do(context.Background(), req, rsp) if err != nil { fmt.Println(err) return } fmt.Printf(\"[client]: received body: %s\\n\", string(rsp.Body())) } } func main() { cfg := \u0026tls.Config{ MinVersion: tls.VersionTLS12, CurvePreferences: []tls.CurveID{tls.X25519, tls.CurveP256}, CipherSuites: []uint16{ tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, }, } cert, err := tls.X509KeyPair([]byte(certPEM), []byte(keyPEM)) if err != nil { fmt.Println(err.Error()) } cfg.Certificates = append(cfg.Certificates, cert) h := server.New(server.WithHostPorts(\":8888\"), server.WithALPN(true), server.WithTLS(cfg)) // register http2 server factory \th.AddProtocol(\"h2\", factory.NewServerFactory( config.WithReadTimeout(time.Minute), config.WithDisableKeepAlive(false))) cfg.NextProtos = append(cfg.NextProtos, \"h2\") h.POST(\"/\", func(c context.Context, ctx *app.RequestContext) { var j map[string]string _ = json.Unmarshal(ctx.Request.Body(), \u0026j) fmt.Printf(\"[server]: received request: %+v\\n\", j) r := map[string]string{ \"msg\": \"hello world\", } for k, v := range j { r[k] = v } ctx.JSON(http.StatusOK, r) }) go runClient() h.Spin() } WithMaxHeaderListSize 用于设置 SETTINGS_MAX_HEADER_LIST_SIZE。\n与 HTTP2 规范不同，这里的0表示使用默认限制（目前是 10MB）。如果想表示无限，可以设置为一个尽可能大的值（0xffffffff 或 1\u003c\u003c32-1）。\n函数签名：\nfunc WithMaxHeaderListSize(maxHeaderListSize uint32) ClientOption WithReadIdleTimeout 用于设置读取超时时间，超时后将使用ping帧进行健康检查。\n注意，一个ping响应将被视为一个接收帧，所以如果连接上没有其他流量，健康检查将在每一个读取超时时间间隔内进行。\n默认值为 0 表示不执行健康检查。\n函数签名：\nfunc WithReadIdleTimeout(readIdleTimeout time.Duration) ClientOption WithWriteByteTimeout 用于设置写入超时时间，超时后连接将被关闭。当数据可以写入时开始计时，并随数据的写入不断延长。\n函数签名：\nfunc WithWriteByteTimeout(writeByteTimeout time.Duration) ClientOption WithStrictMaxConcurrentStreams 用来设置服务器的SETTINGS_MAX_CONCURRENT_STREAMS是否应该被全局使用。\n函数签名：\nfunc WithStrictMaxConcurrentStreams(strictMaxConcurrentStreams bool) ClientOption WithPingTimeout 设置ping响应的超时时间，如果未收到对 Ping 的响应，连接将在该超时时间后关闭。\n默认为 15s\n函数签名：\nfunc WithPingTimeout(pt time.Duration) ClientOption WithAllowHTTP 用于设置是否允许 http。如果启用，客户端将使用 h2c 模式。默认不启用。\n函数签名：\nfunc WithAllowHTTP(allow bool) ClientOption WithDialer 支持自定义拨号器，默认为netpoll.NewDialer()。\n函数签名：\nfunc WithDialer(d network.Dialer) ClientOption 接口定义：\ntype Dialer interface { // DialConnection is used to dial the peer end. \tDialConnection(network, address string, timeout time.Duration, tlsConfig *tls.Config) (conn Conn, err error) // DialTimeout is used to dial the peer end with a timeout. \t// \t// NOTE: Not recommended to use this function. Just for compatibility. \tDialTimeout(network, address string, timeout time.Duration, tlsConfig *tls.Config) (conn net.Conn, err error) // AddTLS will transfer a common connection to a tls connection. \tAddTLS(conn Conn, tlsConfig *tls.Config) (Conn, error) } WithDialTimeout 用于设置与主机建立新连接的超时时间，默认为 1s。\n函数签名：\nfunc WithDialTimeout(timeout time.Duration) ClientOption WithTLSConfig 用于自定义 TLS配置。\n函数签名：\nfunc WithTLSConfig(tlsConfig *tls.Config) ClientOption WithMaxIdleConnDuration 用于设置长连接的最长闲置时间，超过该时间后连接关闭。默认为0。\n函数签名：\nfunc WithMaxIdleConnDuration(d time.Duration) ClientOption WithMaxIdempotentCallAttempts 设置 idempotent calls的最大尝试次数。\n函数签名：\nfunc WithMaxIdempotentCallAttempts(n int) ClientOption WithRetryConfig 用于设置与重试有关的配置。\n函数签名：\nfunc WithRetryConfig(opts ...retry.Option) ClientOption WithClientDisableKeepAlive 用于设置是否在每次请求后关闭连接。默认为false。\n函数签名：\nfunc WithClientDisableKeepAlive(disable bool) ClientOption 更多用法示例详见 hertz-contrib/http2。\n","categories":"","description":"","excerpt":"HTTP/2 是对 HTTP “在线” 表达方式的一种替代。它并不是对协议的彻底重写；HTTP 方法、状态码和语义都是一样的，而且应该可以使 …","ref":"/zh/docs/hertz/tutorials/basic-feature/protocol/http2/","tags":"","title":"HTTP2"},{"body":"The Recovery middleware is preset by the Hertz framework. The server.Default() will register Recovery middleware by default to provide the feature of Panic recovery for the Hertz framework.\nIf you don’t use server.Default(), you can also register the Recovery middleware as followings:\nh := server.New() h.Use(recovery.Recovery()) The Recovery middleware will recover any panics in the Hertz framework. When a panic occurs, the Recover middleware will print out the panic time, content and stack information by default, then set the status code as 500 through *app.RequestContext'.\nImport import \"github.com/cloudwego/hertz/pkg/app/middlewares/server/recovery\" Example package main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.GET(\"/test\", func(ctx context.Context, c *app.RequestContext) { panic(\"test\") c.String(http.StatusOK, \"test interface\") }) h.Spin() } Configuration The Recovery middleware provides a default panic recovery handlerdefaultRecoveryHandler()。\nYou can also use the WithRecoveryHandler() function to customize the handler function when the panic occurs. The function signature is as follows:\nfunc WithRecoveryHandler(f func(c context.Context, ctx *app.RequestContext, err interface{}, stack []byte)) For example, if you attempt to obtain client agent, you can customize your handler function as follows:\npackage main import ( \"context\" \"fmt\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/recovery\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" ) func MyRecoveryHandler(c context.Context, ctx *app.RequestContext, err interface{}, stack []byte) { hlog.SystemLogger().CtxErrorf(c, \"[Recovery] err=%v\\nstack=%s\", err, stack) hlog.SystemLogger().Infof(\"Client: %s\", ctx.Request.Header.UserAgent()) ctx.AbortWithStatus(consts.StatusInternalServerError) } func main() { h := server.New() h.Use(recovery.Recovery(recovery.WithRecoveryHandler(MyRecoveryHandler))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { panic(\"test\") c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } ","categories":"","description":"","excerpt":"The Recovery middleware is preset by the Hertz framework. The …","ref":"/docs/hertz/tutorials/basic-feature/middleware/recovery/","tags":"","title":"Recovery"},{"body":"Recovery中间件是Hertz框架预置的中间件，使用 server.Default() 可以默认注册该中间件，为Hertz框架提供panic恢复的功能。\n如果你不使用server.Default()，你也可以通过以下方式注册Recovery中间件：\nh := server.New() h.Use(recovery.Recovery()) Recovery中间件会恢复Hertz框架运行中的任何panic，在panic发生之后，Recover中间件会默认打印出panic的时间、内容和堆栈信息，同时通过*app.RequestContext将返回响应的状态码设置成500。\n导入 import \"github.com/cloudwego/hertz/pkg/app/middlewares/server/recovery\" 示例代码 package main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.GET(\"/test\", func(ctx context.Context, c *app.RequestContext) { panic(\"test\") c.String(http.StatusOK, \"test interface\") }) h.Spin() } 配置 Recovery中间件提供了默认的panic处理函数defaultRecoveryHandler()。\n同时你也可以通过WithRecoveryHandler()函数来自定义出现panic后的处理函数，函数签名如下：\nfunc WithRecoveryHandler(f func(c context.Context, ctx *app.RequestContext, err interface{}, stack []byte)) 如果你在发生panic之后希望能够获取客户端信息，示例代码如下：\npackage main import ( \"context\" \"fmt\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/recovery\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" ) func MyRecoveryHandler(c context.Context, ctx *app.RequestContext, err interface{}, stack []byte) { hlog.SystemLogger().CtxErrorf(c, \"[Recovery] err=%v\\nstack=%s\", err, stack) hlog.SystemLogger().Infof(\"Client: %s\", ctx.Request.Header.UserAgent()) ctx.AbortWithStatus(consts.StatusInternalServerError) } func main() { h := server.New() h.Use(recovery.Recovery(recovery.WithRecoveryHandler(MyRecoveryHandler))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { panic(\"test\") c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } ","categories":"","description":"","excerpt":"Recovery中间件是Hertz框架预置的中间件，使用 server.Default() 可以默认注册该中间件，为Hertz框架提 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/recovery/","tags":"","title":"Recovery"},{"body":"In HTTP, Basic Access Authentication is a form of login authentication that allows web browsers or other client programs to provide credentials in the form of a username and password upon request. In basic HTTP authentication, a request contains a header field in the form of Authorization: Basic \u003ccredentials\u003e, where credentials is the Base64 encoding of ID and password joined by a single colon :.\nHertz also provides an implementation of Basic Auth, referencing gin’s implementation.\nImport import \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) h.Use(basic_auth.BasicAuth(map[string]string{ \"username1\": \"password1\", \"username2\": \"password2\", })) h.GET(\"/basicAuth\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"hello hertz\") }) h.Spin() } Config Hertz uses basic-auth middleware that allows web browsers or other client programs to provide a username and password form of credentials for login verification upon request. Hertz provides two functions to help users get started with basic access authentication functions. Users can choose different functions to use according to their scenarios.\nIn the Example above, only the base config function BasicAuth is used, and the extended config function BasicAuthForRealm has the following configurable parameters:\nNote: BasicAuth is a wrapper around BasicAuthForRealm and provides default configuration options.\n   Attribute Description     accounts Accounts is a defined type of map[string]string, store the username and password as key-value pairs.   realm Name of realm, the default value is Authorization Required.   userKey The key corresponding to the username which set in the context after authentication, the default value is user.    BasicAuth The basic_auth middleware provides BasicAuth that web browsers or other client programs need to provide credentials in the form of a username and password upon request.\nFunction signatures:\nfunc BasicAuth(accounts Accounts) app.HandlerFunc Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) h.Use(basic_auth.BasicAuth(map[string]string{ \"username1\": \"password1\", \"username2\": \"password2\", })) h.GET(\"/basicAuth\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"hello hertz\") }) h.Spin() } BasicAuthForRealm The basic_auth middleware provides BasicAuthForRealm to provide more configuration extensions such as realm on basis of authentication using BasicAuth.\nFunction signatures:\nfunc BasicAuthForRealm(accounts Accounts, realm, userKey string) app.HandlerFunc Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) // your-realm: name of realm, in this case it will be stored in the response header as Www-Authenticate: Basic realm=\"your-realm\"  // your-userKey: once authenticated, it will be set to the context with userKey as the key and username as the value  h.Use(basic_auth.BasicAuthForRealm(map[string]string{ \"username3\": \"password3\", \"username4\": \"password4\", }, \"your-realm\", \"your-userKey\")) h.GET(\"/basicAuth\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"hello hertz\") }) h.Spin() } Full Example As for usage, you may refer to hertz example\n","categories":"","description":"","excerpt":"In HTTP, Basic Access Authentication is a form of login authentication …","ref":"/docs/hertz/tutorials/basic-feature/middleware/basic-auth/","tags":"","title":"Basic Auth"},{"body":"在 HTTP 中，基本认证（Basic access authentication）是一种用来允许网页浏览器或其他客户端程序在请求时提供用户名和密码形式的身份凭证的一种登录验证方式。 在基本认证中，请求包含一个格式为 Authorization: Basic \u003ccredentials\u003e 的头部字段，其中 credentials 是用户名和密码的 Base64 编码，用一个冒号 : 连接。\nHertz 也提供了 basic auth 的实现 ，参考了 gin 的实现 。\n导入 import \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) h.Use(basic_auth.BasicAuth(map[string]string{ \"username1\": \"password1\", \"username2\": \"password2\", })) h.GET(\"/basicAuth\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"hello hertz\") }) h.Spin() } 配置 Hertz 通过使用中间件可以实现让网页浏览器或其他客户端程序在请求时提供用户名和密码形式作为身份凭证进行登录验证，Hertz 提供了两种函数帮助用户快速使用基本认证（Basic access authentication）功能，用户可以根据业务场景自行选择不同的函数进行使用。\n上述示例代码中，只使用了基本配置函数 BasicAuth，扩展配置函数 BasicAuthForRealm 的参数配置项如下：\n注意： BasicAuth 是对 BasicAuthForRealm 的封装并提供了默认配置项。\n   参数 介绍     accounts Accounts 被定义为 map[string]string 类型，以键值对的形式存储用户名和密码   realm 安全域字符串，默认值为 Authorization Required   userKey 认证通过后在上下文中设置的用户名所对应的键值，默认值为 user    BasicAuth basic_auth 中间件提供了 BasicAuth 用于在客户端对服务端发起请求时进行用户名密码形式的身份验证。\n函数签名：\nfunc BasicAuth(accounts Accounts) app.HandlerFunc 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) h.Use(basic_auth.BasicAuth(map[string]string{ \"username1\": \"password1\", \"username2\": \"password2\", })) h.GET(\"/basicAuth\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"hello hertz\") }) h.Spin() } BasicAuthForRealm basic_auth 中间件提供了 BasicAuthForRealm 用于在使用 BasicAuth 进行身份验证的基础上提供更多例如 Realm 等的扩展配置。\n函数签名：\nfunc BasicAuthForRealm(accounts Accounts, realm, userKey string) app.HandlerFunc 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) // your-realm: 安全域字符串，本例中会以 Www-Authenticate: Basic realm=\"your-realm\" 的形式保存在响应头中  // your-userKey: 认证通过后会以 userKey 为键 username 为值的形式设置在上下文中  h.Use(basic_auth.BasicAuthForRealm(map[string]string{ \"username3\": \"password3\", \"username4\": \"password4\", }, \"your-realm\", \"your-userKey\")) h.GET(\"/basicAuth\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"hello hertz\") }) h.Spin() } 完整示例 完整用法示例详见 example\n","categories":"","description":"","excerpt":"在 HTTP 中，基本认证（Basic access authentication）是一种用来允许网页浏览器或其他客户端程序在请求时提供用户 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/basic-auth/","tags":"","title":"基本认证"},{"body":"Introduction Hertz provides hertz-contrib/opensergo, to facilitate the integration of sentinel-golang\nInstallation go get github.com/hertz-contrib/opensergo Config sentinel-golang The basic configuration of sentinel-golang can be found at documentation\nServer SentinelServerMiddleware SentinelServerMiddleware() returns new app.HandlerFunc\nDefault resource name is {method}:{path}, such as “GET:/api/users/:id”\nDefault block fallback is returning 429 code\nDefine your own behavior by WithServerXxx()\nSample Code:\npackage main // ...  func main() { h := server.Default(server.WithHostPorts(\":8081\")) h.Use(adaptor.SentinelServerMiddleware()) // ... } WithServerResourceExtractor WithServerResourceExtractor sets the resource extractor of the web requests for server side.\nSample Code:\npackage main // ...  func main() { h := server.Default(server.WithHostPorts(\":8081\")) h.Use(adaptor.SentinelServerMiddleware( // customize resource extractor if required \t// method_path by default \tadaptor.WithServerResourceExtractor(func(c context.Context, ctx *app.RequestContext) string { return \"server_test\" }), )) // ... } WithServerBlockFallback WithServerBlockFallback sets the fallback handler when requests are blocked for server side.\nSample Code:\npackage main // ...  func main() { h := server.Default(server.WithHostPorts(\":8081\")) h.Use(adaptor.SentinelServerMiddleware( // customize block fallback if required \t// abort with status 429 by default \tadaptor.WithServerBlockFallback(func(c context.Context, ctx *app.RequestContext) { ctx.AbortWithStatusJSON(400, utils.H{ \"err\": \"too many request; the quota used up\", \"code\": 10222, }) }), )) // ... } Client SentinelClientMiddleware SentinelClientMiddleware() returns new client.Middleware Default resource name is {method}:{path}, such as “GET:/api/users” Default block fallback is returning blockError Define your own behavior by WithClientXxx()\nSample Code:\npackage main // ...  func main() { c, err := client.NewClient() if err != nil { log.Fatalf(\"Unexpected error: %+v\", err) return } c.Use(adaptor.SentinelClientMiddleware()) } WithClientResourceExtractor WithClientResourceExtractor sets the resource extractor of the web requests for client side.\nSample Code:\npackage main // ...  func main() { c, err := client.NewClient() if err != nil { log.Fatalf(\"Unexpected error: %+v\", err) return } c.Use(adaptor.SentinelClientMiddleware( // customize resource extractor if required \t// method_path by default \tadaptor.WithClientResourceExtractor(func(ctx context.Context, request *protocol.Request, response *protocol.Response) string { return \"client_test\" }), )) } WithClientBlockFallback WithClientBlockFallback sets the fallback handler when requests are blocked for client side.\nSample Code:\npackage main // ...  func main() { c, err := client.NewClient() if err != nil { log.Fatalf(\"Unexpected error: %+v\", err) return } c.Use(adaptor.SentinelClientMiddleware( // customize resource extractor if required \t// method_path by default \tadaptor.WithClientBlockFallback(func(ctx context.Context, req *protocol.Request, resp *protocol.Response, blockError error) error { resp.SetStatusCode(http.StatusBadRequest) resp.SetBody([]byte(\"request failed\")) return blockError }), )) } Complete sample code Full usage examples are available at example\n","categories":"","description":"","excerpt":"Introduction Hertz provides hertz-contrib/opensergo, to facilitate the …","ref":"/docs/hertz/tutorials/service-governance/sentinel/","tags":"","title":"Sentinel"},{"body":"简介 Hertz 提供了 hertz-contrib/opensergo, 以方便用户集成 sentinel-golang。\n安装 go get github.com/hertz-contrib/opensergo 配置 前置介绍：\n 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效。\n sentinel-golang 关于 sentinel-golang 的基本配置, 详情参考文档\n服务端 SentinelServerMiddleware SentinelServerMiddleware() 返回 app.HandlerFunc 类型, 用于将 sentinel-golang 集成进入 hertz server\n默认资源名称为 {method}:{path}，如 “GET:/api/users/:id”, 默认 block 时返回 429 状态码\n可以通过 WithServerXxx() 函数来进行自定义格式\n示例代码：\npackage main // ...  func main() { h := server.Default(server.WithHostPorts(\":8081\")) h.Use(adaptor.SentinelServerMiddleware()) // ... } WithServerResourceExtractor WithResourceExtractor 为设置网络请求的自定义函数，通过自定义的资源名和 sentinel-golang 中的热点参数流控规则 的 Resource 相匹配以达到自定义规则的目的\n示例代码：\npackage main // ...  func main() { h := server.Default(server.WithHostPorts(\":8081\")) h.Use(adaptor.SentinelServerMiddleware( // customize resource extractor if required \t// method_path by default \tadaptor.WithServerResourceExtractor(func(c context.Context, ctx *app.RequestContext) string { return \"server_test\" }), )) // ... } WithServerBlockFallback WithServerBlockFallback 为设置请求被阻断时的自定义回调函数，可以通过 context.Context 和 app.RequestContext 分别来进行错误日志打印和自定义回调处理\n示例代码：\npackage main // ...  func main() { h := server.Default(server.WithHostPorts(\":8081\")) h.Use(adaptor.SentinelServerMiddleware( // customize block fallback if required \t// abort with status 429 by default \tadaptor.WithServerBlockFallback(func(c context.Context, ctx *app.RequestContext) { ctx.AbortWithStatusJSON(400, utils.H{ \"err\": \"too many request; the quota used up\", \"code\": 10222, }) }), )) // ... } 客户端 SentinelClientMiddleware SentinelClientMiddleware() 返回一个 client.Middleware 类型, 用于将 sentinel-golang 集成进入 hertz client\n默认的资源名格式为 {method}:{path}, 例如 “GET:/api/users”, 默认 block 时返回 blockError\n可以通过 WithClientXxx() 函数来进行自定义格式\n示例代码：\npackage main // ...  func main() { c, err := client.NewClient() if err != nil { log.Fatalf(\"Unexpected error: %+v\", err) return } c.Use(adaptor.SentinelClientMiddleware()) } WithClientResourceExtractor WithClientResourceExtractor 为设置网络请求的自定义函数，通过自定义的资源名和 sentinel-golang 中的 热点参数 流控规则 的 Resource 相匹配以达到自定义规则的目的\n示例代码：\npackage main // ...  func main() { c, err := client.NewClient() if err != nil { log.Fatalf(\"Unexpected error: %+v\", err) return } c.Use(adaptor.SentinelClientMiddleware( // customize resource extractor if required \t// method_path by default \tadaptor.WithClientResourceExtractor(func(ctx context.Context, request *protocol.Request, response *protocol.Response) string { return \"client_test\" }), )) } WithClientBlockFallback WithClientBlockFallback 为设置请求被阻断时的自定义回调函数，可以通过 context.Context, protocol.Request , protocol.Response 来进行错误日志打印等功能, 也可以通过自定义回调处理 error 来进行自定义错误处理。\n示例代码：\npackage main // ...  func main() { c, err := client.NewClient() if err != nil { log.Fatalf(\"Unexpected error: %+v\", err) return } c.Use(adaptor.SentinelClientMiddleware( // customize resource extractor if required \t// method_path by default \tadaptor.WithClientBlockFallback(func(ctx context.Context, req *protocol.Request, resp *protocol.Response, blockError error) error { resp.SetStatusCode(http.StatusBadRequest) resp.SetBody([]byte(\"request failed\")) return blockError }), )) } 完整示例代码 完整用法示例详见 example\n","categories":"","description":"","excerpt":"简介 Hertz 提供了 hertz-contrib/opensergo, 以方便用户集成 sentinel-golang。\n安装 go …","ref":"/zh/docs/hertz/tutorials/service-governance/sentinel/","tags":"","title":"Sentinel"},{"body":"Route Registration Hertz provides methods like GET, POST, PUT, DELETE, ANY for registering routes.\n   Method Introduce     Hertz.GET The method used to register the HTTP Method as GET   Hertz.POST The method used to register the HTTP Method as POST   Hertz.DELETE The method used to register the HTTP Method as DELETE   Hertz.PUT The method used to register the HTTP Method as PUT   Hertz.PATCH The method used to register the HTTP Method as PATCH   Hertz.HEAD The method used to register the HTTP Method as HEAD   Hertz.OPTIONS The method used to register the HTTP Method as OPTIONS   Hertz.Handle The method supports to register a HTTP Method flexibly, which is the same as the above method when used to register a normal HTTP Method, and it also supports the registration of custom HTTP Method   Hertz.Any The method for registering all HTTP Methods   Hertz.StaticFile/Static/StaticFS For registering static files    Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main(){ h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) h.StaticFS(\"/\", \u0026app.FS{Root: \"./\", GenerateIndexPages: true}) h.GET(\"/get\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"get\") }) h.POST(\"/post\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"post\") }) h.PUT(\"/put\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"put\") }) h.DELETE(\"/delete\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"delete\") }) h.PATCH(\"/patch\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"patch\") }) h.HEAD(\"/head\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"head\") }) h.OPTIONS(\"/options\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"options\") }) h.Any(\"/ping_any\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"any\") }) h.Handle(\"LOAD\",\"/load\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"load\") }) h.Spin() } Group Hertz provides the capability of Group, which are used to support route grouping functionality, and the middleware can also register with Group.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main(){ h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) v1 := h.Group(\"/v1\") v1.GET(\"/get\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"get\") }) v1.POST(\"/post\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"post\") }) v2 := h.Group(\"/v2\") v2.PUT(\"/put\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"put\") }) v2.DELETE(\"/delete\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"delete\") }) h.Spin() } Use middleware with route group\nThe following example uses the BasicAuth middleware in a route group.\nSample Code 1:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) // use middleware \tv1 := h.Group(\"/v1\", basic_auth.BasicAuth(map[string]string{\"test\": \"test\"})) // or use `Use` method \t//v1.Use(basic_auth.BasicAuth(map[string]string{\"test\": \"test\"})) \tv1.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK,\"ping\") }) h.Spin() } Sample Code 2:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) v1 := h.Group(\"/v1\") // use `Use` method \tv1.Use(basic_auth.BasicAuth(map[string]string{\"test\": \"test\"})) v1.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK,\"ping\") }) h.Spin() } Route Types Hertz supports a variety of route types for complex functions, including static route, parametric route, and wildcard route.\nPriority of the route: static route \u003e parametric route \u003e wildcard route\nStatic Route See above for specific examples.\nParametric Route Hertz supports the use of named parameters such as :name to set routes, and named parameters match only a single path segment.\nIf we set the route /user/:name, the match is as follows\n   path      /user/gordon matched   /user/you matched   /user/gordon/profile mismatched   /user/ mismatched    By using the RequestContext.Param method, we can get the parameters carried in the route.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main(){ h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) // This handler will match: \"/hertz/version\", but will not match : \"/hertz/\" or \"/hertz\" \th.GET(\"/hertz/:version\", func(ctx context.Context, c *app.RequestContext) { version := c.Param(\"version\") c.String(consts.StatusOK, \"Hello %s\", version) }) h.Spin() } Wildcard Route Hertz supports routing with wildcard parameters such as *filepath, and the wildcard parameter will match all contents of the current path segment.\nIf we set the route /src/*filepath, the match is as follows\n   path      /src/ matched   /src/somefile.go matched   /src/subdir/somefile.go matched    By using the RequestContext.Param method, we can get the parameters carried in the route.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main(){ h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) // However, this one will match \"/hertz/v1/\" and \"/hertz/v2/send\" \th.GET(\"/hertz/:version/*action\", func(ctx context.Context, c *app.RequestContext) { version := c.Param(\"version\") action := c.Param(\"action\") message := version + \" is \" + action c.String(consts.StatusOK, message) }) h.Spin() } Refer to the example for more detailed examples.\nNote Use anonymous function or decorator to register routes When register route with anonymous function or decorator, if we use RequestContext.HandlerName() to get the handler name, we will get the wrong name.\nYou need to use the GETEX, POSTEX, PUTEX, DELETEEX, HEADEX, AnyEX, HandleEX methods provided by Hertz and manually pass in the handler name to register the route. use app.GetHandlerName to get the handler name.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.AnyEX(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK, app.GetHandlerName(ctx.Handler())) }, \"ping_handler\") h.Spin() } Get route info Hertz provides Routes to get the registered route information.\nRoute information struct:\n// RouteInfo represents a request route's specification which contains method and path and its handler. type RouteInfo struct { Method string // http method \tPath string // url path \tHandler string // handler name \tHandlerFunc app.HandlerFunc } // RoutesInfo defines a RouteInfo array. type RoutesInfo []RouteInfo Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) routeInfo := h.Routes() hlog.Info(routeInfo) h.Spin() } NoRoute And NoMethod Hertz provides NoRoute and NoMethod methods for global handling of HTTP 404 and 405 requests. Use NoMethod in conjunction with WithHandleMethodNotAllowed.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHandleMethodNotAllowed(true)) h.POST(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) // set NoRoute handler \th.NoRoute(func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK, \"no route\") }) // set NoMethod handler \th.NoMethod(func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK, \"no method\") }) h.Spin() } ","categories":"","description":"","excerpt":"Route Registration Hertz provides methods like GET, POST, PUT, DELETE, …","ref":"/docs/hertz/tutorials/basic-feature/route/","tags":"","title":"Route"},{"body":"路由注册 Hertz 提供了 GET、POST、PUT、DELETE、ANY 等方法用于注册路由。\n   方法 介绍     Hertz.GET 用于注册 HTTP Method 为 GET 的方法   Hertz.POST 用于注册 HTTP Method 为 POST 的方法   Hertz.DELETE 用于注册 HTTP Method 为 DELETE 的方法   Hertz.PUT 用于注册 HTTP Method 为 PUT 的方法   Hertz.PATCH 用于注册 HTTP Method 为 PATCH 的方法   Hertz.HEAD 用于注册 HTTP Method 为 HEAD 的方法   Hertz.OPTIONS 用于注册 HTTP Method 为 OPTIONS 的方法   Hertz.Handle 这个方法支持用户手动传入 HTTP Method 用来注册方法，当用于注册普通的 HTTP Method 方法时和上述的方法作用是一致的，并且这个方法同时也支持用于注册自定义 HTTP Method 方法   Hertz.Any 用于注册所有 HTTP Method 方法   Hertz.StaticFile/Static/StaticFS 用于注册静态文件    示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main(){ h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) h.StaticFS(\"/\", \u0026app.FS{Root: \"./\", GenerateIndexPages: true}) h.GET(\"/get\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"get\") }) h.POST(\"/post\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"post\") }) h.PUT(\"/put\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"put\") }) h.DELETE(\"/delete\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"delete\") }) h.PATCH(\"/patch\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"patch\") }) h.HEAD(\"/head\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"head\") }) h.OPTIONS(\"/options\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"options\") }) h.Any(\"/ping_any\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"any\") }) h.Handle(\"LOAD\",\"/load\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"load\") }) h.Spin() } 路由组 Hertz 提供了路由组( Group )的能力，用于支持路由分组的功能，同时中间件也可以注册到路由组上。\n示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main(){ h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) v1 := h.Group(\"/v1\") v1.GET(\"/get\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"get\") }) v1.POST(\"/post\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"post\") }) v2 := h.Group(\"/v2\") v2.PUT(\"/put\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"put\") }) v2.DELETE(\"/delete\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"delete\") }) h.Spin() } 在路由组中使用中间件\n如下示例在路由组中使用 BasicAuth 中间件。\n示例代码 1:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) // use middleware \tv1 := h.Group(\"/v1\", basic_auth.BasicAuth(map[string]string{\"test\": \"test\"})) v1.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK,\"ping\") }) h.Spin() } 示例代码 2:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/middlewares/server/basic_auth\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) v1 := h.Group(\"/v1\") // use `Use` method \tv1.Use(basic_auth.BasicAuth(map[string]string{\"test\": \"test\"})) v1.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK,\"ping\") }) h.Spin() } 路由类型 Hertz 支持丰富的路由类型用于实现复杂的功能，包括静态路由、参数路由(命名参数、通配参数)。\n路由的优先级:静态路由 \u003e 命名参数路由 \u003e 通配参数路由\n静态路由 具体示例可参见上文\n命名参数路由 Hertz 支持使用 :name 这样的命名参数设置路由，并且命名参数只匹配单个路径段。\n如果我们设置/user/:name路由，匹配情况如下\n   路径 是否匹配     /user/gordon 匹配   /user/you 匹配   /user/gordon/profile 不匹配   /user/ 不匹配    通过使用 RequestContext.Param 方法，我们可以获取路由中携带的参数。\n示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main(){ h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) // This handler will match: \"/hertz/version\", but will not match : \"/hertz/\" or \"/hertz\" \th.GET(\"/hertz/:version\", func(ctx context.Context, c *app.RequestContext) { version := c.Param(\"version\") c.String(consts.StatusOK, \"Hello %s\", version) }) h.Spin() } 通配参数路由 Hertz 支持使用 *path 这样的通配参数设置路由，并且通配参数会匹配所有内容。\n如果我们设置/src/*path路由，匹配情况如下\n   路径 是否匹配     /src/ 匹配   /src/somefile.go 匹配   /src/subdir/somefile.go 匹配    通过使用 RequestContext.Param 方法，我们可以获取路由中携带的参数。\n示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main(){ h := server.Default(server.WithHostPorts(\"127.0.0.1:8080\")) // However, this one will match \"/hertz/v1/\" and \"/hertz/v2/send\" \th.GET(\"/hertz/:version/*action\", func(ctx context.Context, c *app.RequestContext) { version := c.Param(\"version\") action := c.Param(\"action\") message := version + \" is \" + action c.String(consts.StatusOK, message) }) h.Spin() } 完整用法示例详见 example\n注意 使用匿名函数与装饰器注册路由 在使用匿名函数或装饰器注册路由时，如果我们使用 RequestContext.HandlerName() 获取 handler 名称则会获取到错误的名称。\n这里需要使用 Hertz 提供的 GETEX、POSTEX、PUTEX、DELETEEX、HEADEX、AnyEX、HandleEX 方法并手动传入 handler 名称注册路由，使用 app.GetHandlerName 获取 handler 名称。\n示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.AnyEX(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK, app.GetHandlerName(ctx.Handler())) }, \"ping_handler\") h.Spin() } 获取路由注册信息 Hertz 提供了 Routes 获取注册的路由信息供用户使用。\n路由信息结构:\n// RouteInfo represents a request route's specification which contains method and path and its handler. type RouteInfo struct { Method string // http method  Path string // url path  Handler string // handler name  HandlerFunc app.HandlerFunc } // RoutesInfo defines a RouteInfo array. type RoutesInfo []RouteInfo 示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) routeInfo := h.Routes() hlog.Info(routeInfo) h.Spin() } NoRoute 与 NoMethod 使用 Hertz 提供了 NoRoute 与 NoMethod 方法用于全局处理 HTTP 404 与 405 请求。 当使用 NoMethod 时需要与 WithHandleMethodNotAllowed 配合使用。\n示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithHandleMethodNotAllowed(true)) h.POST(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) // set NoRoute handler \th.NoRoute(func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK, \"no route\") }) // set NoMethod handler \th.NoMethod(func(c context.Context, ctx *app.RequestContext) { ctx.String(consts.StatusOK, \"no method\") }) h.Spin() } ","categories":"","description":"","excerpt":"路由注册 Hertz 提供了 GET、POST、PUT、DELETE、ANY 等方法用于注册路由。 …","ref":"/zh/docs/hertz/tutorials/basic-feature/route/","tags":"","title":"路由"},{"body":"Hertz provides logger extension, and the interface is defined in pkg/common/hlog.\nInterface Definition In Hertz, the interfaces Logger, CtxLogger, FormatLogger are defined in pkg/common/hlog, and these interfaces are used to output logs in different ways, and a Control interface is defined to control the logger. If you’d like to inject your own logger implementation, you must implement all the above interfaces (i.e. FullLogger). Hertz already provides a default implementation of FullLogger.\n// FullLogger is the combination of Logger, FormatLogger, CtxLogger and Control. type FullLogger interface { Logger FormatLogger CtxLogger Control } Note that the default logger makes use of the standard library log.Logger as its underlying output. So the filenames and line numbers shown in the log messages depend on the settings of call depth. Thus wrapping the implementation of hlog may cause inaccuracies for these two values.\nInject your own logger Hertz provides SetLogger interface to allow injection of your own logger. Besides, SetOutput can be used to redirect the default logger output, and then middlewares and the other components of the framework can use global methods in hlog to output logs. By default, Hertz’s default logger is used.\nSupported Log Extension The log extensions currently supported in the open source version of Hertz are stored in the hertz-logger. You are welcomed to join us in contributing and maintaining for this project.\nZap Example：\nimport ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" hertzzap \"github.com/hertz-contrib/logger/zap\" ) func main() { h := server.Default() logger := hertzzap.NewLogger( hertzzap.WithZapOptions( // ... \t), ) hlog.SetLogger(logger) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { hlog.Info(\"Hello, hertz\") c.String(consts.StatusOK, \"Hello hertz!\") }) h.Spin() } For more details, see hertz-contrib/logger/zap.\nLogrus Example：\nimport ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" hertzlogrus \"github.com/hertz-contrib/logger/logrus\" \"github.com/sirupsen/logrus\" ) func main() { h := server.Default() logger := hertzlogrus.NewLogger( hertzlogrus.WithLogger(\u0026logrus.Logger{ // ... \t}), ) hlog.SetLogger(logger) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { hlog.Info(\"Hello, hertz\") c.String(consts.StatusOK, \"Hello hertz!\") }) h.Spin() } For more details, see hertz-contrib/logger/logrus.\nZerolog Example：\nimport ( \"context\" \"os\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" hertzZerolog \"github.com/hertz-contrib/logger/zerolog\" ) func main() { h := server.Default() logger := hertzZerolog.New( hertzZerolog.WithOutput(os.Stdout), // allows to specify output \thertzZerolog.WithLevel(hlog.LevelInfo), // option with log level \thertzZerolog.WithTimestamp(), // option with timestamp \thertzZerolog.WithCaller(), // option with caller \t// ... \t) hlog.SetLogger(logger) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { hlog.Info(\"Hello, hertz\") c.String(consts.StatusOK, \"Hello hertz!\") }) h.Spin() } For more details, see hertz-contrib/logger/zerolog.\n","categories":"","description":"","excerpt":"Hertz provides logger extension, and the interface is defined in …","ref":"/docs/hertz/tutorials/framework-exten/log/","tags":"","title":"Logger Extension"},{"body":"Usage Add some options when creating a server：\nsvr := api.NewServer(new(DemoImpl), server.WithXXX...) Basic Options WithServerBasicInfo func WithServerBasicInfo(ebi *rpcinfo.EndpointBasicInfo) Option Set the service infos for server, including ServiceName and customized Tags, customized Tag such as Cluster, IDC, Env, and it is no need to set Method field of EndpointBasicInfo. It is strongly recommended to configure this option, and those infos will be used for service registration.\nWithServiceAddr func WithServiceAddr(addr net.Addr) Option Set the listen address for server. Default port is 8888, you can reset the port to 9999 like this:\naddr, _ := net.ResolveTCPAddr(\"tcp\", \"127.0.0.1:9999\") svr := api.NewServer(new(HelloImpl), server.WithServiceAddr(addr)) When local server has multiple IP addresses, you can also use this method to specify them.\nWithMuxTransport func WithMuxTransport() Option Enable Kitex multiplexing transport feature on the server side. Client side also need to turn on this option, or it won’t work. More\nWithMiddleware func WithMiddleware(mw endpoint.Middleware) Option Add a middleware. More\nWithMiddlewareBuilder func WithMiddlewareBuilder(mwb endpoint.MiddlewareBuilder, funcName ...string) Option Add middleware depends on the context passed in by the framework that contains runtime configuration information (the context of non-RPC calls), so that the middleware can take advantage of the framework’s information when initializing.\nWithLimit func WithLimit(lim *limit.Option) Option Set the throttling threshold, which allows you to set a limit on QPS and the number of connections, which uses a built-in throttling implementation that can be scaled if there is a custom throttling requirement, integrating your own throttling policy via WithConcurrencyLimiter or WithQPSLimiter.\nWithReadWriteTimeout func WithReadWriteTimeout(d time.Duration) Option Set the server-side read and write timeout.\nNote: This feature may be changed or removed in subsequent releases.\nWithExitWaitTime func WithExitWaitTime(timeout time.Duration) Option Set the wait time for graceful shutdown of graceful shutdown on the server side.\nWithMaxConnIdleTime func WithMaxConnIdleTime(timeout time.Duration) Option Set the maximum amount of idle time allowed for the server-side connection to the client.\nWithStatsLevel func WithStatsLevel(level stats.Level) Option Set the stats level for the server. More\ngRPC Options  These options only works for scenarios where the transport protocol uses gRPC, with some parameter adjustments to gRPC transfers.\n WithGRPCWriteBufferSize func WithGRPCWriteBufferSize(s uint32) Option WithGRPCWriteBufferSize determines how much data can be batched before doing a write on the wire. The corresponding memory allocation for this buffer will be twice the size to keep syscalls low. The default value for this buffer is 32KB. Zero will disable the write buffer such that each write will be on underlying connection. Note: A Send call may not directly translate to a write. It corresponds to the WriteBufferSize ServerOption of gRPC.\nWithGRPCReadBufferSize func WithGRPCReadBufferSize(s uint32) Option WithGRPCReadBufferSize lets you set the size of read buffer, this determines how much data can be read at most for one read syscall. The default value for this buffer is 32KB. Zero will disable read buffer for a connection so data framer can access the underlying conn directly. It corresponds to the ReadBufferSize ServerOption of gRPC.\nWithGRPCInitialWindowSize func WithGRPCInitialWindowSize(s uint32) Option WithGRPCInitialWindowSize returns a Option that sets window size for stream. The lower bound for window size is 64K and any value smaller than that will be ignored. It corresponds to the InitialWindowSize ServerOption of gRPC.\nWithGRPCInitialConnWindowSize func WithGRPCInitialConnWindowSize(s uint32) Option WithGRPCInitialConnWindowSize returns an Option that sets window size for a connection. The lower bound for window size is 64K and any value smaller than that will be ignored. It corresponds to the InitialConnWindowSize ServerOption of gRPC.\nWithGRPCKeepaliveParams func WithGRPCKeepaliveParams(kp grpc.ServerKeepalive) Option WithGRPCKeepaliveParams returns an Option that sets keepalive and max-age parameters for the server. It corresponds to the KeepaliveParams ServerOption of gRPC.\nWithGRPCKeepaliveEnforcementPolicy func WithGRPCKeepaliveEnforcementPolicy(kep grpc.EnforcementPolicy) Option WithGRPCKeepaliveEnforcementPolicy returns an Option that sets keepalive enforcement policy for the server. It corresponds to the KeepaliveEnforcementPolicy ServerOption of gRPC.\nWithGRPCMaxConcurrentStreams func WithGRPCMaxConcurrentStreams(n uint32) Option WithGRPCMaxConcurrentStreams returns an Option that will apply a limit on the number of concurrent streams to each ServerTransport. It corresponds to the MaxConcurrentStreams ServerOption of gRPC.\nWithGRPCMaxHeaderListSize func WithGRPCMaxHeaderListSize(s uint32) Option WithGRPCMaxHeaderListSize returns a ServerOption that sets the max (uncompressed) size of header list that the server is prepared to accept. It corresponds to the MaxHeaderListSize ServerOption of gRPC.\nAdvanced Options WithSuite func WithSuite(suite Suite) Option Set up a specific configuration, customize according to the scene, configure multiple options and middlewares combinations and encapsulations in the Suite. More\nWithProxy func WithProxy(p proxy.ReverseProxy) Option If the server has a proxy, such as Mesh Ingress, you can modify the listening address through this configuration to communicate with the proxy, such as in the proxy. ReverseProxy modifies to the uds address.\nWithRegistryInfo func WithRegistryInfo(info *registry.Info) Option Customize the registration information reported by the service. More\nWithGeneric func WithGeneric(g generic.Generic) Option Specify the generalization call type, which needs to be used in conjunction with the generalization Client/Server. More\nWithErrorHandler func WithErrorHandler(f func(error) error) Option Set the error handler function, which is executed after the server handler is executed and before the middleware executes.\nWithACLRules func WithACLRules(rules ...acl.RejectFunc) Option Set ACL permission access control, which is executed before service discovery. More\nWithExitSignal func WithExitSignal(f func() \u003c-chan error) Option Set the server exit signal. Kitex has a built-in implementation, if you need some customization can be implemented yourself.\nWithReusePort func WithReusePort(reuse bool) Option Set port reuse, that is, whether to enable the underlying TCP port multiplexing mechanism.\nExtended Options WithRegistry func WithRegistry(r registry.Registry) Option Specify a Registry for service discovery registration reporting. More\nWithTracer func WithTracer(c stats.Tracer) Option Add an additional Tracer. More\nWithCodec func WithCodec(c remote.Codec) Option Specify a Codec for scenarios that require custom protocol. More\nWithPayloadCodec func WithPayloadCodec(c remote.PayloadCodec) Option Specifie a PayloadCodec. More\nWithMetaHandler func WithMetaHandler(h remote.MetaHandler) Option Add a meta handler for customizing transparent information in conjunction with the transport protocol, such as service name, invocation method, machine room, cluster, env, tracerInfo. More\nWithBoundHandler func WithBoundHandler(h remote.BoundHandler) Option Set IO Bound handlers. More\nWithConcurrencyLimiter func WithConcurrencyLimiter(conLimit limiter.ConcurrencyLimiter) Option Set the concurrency limit for server.\nWithQPSLimiter func WithQPSLimiter(qpsLimit limiter.RateLimiter) Option Set the QPS limit for server.\nWithLimitReporter func WithLimitReporter(r limiter.LimitReporter) Option Set LimitReporter, and when QPS throttling or connection limiting occurs, you can customize the escalation through LimitReporter.\nWithTransHandlerFactory func WithTransHandlerFactory(f remote.ServerTransHandlerFactory) Option Set transHandlerFactory. More\nWithTransServerFactory func WithTransServerFactory(f remote.TransServerFactory) Option Set transServerFactory. More\nWithDiagnosisService func WithDiagnosisService(ds diagnosis.Service) Option Set diagnosis service. More\n","categories":"","description":"Kitex Server Option instructions.","excerpt":"Kitex Server Option instructions.","ref":"/docs/kitex/tutorials/options/server_options/","tags":"","title":"Server Option"},{"body":"用法 在创建服务端时，带上 Option 参数即可：\nsvr := api.NewServer(new(DemoImpl), server.WithXXX...) 基础 Option 基本信息 - WithServerBasicInfo func WithServerBasicInfo(ebi *rpcinfo.EndpointBasicInfo) Option 设置 Server 侧的 Service 信息，包括 ServiceName 和自定义的 Tags，自定义 Tag 如 Cluster、IDC、Env，无需设置 EndpointBasicInfo 的 Method 字段。强烈建议配置该 Option，会用于服务注册。\n指定地址 - WithServiceAddr func WithServiceAddr(addr net.Addr) Option 指定服务端监听地址，默认是 8888 端口，配置示例-配置端口为 9999：\naddr, _ := net.ResolveTCPAddr(\"tcp\", \"127.0.0.1:9999\") svr := api.NewServer(new(HelloImpl), server.WithServiceAddr(addr)) 在遇到本机有多个 IP 地址时，例如服务发现等场景需要 内网/外网 IP 地址，也可以用这个方法进行指定。\n多路复用 - WithMuxTransport func WithMuxTransport() Option 服务端启用多路复用。需要配合客户端的同时开启，详见连接类型-连接多路复用。\n中间件扩展 - WithMiddleware func WithMiddleware(mw endpoint.Middleware) Option 添加一个中间件，使用方式和 client 一致。用法参考 Middleware 扩展。\n中间件扩展 - WithMiddlewareBuilder func WithMiddlewareBuilder(mwb endpoint.MiddlewareBuilder, funcName ...string) Option 用于创建并添加中间件，可以根据 ctx 判断场景并创建中间件。 ctx 是框架传入的包含运行时配置信息的上下文（非 RPC 调用的上下文），以便中间件初始化时能利用框架的信息。\n限流控制 - WithLimit func WithLimit(lim *limit.Option) Option 设置限流阈值，可以设置对 QPS 和连接数的限制，该配置使用内置的限流实现，如果有定制的限流需求可以自行扩展，通过 WithConcurrencyLimiter 或者 WithQPSLimiter 集成自己的限流策略。\n超时设置 - WithReadWriteTimeout func WithReadWriteTimeout(d time.Duration) Option 设置服务端读写超时的时间。\n注意：这个功能在后续版本中可能会有改动或者删除。\n退出等待 - WithExitWaitTime func WithExitWaitTime(timeout time.Duration) Option 设置服务端 Graceful Shutdown 优雅关闭的等待的时间。\n连接闲置设置 - WithMaxConnIdleTime func WithMaxConnIdleTime(timeout time.Duration) Option 设置服务端对客户端连接的最大允许空闲的时间。\n埋点粒度 - WithStatsLevel func WithStatsLevel(level stats.Level) Option 为 Server 设置埋点粒度，详见埋点粒度。\ngRPC 相关配置  这类设置只对传输协议使用 gRPC 的场景生效，对 gRPC 传输进行一些参数调整。\n WithGRPCWriteBufferSize func WithGRPCWriteBufferSize(s uint32) Option 设置 gRPC 写缓冲大小，写缓冲决定了每次批量调用底层写发送数据的大小。默认值为32KB，如果设置为0，则相当于禁用缓冲区，每次写操作都直接调用底层连接进行发送。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCReadBufferSize func WithGRPCReadBufferSize(s uint32) Option 设置 gRPC 的读缓冲大小，读缓冲决定了每次批量从底层读取多少数据。默认值为32KB，如果设置为0，则相当于禁用缓冲区，每次读操作都直接从底层连接进行读操作。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCInitialWindowSize func WithGRPCInitialWindowSize(s uint32) Option 设置 gRPC 每个 Stream 的初始收发窗口大小，最低为64KB，若设置的值小于最低值，则会被忽略。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCInitialConnWindowSize func WithGRPCInitialConnWindowSize(s uint32) Option 设置 gRPC 单条连接上的初始窗口大小，最低为64KB，若设置的值小于最低值，则会被忽略。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCKeepaliveParams func WithGRPCKeepaliveParams(kp grpc.ServerKeepalive) Option 设置 gRPC 服务端 Keepalive 的各项参数。该设置只对传输协议使用 gRPC 的场景生效。\nWithGRPCKeepaliveEnforcementPolicy func WithGRPCKeepaliveEnforcementPolicy(kep grpc.EnforcementPolicy) Option 设置 gRPC 服务端 Keepalive 里对于客户端策略的一些检查标准。\nWithGRPCMaxConcurrentStreams func WithGRPCMaxConcurrentStreams(n uint32) Option 设置 gRPC 服务端最大能接受的 Stream 数量限制。\nWithGRPCMaxHeaderListSize func WithGRPCMaxHeaderListSize(s uint32) Option 设置 gRPC MaxHeaderListSize 参数，该参数决定了每次调用允许发送的header的最大条数。该设置只对传输协议使用 gRPC 的场景生效。\n高级 Option 配套扩展 - WithSuite func WithSuite(suite Suite) Option 设置一套特定配置，可根据场景进行定制，在 Suite 中配置多个 Option 和 Middleware 的组合和封装，详见 Suite 扩展。\n代理 - WithProxy func WithProxy(p proxy.ReverseProxy) Option 如果服务端有代理，如 Mesh Ingress，可以通过该配置修改监听地址，用于与 Proxy 通信，比如在 proxy.ReverseProxy 修改为 uds 地址。\n注册信息 - WithRegistryInfo func WithRegistryInfo(info *registry.Info) Option 自定义服务上报的注册信息，用法详见服务发现。\n泛化调用 - WithGeneric func WithGeneric(g generic.Generic) Option 指定泛化调用类型，泛化需要结合泛化 Client/Server 使用，详见 Kitex 泛化调用使用指南。\n异常处理 - WithErrorHandler func WithErrorHandler(f func(error) error) Option 设置异常处理函数，该函数会在服务端 handler 执行后，中间件执行前被执行。\n权限控制 - WithACLRules func WithACLRules(rules ...acl.RejectFunc) Option 设置 ACL 权限访问控制，该模块会在服务发现之前执行，具体用法详见自定义访问控制。\n退出信号 - WithExitSignal func WithExitSignal(f func() \u003c-chan error) Option 设置服务端退出信号，Kitex 有内置实现，如果需要一些定制可以自行实现。\n端口重用 - WithReusePort func WithReusePort(reuse bool) Option 设置端口重用，即是否开启底层的 TCP 端口复用机制。\n扩展 Option 服务发现 - WithRegistry func WithRegistry(r registry.Registry) Option 指定一个 Registry 进行服务发现的注册上报，用法详见服务发现。\n链路监控 - WithTracer func WithTracer(c stats.Tracer) Option 额外添加一个 Tracer 进行链路监控，详见链路跟踪-自定义 tracer。\n编解码 - WithCodec func WithCodec(c remote.Codec) Option 指定 Codec，用于需要自定义协议的场景，详见编解码协议扩展。\nPayload 编解码 - WithPayloadCodec func WithPayloadCodec(c remote.PayloadCodec) Option 指定 PayloadCodec，详见编解码协议扩展。\n元信息处理 - WithMetaHandler func WithMetaHandler(h remote.MetaHandler) Option 添加一个元信息处理器，用于结合传输协议定制透传信息，如服务名、调用方法、机房、集群、env、TracerInfo，用法详见元信息传递扩展。\nIO Bound 扩展 - WithBoundHandler func WithBoundHandler(h remote.BoundHandler) Option 自定义 IO Bound，详见 Transport Pipeline-Bound 扩展。\n并发限制 - WithConcurrencyLimiter func WithConcurrencyLimiter(conLimit limiter.ConcurrencyLimiter) Option 设置服务端的连接数限制。\nQPS 限制 - WithQPSLimiter func WithQPSLimiter(qpsLimit limiter.RateLimiter) Option 设置服务端的 QPS 限制。\n限流报告器 - WithLimitReporter func WithLimitReporter(r limiter.LimitReporter) Option 设置 LimitReporter，当发生 QPS 限流或连接数限流时，可以通过 LimitReporter 进行定制上报。\n传输扩展 - WithTransHandlerFactory func WithTransHandlerFactory(f remote.ServerTransHandlerFactory) Option 自定义传输模块，详见传输模块扩展。\n传输扩展 - WithTransServerFactory func WithTransServerFactory(f remote.TransServerFactory) Option 自定义传输模块，详见传输模块扩展。\n诊断扩展 - WithDiagnosisService func WithDiagnosisService(ds diagnosis.Service) Option 添加一个自定义的 DiagnosisService，用来获取更多的诊断信息，详见诊断模块扩展。\n","categories":"","description":"Kitex Server Option 使用说明。","excerpt":"Kitex Server Option 使用说明。","ref":"/zh/docs/kitex/tutorials/options/server_options/","tags":"","title":"Server Option"},{"body":" This feature only works when using Thrift\n Usage Scenarios There could be decades method defined in service, but only one or two methods is needed by client. Combine Service provides a way to split one service into several services. For Example, there is a ExampleService\nserviceExampleService{ExampleResponseMethod0(3:ExampleRequestreq)ExampleResponseMethod1(3:ExampleRequestreq)ExampleResponseMethod2(3:ExampleRequestreq)}We can split it into three services:\nserviceExampleService0{ExampleResponseMethod0(3:ExampleRequestreq)}serviceExampleService1{ExampleResponseMethod1(3:ExampleRequestreq)}serviceExampleService2{ExampleResponseMethod2(3:ExampleRequestreq)}Client can use one of them to generate code.\nPractice root thrift:\nserviceExampleService0{ExampleResponseMethod0(3:ExampleRequestreq)}serviceExampleService1{ExampleResponseMethod1(3:ExampleRequestreq)}serviceExampleService2{ExampleResponseMethod2(3:ExampleRequestreq)}with --combine-service parameter, it will generate a new service named CombineService and also client/server code. It’s definition:\nserviceCombineService{ExampleResponseMethod0(3:ExampleRequestreq)ExampleResponseMethod1(3:ExampleRequestreq)ExampleResponseMethod2(3:ExampleRequestreq)}When used with -service at the same time, it will use CombineService to generate main package. Attention: CombineService just combine methods defined in services, it won’t generate code when method method name conflicts.\nTips: You can use extends to combine services defined in several thrift files. like:\nservice ExampleService0 extends thriftA.Service0 { } service ExampleService1 extends thriftB.Service1 { } service ExampleService2 extends thriftC.Service2 { } Example This feature only supports Thrift.\nFor Example, now there are 3 Services need to be combined, and the Thrift IDL file demo.thrift is as follow:\nnamespacegoapistructExampleRequest{1:stringmessage}structExampleResponse{1:stringmessage}serviceExampleService0{ExampleResponseMethod0(1:ExampleRequestreq)}serviceExampleService1{ExampleResponseMethod1(1:ExampleRequestreq)}serviceExampleService2{ExampleResponseMethod2(1:ExampleRequestreq)}Execute Kitex code generating command with --combine-service to combine these services:\nkitex --combine-service -service demo.kitex.combine demo.thrift The directory generated is like this:\n├── kitex_gen └── api ├── combineservice │ ├── client.go │ ├── combineservice.go │ ├── invoker.go │ └── server.go ├── demo.go ├── exampleservice0 │ ├── client.go │ ├── exampleservice0.go │ ├── invoker.go │ └── server.go ├── exampleservice1 │ ├── client.go │ ├── exampleservice1.go │ ├── invoker.go │ └── server.go ├── exampleservice2 │ ├── client.go │ ├── exampleservice2.go │ ├── invoker.go │ └── server.go ├── k-consts.go └── k-demo.go exampleservice0, exampleservice1 and exampleservice2 are normally generated codes.\ncombineservice is the code of the combined service generated by --combine-service, in which each method is an aggregation of another service, which can be used uniformly through this service.\nSo when the server starts, you only need to run the Service of this merged service, and you can run all the methods together:\nfunc main() { svr := api.NewServer(new(combineservice.CombineService)) err := svr.Run() if err != nil { log.Println(err.Error()) } } ","categories":"","description":"","excerpt":" This feature only works when using Thrift\n Usage Scenarios There …","ref":"/docs/kitex/tutorials/code-gen/combine_service/","tags":"","title":"Combine Service"},{"body":" 本功能仅支持 Thrift 场景\n 使用场景 有些服务提供了几十个方法，而对于调用方可能只请求其中一两个方法，为了避免这种大型 Service 带来的庞大的生成代码，Combine Service 可以让用户将原来一个 Service 的几十个方法拆分成多个 Service。比如原来的 Service 是：\nserviceExampleService{ExampleResponseMethod0(3:ExampleRequestreq)ExampleResponseMethod1(3:ExampleRequestreq)ExampleResponseMethod2(3:ExampleRequestreq)}用户 IDL 定义可以拆分为三个 Service：\nserviceExampleService0{ExampleResponseMethod0(3:ExampleRequestreq)}serviceExampleService1{ExampleResponseMethod1(3:ExampleRequestreq)}serviceExampleService2{ExampleResponseMethod2(3:ExampleRequestreq)}调用方可以只保留其中一个 Service 生成代码，方法名和参数保持一致不影响 RPC 调用。\n具体描述 当 root thrift 文件中存在形如下述定义时：\nserviceExampleService0{ExampleResponseMethod0(3:ExampleRequestreq)}serviceExampleService1{ExampleResponseMethod1(3:ExampleRequestreq)}serviceExampleService2{ExampleResponseMethod2(3:ExampleRequestreq)}带上--combine-service 参数后，会生成一个名为 CombineService 的新 service 及其对应的 client/server 代码。 其定义为：\nserviceCombineService{ExampleResponseMethod0(3:ExampleRequestreq)ExampleResponseMethod1(3:ExampleRequestreq)ExampleResponseMethod2(3:ExampleRequestreq)}当同时使用了-service 参数时，会使用 CombineService 作为 main package 中 server 对应的 service 。 注意： CombineService 只是 method 的聚合，因此当 method 名冲突时将无法生成 CombineService 。\nTips：\n配合 extends 关键字，可以实现跨文件的 CombineService\n如：\nservice ExampleService0 extends thriftA.Service0 { } service ExampleService1 extends thriftB.Service1 { } service ExampleService2 extends thriftC.Service2 { } 使用示例 本功能只支持 Thrift 场景。例如目前有三个 Service 需要合并，编写 Thrift IDL 文件 demo.thrift 如下：\nnamespacegoapistructExampleRequest{1:stringmessage}structExampleResponse{1:stringmessage}serviceExampleService0{ExampleResponseMethod0(1:ExampleRequestreq)}serviceExampleService1{ExampleResponseMethod1(1:ExampleRequestreq)}serviceExampleService2{ExampleResponseMethod2(1:ExampleRequestreq)}执行如下命令，添加 --combine-service 进行合并服务的代码生成：\nkitex --combine-service -service demo.kitex.combine demo.thrift 得到的生成内容如下：\n├── kitex_gen └── api ├── combineservice │ ├── client.go │ ├── combineservice.go │ ├── invoker.go │ └── server.go ├── demo.go ├── exampleservice0 │ ├── client.go │ ├── exampleservice0.go │ ├── invoker.go │ └── server.go ├── exampleservice1 │ ├── client.go │ ├── exampleservice1.go │ ├── invoker.go │ └── server.go ├── exampleservice2 │ ├── client.go │ ├── exampleservice2.go │ ├── invoker.go │ └── server.go ├── k-consts.go └── k-demo.go 其中，exampleservice0，exampleservice1，exampleservice2 都是正常生成的代码\n而 combineservice 则为 --combine-service 生成的合并服务的代码，其中各个方法都是对另外的 Service 进行的聚合，可以通过这个 Service 进行统一的使用。\n所以在服务端启动时，只需要运行这个合并服务的 Service，就可以将所有的方法一起运行：\nfunc main() { svr := api.NewServer(new(combineservice.CombineService)) err := svr.Run() if err != nil { log.Println(err.Error()) } } ","categories":"","description":"","excerpt":" 本功能仅支持 Thrift 场景\n 使用场景 有些服务提供了几十个方法，而对于调用方可能只请求其中一两个方法， …","ref":"/zh/docs/kitex/tutorials/code-gen/combine_service/","tags":"","title":"Combine Service"},{"body":"会议主题： CloudWeGo 社区会议 3.11\n参会人员： CoderPoet, liu-song, GuangmingLuo, Zheming Li, YangruiEmma, li-jin-gou, simon0-o, Dianjun Suo, jasondeng1997, lvnszn, baiyutang, Duslia, joway, Xuewu Jiang, AshleeT, yccpt.\n会前必读： http://www.cloudwego.io/; https://github.com/cloudwego\n议程 1 ：新人自我介绍 内容：社区新成员和首次参加社区会议的内部成员分别进行自我介绍，主要包含个人基本情况和历史贡献。\n议程 2 ：CloudWeGo 仓库介绍  对 CloudWeGo 主仓库进行了简要介绍，欢迎社区成员对仓库进行补充加强。例如：欢迎大家在 Kitex_examples 仓库提交一些 Business demo，例如电商、医疗等不同行业场景下的典型案例 。 Community 仓库：首先，Community 仓库刚成立不久，主要用于归档社区相关的材料，包括双周会的会议纪要（meeting_notes）和周报（weekly_report）。其次，也欢迎大家成为该仓库的正式成员，后续的活动可以第一时间通知到大家，便于大家参与到核心功能的讨论与开发。 Kitex-contrib 仓库：该仓库包含了各种扩展的对接实现，比如对接 Prometheus，对接Opentracing 等。其中，OpenTelemetry 对接项目正处于提交 PR 的状态，欢迎大家参与到项目的共建和 review。  议程 3：社区后续工作介绍  源码解析和微服务实践解析系列文章志愿者筹集，以及宣传运营支持：譬如：我们可以通过开源中国等渠道去发布一些优质文章，欢迎大家在源码解析和微服务实践方面文章的投稿。 开放服务治理：后续会和其他的一些厂商以及开源社区共同合作，去完成服务治理标准的制定。 官网文档和页面优化：对 CloudWeGo 官网的 Document、About、Blog 和 Community 页面提出意见，进行优化。  议程 4： Kitex 3、4月 TO DO/DOING 事项介绍\n 性能优化   Kitex-gRPC Streaming 性能提升。 Protobuf 编解码性能优化，初步完成，完善边界 case 。 Frugal - 无生成代码的高性能动态 Thrift编解码库。  新特性支持   Thrift 泛化调用 新增对 Protobuf 的支持用于网关 Protobuf \u003c-\u003e Thrift 高性能的协议转换 重试:支持用户自定义异常重试 Proxyless 支持:完成服务发现/路由对 xds 接口扩展  功能优化:   重写连接池逻辑，支持更加优雅的空闲连接清理 增加字段 Size 校验  外部需求   连接预热、连接多路复用通知上游退出  Action Items\n Kitex 开源库单元测试补全任务：希望社区同学能够加入进行补全。有助于促进大家熟悉源代码，帮助大家的后续开发。重点需要补充的 package 后续会在 Kitex 仓库创建独立的 Issue, 欢迎大家认领。  补充单元测试原则\n  补充的单测必须是有意义的，验证某个逻辑的正确性，或者异常表现是否符合预期。\n  杜绝为了覆盖率而补全单测，宁可不加。\n  每个单测必须要有断言。\n  可以添加 mock 辅助单测。\n  建议单测通过注释明确验证的逻辑。\n  不要在单测代码里用 printf 等手段打日志人肉去检验。\n  议程 5：Q\u0026A Q：Kitex 啥时候支持 Thrift Streaming？\nA：Kitex 支持 Thrift streaming 我们刚开始是计划要做的，但是之后了解到目前没有应用场景，没有用户提出需要用到 Thrift Streaming， 因此，这个计划我们就搁置了。如果没有收到真实的业务场景需求，我们暂时不去安排这个功能支持。\nQ：Proxyless 支持这块是一个 doing 状态吗？\nA：之前是有一个同学在跟进，但是后来因为内部有其它事情处理就没有再继续做了。如果你感兴趣的话，可以加入进来一起支持。\nQ：字段 size 是说大包性能的问题么。类似拆包去分发？\nA：首先，大包这一块的问题，我们目前是在 v1.8.0版本，就支持了可以去自定义整个包的 size。 其次，字段 size 校验的话，有可能有时我们的包出现错误，这个时候如果我们没有去校验 size， 那在解码的过程中，会因为这个错误的 size 可能导致去分配很大的内存。所以我们想对这个字段 size 增加一个校验。\nQ：连接池优化是指高并发的时候，长连接变成短连接的问题吗？\nA：不是的。我们的连接池有一个空闲连接的策略，空闲连接是指你配置了空闲时间，那么到了这个空闲时间，你这个连接就应该被清理掉。但实际上目前不是这样的逻辑，目前是我在用到这个连接的时候，我发现这个连接可能已经达到了我的空闲时间了，然后我才会把它给清理掉，这个是不合理的。基于此，我们打算重写这块的逻辑。\n","categories":"","description":"","excerpt":"会议主题： CloudWeGo 社区会议 3.11\n参会人员： CoderPoet, liu-song, GuangmingLuo, …","ref":"/zh/community/meeting_notes/2022-03-11/","tags":"","title":"CloudWeGo 社区会议 3.11"},{"body":"Meta Information As an RPC framework, Kitex services communicate with each other through protocols described by IDL (thrift, protobuf, etc.). The interface defined in an IDL determines the data structures that could be transmitted between the client and the server.\nHowever, in the production environment, we somehow may need to send special information to a remote server and that information is temporary or has an unstable format which can not be explicitly defined in the IDL. Such a situation requests the framework to be capable of sending meta information.\nNOTE MUST use the underlying transport protocol that supports passthrough of meta information，such as TTHeader, gRPC, HTTP。\nTo decouple with the underlying transport protocols, and interoperate with other frameworks, Kitex does not provide APIs to read or write meta information directly. Instead, it uses a stand-alone library metainfo to support meta information transmitting.\nForward Meta Information Transmitting Package metainfo provides two kinds of API for sending meta information forward – transient and persistent. The former is for ordinary needs of sending meta information; while the later is used when the meta information needs to be kept and sent to the next service and on, like a log ID or a dying tag. Of course, the persistent APIs works only when the next service and its successors all supports the meta information tarnsmitting convention.\nA client side example:\nimport \"github.com/bytedance/gopkg/cloud/metainfo\" func main() { ... ctx := context.Background() cli := myservice.MustNewClient(...) req := myservice.NewSomeRequest() ctx = metainfo.WithValue(ctx, \"temp\", \"temp-value\") // attach the meta information to the context  ctx = metainfo.WithPersistentValue(ctx, \"logid\", \"12345\") // attach persistent meta information  resp, err := cli.SomeMethod(ctx, req) // pass the context as an argument  ... } A server side example:\nimport ( \"context\" \"github.com/bytedance/gopkg/cloud/metainfo\" ) var cli2 = myservice2.MustNewClient(...) // the client for next service  func (MyServiceImpl) SomeMethod(ctx context.Context, req *SomeRequest) (res *SomeResponse, err error) { temp, ok1 := metainfo.GetValue(ctx, \"temp\") logid, ok2 := metainfo.GetPersistentValue(ctx, \"logid\") if !(ok1 \u0026\u0026 ok2) { panic(\"It looks like the protocol does not support transmitting meta information\") } println(temp) // \"temp-value\"  println(logid) // \"12345\"  // if we need to call another service  req2 := myservice2.NewRequset() res2, err2 := cli2.SomeMethod2(ctx, req2) // pass the context to other service for the persistent meta information to be transmitted continuously  ... } Backward Meta Information Transmitting Some transport protocols also support backward meta information transmitting. So Kitex supports that through metainfo, too.\nA client side example:\nimport \"github.com/bytedance/gopkg/cloud/metainfo\" func main() { ... ctx := context.Background() cli := myservice.MustNewClient(...) req := myservice.NewSomeRequest() ctx = metainfo.WithBackwardValues(ctx) // mark the context to receive backward meta information  resp, err := cli.SomeMethod(ctx, req) // pass the context as an argument  if err == nil { val, ok := metainfo.RecvBackwardValue(ctx, \"something-from-server\") // receive the meta information from server side  println(val, ok) } ... } A server side example:\nimport ( \"context\" \"github.com/bytedance/gopkg/cloud/metainfo\" ) func (MyServiceImpl) SomeMethod(ctx context.Context, req *SomeRequest) (res *SomeResponse, err error) { ok := metainfo.SendBackwardValue(ctx, \"something-from-server\") if !ok { panic(\"It looks like the protocol does not support transmitting meta information backward\") } ... } Kitex gRPC metadata Kitex gRPC scenarios can also use metainfo. But note that the key of the CGI gateway style interface in the format of uppercase + ‘_’ needs to be satisfied.\nIn addition to metainfo usage, it is also compatible with the original metadata transmission method. But the two cannot be mixed.\nSimilar to native gRPC, the forward pass is implemented through metadata. Reverse transmission is sent back through Header or Trailer, the specific usage is as follows:\nForward Client send settings:\nctx := metadata. AppendToOutgoingContext(ctx, \"k1\", \"v1\", \"k1\", \"v2\", \"k2\", \"v3\") // unary scene  resp, err := client. SayHello(ctx, req) // stream scene  stream, err := client. CallStream(ctx) Server receives:\n// unary scene  md, ok := metadata. FromIncomingContext(ctx) // stream scene  md, ok := metadata.FromIncomingContext(stream.Context()) Backward Unary In the unary scenario, the server sends meta information to the client as follows:\nServer settings:\nnphttp2. SendHeader(ctx, metadata. Pairs(\"k1\", \"v1\")) nphttp2. SetHeader(ctx, metadata. Pairs(\"k1\", \"v1\")) nphttp2. SetTrailer(ctx, metadata. Pairs(\"k2\", \"v2\")) Client receives:\n// set in advance  var header, trailer metadata.MD ctx = nphttp2.GRPCHeader(ctx, \u0026header) ctx = nphttp2. GRPCTrailer(ctx, \u0026trailer) // RPC Call  resp, err := client. SayHello(ctx, req) // get header and trailer  log.Println(\"header is \", header) log.Println(\"trailer is \", trailer) Streaming In the Streaming scenario, the server sends meta information to the client as follows: Server sends:\nstream.SetHeader(metadata. Pairs(\"k1\", \"v1\")) stream.SetTrailer(metadata. Pairs(\"k2\",\"v2\")) Client receives:\n// After stream call  md, _ := stream.Header() md = stream.Trailer() ","categories":"","description":"In addition to IDL-defined data structures, Kitex supports additional meta-info transmitting capabilities and interoperability with different frameworks.","excerpt":"In addition to IDL-defined data structures, Kitex supports additional …","ref":"/docs/kitex/tutorials/advanced-feature/metainfo/","tags":"","title":"Metainfo"},{"body":"元信息 作为一个 RPC 框架，Kitex 服务之间的通信都是基于 IDL（thrift、protobuf 等）描述的协议进行的。IDL 定义的服务接口决定了客户端和服务端之间可以传输的数据结构。\n然而在实际生产环境，我们偶尔会有特殊的信息需要传递给对端服务，而又不希望将这些可能是临时或者格式不确定的内容显式定义在 IDL 里面，这就需要框架能够支持一定的元信息传递能力。\n注意 必须使用支持元信息的透传的底层传输协议才可用，例如 TTheader、HTTP、gRPC。\n为了和底层的协议解耦，同时也为了支持与不同框架之间的互通，Kitex 并没有直接提供读写底层传输协议的元信息的 API，而是通过一个独立维护的基础库 metainfo 来支持元信息的传递。\n正向元信息传递 包 metainfo 提供了两种类型的正向元信息传递 API：临时的（transient）和持续的（persistent）。前者适用于通常的元信息传递的需求；后者是在对元信息有持续传递需求的场合下使用，例如日志 ID、染色等场合，当然，持续传递的前提是下游以及更下游的服务都是支持这一套数据透传的约定，例如都是 Kitex 服务。\n客户端的例子：\nimport \"github.com/bytedance/gopkg/cloud/metainfo\" func main() { ... ctx := context.Background() cli := myservice.MustNewClient(...) req := myservice.NewSomeRequest() ctx = metainfo.WithValue(ctx, \"temp\", \"temp-value\") // 附加元信息到 context 里  ctx = metainfo.WithPersistentValue(ctx, \"logid\", \"12345\") // 附加能持续透传的元信息  resp, err := cli.SomeMethod(ctx, req) // 将得到的 context 作为客户端的调用参数  ... } 服务端的例子：\nimport ( \"context\" \"github.com/bytedance/gopkg/cloud/metainfo\" ) var cli2 = myservice2.MustNewClient(...) // 更下游的服务的客户端  func (MyServiceImpl) SomeMethod(ctx context.Context, req *SomeRequest) (res *SomeResponse, err error) { temp, ok1 := metainfo.GetValue(ctx, \"temp\") logid, ok2 := metainfo.GetPersistentValue(ctx, \"logid\") if !(ok1 \u0026\u0026 ok2) { panic(\"It looks like the protocol does not support transmitting meta information\") } println(temp) // \"temp-value\"  println(logid) // \"12345\"  // 如果需要调用其他服务的话  req2 := myservice2.NewRequset() res2, err2 := cli2.SomeMethod2(ctx, req2) // 在调用其他服务时继续传递收到的 context，可以让持续的元信息继续传递下去  ... } 反向元信息传递 一些传输协议还支持反向的元数据传递，因此 Kitex 也利用 metainfo 做了支持。\n客户端的例子：\nimport \"github.com/bytedance/gopkg/cloud/metainfo\" func main() { ... ctx := context.Background() cli := myservice.MustNewClient(...) req := myservice.NewSomeRequest() ctx = metainfo.WithBackwardValues(ctx) // 标记要接收反向传递的数据的 context  resp, err := cli.SomeMethod(ctx, req) // 将得到的 context 作为客户端的调用参数  if err == nil { val, ok := metainfo.RecvBackwardValue(ctx, \"something-from-server\") // 获取服务端传回的元数据  println(val, ok) } ... } 服务端的例子：\nimport ( \"context\" \"github.com/bytedance/gopkg/cloud/metainfo\" ) func (MyServiceImpl) SomeMethod(ctx context.Context, req *SomeRequest) (res *SomeResponse, err error) { ok := metainfo.SendBackwardValue(ctx, \"something-from-server\") if !ok { panic(\"It looks like the protocol does not support transmitting meta information backward\") } ... } Kitex gRPC metadata Kitex gRPC 场景也可以同样使用 metainfo。但注意，需要满足用大写 + ‘_’ 格式的 CGI 网关风格接口的 key 。\n除了 metainfo 用法，也兼容了原本的 metadata 传输方式。但二者不可混合使用。\n与原生 gRPC 类似，正向传递通过 metadata 实现。反向传递通过 Header 或者 Trailer 发回，具体用法如下：\n正向传递 Client 发送设置：\nctx := metadata.AppendToOutgoingContext(ctx, \"k1\", \"v1\", \"k1\", \"v2\", \"k2\", \"v3\") // unary 场景  resp, err := client.SayHello(ctx, req) // stream 场景  stream, err := client.CallStream(ctx) Server 接收：\n// unary 场景  md, ok := metadata.FromIncomingContext(ctx) // stream 场景  md, ok := metadata.FromIncomingContext(stream.Context()) 反向传递 Unary Unary 场景中，Server 向 Client 发送元信息方式如下：\nServer 设置:\nnphttp2.SendHeader(ctx, metadata.Pairs(\"k1\", \"v1\")) nphttp2.SetHeader(ctx, metadata.Pairs(\"k1\", \"v1\")) nphttp2.SetTrailer(ctx, metadata.Pairs(\"k2\", \"v2\")) Client 接收：\n// 提前设置  var header, trailer metadata.MD ctx = nphttp2.GRPCHeader(ctx, \u0026header) ctx = nphttp2.GRPCTrailer(ctx, \u0026trailer) // RPC Call  resp, err := client.SayHello(ctx, req) // 获取 header 和 trailer  log.Println(\"header is \", header) log.Println(\"trailer is \", trailer) Streaming Streaming 场景中，Server 向 Client 发送元信息方式如下： Server 发送：\nstream.SetHeader(metadata.Pairs(\"k1\", \"v1\")) stream.SetTrailer(metadata.Pairs(\"k2\",\"v2\")) Client 接收：\n// 发起 stream call 之后  md, _ := stream.Header() md = stream.Trailer() ","categories":"","description":"除了 IDl 定义的数据结构外，Kitex 支持额外的元信息传递的能力，并且支持与不同框架之间的互通。","excerpt":"除了 IDl 定义的数据结构外，Kitex 支持额外的元信息传递的能力，并且支持与不同框架之间的互通。","ref":"/zh/docs/kitex/tutorials/advanced-feature/metainfo/","tags":"","title":"Metainfo"},{"body":"The framework provides a Tracer interface. Users can implement it and inject it by WithTracer Option.\n// Tracer is executed at the start and finish of an RPC. type Tracer interface { Start(ctx context.Context) context.Context Finish(ctx context.Context) } The monitoring extension of prometheus is provided in kitex-contrib, usage example:\nClient Side:\nimport ( \"github.com/kitex-contrib/monitor-prometheus\" kClient \"github.com/cloudwego/kitex/client\" ) ... client, _ := testClient.NewClient( \"DestServiceName\", kClient.WithTracer(prometheus.NewClientTracer(\":9091\", \"/kitexclient\"))) resp, _ := client.Send(ctx, req) ... Server Side:\nimport ( \"github.com/kitex-contrib/monitor-prometheus\" kServer \"github.com/cloudwego/kitex/server\" ) func main() {... svr := xxxservice.NewServer( \u0026myServiceImpl{}, kServer.WithTracer(prometheus.NewServerTracer(\":9092\", \"/kitexserver\"))) svr.Run() ... } ","categories":"","description":"Kitex has monitoring capability built in, but does not have any monitoring features itself, and can be extended by the interface.","excerpt":"Kitex has monitoring capability built in, but does not have any …","ref":"/docs/kitex/tutorials/service-governance/monitoring/","tags":"","title":"Monitoring"},{"body":"Thrift Kitex only support Thrift Binary protocol codec, Compact currently is not supported.\nIf you are using thrift protocol encoding, codes should be generated by kitex cmd tool:\nClient side：\nkitex -type thrift ${service_name} ${idl_name}.thrift Server side:\nkitex -type thrift -service ${service_name} ${idl_name}.thrift We have optimized Thrift’s Binary protocol codec. For details of the optimization, please refer to the “Reference - High Performance Thrift Codec” chapter. If you want to close these optimizations, you can add the -no-fast-api argument when generating code.\nProtobuf Protocol Type Kitex supports two types of protocol for protobuf:\n Custom message protocol: it’s been considered as kitex protobuf, the way of generated code is consistent with Thrift. gRPC protocol: it can communication with grpc directly, and support streaming.  If the streaming method is defined in the IDL, the serialization protocol would adopt gRPC protocol, otherwise Kitex protobuf would be adopted. If you want using gRPC protocol, but without stream definition in your proto file, you need specify the transport protocol when initializing client (No changes need to be made on the server because protocol detection is supported)：\n// Using WithTransportProtocol specify the transport protocol cli, err := service.NewClient(destService, client.WithTransportProtocol(transport.GRPC)) Generated Code Only support proto3, the grammar reference: https://developers.google.com/protocol-buffers/docs/gotutorial.\nNotice:\n What is different from other languages, generating go codes must define go_package in the proto file Instead of the full path, just using go_package specify the package name, such as: go_package = “pbdemo” Download the protoc binary and put it in the $PATH directory  Client side：\nkitex -type protobuf -I idl/ idl/${proto_name}.proto Server side:\nkitex -type protobuf -service ${service_name} -I idl/ idl/${proto_name}.proto ","categories":"","description":"Kitex supports Thrift and Protobuf codec.","excerpt":"Kitex supports Thrift and Protobuf codec.","ref":"/docs/kitex/tutorials/basic-feature/serialization_protocol/","tags":"","title":"Serialization Protocol"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/kitex/tutorials/service-governance/","tags":"","title":"Service Governance"},{"body":"Encapsulating Custom Governance Modules Suite is a high-level abstraction of extensions, a combination and encapsulation of Option and Middleware.\nAs mentioned in the middleware extensions document, there are two principles should be remembered in extensions:\n Middleware and Suit are only allowed to be set before initializing Server and Client, do not allow modified dynamically. Behind override ahead.  These tow principle is also valid for Suite.\nSuite is defined as follows:\ntype Suite interface { Options() []Option } // TODO: Add example.\nBoth Server side and Client side use the WithSuite method to enable new Suite.\nWhen initializing Server and Client, Suite is setup in DFS(Deep First Search) way.\nFor example, if we have the following code:\ntype s1 struct { timeout time.Duration } func (s s1) Options() []client.Option { return []client.Option { client.WithRPCTimeout(s.timeout)} } type s2 struct { } func (s2) Options() []client.Option { return []client.Option{client.WithSuite(s1{timeout:1*time.Second}), client.WithRPCTimeout(2*time.Second)} } Then if we use client.WithSuite(s2{}), client.WithRPCTimeout(3*time.Second), it will execute client.WithSuite(s1{}) first, followed by client. WithRPCTimeout(1*time.Second), followed by client.WithRPCTimeout(2*time.Second), and finally client.WithRPCTimeout(3*time.Second). After this initialization, the value of RPCTimeout will be set to 3s (see the principle described at the beginning).\nSummary Suite is a higher-level combination and encapsulation, and it is recommended that third-party developers provide Kitex extensions based on Suite. Suite allows dynamically injecting values at creation time, or dynamically specifying values in its own middleware at runtime, making it easier for users and third-party developers to use and develop without relying on global variables, and making it possible to use different configurations for each client.\n","categories":"","description":"","excerpt":"Encapsulating Custom Governance Modules Suite is a high-level …","ref":"/docs/kitex/tutorials/framework-exten/suite/","tags":"","title":"Suite Extensions"},{"body":"Suite 扩展 - 封装自定义治理模块 Suite（套件）是一种对于扩展的高级抽象，可以理解为是对于 Option 和 Middleware 的组合和封装。\n在 middleware 扩展一文中我们有说到，在扩展过程中，要记得两点原则：\n 中间件和套件都只允许在初始化 Server、Client 的时候设置，不允许动态修改。 后设置的会覆盖先设置的。  这个原则针对 Suite 也是一样有效的。\nSuite 的定义如下：\ntype Suite interface { Options() []Option } 这也是为什么说，Suite 是对于 Option 和 Middleware（通过 Option 设置）的组合和封装。\n// TODO: 增加示例。\nServer 端和 Client 端都是通过 WithSuite 这个方法来启用新的套件。\n在初始化 Server 和 Client 的时候，Suite 是采用 DFS(Deep First Search) 方式进行设置。\n举个例子，假如我有以下代码：\ntype s1 struct { timeout time.Duration } func (s s1) Options() []client.Option { return []client.Option{client.WithRPCTimeout(s.timeout)} } type s2 struct { } func (s2) Options() []client.Option { return []client.Option{client.WithSuite(s1{timeout:1*time.Second}), client.WithRPCTimeout(2*time.Second)} } 那么如果我在创建 client 时传入 client.WithSuite(s2{}), client.WithRPCTimeout(3*time.Second)，在初始化的时候，会先执行到 client.WithSuite(s1{})，然后是 client.WithRPCTimeout(1*time.Second)，接着是 client.WithRPCTimeout(2*time.Second)，最后是 client.WithRPCTimeout(3*time.Second)。这样初始化之后，RPCTimeout 的值会被设定为 3s（参见开头所说的原则）。\n总结 Suite 是一种更高层次的组合和封装，更加推荐第三方开发者能够基于 Suite 对外提供 Kitex 的扩展，Suite 可以允许在创建的时候，动态地去注入一些值，或者在运行时动态地根据自身的某些值去指定自己的 middleware 中的值，这使得用户的使用以及第三方开发者的开发都更加地方便，无需再依赖全局变量，也使得每个 client 使用不同的配置成为可能。\n","categories":"","description":"","excerpt":"Suite 扩展 - 封装自定义治理模块 Suite（套件）是一种对于扩展的高级抽象，可以理解为是对于 Option …","ref":"/zh/docs/kitex/tutorials/framework-exten/suite/","tags":"","title":"Suite 扩展"},{"body":"Thrift Kitex 支持了 Thrift 的 Binary 协议，暂时没有支持 Compact 协议。\n生成代码时指定 Thrift 协议，也可以不指定，默认就是 Thrift：\n  客户端\nkitex -type thrift ${service_name} ${idl_name}.thrift   服务端\nkitex -type thrift -service ${service_name} ${idl_name}.thrift   我们针对 Thrift 的 binary 协议编解码进行了优化，具体优化细节参考 “Reference - 高性能 Thrift 编解码 \" 篇章，假如想要关闭这些优化，生成代码时可以加上 -no-fast-api 参数。\nProtobuf 协议说明 Kitex 对 protobuf 支持的协议有两种：\n 自定义的消息协议，可以理解为 Kitex Protobuf，使用方式与 thrift 一样 gRPC 协议，可以与 gRPC 互通，并且支持 streaming 调用  如果 IDL 文件中定义了 streaming 方法则走 gRPC 协议，否则走 Kitex Protobuf。没有 streaming 方法，又想指定 gRPC 协议，需要 client 初始化做如下配置（server 支持协议探测无需配置） ：\n// 使用 WithTransportProtocol 指定 transport cli, err := service.NewClient(destService, client.WithTransportProtocol(transport.GRPC)) 生成代码 只支持 proto3，语法参考 https://developers.google.com/protocol-buffers/docs/gotutorial\n注意：\n 相较其他语言，必须定义 go_package ，以后 pb 官方也会将此作为必须约束 go_package 和 thrift 的 namespace 定义一样，不用写完整的路径，只需指定包名，相当于 thrift 的 namespace，如：go_package = “pbdemo” 提前下载好 protoc 二进制放在 $PATH 目录下  生成代码时需要指定 protobuf 协议：\n  客户端\nkitex -type protobuf -I idl/ idl/${proto_name}.proto   服务端\nkitex -type protobuf -service ${service_name} -I idl/ idl/${proto_name}.proto   ","categories":"","description":"Kitex 支持 Thrift 和 Protobuf 两种编解码。","excerpt":"Kitex 支持 Thrift 和 Protobuf 两种编解码。","ref":"/zh/docs/kitex/tutorials/basic-feature/serialization_protocol/","tags":"","title":"序列化协议"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/kitex/tutorials/service-governance/","tags":"","title":"治理特性"},{"body":"框架提供了 Tracer 接口，用户可以根据需求实现该接口，并通过 WithTracer Option 来注入监控的具体实现。\n// Tracer is executed at the start and finish of an RPC. type Tracer interface { Start(ctx context.Context) context.Context Finish(ctx context.Context) } kitex-contrib 中提供了 prometheus 的监控扩展，使用方式：\nClient\nimport ( \"github.com/kitex-contrib/monitor-prometheus\" kClient \"github.com/cloudwego/kitex/client\" ) ... client, _ := testClient.NewClient( \"DestServiceName\", kClient.WithTracer(prometheus.NewClientTracer(\":9091\", \"/kitexclient\"))) resp, _ := client.Send(ctx, req) ... Server\nimport ( \"github.com/kitex-contrib/monitor-prometheus\" kServer \"github.com/cloudwego/kitex/server\" ) func main() { ... svr := xxxservice.NewServer( \u0026myServiceImpl{}, kServer.WithTracer(prometheus.NewServerTracer(\":9092\", \"/kitexserver\"))) svr.Run() ... } ","categories":"","description":"Kitex 框架内置了监控能力，但是本身不带任何监控打点，通过接口的方式进行扩展。","excerpt":"Kitex 框架内置了监控能力，但是本身不带任何监控打点，通过接口的方式进行扩展。","ref":"/zh/docs/kitex/tutorials/service-governance/monitoring/","tags":"","title":"监控"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/tutorials/basic-feature/","tags":"","title":"Basic Feature"},{"body":"Volo-gRPC is an RPC framework so that the bottom layer requires two major functions: Serialization and Transport.\nIDL is short for Interface Definition Language.\nWhy IDL If we want to do RPC, we need to know what interface is for the server, what parameters to pass, and what the return value is, just like two people talking to each other, we need to make sure we are speaking the same language and doing the same thing.\nAt this time, we need to use IDL to specify the protocol for both sides, just like when writing code, we need to know the function signature while calling a function.\nProtobuf IDL is a full-stack RPC solution for cross-language, the specific syntax can be seen in protocol-buffers/docs/proto3.\nWrite IDL To create a gRPC project, we need to write a protobuf IDL at first.\nIn your working directory, execute the following command:\n$ mkdir volo-example $ cd volo-example $ mkdir idl $ vim idl/volo_example.proto Then, enter the following content:\nsyntax = \"proto3\";package volo.example;message Item { int64 id = 1; string title = 2; string content = 3; map\u003cstring, string\u003e extra = 10;}message GetItemRequest { int64 id = 1;}message GetItemResponse { Item item = 1;}service ItemService { rpc GetItem(GetItemRequest) returns (GetItemResponse);}After saving and exiting, we execute the following command:\n$ volo init --includes=idl volo-example idl/volo_example.proto Here we use the init command, followed by the name of our project, which means we need to generate template code. At the end, you need to specify an IDL used by the server.\nIf you only need to add an IDL (such as the client IDL) without generating a template, do as follows:\n$ volo idl add idl/volo_example.proto | What’s more, the volo tool also supports downloading IDL from git and then generating code, such as:\n$ volo idl add -g git@github.com:org/repo.git -r main /path/to/your/idl.proto | You may directly enter volo to see the detailed usage ~ next back to the topic ~\nAt this point, our entire directory structure looks like this:\n. ├── Cargo.toml ├── idl │ └── volo_example.proto ├── rust-toolchain.toml ├── src │ ├── bin │ │ └── server.rs │ └── lib.rs └── volo-gen ├── Cargo.toml ├── build.rs ├── src │ └── lib.rs └── volo.yml Then we open src/lib.rs and add the method implementation to the impl block. The resulting code should look like this:\n#![feature(type_alias_impl_trait)]pubstruct S;#[volo::async_trait]implvolo_gen::volo::example::ItemServiceforS{// This is the part of the code we need to add asyncfn get_item(\u0026self,_req: volo_grpc::Request\u003cvolo_gen::volo::example::GetItemRequest\u003e,)-\u003e core::result::Result\u003cvolo_grpc::Response\u003cvolo_gen::volo::example::GetItemResponse\u003e,volo_grpc::Status\u003e{Ok(volo_grpc::Response::new(Default::default()))}}Then execute:\n$ cargo update $ cargo build At this point, You will find volo_gen.rs file under OUT_DIR Directory.\nThen execute the following command to get our server running:\n$ cargo run --bin server At this point, we have our server running!\n","categories":"","description":"","excerpt":"Volo-gRPC is an RPC framework so that the bottom layer requires two …","ref":"/docs/volo/volo-grpc/getting-started/part_2/","tags":"","title":"Part 2. Create a gRPC Server"},{"body":"Volo-Thrift is an RPC framework so that the bottom layer requires two major functions: Serialization and Transport.\nIDL is short for Interface Definition Language.\nWhy IDL If we want to do RPC, we need to know what interface is for the server, what parameters to pass, and what the return value is, just like two people talking to each other, we need to make sure we are speaking the same language and doing the same thing.\nAt this time, we need to use IDL to specify the protocol for both sides, just like when writing code, we need to know the function signature while calling a function.\nThrift IDL is a full-stack RPC solution for cross-language. You can see the syntax of Thrift IDL in thrift-missing-guide or Thrift interface description language.\nWrite IDL To create a Thrift project, we need to write a Thrift IDL at first.\nIn your working directory, execute the following command:\n$ mkdir volo-example $ cd volo-example $ mkdir idl $ vim idl/volo_example.thrift Then, enter the following content:\nnamespacersvolo.examplestructItem{1:requiredi64id,2:requiredstringtitle,3:requiredstringcontent,10:optionalmap\u003cstring,string\u003eextra,}structGetItemRequest{1:requiredi64id,}structGetItemResponse{1:requiredItemitem,}serviceItemService{GetItemResponseGetItem (1:GetItemRequestreq),}After saving and exiting, we execute the following command:\n$ volo init volo-example idl/volo_example.thrift Here we use the init command, followed by the name of our project, which means we need to generate template code. At the end, you need to specify an IDL used by the server.\nIf you only need to add an IDL (such as the client IDL) without generating a template, do as follows:\n$ volo idl add idl/volo_example.thrift | What’s more, the volo tool also supports downloading IDL from git and then generating code, such as:\n$ volo idl add -g git@github.com:org/repo.git -r main /path/to/your/idl.thrift | You may directly enter volo to see the detailed usage ~ next back to the topic ~\nAt this point, our entire directory structure looks like this:\n. ├── Cargo.toml ├── idl │ └── volo_example.thrift ├── rust-toolchain.toml ├── src │ ├── bin │ │ └── server.rs │ └── lib.rs └── volo-gen ├── Cargo.toml ├── build.rs ├── src │ └── lib.rs └── volo.yml Then we open src/lib.rs and add the method implementation to the impl block. The resulting code should look like this:\n#![feature(type_alias_impl_trait)]pubstruct S;#[volo::async_trait]implvolo_gen::volo::example::ItemServiceforS{// This is the part of the code we need to add asyncfn get_item(\u0026self,_req: volo_gen::volo::example::GetItemRequest,)-\u003e core::result::Result\u003cvolo_gen::volo::example::GetItemResponse,volo_thrift::AnyhowError\u003e{Ok(Default::default())}}Then execute:\n$ cargo update $ cargo build At this point, You will find volo_gen.rs file under OUT_DIR Directory.\nThen execute the following command to get our server running:\n$ cargo run --bin server At this point, we have our server running!\n","categories":"","description":"","excerpt":"Volo-Thrift is an RPC framework so that the bottom layer requires two …","ref":"/docs/volo/volo-thrift/getting-started/part_2/","tags":"","title":"Part 2. Create a Thrift Server"},{"body":"Exception Type Defined in github.com/cloudwego/kitex/pkg/kerrors\ninternal exception ErrInternalException, framework internal error, it cloud be:\n ErrNotSupported, \"operation not supported\", have some operation not supported yet ErrNoResolver, \"no resolver available\", no resolver is available ErrNoDestService, \"no dest service\", target service is not specified ErrNoDestAddress, \"no dest address\", target address is not specified ErrNoConnection, \"no connection available\", not connection is available ErrNoIvkRequest, \"invoker request not set\", request is not set in invoker mode  service discovery error ErrServiceDiscovery, service discovery error, see error message for detail.\nget connection error ErrGetConnection, get connection error, see error message for detail.\nloadbalance error ErrLoadbalance, loadbalance error, see error message for detail.\nno more instances to retry ErrNoMoreInstance, no more instance to retry, see last call error message for detail.\nrpc timeout ErrRPCTimeout, RPC timeout, see error message for detail.\nrequest forbidden ErrACL, RPC is rejected by ACL, see error message for detail.\nforbidden by circuitbreaker ErrCircuitBreak, request is circuitbreaked, it could be two type of circuitbreak:\n ErrServiceCircuitBreak, \"service circuitbreak\", service level circuitbreak encountered, request is rejected. ErrInstanceCircuitBreak, \"instance circuitbreak\", instance level circuitbreak encountered, request is rejected.  remote or network error ErrRemoteOrNetwork, remote server error, or network error, see error message for detail.\n[remote] indicates the error is returned by server\nrequest over limit ErrOverlimit, overload protection error, it cloud be:\n ErrConnOverLimit, \"too many connections\", connection overload, connection number is over limit ErrQPSOverLimit, \"request too frequent\", concurrent request overload, concurrent request number is over limit  panic ErrPanic, panic detected.\n[happened in biz handler] indicated panic happened in server handler, usually call stack will attached to error message.\nbiz error ErrBiz, server handler error.\nretry error ErrRetry, retry error, see error message for detail.\nTHRIFT Error Code These error is thrift Application Exception, usually these error will be wrapped to remote or network error.\n   Code Name Meaning     0 UnknownApplicationException Unknown Error   1 UnknownMethod Unknown Function   2 InValidMessageTypeException Invalid Message Type   3 WrongMethodName Wrong Method Name   4 BadSequenceID Bad Sequence ID   5 MissingResult Result is missing   6 InternalError Internal Error   7 ProtocolError Protocol Error    Exception Check Check whether a Kitex error Use IsKitexError in kerrors package\nimport \"github.com/cloudwego/kitex/pkg/kerrors\" ... isKitexErr := kerrors.IsKitexError(kerrors.ErrInternalException) // return true Check Specified Error type Use errors.Is, detailed error cloud use to check detailed error:\nimport \"errors\" import \"github.com/cloudwego/kitex/client\" import \"github.com/cloudwego/kitex/pkg/kerrors\" ... _, err := echo.NewClient(\"echo\", client.WithResolver(nil)) // return kerrors.ErrNoResolver ... isKitexErr := errors.Is(err, kerrors.ErrNoResolver) // return true detailed error is also a basic error:\nimport \"errors\" import \"github.com/cloudwego/kitex/client\" import \"github.com/cloudwego/kitex/pkg/kerrors\" ... _, err := echo.NewClient(\"echo\", client.WithResolver(nil)) // return kerrors.ErrNoResolver ... isKitexErr := errors.Is(err, kerrors.ErrInternalException) // return true Specially, you can use IsTimeoutError in kerrors to check whether it is a timeout error\nGet Detailed Error Message All detailed errors is defined by DetailedError in kerrors, so you can use errors.As to get specified DetailedError, like:\nimport \"errors\" import \"github.com/cloudwego/kitex/client\" import \"github.com/cloudwego/kitex/pkg/kerrors\" ... _, err := echo.NewClient(\"echo\", client.WithResolver(nil)) // return kerrors.ErrNoResolver ... var de *kerrors.DetailedError ok := errors.As(err, \u0026ke) // return true if de.ErrorType() == kerrors.ErrInternalException {} // return true DetailedError provide following functions to get detail message.\n ErrorType() error, used to get basic error type Stack() string, used to get stack (for now only works for ErrPanic)  ","categories":"","description":"Kitex Exception Types and exception judgement guide.","excerpt":"Kitex Exception Types and exception judgement guide.","ref":"/docs/kitex/reference/exception/","tags":"","title":"Exception Instruction"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/motore/faq/","tags":"","title":"FAQ"},{"body":"cwgo is a CloudWeGo All in one code generation tool that integrates the advantages of each component to improve the developer experience.\nPrepare Golang development environment  If you have not set up a Golang development environment before, you can refer to Golang Installation It is recommended to use the latest version of Golang, we guarantee the compatibility of the latest two official versions (now \u003e= v1.18). Make sure to enable go mod support (when Golang \u003e= 1.15, it is enabled by default) cwgo does not support Windows for the time being. If the local development environment is Windows, it is recommended to use WSL2  After completing the environment preparation, the next step will help you get started with cwgo quickly.\nInstall $ go install github.com/cloudwego/cwgo@latest It’s easiest to install with the go command, or you can choose to build and install from source yourself. To see where cwgo is installed, use:\n$ go list -f {{.Target}} github.com/cloudwego/cwgo To use thrift or protobuf’s IDL to generate code, you need to install the corresponding compiler: thriftgo or protoc.\nthriftgo install:\n$ GO111MODULE=on go install github.com/cloudwego/thriftgo@latest protoc install\n# brew install $ brew install protobuf # Official image installation, take macos as an example $ wget https://github.com/protocolbuffers/protobuf/releases/download/v3.19.4/protoc-3.19.4-osx-x86_64.zip $ unzip protoc-3.19.4-osx-x86_64.zip $ cp bin/protoc /usr/local/bin/protoc # Make sure include/google is placed under /usr/local/include $ cp -r include/google /usr/local/include/google First, we need to install the command-line code generation tools needed to use this example:\n Make sure the GOPATH environment variable has been defined correctly (e.g. export GOPATH=~/go) and add $GOPATH/bin to the PATH environment variable (e.g. export PATH=$GOPATH/ bin:$PATH); do not set GOPATH to a directory that the current user does not have read and write permissions Install cwgo: go install github.com/cloudwego/cwgo@latest Install thriftgo: go install github.com/cloudwego/thriftgo@latest  After the installation is successful, execute cwgo --version and thriftgo --version and you should be able to see the output of the specific version number (the version number is different, take x.x.x as an example):\n$ cwgo --version vx.x.x $ thriftgo --version vx.x.x $ protoc --version libprotoc x.x.x Determine where to place the code  If the code is placed under $GOPATH/src, you need to create an additional directory under $GOPATH/src, and then get the code after entering this directory:  $ mkdir -p $(go env GOPATH)/src/github.com/cloudwego $ cd $(go env GOPATH)/src/github.com/cloudwego If you put the code outside GOPATH, you can get it directly  Precautions The bottom layer of cwgo uses kitex, hz, gen tools, so the corresponding tool specifications also need to be followed, such as kitex precautions and Notes for hz.\nUsing For specific usage of cwgo, please refer to Command Line Tool\nLet’s take thrift as an example\n First create a directory  $ mkdir -p $GOPATH/src/local/cwgo_test $ cd $GOPATH/src/local/cwgo_test Create an idl directory  $ mkdir idl Write the idl/hello.thrift file  # idl/hello.thriftnamespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");// Add api annotations to facilitate parameter binding }structHelloResp{1:stringRespBody;}serviceHelloService{HelloRespHelloMethod(1:HelloReqrequest)(api.get=\"/hello\");}Generate project layout  static command line\n$ cwgo server -service=a.b.c -type HTTP -idl=idl/hello.thrift dynamic command line\nCompile and run  $ go mod tidy \u0026\u0026 go mod verify $ sh build.sh \u0026\u0026 sh output/bootstrap.sh Initiate the call  $ curl http://127.0.0.1:8080/ping pong Congratulations! So far you have successfully written a Cwgo server and completed a call!\n","categories":"","description":"","excerpt":"cwgo is a CloudWeGo All in one code generation tool that integrates …","ref":"/docs/cwgo/getting-started/","tags":"","title":"Getting Started"},{"body":"Set Up Golang Development Environment  If you haven’t set up your Golang environment yet, you can refer to Golang Install. We recommend that you use the latest version of Golang, or make sure it’s \u003e= v1.15. You can choose to use the earlier versions, but the compatibility and stability are not guaranteed. Make sure the go mod support is enabled (for Golang versions \u003e= v1.15, it is enabled by default).   Currently, Hertz supports Linux, macOS, and Windows systems.\n Quick Start After you have prepared the Golang environment, this chapter will help you to get familiar with Hertz in a very short time.\nInstall the commend tool of hz First, you need to install the commend tool hz which is used in this chapter\n Confirm the GOPATH environment has been defined correctly (For example export GOPATH=~/go) and the $GOPATH/bin has been added to PATH environment (For example export PATH=$GOPATH/bin:$PATH); Attention, do not set GOPATH to a directory that the current user does not have read/write access to. Install hz: go install github.com/cloudwego/hertz/cmd/hz@latest  For more information on how to use hz, please refer to: hz\nDetermine Where to Store Your Code  If your codes are located in $GOPATH/src, you will need to create an additional dictionary in $GOPATH/src and retrieve your code from that dictionary.  $ mkdir -p $(go env GOPATH)/src/github.com/cloudwego $ cd $(go env GOPATH)/src/github.com/cloudwego If your codes are not placed under GOPATH, you can retrieve them directly.  Generate/Complete the Sample Code  Create the hertz_demo folder in the current directory and go to that directory Generate code hz new Tidy \u0026 get dependencies  $ go mod tidy If you are currently using a Windows system, you can write the following sample code.\n Create the hertz_demo folder in the current directory and go to that directory Create the main.go file Add the following code to the main.go file  package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"message\": \"pong\"}) }) h.Spin() } Generate the go.mod file  $ go mod init hertz_demo Tidy \u0026 get dependencies  $ go mod tidy Run the Sample Code After you have completed the previous steps, you are able to compile \u0026 launch the server\n$ go build -o hertz_demo \u0026\u0026 ./hertz_demo If the server is launched successfully, you will see following message\n2022/05/17 21:47:09.626332 engine.go:567: [Debug] HERTZ: Method=GET absolutePath=/ping --\u003e handlerName=main.main.func1 (num=2 handlers) 2022/05/17 21:47:09.629874 transport.go:84: [Info] HERTZ: HTTP server listening on address=[::]:8888 Then, we can test the interface\n$ curl http://127.0.0.1:8888/ping If nothing goes wrong, we can see the following output\n$ {\"message\":\"pong\"} You have now successfully launched Hertz Server successfully and completed an API call. More API examples can be found at API Examples.\nAs for the layout of the Project Dictionary, here is a sample project layout that you can refer to. You can also organise the layout according to your business scenario.\nDirectory Structure As for the project directory structure, you may check Project Layout for reference, it can be organized according to the actual situation of the business logic.\nMore examples Please refer：hertz-examples\n","categories":"","description":"","excerpt":"Set Up Golang Development Environment  If you haven’t set up your …","ref":"/docs/hertz/getting-started/","tags":"","title":"Getting Started"},{"body":"Prerequisites  If you don’t have the golang development environment set up, please follow Install Go to install go. We strongly recommend that you use the latest version of golang. And compatibility is guaranteed within three latest minor release versions (currently \u003e= v1.16). Make sure that GO111MODULE is set to on. Currently Windows is not well supported by Kitex, if your development environment is Windows it is recommended to use WSL2.  Quick Start This chapter will get you started with Kitex using a simple executable example.\nInstall the compiler First of all, let’s install the compilers we will be working with.\n Make sure the GOPATH environment variable is properly defined (e.g. export GOPATH=~/go), then add $GOPATH/bin to the PATH environment variable (e.g. export PATH=$GOPATH/bin:$PATH). Make sure that GOPATH is accessible. Install Kitex: go install github.com/cloudwego/kitex/tool/cmd/kitex@latest. Install thriftgo: go install github.com/cloudwego/thriftgo@latest.  Now you can run kitex --version and thriftgo --version and you should see some output like below if you have successfully set up the compilers.\n$ kitex --version vx.x.x $ thriftgo --version thriftgo x.x.x Tips: If you encounter any problems during the installation, it’s probably because you haven’t set up the golang development environment properly. In most cases you can search the error message to find a solution.\nGet the example  You can simply click HERE to download the example. Or you can clone the sample repository git clone https://github.com/cloudwego/kitex-examples.git.  Run the example Run with go   change to the hello directory\ncd kitex-examples/hello\n  run server\ngo run .\n  run client\nopen another terminal and go run ./client.\n  Run with Docker   go to the examples directory\ncd kitex-examples\n  build the example project\ndocker build -t kitex-examples .\n  run the server\ndocker run --network host kitex-examples ./hello-server\n  run the client\nOpen another terminal and run docker run --network host kitex-examples ./hello-client\n  Congratulations! You have successfully used Kitex to complete an RPC.\nAdd a new method Open hello.thrift, you will see the following code:\nnamespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}serviceHello{Responseecho(1:Requestreq)}Now let’s define a new request and response AddRequest 和 AddResponse, then add the add method to service Hello:\nnamespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}structAddRequest{1:i64first2:i64second}structAddResponse{1:i64sum}serviceHello{Responseecho(1:Requestreq)AddResponseadd(1:AddRequestreq)}When you are finished, hello.thrift should look like the above.\nRegenerate code Run the command below, then the kitex compiler will recompile hello.thrift and update the generated code.\nkitex -service a.b.c hello.thrift # If the current directory is not under $GOPATH/src, you need to add the -module parameter which usually is same as the module name in go.mod kitex -module \"your_module_name\" -service a.b.c hello.thrift After running the above command, the kitex compiler will update these files:\n update ./handler.go, adding a simple implementation of the add method. update ./kitex_gen, updating the client and server implementations.  Update handler When you finish the Regenerate Code chapter, kitex will add a basic implementation of Add to ./handler.go, just like:\n// Add implements the HelloImpl interface. func (s *HelloImpl) Add(ctx context.Context, req *api.AddRequest) (resp *api.AddResponse, err error) { // TODO: Your code here...  return } Let’s complete the process logic, such as:\n// Add implements the HelloImpl interface. func (s *HelloImpl) Add(ctx context.Context, req *api.AddRequest) (resp *api.AddResponse, err error) { // TODO: Your code here...  resp = \u0026api.AddResponse{Sum: req.First + req.Second} return } Call the add method Let’s add the add RPC to the client example.\nYou can see something like below in ./client/main.go:\nfor { req := \u0026api.Request{Message: \"my request\"} resp, err := client.Echo(context.Background(), req) if err != nil { log.Fatal(err) } log.Println(resp) time.Sleep(time.Second) } Let’s add the add RPC:\nfor { req := \u0026api.Request{Message: \"my request\"} resp, err := client.Echo(context.Background(), req) if err != nil { log.Fatal(err) } log.Println(resp) time.Sleep(time.Second) addReq := \u0026api.AddRequest{First: 512, Second: 512} addResp, err := client.Add(context.Background(), addReq) if err != nil { log.Fatal(err) } log.Println(addResp) time.Sleep(time.Second) } Run the application again Shut down the server and the client we ran. Then:\n  run server\ngo run .\n  run the client\nOpen another terminal and go run ./client.\nNow you can see the output of the add RPC.\n  Tutorial About Kitex Kitex is a RPC framework which supports multiple serialization protocols and transport protocols.\nKitex compiler supports both thrift and proto3 IDL, and fairly Kitex supports thrift and protobuf serialization protocol. Kitex extends thrift as transport protocol, and also supports gRPC protocol.\nWHY IDL We use IDL to define interface.\nThrift IDL grammar: Thrift interface description language.\nproto3 grammar: Language Guide(proto3).\nCreate project directory Let’s create a directory to setup project.\n$ mkdir example\nenter directory\n$ cd example\nKitex compiler kitex is a compiler which has the same name as Kitex framework, it can generate a project including client and server conveniently.\nInstall You can use following command to install and upgrade kitex:\n$ go install github.com/cloudwego/kitex/tool/cmd/kitex@latest\nAfter that, you can just run it to check whether it’s installed successfully.\n$ kitex\nIf you see some outputs like below, congratulation!\n$ kitex\nNo IDL file found.\nIf you see something like command not found, you should add $GOPATH/bin to $PATH. For detail, see chapter Prerequisites .\nUsage You can visit Compiler for detailed usage.\nWrite IDL For example, a thrift IDL.\ncreate a echo.thrift file, and define a service like below:\nnamespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}serviceEcho{Responseecho(1:Requestreq)}Generate echo service code We can use kitex compiler to compile the IDL file to generate whole project.\n$ kitex -module example -service example echo.thrift\n-module indicates go module name of project，-service indicates expected to generate a executable service named example, the last parameter is path to IDL file.\nGenerated project layout:\n. |-- build.sh |-- echo.thrift |-- handler.go |-- kitex_gen | `-- api | |-- echo | | |-- client.go | | |-- echo.go | | |-- invoker.go | | `-- server.go | |-- echo.go | `-- k-echo.go |-- main.go `-- script `-- bootstrap.sh Get latest Kitex Kitex expect project to use go module as dependency manager. It cloud be easy to upgrade Kitex:\n$ go get github.com/cloudwego/kitex@latest $ go mod tidy If you encounter something like below :\ngithub.com/apache/thrift/lib/go/thrift: ambiguous import: found package github.com/apache/thrift/lib/go/thrift in multiple modules\nOr:\ngithub.com/cloudwego/kitex@v0.X.X/pkg/utils/thrift.go: not enough arguments in call to t.tProt.WriteMessageBegin\nRun following command, and try again:\ngo mod edit -droprequire=github.com/apache/thrift/lib/go/thrift go mod edit -replace=github.com/apache/thrift=github.com/apache/thrift@v0.13.0 This is because the Thrift official release 0.14 introduced a breaking change to the Thrift interface, resulting in generated code that is incompatible.\nWrite echo service process All method process entry should be in handler.go, you should see something like below in this file:\npackage main import ( \"context\" \"example/kitex_gen/api\" ) // EchoImpl implements the last service interface defined in the IDL. type EchoImpl struct{} // Echo implements the EchoImpl interface. func (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) { // TODO: Your code here... \treturn } Echo method represents the echo we defined in thrift IDL.\nNow let’s make Echo a real echo.\nmodify Echo method:\nfunc (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) { return \u0026api.Response{Message: req.Message}, nil } Compile and Run kitex compiler has generated scripts to compile and run the project:\nCompile:\n$ sh build.sh\nThere should be a output directory After you execute above command, which includes compilation productions .\nRun:\n$ sh output/bootstrap.sh\nNow, Echo service is running!\nWrite Client Let’s write a client to call Echo server.\ncreate a directory as client package:\n$ mkdir client\nenter directory:\n$ cd client\ncreate a main.go file.\nCreate Client Let’s new a client to do RPC：\nimport \"example/kitex_gen/api/echo\" import \"github.com/cloudwego/kitex/client\" ... c, err := echo.NewClient(\"example\", client.WithHostPorts(\"0.0.0.0:8888\")) if err != nil { log.Fatal(err) } echo.NewClient is used to new a client, the first parameter is service name, the second parameter is options which is used to pass options. client.WithHostPorts is used to specify server address, see chapter Basic Feature for details.\nDo RPC Let’s write call code:\nimport \"example/kitex_gen/api\" ... req := \u0026api.Request{Message: \"my request\"} resp, err := c.Echo(context.Background(), req, callopt.WithRPCTimeout(3*time.Second)) if err != nil { log.Fatal(err) } log.Println(resp) We new a request req, then we use c.Echo to do a RPC call.\nThe first parameter context.Context, is used to transfer information or to control some call behaviors. You will see detailed usage in behind chapters.\\\nThe seconde parameter is request.\nThe third parameter is call options, which is called callopt, these options only works for this RPC call. callopt.WithRPCTimeout is used to specify timeout for this RPC call. See chapter Basic Feature for detail.\nRun Client You can run following command to run a client:\n$ go run main.go\nYou should see some outputs like below:\n2021/05/20 16:51:35 Response({Message:my request})\nCongratulation! You have written a Kitex server and client, and have done a RPC call.\n","categories":"","description":"This document covers the preparation of the development environment, quick start and basic tutorials of Kitex.","excerpt":"This document covers the preparation of the development environment, …","ref":"/docs/kitex/getting-started/","tags":"","title":"Getting Started"},{"body":" This tutorial gets you started with Netpoll through some simple examples, includes how to use Server, Client and nocopy APIs.\n 1. Use Server Here is a simple server demo, we will explain how it is constructed next.\n1.1 Create Listener First we need to get a Listener, it can be net.Listener or netpoll.Listener, which is no difference for server usage. Create a Listener as shown below:\npackage main import \"net\" func main() { listener, err := net.Listen(network, address) if err != nil { panic(\"create net listener failed\") } ... } or\npackage main import \"github.com/cloudwego/netpoll\" func main() { listener, err := netpoll.CreateListener(network, address) if err != nil { panic(\"create netpoll listener failed\") } ... } 1.2 New EventLoop EventLoop is an event-driven scheduler, a real NIO Server, responsible for connection management, event scheduling, etc.\nparams:\n OnRequest is an interface that users should implement by themselves to process business logic. Code Comment describes its behavior in detail. Option is used to customize the configuration when creating EventLoop, and the following example shows its usage. For more details, please refer to options.  The creation process is as follows:\npackage main import ( \"time\" \"github.com/cloudwego/netpoll\" ) var eventLoop netpoll.EventLoop func main() { ... eventLoop, _ := netpoll.NewEventLoop( handle, netpoll.WithOnPrepare(prepare), netpoll.WithReadTimeout(time.Second), ) ... } 1.3 Run Server EventLoop provides services by binding Listener, as shown below. Serve function will block until an error occurs, such as a panic or the user actively calls Shutdown.\npackage main import ( \"github.com/cloudwego/netpoll\" ) var eventLoop netpoll.EventLoop func main() { ... // start listen loop ... \teventLoop.Serve(listener) } 1.4 Shutdown Server EventLoop provides the Shutdown function, which is used to stop the server gracefully. The usage is as follows.\npackage main import ( \"context\" \"time\" \"github.com/cloudwego/netpoll\" ) var eventLoop netpoll.EventLoop func main() { // stop server ... \tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() eventLoop.Shutdown(ctx) } 2. Use Dialer Netpoll also has the ability to be used on the Client side. It provides Dialer, similar to net.Dialer. Again, here is a simple client demo, and then we introduce it in detail.\n2.1 The Fast Way Similar to Net, Netpoll provides several public functions for directly dialing a connection. such as:\nDialConnection(network, address string, timeout time.Duration) (connection Connection, err error) DialTCP(ctx context.Context, network string, laddr, raddr *TCPAddr) (*TCPConnection, error) DialUnix(network string, laddr, raddr *UnixAddr) (*UnixConnection, error) 2.2 Create Dialer Netpoll also defines the Dialer interface. The usage is as follows: (of course, you can usually use the fast way)\npackage main import ( \"github.com/cloudwego/netpoll\" ) func main() { // Dial a connection with Dialer. \tdialer := netpoll.NewDialer() conn, err := dialer.DialConnection(network, address, timeout) if err != nil { panic(\"dial netpoll connection failed\") } ... } 3. Use Nocopy API Connection provides Nocopy APIs - Reader and Writer, to avoid frequent copying. Let’s introduce their simple usage.\npackage main type Connection interface { // Recommended nocopy APIs \tReader() Reader Writer() Writer ... // see code comments for more details } 3.1 Simple Usage Nocopy APIs is designed as a two-step operation.\nOn Reader, after reading data through Next, Peek, ReadString, etc., you still have to actively call Release to release the buffer(Nocopy reads the original address of the buffer, so you must take the initiative to confirm that the buffer is no longer used).\nSimilarly, on Writer, you first need to allocate a buffer to write data, and then call Flush to confirm that all data has been written. Writer also provides rich APIs to allocate buffers, such as Malloc, WriteString and so on.\nThe following shows some simple examples of reading and writing data. For more details, please refer to the code comments.\npackage main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection var reader, writer = conn.Reader(), conn.Writer() // reading \tbuf, _ := reader.Next(n) ... parse the read data ... reader.Release() // writing \tvar write_data []byte ... make the write data ... alloc, _ := writer.Malloc(len(write_data)) copy(alloc, write_data) // write data \twriter.Flush() } 3.2 Advanced Usage If you want to use the connection to send (or receive) multiple sets of data, then you will face the work of packing and unpacking the data.\nOn net, this kind of work is generally done by copying. An example is as follows:\npackage main import ( \"net\" ) func main() { var conn net.Conn var buf = make([]byte, 8192) // reading \tfor { n, _ := conn.Read(buf) ... unpacking \u0026 handling ... var i int for i = 0; i \u003c= n-pkgsize; i += pkgsize { pkg := append([]byte{}, buf[i:i+pkgsize]...) go func() { ... handling pkg ... } } buf = append(buf[:0], buf[i:n]...) } // writing \tvar write_datas \u003c-chan []byte ... packing write ... for { pkg := \u003c-write_datas conn.Write(pkg) } } But, this is not necessary in Netpoll, nocopy APIs supports operations on the original address of the buffer, and realizes automatic recycling and reuse of resources through reference counting.\nExamples are as follows(use function Reader.Slice and Writer.Append):\npackage main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection // reading \treader := conn.Reader() for { ... unpacking \u0026 handling ... pkg, _ := reader.Slice(pkgsize) go func() { ... handling pkg ... pkg.Release() } } // writing \tvar write_datas \u003c-chan netpoll.Writer ... packing write ... writer := conn.Writer() for { select { case pkg := \u003c-write_datas: writer.Append(pkg) default: if writer.MallocLen() \u003e 0 { writer.Flush() } } } } ","categories":"","description":"","excerpt":" This tutorial gets you started with Netpoll through some simple …","ref":"/docs/netpoll/getting-started/","tags":"","title":"Getting Started"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/releases/hertz/","tags":"","title":"Hertz Release"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/","tags":"","title":"Hertz"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/blog/releases/hertz/","tags":"","title":"Hertz Release"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/","tags":"","title":"Hertz"},{"body":"The cwgo tool supports the generation of MVC Layout at present, and more templates will be expanded for users to use in the future.\nCode Structure The MVC layout is automatically generated when the server code is generated using the cwgo tool. When using the demo in Quick Start, the generated HTTP project directory is as follows\n├── biz // business logic directory │ ├── dal // data access layer │ │ ├── init.go │ │ ├── mysql │ │ │ └── init.go │ │ └── redis │ │ └── init.go │ ├── handler // view layer │ │ └── hello │ │ └── example | │ │ └── hello_service_test.go // single test file │ ├── router // generated code related to routes defined in idl │ │ ├── hello │ │ │ └── example // hello/example corresponds to the namespace defined in thrift idl; for protobuf idl, it corresponds to the last level of go_package │ │ │ ├── hello.go // The route registration code generated by cwgo for the route defined in hello.thrift; every update related idl will regenerate the file │ │ │ └── middleware.go // Default middleware function, hz adds a middleware to each generated routing group by default; when updating, it will search for existing middleware in the current file and append new middleware at the end │ │ └── register.go // call to register the routing definition in each idl file; when a new idl is added, it will automatically insert its routing registration call when updating; do not move │ ├── service // service layer, where business logic is stored. When updating, the new method appends the file. │ │ ├── hello_method.go specific business logic │ │ └── hello_method_test.go │ └── utils // tool directory │ └── resp.go ├── build.sh // compile script ├── conf // Store configuration files in different environments │ └── ... ├── docker-compose.yaml ├── go.mod // go.mod file, if not specified on the command line, the relative path relative to GOPATH will be used as the module name by default ├── hertz_gen // Generate code related to IDL content │ └── ... ├── idl │ └── hello.thrift ├── main.go // program entry ├── readme.md └── script // startup script └── bootstrap.sh The RPC project directory is as follows\n├── biz // business logic directory │ ├── dal // data access layer │ │ ├── init.go │ │ ├── mysql │ │ │ └── init.go │ │ └── redis │ │ └── init.go │ └── service // service layer, where business logic is stored. When updating, the new method appends the file. │ ├── HelloMethod.go │ └── HelloMethod_test.go ├── build.sh ├── conf // Store configuration files in different environments │ └── ... ├── docker-compose.yaml ├── go.mod // go.mod file, if not specified on the command line, the relative path relative to GOPATH will be used as the module name by default ├── handler.go // Business logic entry, will be fully covered when updated ├── idl │ └── hello. thrift ├──kitex.yaml ├── kitex_gen // Generate code related to IDL content, do not touch │ └── ... ├── main.go // program entry ├── readme.md └── script // startup script └── bootstrap.sh ","categories":"","description":"","excerpt":"The cwgo tool supports the generation of MVC Layout at present, and …","ref":"/docs/cwgo/tutorials/layout/","tags":"","title":"Layout"},{"body":"cwgo 工具支持目前支持生成 MVC Layout，未来还会拓展更多的模板供用户使用。\n代码结构 使用 cwgo 工具生成 server 代码时会自动生成 MVC layout。完成快速上手里面的步骤指引，会在本地生成一个 demo，其 HTTP 项目目录如下:\n├── biz // 业务逻辑目录 │ ├── dal // 数据访问层 │ │ ├── init.go │ │ ├── mysql │ │ │ └── init.go │ │ └── redis │ │ └── init.go │ ├── handler // view 层 │ │ └── hello │ │ └── example │ │ ├── hello_service.go // handler 文件，用户在该文件里实现 IDL service 定义的方法，update 时会查找当前文件已有的 handler 后，在尾部追加新的 handler │ │ └── hello_service_test.go // 单测文件 │ ├── router // idl 中定义的路由相关生成代码 │ │ ├── hello │ │ │ └── example // hello/example 对应 thrift idl 中定义的namespace；而对于 protobuf idl，则是对应 go_package 的最后一级 │ │ │ ├── hello.go // cwgo 为 hello.thrift 中定义的路由生成的路由注册代码；每次 update 相关 idl 会重新生成该文件 │ │ │ └── middleware.go // 默认中间件函数，hz 为每一个生成的路由组都默认加了一个中间件；update 时会查找当前文件已有的 middleware 在尾部追加新的 middleware │ │ └── register.go // 调用注册每一个 idl 文件中的路由定义；当有新的 idl 加入，在更新的时候会自动插入其路由注册的调用；勿动 │ ├── service // service 层，业务逻辑存放的地方。更新时，新的方法会追加文件。 │ │ ├── hello_method.go 具体的业务逻辑 │ │ └── hello_method_test.go │ └── utils // 工具目录 │ └── resp.go ├── build.sh // 编译脚本 ├── conf // 存放不同环境下的配置文件 │ └── ... ├── docker-compose.yaml ├── go.mod // go.mod 文件，如不在命令行指定，则默认使用相对于GOPATH的相对路径作为 module 名 ├── hertz_gen // IDL 内容相关的生成代码 │ └── ... ├── idl │ └── hello.thrift ├── main.go // 程序入口 ├── readme.md └── script // 启动脚本 └── bootstrap.sh RPC 项目目录如下\n├── biz // 业务逻辑目录 │ ├── dal // 数据访问层 │ │ ├── init.go │ │ ├── mysql │ │ │ └── init.go │ │ └── redis │ │ └── init.go │ └── service // service 层，业务逻辑存放的地方。更新时，新的方法会追加文件。 │ ├── HelloMethod.go │ └── HelloMethod_test.go ├── build.sh ├── conf // 存放不同环境下的配置文件 │ └── ... ├── docker-compose.yaml ├── go.mod // go.mod 文件，如不在命令行指定，则默认使用相对于GOPATH的相对路径作为 module 名 ├── handler.go // 业务逻辑入口，更新时会全量覆盖 ├── idl │ └── hello.thrift ├── kitex.yaml ├── kitex_gen // IDL 内容相关的生成代码，勿动 │ └── ... ├── main.go // 程序入口 ├── readme.md └── script // 启动脚本 └── bootstrap.sh ","categories":"","description":"","excerpt":"cwgo 工具支持目前支持生成 MVC Layout，未来还会拓展更多的模板供用户使用。\n代码结构 使用 cwgo 工具生成 server  …","ref":"/zh/docs/cwgo/tutorials/layout/","tags":"","title":"Layout"},{"body":"**Currently, annotations are only supported for thrift idl. **\npilota.name You can use pilota.name to specify an alias for generating rust code, for example:\nconststringid=\"id\"(pilota.name=\"LANG_ID\");// will use LANG_ID to generate the corresponding structure // pub const LANG_ID: \u0026'static str = \"id\"; structTest{1:requiredstringID,2:requiredstringId (pilota.name=\"hello\"),// hello will be used instead of id as the field name of the Rust structure }pilota.rust_type Currently thrift’s string will generate FastStr with better performance by default, but FastStr does not support modification (but it can be modified after to_string). If you need to use the native String type, you need to add pilota.rust_type = \"string\" annotation:\nstructA{1:requiredstringfaststr,2:requiredstringstring(pilota.rust_type=\"string\"),}pilota.rust_wrapper_arc Arc wrapper can be added to the specified field type. If the field is a container type such as list map set, then an Arc wrapper will be added to the innermost type of the container.\nstructTEST{1:requiredAName2(pilota.rust_wrapper_arc=\"true\"),// will generate Arc\u003cA\u003e 2:requiredlist\u003clist\u003cA\u003e\u003eName2(pilota.rust_wrapper_arc=\"true\"),// will generate Vec\u003cVec\u003cArc\u003cA\u003e\u003e\u003e 3:requiredmap\u003ci32,list\u003cA\u003e\u003eName3(pilota.rust_wrapper_arc=\"true\"),// will generate Map\u003ci32, Vec\u003cArc\u003cA\u003e\u003e\u003e }","categories":"","description":"","excerpt":"**Currently, annotations are only supported for thrift idl. ** …","ref":"/docs/pilota/guide/annotation/","tags":"","title":"Pilota Supported Annotations"},{"body":"目前注解仅对 thrift idl 做了支持。\npilota.name 可以通过 pilota.name 来指定生成 rust 代码的别名，比如：\nconststringid=\"id\"(pilota.name=\"LANG_ID\");/// 会使用 LANG_ID 生成对应的结构 // pub const LANG_ID: \u0026'static str = \"id\"; structTest{1:requiredstringID,2:requiredstringId (pilota.name=\"hello\"),// 会生用 hello 代替 id 来作为 Rust 结构的字段名 }pilota.rust_type 目前 thrift 的 string 会默认生成性能更好的 FastStr，但是 FastStr 并不支持修改（但是可以 to_string 后修改）。如果需要使用原生的 String 类型，需要加上 pilota.rust_type = “string” 的注解：\nstructA{1:requiredstringfaststr,2:requiredstringstring(pilota.rust_type=\"string\"),}pilota.rust_wrapper_arc 可以对为指定的字段类型增加 Arc wrapper。如果该字段为 list map set 等容器类型，那么则会为容器的最里层类型增加 Arc wrapper。\nstructTEST{1:requiredAName2(pilota.rust_wrapper_arc=\"true\"),// 会生成 Arc\u003cA\u003e 2:requiredlist\u003clist\u003cA\u003e\u003eName2(pilota.rust_wrapper_arc=\"true\"),// 会生成 Vec\u003cVec\u003cArc\u003cA\u003e\u003e\u003e 3:requiredmap\u003ci32,list\u003cA\u003e\u003eName3(pilota.rust_wrapper_arc=\"true\"),// 会生成 Map\u003ci32, Vec\u003cArc\u003cA\u003e\u003e\u003e }","categories":"","description":"","excerpt":"目前注解仅对 thrift idl 做了支持。\npilota.name 可以通过 pilota.name 来指定生成 rust 代码的别名， …","ref":"/zh/docs/pilota/guide/annotation/","tags":"","title":"Pilota 支持的注解"},{"body":"在 Tower 的 Service 中，有一个方法 poll_ready，用来在请求之前先确定下游 Service 有足够的处理能力，并在处理能力不足时提供背压。 这是一个非常精妙的设计，Tower 在 inventing-the-service-trait 这篇介绍文章中，也有详细介绍这么设计的原因。\n但是在我们真实的开发体验中，我们总结出了以下的经验：\n 绝大多数的 poll_ready 的实现都是直接 self.inner.poll_ready(cx)；剩下的 poll_ready 实现更干脆，直接 Poll::Ready(Ok(()))。 poll_ready 一般不会真正跨服务去 check 负载（也就是说，不会真的发个请求问下游“大兄弟，你还能支棱起来不？”），所以一般也就是在本地的中间件（比如 Tower 的例子是速率限制中间件）里面根据某些特定条件判断一下。 基于上两条，几乎所有的 poll_ready 场景，我们都可以直接在 call 里面做达到一样的效果，因为实践中外层的 service 在返回 Poll::Pending 的时候就是空等，不如直接采用 async-await 的方式来编写代码，更符合人体工程学。 至于（可能的）资源浪费的问题，一般来说可能发生拦截的中间件，肯定是放在越前面越好，所以通过合理地排布中间件的顺序，就能解决这个问题。  因此，出于“如无必要勿增实体”的原则，也为了提升易用性，我们最终决定在我们的设计中不包含 poll_ready 方法。\n","categories":"","description":"","excerpt":"在 Tower 的 Service 中，有一个方法 poll_ready，用来在请求之前先确定下游 Service 有足够的处理能力，并在处 …","ref":"/zh/docs/motore/faq/q2_pull_ready/","tags":"","title":"poll_ready（背压）哪去了？"},{"body":"Overview Thanks to the layered design of Hertz, in addition to the HTTP1/HTTP2 (to be open source) protocol server that comes with the Hertz framework by default, users can easily add/customize protocol processing logic that meets the needs of their own business scenarios according to their own needs.\nIn short, a server that implements the following interface can be added to Hertz as a custom extension server:\ntype Server interface { Serve(c context.Context, conn network.Conn) error } Three elements of protocol layer extension Protocol layer server initialization Because the interface mentioned in the overview is actually a standard callback after the data is prepared at the network layer, the processing logic of our protocol layer will only be entered after a new request is established for a connection.\nIn this logic, we can customize the protocol parsing method, introduce business Handler execution, write data back and other standard behaviors of the protocol layer. This is also the core logic of our custom server.\ntype myServer struct{ xxx xxx } func (s *myServer) Serve (c context.Context, conn network.Conn) error{ // protocol parsing \t... // Go to the logic function of business registration (Route, Middleware, Handler...) \t... // write data back \t... } Defining a protocol processing logic is as simple as that! However, the two steps of parsing the protocol and writing data back can be easily achieved through the conn interface provided in the input parameters, but how to go to the logical function of business registration?\nInteraction with upper-level logic A complete protocol must introduce business logic control (except for very few special situations), so how does the custom protocol in the Hertz framework realize this part of the ability? In fact, in the process of custom server initialization, the framework has naturally handed over this part of the capabilities to the custom protocol server.\ntype ServerFactory interface { New(core Core) (server protocol.Server, err error) } // Core is the core interface that promises to be provided for the protocol layer extensions type Core interface { // IsRunning Check whether engine is running or not  IsRunning() bool // A RequestContext pool ready for protocol server impl  GetCtxPool() *sync.Pool // Business logic entrance  // After pre-read works, protocol server may call this method  // to introduce the middlewares and handlers  ServeHTTP(c context.Context, ctx *app.RequestContext) // GetTracer for tracing requirement  GetTracer() tracer.Controller } A custom server only needs to implement a protocol server generation factory according to the above interface. The Core in the parameters actually includes the introduction of upper-layer logic interaction and the specific implementation of other core application layer interfaces. When initializing a custom server, normally you only need to save the Core to the server. When you need to transfer to the business logic, you can guide the process to the application layer processing logic (Route, Middleware, Logic Handler) through the Core. When the business logic is executed and returned, further packets can be written back based on the business data.\ntype myServer struct{ suite.Core xxx } func (s *myServer) Serve (c context.Context, conn network.Conn) error{ // protocol parsing \t... Core.ServeHTTP(c, ctx) // write data back \t... } So far, a custom protocol layer server has been developed.\nRegistration of custom protocol server into Hertz After completing the development of the server generation factory according to the above interface, it is very easy to load it into Hertz. Hertz’s core engine naturally provides an interface for registering a custom protocol server:\nfunc (engine *Engine) AddProtocol(protocol string, factory suite.ServerFactory) { engine.protocolSuite.Add(protocol, factory) } It is only necessary to register the user’s custom server generation factory with the engine according to the parameters specified by the interface. But it is worth noting that the protocol (string) registered here actually corresponds to the protocol negotiation key in ALPN (Application-Layer Protocol Negotiation), so if you want to access a custom protocol server through ALPN , directly specify the key as the corresponding key during ALPN negotiation. Currently, Hertz integrates an HTTP1 protocol server by default (the corresponding key is “http/1.1”). If you need to customize the HTTP1 protocol processing logic, you can directly specify the key as “http/1.1” within AddProtocol to overwrite.\nExample package main import ( \"bytes\" \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/errors\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/network\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/cloudwego/hertz/pkg/protocol/suite\" ) type myServer struct { suite.Core } func (m myServer) Serve(c context.Context, conn network.Conn) error { firstThreeBytes, _ := conn.Peek(3) if !bytes.Equal(firstThreeBytes, []byte(\"GET\")) { return errors.NewPublic(\"not a GET method\") } ctx := m.GetCtxPool().Get().(*app.RequestContext) defer func() { m.GetCtxPool().Put(ctx) conn.Skip(conn.Len()) conn.Flush() }() ctx.Request.SetMethod(\"GET\") ctx.Request.SetRequestURI(\"/test\") m.ServeHTTP(c, ctx) conn.WriteBinary([]byte(\"HTTP/1.1 200 OK\\n\" + \"Server: hertz\\n\" + \"Date: Sun, 29 May 2022 10:49:33 GMT\\n\" + \"Content-Type: text/plain; charset=utf-8\\n\" + \"Content-Length: 2\\n\\nok\\n\")) return nil } type serverFactory struct { } func (s *serverFactory) New(core suite.Core) (server protocol.Server, err error) { return \u0026myServer{ core, }, nil } func main() { h := server.New() h.GET(\"/test\", func(c context.Context, ctx *app.RequestContext) { hlog.Info(\"in handler\") }) h.AddProtocol(\"http/1.1\", \u0026serverFactory{}) h.Spin() } ","categories":"","description":"","excerpt":"Overview Thanks to the layered design of Hertz, in addition to the …","ref":"/docs/hertz/tutorials/framework-exten/advanced-exten/protocol/","tags":"","title":"Protocol extension"},{"body":"案例介绍   近些年电商行业高速发展，森马电商线上业务激增，面临着高并发、高性能的业务场景需求。森马通过使用 Kitex 接入 Istio，极大地提高了对高并发需求的处理能力。\n本文将从四个方面为大家讲解 Kitex 在森马电商场景下的落地实践：\n 森马电商订单流转中心——天枢所面临的业务挑战； 项目的技术选型过程； 项目上线性能压测对比； CloudWeGo 团队的技术支持。  森马电商订单流转中心——天枢 业务增长 第一部分给大家介绍订单流转中心——天枢。天枢的主要功能是对接各大电商平台，把订单、商品、退单等信息统一处理后流转到下游系统，是下游系统和平台对接的中间枢纽。 目前森马电商在运营的电商平台几十家，如：天猫、抖店、京东、拼多多等，由于每个平台的接口和对接的方式不统一，我们专门开发了这套系统，去统一对接电商平台，然后把数据处理成统一的格式发到下游系统，如：OMS 和 WMS。 该系统在电商活动，如 6·18，双十一等订单峰值流量下发挥了重要作用。\n从 2015 年至 2021 年，森马的双十一业务量增长非常迅速。2015 年双十一的业绩有 3 亿+，而去年的双十一业绩为 20 亿+，2021 年商品交易总额（GMV） 更是突破百亿。 随着业务的增长，对订单系统的性能和稳定性要求越来越高。而且随着系统的规模增长，集群内的 Pod 数量和 Service 不断增加，对系统底层架构有很大的考验。 目前从旧系统迁移的平台有：有赞、抖音、拼多多、快手等，集群内的 Pod 数已经超过 200 个，后续会接入京东、唯品会、天猫等平台后，Pod 数会成倍的增长，更需要一个成熟的系统架构作为支撑。\n面临的问题 随着直播行业的兴起，我们请了一些网红主播和流量明星来直播带货。直播期间，订单量经常会出现几秒内突然爆发的情况，订单推送到系统后，如果系统处理较慢，订单就不能及时流入下游系统， 下游系统的 OMS 不知道已经产生如此大的订单量，就会出现不能同步的情况，即超卖现象。在电商行业，超卖是很严重的问题，如果用户下单后不能及时发货，不仅需要大量的人力去跟客户解释道歉， 也要以优惠券等形式赔偿用户遭受的损失，甚至会接到大量投诉，严重影响我们在电商平台的信誉，电商平台也会对我们进行处罚。我们经历过当 GMV 超过千万时，订单系统延迟超过半个小时的情况，对我们造成了极大的影响。 因此，当遇到如双十一，6·18 大促等活动时，特别是在直播时订单量短时间内暴增的情况下，我们原有的系统架构已经无法支撑，不能及时处理订单数据。这影响了我们发货及库存同步，间接地产生了不同类型的资损。\n技术挑战 我们在技术上面临的挑战主要有以下三个方面：\n 高并发。在电商业务场景下，不管是面向用户，比如秒杀，还是面向业务，比如订单处理，如果实现不了高并发，系统就很难做大，很难适应业务的增长。 高性能。除了用高并发来实现业务的快速处理外，性能也是一个挑战。例如在当前疫情状态下，各行各业都在降本增效，解决不了性能问题，就会不断地增加服务器资源，大大增加企业成本。 技术保障。我们电商行业的公司，大多资源和精力都在销售端，运营端，技术方面投入相对薄弱。因此在技术选型上需要从可靠、安全、支持等维度去考量。  项目的技术选型 如何选择 在开发语言的选择方面，开发语言没有好坏之分，只有这个语言在相关场景下合适不合适的问题。我们从性能、多线程、编译、效率等方面综合考虑，选择了 Golang。\n在微服务框架的选择方面，团队分别用 Google 开源的 gRPC 和字节跳动开源的 CloudWeGo-Kitex 做了技术评估和性能压测。经过专业测试同学的压力测试，最终选择了 CloudWeGo-Kitex 作为我们的微服务框架。\n选择 Kitex 的原因主要有两点。第一是 Kitex 背后有强大的技术团队提供及时有效的技术支持。第二是经过压力测试，Kitex 的性能优于其他微服务框架。\n关于微服务 使用微服务框架，一定会涉及到选择第三方开源的服务注册中心，那么是选择常用的开源注册中心（Zookeeper、Eureka、Nacos、Consul 和 ETCD）， 还是直接选择云原生的服务网格（Istio）？那么我从流量转发、服务注册和服务发现维度介绍一下微服务集群的两种形式。\n第一种是 Kubernetes Native，Kubernetes 集群中的每个节点都部署了一个 Kube-proxy 组件，该组件与 Kubernetes API Server 进行通信，观测服务和节点中的变化，进行负载均衡的转发。 这种开源注册中心默认使用 TCP 协议，由于 K8s 负载均衡不支持 RPC 协议（HTTP2），因而需要额外的第三方服务注册中心支持。\n第二种是基于 Istio 的服务网格，它并不需要额外的注册中心组件支持。Istio 接管了 K8s 的网络，通过 Sidecar Proxy 的方式将 Kubernetes 中的流量控制从服务层中抽离出来， Istio 基于 Enovy 的 xDS 协议扩展了其控制平面，每个 Pod 中放入原有的 Kube-proxy 路由转发功能。Istio 具备了流量管理、策略控制、可观察性等特点，将“应用程序”与“网络”解耦，因此不需要额外使用第三方注册中心。\n 那么这两种服务注册与发现的流程是怎样的呢？ 下图中左侧就是常用的服务注册中心使用流程。目标服务先把实例注册到服务注册中心，客户端从服务注册中心拿到目标实例的数据，根据负载均衡策略去选择一个服务实例，完成整个请求。 右侧是使用了基于 Istio 的服务网格。大概流程是 Client 访问目标服务的时候，流量先进入 Service 的 Proxy，被 Proxy 拦截，Proxy 会从服务发现（Pilot）拿到服务与服务实例的映射关系， 同时会拿到负载均衡的策略，去选择 Service 一个实例。总体来看，这两种流程大致相同，但实现方式有所差别，各有所长。\n天枢系统基本架构 像抖音、快手、拼多多和有赞等这样成熟的平台在产生订单时，都会将订单以消息推送的形式发送到服务网格中。我们先后通过 Ingress Gateway 网格入口管理程序、VirtualService 把订单转发到网格的不同服务中， 内部再通过不同服务之间进行调用。其中，Kitex 作为微服务的 RPC 框架，服务发现和服务注册均是基于云原生的服务网格 Istio。\nKitex 接入 Istio 那么 Kitex 接入 Istio 是怎么实现的呢？如下图所示，服务端注册服务之后，在创建客户端的时候，客户端的 Server-host 要写实际集群中的内网地址，例如：server-douyin.default.svc.cluster.local，如上文所说，不用再搭配第三方的服务注册中心。\n由于 Kitex 使用 gRPC 协议，在创建客户端的时候需指定使用 gRPC 协议：\n在 Istio 中怎么部署我们的客户端或者服务端呢？有以下两种方式：\n 为命名空间开启自动注入：kubectl label namespace default istio-injection=enabled。注入之后会产生两个重要的容器，第一个是 Istio-proxy，负责流量拦截和流量代理，比如做流量转发；第二个是 Server-douyin，是负责开发的应用容器。  把 Go 代码打包的镜像部署到集群中： 例如我们创建了一个 Deployment，名为 Server-douyin，另外作为服务端需要创建相应的 Service。  压测对比 我们将 Kitex 和 gRPC 在以下相同服务器硬件资源和网络环境下进行了压测对比：\n 压测工具：JMeter； 阿里云 ECS （8 vCPU，16 GiB，5 台）； 集群：Kubernetes 1.20.11； 服务网格：Istio v1.10.5.39。  通过对比发现，在指定时间相同的情况下，Kitex 在单位时间内处理订单数量更多。在指定订单数量的情况下，Kitex 对于处理相同数量的订单所需时间更短，且订单量越大，这种性能差别越明显。总体来看，Kitex 在处理大批订单时优势还是非常突出的。\nKitex 产生性能优势的原因 CloudWeGo 团队来森马做技术支持时讲到对自研网络库 Netpoll 做了一些性能优化，比如：\n 连接利用率； 调度延迟优化； 优化 I/O 调用； 序列化/反序列化优化； …….  更多资料可以查看 CloudWeGo 官网或参考官网博客\nCloudWeGo 团队的技术支持 我们选择 Kitex 之后，CloudWeGo 技术团队给予了足够的技术支持，包括现场支持和远程协助。这也让我们对使用 Kitex 有了信心，不管遇到什么样的技术难题，都会有强大的技术团队来协助解决。\n后续规划 Thrift 和 Protobuf 如何选择 我们在项目初期选择 gRPC 协议 Protobuf 是因为选择了 Istio 服务网格，而选择 Istio 服务网格主要是因为它有多流量转发和服务治理等功能，例如在电商场景下， 不同平台的推送消息都可以通过 VirtualService 转发到不同的服务，相当方便。但是目前每个 Pod 中放入原有的 Kube-proxy 路由转发功能，会增加响应延迟。由于 Sidecar 拦截流量时跳数更多，会消耗更多的资源。\n而对于 Thrift，它是 Kitex 默认支持的协议，字节官方对它做了很多性能上的优化，如：使用 SIMD 优化 Thrift 编码，减少函数调用，减少内存操作等，还开源了高性能 Thrift 编解码器 Frugal， Frugal 具有无需生成代码、高性能（在多核场景下，Frugal 的性能可以达到传统编解码方式的 5 倍）和稳定性等特点，进一步提升了性能和开发效率。\n因此，我们目前也在考虑在下一次系统版本的架构中改用 Thrift 协议。\n服务、合作共赢 我们开发的电商相关产品不仅可以为自己电商品牌所使用，产品成熟后还可以服务于其他相似的电商公司。后续我们也希望能够和 Kitex 官方有更深的技术合作，为社区带来更大价值。\n","categories":"","description":"","excerpt":"案例介绍   近些年电商行业高速发展，森马电商线上业务激增，面临着高并发、高性能的业务场景需求。森马通过使用 Kitex 接入 Istio， …","ref":"/cooperation/semir/","tags":"","title":"Kitex 在森马电商场景的落地实践"},{"body":"In microservices, link tracing is a very important capability, which plays an important role in quickly locating problems, analyzing business bottlenecks, and restoring the link status of a request. Hertz provides the capability of link tracking and also supports user-defined link tracking.\nHertz abstracts trace as the following interface：\n// Tracer is executed at the start and finish of an HTTP. type Tracer interface { Start(ctx context.Context, c *app.RequestContext) context.Context Finish(ctx context.Context, c *app.RequestContext) } Use the server.WithTracer() configuration to add a tracer, you can add multiple tracers.\nHertz will execute the Start method of all tracers before the request starts (before reading the packet), and execute the Finish method of all tracers after the request ends (after writing back the data). Care should be taken when implementing this：\n When the Start method is executed, it just starts accepting packets, and at this time requestContext is an “empty” requestContext, so we can’t get information about this request. If you want to get some information (such as the traceID in the header, etc.) after unpacking, you can use the middleware capability to inject the traceID into the span. Changes to the context within the middleware are invalid.  There is traceInfo in the requestContext memory, which has the following information\ntype HTTPStats interface { Record(event stats.Event, status stats.Status, info string) // Recording events  GetEvent(event stats.Event) Event // Get events  SendSize() int // Get SendSize  RecvSize() int // Get RecvSize  Error() error // Get Error  Panicked() (bool, interface{}) // Get Panic  Level() stats.Level // Get the current trace level  SetLevel(level stats.Level) // Set the trace level to not report when the event level is higher than the trace level  ... } Events include：\nHTTPStart = newEvent(httpStart, LevelBase) // Request start HTTPFinish = newEvent(httpFinish, LevelBase) // Request end  ServerHandleStart = newEvent(serverHandleStart, LevelDetailed) // Business handler start ServerHandleFinish = newEvent(serverHandleFinish, LevelDetailed) // Business handler end ReadHeaderStart = newEvent(readHeaderStart, LevelDetailed) // Read header start ReadHeaderFinish = newEvent(readHeaderFinish, LevelDetailed) // Read header end ReadBodyStart = newEvent(readBodyStart, LevelDetailed) // Read body start ReadBodyFinish = newEvent(readBodyFinish, LevelDetailed) // Read body end WriteStart = newEvent(writeStart, LevelDetailed) // Write response start WriteFinish = newEvent(writeFinish, LevelDetailed) // Write response end The above information is available at Finish\nAt the same time, if you don’t want to log this information, you don’t have to register any tracer, and the framework stops logging this information.\nAn extension for opentracing is provided in hertz-contrib, and a demo for calling from http to rpc is also available in hertz-examples.\nRelated Repository： https://github.com/hertz-contrib/tracer\n","categories":"","description":"","excerpt":"In microservices, link tracing is a very important capability, which …","ref":"/docs/hertz/tutorials/observability/tracing/","tags":"","title":"Tracing"},{"body":"Hertz complies with the Semantic Version 2.0.0 release version.\n Master version number: Upgrade this version number if the API provided by Hertz becomes incompatible Secondary version number: Upgrade this version number when Hertz provides new features while maintaining backward compatibility Revision number: Upgrade this version number when Hertz’s code provides minor features or backward-compatible optimizations and issue fixes  ","categories":"","description":"","excerpt":"Hertz complies with the Semantic Version 2.0.0 release version. …","ref":"/docs/hertz/reference/version/","tags":"","title":"Version Descriptions"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/volo/volo-thrift/","tags":"","title":"Volo-Thrift"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/volo/volo-thrift/","tags":"","title":"Volo-Thrift"},{"body":" SUPPORT Vulnerability Management   # Vulnerability Response   CloudWeGo 社区非常重视社区版本的安全性，CloudWeGo 安全委员会负责接收、调查和披露 CloudWeGo 社区相关的安全漏洞。我们鼓励漏洞研究人员和行业组织主动将 CloudWeGo 社区的疑似安全漏洞报告给 CloudWeGo 社区安全委员会。我们会快速的响应、分析和解决上报的安全问题或安全漏洞。\n# Supported Version  漏洞响应流程主要支持 CloudWeGo 社区各个子项目的最新版本，如果您还没有升级请尽快升级。\n# Vulnerability Handling Process 每个一个安全漏洞都会有一个指定的人员进行跟踪和处理，协调员是 CloudWeGo 安全委员会的成员，他将负责跟踪和推动漏洞的修复和披露。漏洞端到端的处理流程如下图。\n在这里我们主要介绍流程中漏洞上报、漏洞评估和漏洞披露这三部分内容。\n# Vulnerability Report 如果您认为 CloudWeGo 产品存在一个疑似安全漏洞，我们希望您将漏洞上报给 CloudWeGo 社区，并与我们配合以负责任的方式修复和披露该问题。\n# Reporting Methods 您可以通过 email 将 CloudWeGo 产品的潜在安全漏洞发送到 CloudWeGo 安全团队邮箱（security@cloudwego.io）。 # Reporting Methods 为了便于快速的确认和验证疑似漏洞，请在漏洞上报邮件中包含但不限于以下内容：\n 基本信息：包括漏洞影响的模块、漏洞的触发条件和成功利用后对系统的影响等。\n 技术细节：包括系统配置、定位方法、Exploit 的描述、POC、问题重现方法和步骤等。\n 修复方案建议。\n 上报者的组织和联系方式。\n 上报者可能的漏洞披露计划。\n  # Email Response Time 我们将在48小时内响应通过邮箱上报的疑似安全漏洞，并向上报者反馈漏洞处理的进展。\n# Vulnerability Severity Assessment  业界普遍使用 CVSS 标准评估漏洞的严重性，CloudWeGo 在使用 CVSSv3 进行漏洞评估时，需要设定漏洞攻击场景，基于在该攻击场景下的实际影响进行评估。漏洞严重等级评估是指针对漏洞利用难易程度，以及利用后对机密性、完整性、可用性的影响进行评估，并生成一个评分值。\n# Assessment Criteria CloudWeGo 社区采用 CVSS v3对漏洞进行评估，CVSS V3 由通过对以下向量来评估一个漏洞的影响：\n 攻击向量（AV）-表示攻击的“远程性”以及如何利用此漏洞。\n 攻击复杂性（AC）-讲述攻击执行的难度以及成功进行攻击需要哪些因素。\n 用户交互（UI）-确定攻击是否需要用户参与。\n 所需的权限（PR）-记录成功进行攻击所需的用户身份验证级别。\n 范围（S）-确定攻击者是否可以影响具有不同权限级别的组件。\n 机密性（C）-衡量信息泄露给非授权方后导致的影响程度。\n 完整性（I）-衡量信息被篡改后导致的影响程度。\n 可用性（A）-衡量用户在需要访问数据或服务时受影响的程度。\n  # Assessment Principles  评估漏洞的严重等级，不是评估风险。\n 评估时必须基于攻击场景，且保证在该场景下，攻击者成功攻击后能对系统造成机密性、完整性、可用性影响。\n 当安全漏洞有多个攻击场景时，应以造成最大的影响，即 CVSS 评分最高的攻击场景为依据。\n 被嵌入调用的库存在漏洞，要根据该库在产品中的使用方式，确定漏洞的攻击场景后进行评估。\n 安全缺陷不能被触发或不影响 CIA(机密性/完整性/可用性)，CVSS 评分为0分。\n  # Assessment Steps 对漏洞进行评估时，可根据下述步骤进行操作：\n 设定可能的攻击场景，基于攻击场景评分。\n 确定漏洞组件（Vulnerable Component）和受影响组件（Impact Component）。\n 选择基础评估指标的值：通过对可利用指标（攻击向量/攻击复杂度/所需权限/用户交互/范围）和受影响指标（机密性/完整性/可用性）给出漏洞影响评估。\n  # Severity Classification   严重等级（Severity Rating） CVSS评分（Score）   致命（Critical） 9.0 - 10.0   高（High） 7.0 - 8.9   中（Medium） 4.0 - 6.9   低（Low） 0.1 - 3.9   无（None） 0.0    # Vulnerability Disclosure  为了保护 CloudWeGo 用户的安全，在进行调查、修复和发布安全公告之前，CloudWeGo 社区不会公开披露、讨论或确认 CloudWeGo 产品的安全问题。安全漏洞修复后 CloudWeGo 社区会发布安全公告，安全公告内容包括该漏洞的技术细节、CVE 编号、CVSS 安全评分、严重性等级以及受到该漏洞影响的版本和修复版本等信息。   ","categories":"","description":"","excerpt":" SUPPORT Vulnerability Management   # Vulnerability Response …","ref":"/security/vulnerability-reporting/","tags":"","title":"vulnerability-reporting"},{"body":"Volo-gRPC 是一个 RPC 框架，既然是 RPC，底层就需要两大功能：\n Serialization 序列化 Transport 传输  IDL 全称是 Interface Definition Language，接口定义语言。\nWhy IDL 如果我们要进行 RPC，就需要知道对方的接口是什么，需要传什么参数，同时也需要知道返回值是什么样的，就好比两个人之间交流，需要保证在说的是同一个语言、同一件事。 这时候，就需要通过 IDL 来约定双方的协议，就像在写代码的时候需要调用某个函数，我们需要知道函数签名一样。\nProtobuf IDL 是一套跨语言的全栈式 RPC 解决方案，具体的语法可以看参考 protocol-buffers/docs/proto3。\n编写 IDL 为了创建一个 gRPC 项目，我们需要先编写一个 protobuf IDL。\n在你的工作目录下，我们先执行以下命令：\n$ mkdir volo-example $ cd volo-example $ mkdir idl $ vim idl/volo_example.proto 随后，我们输入以下内容：\nsyntax = \"proto3\";package volo.example;message Item { int64 id = 1; string title = 2; string content = 3; map\u003cstring, string\u003e extra = 10;}message GetItemRequest { int64 id = 1;}message GetItemResponse { Item item = 1;}service ItemService { rpc GetItem(GetItemRequest) returns (GetItemResponse);}保存退出后，我们执行以下命令：\n$ volo init --includes=idl volo-example idl/volo_example.proto 这里我们使用init命令，后面跟了我们项目的名字，意思是需要生成模板代码。在末尾，需要指定一个 IDL 表示 server 使用的 IDL。\n如果只需要增加一个 IDL（如 client 的 IDL）而不需要生成模板的话，如：\n$ volo idl add idl/volo_example.proto | 插播一个广告，volo 工具还支持从 git 下载 IDL 并生成代码哦，如：\n$ volo idl add -g git@github.com:org/repo.git -r main /path/to/your/idl.proto | 感兴趣可以直接输入 volo 看详细用法~ 接下来回到正题~\n这时候，我们整个目录的结构如下：\n. ├── Cargo.toml ├── idl │ └── volo_example.proto ├── rust-toolchain.toml ├── src │ ├── bin │ │ └── server.rs │ └── lib.rs └── volo-gen ├── Cargo.toml ├── build.rs ├── src │ └── lib.rs └── volo.yml 然后，我们打开 src/lib.rs，在 impl 块中加入方法的实现，最终的代码应该是这样的：\n#![feature(type_alias_impl_trait)]pubstruct S;#[volo::async_trait]implvolo_gen::volo::example::ItemServiceforS{// 这部分是我们需要增加的代码 asyncfn get_item(\u0026self,_req: volo_grpc::Request\u003cvolo_gen::volo::example::GetItemRequest\u003e,)-\u003e core::result::Result\u003cvolo_grpc::Response\u003cvolo_gen::volo::example::GetItemResponse\u003e,volo_grpc::Status\u003e{Ok(volo_grpc::Response::new(Default::default()))}}然后执行：\n$ cargo update $ cargo build 这时候，就会发现 OUT_DIR 目录下多出来一个 volo_gen.rs 的文件了。\n然后执行以下命令，即可把我们的 server 端跑起来：\n$ cargo run --bin server 至此，我们已经能把我们的 server 跑起来啦！\n","categories":"","description":"","excerpt":"Volo-gRPC 是一个 RPC 框架，既然是 RPC，底层就需要两大功能：\n Serialization 序列化 Transport 传 …","ref":"/zh/docs/volo/volo-grpc/getting-started/part_2/","tags":"","title":"Part 2. 创建一个 gRPC Server"},{"body":"Volo-Thrift 是一个 RPC 框架，既然是 RPC，底层就需要两大功能：\n Serialization 序列化 Transport 传输  IDL 全称是 Interface Definition Language，接口定义语言。\nWhy IDL 如果我们要进行 RPC，就需要知道对方的接口是什么，需要传什么参数，同时也需要知道返回值是什么样的，就好比两个人之间交流，需要保证在说的是同一个语言、同一件事。 这时候，就需要通过 IDL 来约定双方的协议，就像在写代码的时候需要调用某个函数，我们需要知道函数签名一样。\nThrift IDL 是一套跨语言的全栈式 RPC 解决方案，具体的语法可以看参考 thrift-missing-guide 或官方 Thrift interface description language。\n编写 IDL 为了创建一个 Thrift 项目，我们需要先编写一个 Thrift IDL。\n在你的工作目录下，我们先执行以下命令：\n$ mkdir volo-example $ cd volo-example $ mkdir idl $ vim idl/volo_example.thrift 随后，我们输入以下内容：\nnamespacersvolo.examplestructItem{1:requiredi64id,2:requiredstringtitle,3:requiredstringcontent,10:optionalmap\u003cstring,string\u003eextra,}structGetItemRequest{1:requiredi64id,}structGetItemResponse{1:requiredItemitem,}serviceItemService{GetItemResponseGetItem (1:GetItemRequestreq),}保存退出后，我们执行以下命令：\n$ volo init volo-example idl/volo_example.thrift 这里我们使用init命令，后面跟了我们项目的名字，意思是需要生成模板代码。在末尾，需要指定一个 IDL 表示 server 使用的 IDL。\n如果只需要增加一个 IDL（如 client 的 IDL）而不需要生成模板的话，如：\n$ volo idl add idl/volo_example.thrift | 插播一个广告，volo 工具还支持从 git 下载 IDL 并生成代码哦，如：\n$ volo idl add -g git@github.com:org/repo.git -r main /path/to/your/idl.thrift | 感兴趣可以直接输入 volo 看详细用法~ 接下来回到正题~\n这时候，我们整个目录的结构如下：\n. ├── Cargo.toml ├── idl │ └── volo_example.thrift ├── rust-toolchain.toml ├── src │ ├── bin │ │ └── server.rs │ └── lib.rs └── volo-gen ├── Cargo.toml ├── build.rs ├── src │ └── lib.rs └── volo.yml 然后，我们打开 src/lib.rs，在 impl 块中加入方法的实现，最终的代码应该是这样的：\n#![feature(type_alias_impl_trait)]pubstruct S;#[volo::async_trait]implvolo_gen::volo::example::ItemServiceforS{// 这部分是我们需要增加的代码 asyncfn get_item(\u0026self,_req: volo_gen::volo::example::GetItemRequest,)-\u003e core::result::Result\u003cvolo_gen::volo::example::GetItemResponse,volo_thrift::AnyhowError\u003e{Ok(Default::default())}}然后执行：\n$ cargo update $ cargo build 这时候，就会发现 OUT_DIR 目录下多出来一个 volo_gen.rs 的文件了。\n然后执行以下命令，即可把我们的 server 端跑起来：\n$ cargo run --bin server 至此，我们已经能把我们的 server 跑起来啦！\n","categories":"","description":"","excerpt":"Volo-Thrift 是一个 RPC 框架，既然是 RPC，底层就需要两大功能：\n Serialization 序列化 Transport …","ref":"/zh/docs/volo/volo-thrift/getting-started/part_2/","tags":"","title":"Part 2. 创建一个 Thrift Server"},{"body":"概述 得益于 Hertz 的分层设计，除了 Hertz 框架默认自带的 HTTP1/HTTP2（即将开源）协议 server，框架的使用者能够非常容易的按照自身的需求增加/定制符合自身业务场景需求的协议处理逻辑。\n简单来说实现了以下接口的 server 即可作为自定义扩展 server 加入到 Hertz 当中来：\ntype Server interface { Serve(c context.Context, conn network.Conn) error } 协议层扩展三要素 协议层 server 初始化 前言里面提到的接口其实就是网络层将数据准备好之后的一个标准回调，即当有新的请求建立连接之后，进入到我们的协议层的处理逻辑。 在这个逻辑中我们可以自定义诸如协议解析方式，引入业务 Handler 执行，数据写回等协议层标准行为。这也是我们的自定义 server 的核心逻辑所在。\ntype myServer struct{ xxx xxx } func (s *myServer)Serve(c context.Context, conn network.Conn) error{ // 解析协议 \t... // 转到业务注册的逻辑函数（路由、中间件、Handler） \t... // 将数据写回 \t... } 定义一个协议处理逻辑就这么简单，不过解析协议、将数据写回这两个步骤通过入参中提供的 conn 接口能够轻易达成，但转到业务注册的逻辑函数这一步是如何办到的呢？\n与上层逻辑交互 一个完整的协议一定少不了引入业务逻辑控制（极少数特殊场景除外），在 Hertz 框架中自定义的协议是如何实现这部分能力的呢？其实，在自定义 server 初始化的过程中，框架已经天然的将这部分能力交给自定义协议 server 了。\ntype ServerFactory interface { New(core Core) (server protocol.Server, err error) } // Core is the core interface that promises to be provided for the protocol layer extensions type Core interface { // IsRunning Check whether engine is running or not  IsRunning() bool // A RequestContext pool ready for protocol server impl  GetCtxPool() *sync.Pool // Business logic entrance  // After pre-read works, protocol server may call this method  // to introduce the middlewares and handlers  ServeHTTP(c context.Context, ctx *app.RequestContext) // GetTracer for tracing requirement  GetTracer() tracer.Controller } 自定义 server 只需要按照以上接口实现一个协议 server 生成工厂即可，入参里面的 Core，其实就是包含了引入上层逻辑交互以及其他核心应用层接口的具体实现，在初始化自定义 server 的时候， 正常情况只需要将 Core 保存到 server 中，当需要转到业务逻辑时，通过 Core 即可将流程引导到应用层处理逻辑（路由、中间件、逻辑 Handler），当业务逻辑执行完毕返回后，即可根据业务数据进行进一步的数据包写回。\ntype myServer struct{ suite.Core xxx } func (s *myServer)Serve(c context.Context, conn network.Conn) error{ // 解析协议 \t... Core.ServeHTTP(c, ctx) // 将数据写回 \t... } 至此，一个自定义的协议层 server 就开发完毕了。\n注册自定义协议 server 到 Hertz 中 按照上述接口完成 server 生成工厂的开发后，将其加载到 Hertz 当中来就非常的容易了，我们在 Hertz 的核心引擎上面天然提供了一个注册自定义协议 server 的接口:\nfunc (engine *Engine) AddProtocol(protocol string, factory suite.ServerFactory) { engine.protocolSuite.Add(protocol, factory) } 只需要按照接口指定的参数将我们的自定义 server 生成工厂注册到 engine 上即可。值得注意的一点是，这里注册的 protocol（string）其实和 ALPN 中的协议协商 key 也是一一对应的， 所以，如果是想通过 ALPN 的方式接入自定义的协议 server，直接将 key 指定为对应的 ALPN 协商时的 key 即可。当前 Hertz 默认集成了一个 HTTP1 的协议 server（对应的 key 为\"http/1.1\"）， 如果有自定义 HTTP1 协议处理逻辑的需求，在 AddProtocol 时直接将 key 指定为\"http/1.1\"即可完成覆盖。\n例子 package main import ( \"bytes\" \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/errors\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/network\" \"github.com/cloudwego/hertz/pkg/protocol\" \"github.com/cloudwego/hertz/pkg/protocol/suite\" ) type myServer struct { suite.Core } func (m myServer) Serve(c context.Context, conn network.Conn) error { firstThreeBytes, _ := conn.Peek(3) if !bytes.Equal(firstThreeBytes, []byte(\"GET\")) { return errors.NewPublic(\"not a GET method\") } ctx := m.GetCtxPool().Get().(*app.RequestContext) defer func() { m.GetCtxPool().Put(ctx) conn.Skip(conn.Len()) conn.Flush() }() ctx.Request.SetMethod(\"GET\") ctx.Request.SetRequestURI(\"/test\") m.ServeHTTP(c, ctx) conn.WriteBinary([]byte(\"HTTP/1.1 200 OK\\n\" + \"Server: hertz\\n\" + \"Date: Sun, 29 May 2022 10:49:33 GMT\\n\" + \"Content-Type: text/plain; charset=utf-8\\n\" + \"Content-Length: 2\\n\\nok\\n\")) return nil } type serverFactory struct { } func (s *serverFactory) New(core suite.Core) (server protocol.Server, err error) { return \u0026myServer{ core, }, nil } func main() { h := server.New() h.GET(\"/test\", func(c context.Context, ctx *app.RequestContext) { hlog.Info(\"in handler\") }) h.AddProtocol(\"http/1.1\", \u0026serverFactory{}) h.Spin() } ","categories":"","description":"","excerpt":"概述 得益于 Hertz 的分层设计，除了 Hertz 框架默认自带的 HTTP1/HTTP2（即将开源）协议 server，框架的使用者能 …","ref":"/zh/docs/hertz/tutorials/framework-exten/advanced-exten/protocol/","tags":"","title":"协议扩展"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/blog/releases/","tags":"","title":"发布"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/tutorials/basic-feature/","tags":"","title":"基本特性"},{"body":"异常类型 Kitex 框架定义在 github.com/cloudwego/kitex/pkg/kerrors 下\nInternal Exception ErrInternalException, 框架内部发生的错误，具体包括以下几种：\n ErrNotSupported, \"operation not supported\"，进行了尚不支持的操作 ErrNoResolver, \"no resolver available\"，没有可用的 resolver ErrNoDestService, \"no dest service\"，没有指定目标 service ErrNoDestAddress, \"no dest address\"，没有指定目标地址 ErrNoConnection, \"no connection available\"，当前没有可用连接 ErrNoIvkRequest, \"invoker request not set\"，invoker 模式下调用时为设置 request  service discovery error ErrServiceDiscovery, 服务发现错误，具体错误见报错信息\nget connection error ErrGetConnection, 获取连接错误，具体错误见报错信息\nloadbalance error ErrLoadbalance, 负载均衡错误\nno more instances to retry ErrNoMoreInstance, 没有可供重试的示例，上一次调用的错误见报错信息\nrpc timeout ErrRPCTimeout, RPC 调用超时，具体错误见报错信息\nrequest forbidden ErrACL, 调用被拒绝，具体错误见报错信息\nforbidden by circuitbreaker ErrCircuitBreak, 发生熔断后请求被拒绝，通常包含两种错误：\n ErrServiceCircuitBreak, \"service circuitbreak\"，发生服务级别熔断后请求被拒绝 ErrInstanceCircuitBreak, \"instance circuitbreak\"，发生实例级别熔断后请求被拒绝  remote or network error ErrRemoteOrNetwork, 远端服务发生错误，或者出现网络错误。具体错误见报错信息\n当带有[remote] 字样时，代表此错误为远端返回\nrequest over limit ErrOverlimit, 过载保护错误。通常包括以下两种错误：\n ErrConnOverLimit, \"too many connections\"，连接过载，建立的连接超过限制 ErrQPSOverLimit, \"request too frequent\"，请求过载，请求数超过限制  panic ErrPanic, 服务发生 panic 。\n当带有[happened in biz handler] 字样时，代表 panic 发生在服务端 handler 中，此时错误信息中会带上堆栈。\nbiz error ErrBiz, 服务端 handler 返回的错误。\nretry error ErrRetry, 重试时发生错误，具体错误见报错信息。\nTHRIFT 错误码 该类别对应 Thrift 框架原生的 Application Exception 错误，通常，这些错误会被 Kitex 框架包装成 remote or network error 。\n   错误码 名称 含义     0 UnknownApplicationException 未知错误   1 UnknownMethod 未知方法   2 InValidMessageTypeException 无效的消息类型   3 WrongMethodName 错误的方法名字   4 BadSequenceID 错误的包序号   5 MissingResult 返回结果缺失   6 InternalError 内部错误   7 ProtocolError 协议错误    异常判断 判断是否是 Kitex 的错误 可以通过 kerrors 包提供的 IsKitexError 直接进行判断\nimport \"github.com/cloudwego/kitex/pkg/kerrors\" ... isKitexErr := kerrors.IsKitexError(kerrors.ErrInternalException) // 返回 true 判断具体的错误类型 可以通过 errors.Is 进行判断，其中详细错误可以通过详细错误判断，如：\nimport \"errors\" import \"github.com/cloudwego/kitex/client\" import \"github.com/cloudwego/kitex/pkg/kerrors\" ... _, err := echo.NewClient(\"echo\", client.WithResolver(nil)) // 返回 kerrors.ErrNoResolver ... isKitexErr := errors.Is(err, kerrors.ErrNoResolver) // 返回 true 也可以通过基本错误进行判断，如：\nimport \"errors\" import \"github.com/cloudwego/kitex/client\" import \"github.com/cloudwego/kitex/pkg/kerrors\" ... _, err := echo.NewClient(\"echo\", client.WithResolver(nil)) // 返回 kerrors.ErrNoResolver ... isKitexErr := errors.Is(err, kerrors.ErrInternalException) // 返回 true 特别的，timeout 错误可以通过 kerrors 包提供的 IsTimeoutError 进行判断\n获取更详细的错误信息 kerrors 中所有的具体错误类型都是 kerrors 包下的 DetailedError，故而可以通过 errors.As 获取到实际的 DetailedError，如：\nimport \"errors\" import \"github.com/cloudwego/kitex/client\" import \"github.com/cloudwego/kitex/pkg/kerrors\" ... _, err := echo.NewClient(\"echo\", client.WithResolver(nil)) // 返回 kerrors.ErrNoResolver ... var de *kerrors.DetailedError ok := errors.As(err, \u0026ke) // 返回 true if de.ErrorType() == kerrors.ErrInternalException {} // 返回 true DetailedError 提供了下述方法用于获取更详细的信息：\n ErrorType() error ，用于获取基本错误类型 Stack() string ，用于获取堆栈信息（目前仅 ErrPanic 会带上）  ","categories":"","description":"Kitex 异常类型介绍以及异常判断指南。","excerpt":"Kitex 异常类型介绍以及异常判断指南。","ref":"/zh/docs/kitex/reference/exception/","tags":"","title":"异常说明"},{"body":"cwgo 是 CloudWeGo All in one 代码生成工具，整合了各个组件的优势，提高开发者提体验。\n准备 Golang 开发环境  如果您之前未搭建 Golang 开发环境， 可以参考 Golang 安装 推荐使用最新版本的 Golang，我们保证最新两个正式版本的兼容性(现在 \u003e= v1.18)。 确保打开 go mod 支持 (Golang \u003e= 1.15时，默认开启) cwgo 暂时没有针对 Windows 做支持，如果本地开发环境是 Windows 建议使用 WSL2  在完成环境准备后，接下来将帮助你快速上手 cwgo。\n安装 cwgo 工具 $ go install github.com/cloudwego/cwgo@latest 用 go 命令来安装是最简单的，你也可以选择自己从源码构建和安装。要查看 cwgo 的安装位置，可以用：\n$ go list -f {{.Target}} github.com/cloudwego/cwgo 要使用 thrift 或 protobuf 的 IDL 生成代码，需要安装相应的编译器：thriftgo 或 protoc。\nthriftgo 安装：\n$ GO111MODULE=on go install github.com/cloudwego/thriftgo@latest protoc 安装\n# brew 安装 $ brew install protobuf # 官方镜像安装，以 macos 为例 $ wget https://github.com/protocolbuffers/protobuf/releases/download/v3.19.4/protoc-3.19.4-osx-x86_64.zip $ unzip protoc-3.19.4-osx-x86_64.zip $ cp bin/protoc /usr/local/bin/protoc # 确保 include/google 放入 /usr/local/include下 $ cp -r include/google /usr/local/include/google 首先，我们需要安装使用本示例所需要的命令行代码生成工具：\n 确保 GOPATH 环境变量已经被正确地定义（例如 export GOPATH=~/go）并且将$GOPATH/bin添加到 PATH 环境变量之中（例如 export PATH=$GOPATH/bin:$PATH）；请勿将 GOPATH 设置为当前用户没有读写权限的目录 安装 cwgo：go install github.com/cloudwego/cwgo@latest 安装 thriftgo：go install github.com/cloudwego/thriftgo@latest  安装成功后，执行 cwgo --version 和 thriftgo --version 应该能够看到具体版本号的输出（版本号有差异，以 x.x.x 示例）：\n$ cwgo --version vx.x.x $ thriftgo --version vx.x.x $ protoc --version libprotoc x.x.x 确定代码放置位置  若将代码放置于 $GOPATH/src 下，需在 $GOPATH/src 下创建额外目录，进入该目录后再获取代码：  $ mkdir -p $(go env GOPATH)/src/github.com/cloudwego $ cd $(go env GOPATH)/src/github.com/cloudwego 若将代码放置于 GOPATH 之外，可直接获取  注意事项 cwgo 底层使用 kitex、hz、gen 工具，所以其相应的工具规范也需要遵守，如 kitex 的注意事项和 hz 的注意事项。\n使用 cwgo 的具体使用请参考命令行工具\n下面以 thrift 为例\n 首先创建一个目录  $ mkdir -p $GOPATH/src/local/cwgo_test $ cd $GOPATH/src/local/cwgo_test 创建一个 idl 目录  $ mkdir idl 编写 idl/hello.thrift 文件  # idl/hello.thriftnamespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");// 添加 api 注解为方便进行参数绑定 }structHelloResp{1:stringRespBody;}serviceHelloService{HelloRespHelloMethod(1:HelloReqrequest)(api.get=\"/hello\");}生成项目 layout  静态命令行\n$ cwgo server -service=a.b.c -type HTTP -idl=idl/hello.thrift 动态命令行\n编译运行  $ go mod tidy \u0026\u0026 go mod verify $ sh build.sh \u0026\u0026 sh output/bootstrap.sh 发起调用  $ curl http://127.0.0.1:8080/ping pong 恭喜你！至此你成功编写了一个 Cwgo 的服务端，并完成了一次调用！\n","categories":"","description":"","excerpt":"cwgo 是 CloudWeGo All in one 代码生成工具，整合了各个组件的优势，提高开发者提体验。\n准备 Golang …","ref":"/zh/docs/cwgo/getting-started/","tags":"","title":"快速开始"},{"body":"准备 Golang 开发环境  如果您之前未搭建 Golang 开发环境，可以参考 Golang 安装。 推荐使用最新版本的 Golang，或保证现有 Golang 版本 \u003e= 1.15。小于 1.15 版本，可以自行尝试使用但不保障兼容性和稳定性。 确保打开 go mod 支持 (Golang \u003e= 1.15时，默认开启)。   目前，Hertz 支持 Linux、macOS、Windows 系统\n 快速上手 在完成环境准备后，本章节将帮助你快速上手 Hertz。\n安装命令行工具 hz 首先，我们需要安装使用本示例所需要的命令行工具 hz：\n 确保 GOPATH 环境变量已经被正确地定义（例如 export GOPATH=~/go）并且将$GOPATH/bin添加到 PATH 环境变量之中(例如 export PATH=$GOPATH/bin:$PATH)；请勿将 GOPATH 设置为当前用户没有读写权限的目录 安装 hz：go install github.com/cloudwego/hertz/cmd/hz@latest  更多 hz 使用方法可参考: hz\n确定代码放置位置  若将代码放置于$GOPATH/src下，需在$GOPATH/src下创建额外目录，进入该目录后再获取代码：  $ mkdir -p $(go env GOPATH)/src/github.com/cloudwego $ cd $(go env GOPATH)/src/github.com/cloudwego 若将代码放置于 GOPATH 之外，可直接获取  生成/编写示例代码  在当前目录下创建 hertz_demo 文件夹，进入该目录中 生成代码 hz new 整理 \u0026 拉取依赖  $ go mod tidy 如果当前使用的是 Windows 环境，可以编写如下的示例代码：\n 在当前目录下创建 hertz_demo 文件夹，进入该目录中 创建 main.go 文件 在 main.go 文件中添加以下代码  package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"message\": \"pong\"}) }) h.Spin() } 生成 go.mod 文件  $ go mod init hertz_demo 整理 \u0026 拉取依赖  $ go mod tidy 运行示例代码 完成以上操作后，我们可以直接编译并启动 Server\n$ go build -o hertz_demo \u0026\u0026 ./hertz_demo 如果成功启动，你将看到以下信息\n2022/05/17 21:47:09.626332 engine.go:567: [Debug] HERTZ: Method=GET absolutePath=/ping --\u003e handlerName=main.main.func1 (num=2 handlers) 2022/05/17 21:47:09.629874 transport.go:84: [Info] HERTZ: HTTP server listening on address=[::]:8888 接下来，我们可以对接口进行测试\n$ curl http://127.0.0.1:8888/ping 如果不出意外，我们可以看到类似如下输出\n$ {\"message\":\"pong\"} 到现在，我们已经成功启动了 Hertz Server，并完成了一次调用。更多 API 示例请参考 API 示例\n目录结构 关于项目目录结构组织，这里有一个目录结构可供参考，具体可以根据业务的实际情况进行组织\n更多示例 参考：hertz-examples\n","categories":"","description":"","excerpt":"准备 Golang 开发环境  如果您之前未搭建 Golang 开发环境，可以参考 Golang 安装。 推荐使用最新版本的 Golang， …","ref":"/zh/docs/hertz/getting-started/","tags":"","title":"快速开始"},{"body":"准备 Golang 开发环境  如果您之前未搭建 Golang 开发环境， 可以参考 Golang 安装 推荐使用最新版本的 Golang，我们保证最新三个正式版本的兼容性(现在 \u003e= v1.16)。 确保打开 go mod 支持 (Golang \u003e= 1.15时，默认开启) kitex 暂时没有针对 Windows 做支持，如果本地开发环境是 Windows 建议使用 WSL2  快速上手 在完成环境准备后，本章节将帮助你快速上手 Kitex\n安装代码生成工具 首先，我们需要安装使用本示例所需要的命令行代码生成工具：\n 确保 GOPATH 环境变量已经被正确地定义（例如 export GOPATH=~/go）并且将$GOPATH/bin添加到 PATH 环境变量之中（例如 export PATH=$GOPATH/bin:$PATH）；请勿将 GOPATH 设置为当前用户没有读写权限的目录 安装 kitex：go install github.com/cloudwego/kitex/tool/cmd/kitex@latest 安装 thriftgo：go install github.com/cloudwego/thriftgo@latest  安装成功后，执行 kitex --version 和 thriftgo --version 应该能够看到具体版本号的输出（版本号有差异，以 x.x.x 示例）：\n$ kitex --version vx.x.x $ thriftgo --version thriftgo x.x.x 如果在安装阶段发生问题，可能主要是由于对 Golang 的不当使用造成，请依照报错信息进行检索  确定代码放置位置  若将代码放置于 $GOPATH/src 下，需在 $GOPATH/src 下创建额外目录，进入该目录后再获取代码：  mkdir -p $(go env GOPATH)/src/github.com/cloudwego cd $(go env GOPATH)/src/github.com/cloudwego 若将代码放置于 GOPATH 之外，可直接获取  获取示例代码  你可以直接点击 此处 下载示例仓库 也可以克隆该示例仓库到本地 git clone https://github.com/cloudwego/kitex-examples.git  运行示例代码 方式一：直接启动   进入示例仓库的 hello 目录\ncd kitex-examples/hello\n  运行 server\ngo run .\n  运行 client\n另起一个终端后，go run ./client\n  方式二：使用 Docker 快速启动   进入示例仓库目录\ncd kitex-examples\n  编译项目\ndocker build -t kitex-examples .\n  运行 server\ndocker run --network host kitex-examples ./hello-server\n  运行 client\n另起一个终端后，docker run --network host kitex-examples ./hello-client\n  恭喜你，你现在成功通过 Kitex 发起了 RPC 调用。\n增加一个新的方法 打开 hello.thrift，你会看到如下内容：\nnamespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}serviceHello{Responseecho(1:Requestreq)}现在让我们为新方法分别定义一个新的请求和响应，AddRequest 和 AddResponse，并在 service Hello 中增加 add 方法：\nnamespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}structAddRequest{1:i64first2:i64second}structAddResponse{1:i64sum}serviceHello{Responseecho(1:Requestreq)AddResponseadd(1:AddRequestreq)}完成之后 hello.thrift 的内容应该和上面一样。\n重新生成代码 运行如下命令后，kitex 工具将根据 hello.thrift 更新代码文件。\nkitex -service a.b.c hello.thrift # 若当前目录不在 $GOPATH/src 下，需要加上 -module 参数，一般为 go.mod 下的名字 kitex -module \"your_module_name\" -service a.b.c hello.thrift 执行完上述命令后，kitex 工具将更新下述文件\n 更新 ./handler.go，在里面增加一个 Add 方法的基本实现 更新 ./kitex_gen，里面有框架运行所必须的代码文件  更新服务端处理逻辑 上述步骤完成后，./handler.go 中会自动补全一个 Add 方法的基本实现，类似如下代码：\n// Add implements the HelloImpl interface. func (s *HelloImpl) Add(ctx context.Context, req *api.AddRequest) (resp *api.AddResponse, err error) { // TODO: Your code here...  return } 让我们在里面增加我们所需要的逻辑，类似如下代码：\n// Add implements the HelloImpl interface. func (s *HelloImpl) Add(ctx context.Context, req *api.AddRequest) (resp *api.AddResponse, err error) { // TODO: Your code here...  resp = \u0026api.AddResponse{Sum: req.First + req.Second} return } 增加客户端调用 服务端已经有了 Add 方法的处理，现在让我们在客户端增加对 Add 方法的调用。\n在 ./client/main.go 中你会看到类似如下的 for 循环：\nfor { req := \u0026api.Request{Message: \"my request\"} resp, err := client.Echo(context.Background(), req) if err != nil { log.Fatal(err) } log.Println(resp) time.Sleep(time.Second) } 现在让我们在里面增加 Add 方法的调用：\nfor { req := \u0026api.Request{Message: \"my request\"} resp, err := client.Echo(context.Background(), req) if err != nil { log.Fatal(err) } log.Println(resp) time.Sleep(time.Second) addReq := \u0026api.AddRequest{First: 512, Second: 512} addResp, err := client.Add(context.Background(), addReq) if err != nil { log.Fatal(err) } log.Println(addResp) time.Sleep(time.Second) } 重新运行示例代码 关闭之前运行的客户端和服务端之后\n  运行 server\ngo run .\n  运行 client\n另起一个终端后，go run ./client\n现在，你应该能看到客户端在调用 Add 方法了。\n  基础教程 关于 Kitex Kitex 是一个 RPC 框架，既然是 RPC，底层就需要两大功能：\n Serialization 序列化 Transport 传输  Kitex 框架及命令行工具，默认支持 thrift 和 proto3 两种 IDL，对应的 Kitex 支持 thrift 和 protobuf 两种序列化协议。 传输上 Kitex 使用扩展的 thrift 作为底层的传输协议（注：thrift 既是 IDL 格式，同时也是序列化协议和传输协议）。IDL 全称是 Interface Definition Language，接口定义语言。\n为什么要使用 IDL 如果我们要进行 RPC，就需要知道对方的接口是什么，需要传什么参数，同时也需要知道返回值是什么样的，就好比两个人之间交流，需要保证在说的是同一个语言、同一件事。 这时候，就需要通过 IDL 来约定双方的协议，就像在写代码的时候需要调用某个函数，我们需要知道函数签名一样。\nThrift IDL 语法可参考：Thrift interface description language。\nproto3 语法可参考：Language Guide(proto3)。\n创建项目目录 在开始后续的步骤之前，先让我们创建一个项目目录用于后续的教程。\n$ mkdir example\n然后让我们进入项目目录\n$ cd example\nKitex 命令行工具 Kitex 自带了一个同名的命令行工具 kitex，用来帮助大家很方便地生成代码，新项目的生成以及之后我们会学到的 server、client 代码的生成都是通过 kitex 工具进行。\n安装 可以使用以下命令来安装或者更新 kitex：\n$ go install github.com/cloudwego/kitex/tool/cmd/kitex@latest\n完成后，可以通过执行 kitex 来检测是否安装成功。\n$ kitex\n如果出现如下输出，则安装成功。\n$ kitex\nNo IDL file found.\n如果出现 command not found 错误，可能是因为没有把 $GOPATH/bin 加入到 $PATH 中，详见环境准备一章。\n使用 kitex 的具体使用请参考代码生成工具\n编写 IDL 首先我们需要编写一个 IDL，这里以 thrift IDL 为例。\n首先创建一个名为 echo.thrift 的 thrift IDL 文件。\n然后在里面定义我们的服务\nnamespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}serviceEcho{Responseecho(1:Requestreq)}生成 echo 服务代码 有了 IDL 以后我们便可以通过 kitex 工具生成项目代码了，执行如下命令：\n$ kitex -module example -service example echo.thrift\n上述命令中，-module 表示生成的该项目的 go module 名，-service 表明我们要生成一个服务端项目，后面紧跟的 example 为该服务的名字。最后一个参数则为该服务的 IDL 文件。\n生成后的项目结构如下：\n. |-- build.sh |-- echo.thrift |-- handler.go |-- kitex_gen | `-- api | |-- echo | | |-- client.go | | |-- echo.go | | |-- invoker.go | | `-- server.go | |-- echo.go | `-- k-echo.go |-- main.go `-- script `-- bootstrap.sh 获取最新的 Kitex 框架 由于 kitex 要求使用 go mod 进行依赖管理，所以我们要升级 kitex 框架会很容易，只需要执行以下命令即可：\n$ go get github.com/cloudwego/kitex@latest $ go mod tidy 如果遇到类似如下报错：\ngithub.com/apache/thrift/lib/go/thrift: ambiguous import: found package github.com/apache/thrift/lib/go/thrift in multiple modules\n或\ngithub.com/cloudwego/kitex@v0.X.X/pkg/utils/thrift.go: not enough arguments in call to t.tProt.WriteMessageBegin\n先执行一遍下述命令，再继续操作：\ngo mod edit -droprequire=github.com/apache/thrift/lib/go/thrift go mod edit -replace=github.com/apache/thrift=github.com/apache/thrift@v0.13.0 这是因为 thrift 官方在 0.14 版本对 thrift 接口做了 breaking change，导致生成代码不兼容。\n编写 echo 服务逻辑 我们需要编写的服务端逻辑都在 handler.go 这个文件中，现在这个文件应该如下所示：\npackage main import ( \"context\" \"example/kitex_gen/api\" ) // EchoImpl implements the last service interface defined in the IDL. type EchoImpl struct{} // Echo implements the EchoImpl interface. func (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) { // TODO: Your code here...  return } 这里的 Echo 函数就对应了我们之前在 IDL 中定义的 echo 方法。\n现在让我们修改一下服务端逻辑，让 Echo 服务名副其实。\n修改 Echo 函数为下述代码：\nfunc (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) { return \u0026api.Response{Message: req.Message}, nil } 编译运行 kitex 工具已经帮我们生成好了编译和运行所需的脚本：\n编译：\n$ sh build.sh\n执行上述命令后，会生成一个 output 目录，里面含有我们的编译产物。\n运行：\n$ sh output/bootstrap.sh\n执行上述命令后，Echo 服务就开始运行啦！\n编写客户端 有了服务端后，接下来就让我们编写一个客户端用于调用刚刚运行起来的服务端。\n首先，同样的，先创建一个目录用于存放我们的客户端代码：\n$ mkdir client\n进入目录：\n$ cd client\n创建一个 main.go 文件，然后就开始编写客户端代码了。\n创建 client 首先让我们创建一个调用所需的 client：\nimport \"example/kitex_gen/api/echo\" import \"github.com/cloudwego/kitex/client\" ... c, err := echo.NewClient(\"example\", client.WithHostPorts(\"0.0.0.0:8888\")) if err != nil { log.Fatal(err) } 上述代码中，echo.NewClient 用于创建 client，其第一个参数为调用的 服务名，第二个参数为 options，用于传入参数， 此处的 client.WithHostPorts 用于指定服务端的地址，更多参数可参考基本特性一节。\n发起调用 接下来让我们编写用于发起调用的代码：\nimport \"example/kitex_gen/api\" ... req := \u0026api.Request{Message: \"my request\"} resp, err := c.Echo(context.Background(), req, callopt.WithRPCTimeout(3*time.Second)) if err != nil { log.Fatal(err) } log.Println(resp) 上述代码中，我们首先创建了一个请求 req , 然后通过 c.Echo 发起了调用。\n其第一个参数为 context.Context，通过通常用其传递信息或者控制本次调用的一些行为，你可以在后续章节中找到如何使用它。\n其第二个参数为本次调用的请求。\n其第三个参数为本次调用的 options ，Kitex 提供了一种 callopt 机制，顾名思义——调用参数 ，有别于创建 client 时传入的参数，这里传入的参数仅对此次生效。 此处的 callopt.WithRPCTimeout 用于指定此次调用的超时（通常不需要指定，此处仅作演示之用）同样的，你可以在基本特性一节中找到更多的参数。\n发起调用 在编写完一个简单的客户端后，我们终于可以发起调用了。\n你可以通过下述命令来完成这一步骤：\n$ go run main.go\n如果不出意外，你可以看到类似如下输出：\n2021/05/20 16:51:35 Response({Message:my request})\n恭喜你！至此你成功编写了一个 Kitex 的服务端和客户端，并完成了一次调用！\n","categories":"","description":"Kitex 开发环境准备、快速上手与基础教程。","excerpt":"Kitex 开发环境准备、快速上手与基础教程。","ref":"/zh/docs/kitex/getting-started/","tags":"","title":"快速开始"},{"body":" 本教程通过一些简单的示例帮助您开始使用 Netpoll，包括如何使用 Server、Client 和 nocopy API。\n 1. 使用 Server 这里 是一个简单的 server 例子，接下来我们会解释它是如何构建的。\n1.1 创建 Listener 首先我们需要一个 Listener，它可以是 net.Listener 或者 netpoll.Listener，两者都可以，依据你的代码情况自由选择。 创建 Listener 的过程如下：\npackage main import \"net\" func main() { listener, err := net.Listen(network, address) if err != nil { panic(\"create net listener failed\") } ... } 或者\npackage main import \"github.com/cloudwego/netpoll\" func main() { listener, err := netpoll.CreateListener(network, address) if err != nil { panic(\"create netpoll listener failed\") } ... } 1.2 创建 EventLoop EventLoop 是一个事件驱动的调度器，一个真正的 NIO Server，负责连接管理、事件调度等。\n参数说明:\n OnRequest 是用户应该自己实现来处理业务逻辑的接口。 注释 详细描述了它的行为。 Option 用于自定义 EventLoop 创建时的配置，下面的例子展示了它的用法。更多详情请参考 options 。  创建过程如下：\npackage main import ( \"time\" \"github.com/cloudwego/netpoll\" ) var eventLoop netpoll.EventLoop func main() { ... eventLoop, _ = netpoll.NewEventLoop( handle, netpoll.WithOnPrepare(prepare), netpoll.WithReadTimeout(time.Second), ) ... } 1.3 运行 Server EventLoop 通过绑定 Listener 来提供服务，如下所示。Serve 方法为阻塞式调用，直到发生 panic 等错误，或者由用户主动调用 Shutdown 时触发退出。\npackage main import ( \"github.com/cloudwego/netpoll\" ) var eventLoop netpoll.EventLoop func main() { ... // start listen loop ... \teventLoop.Serve(listener) } 1.4 关闭 Server EventLoop 提供了 Shutdown 功能，用于优雅地停止服务器。用法如下：\npackage main import ( \"context\" \"time\" \"github.com/cloudwego/netpoll\" ) var eventLoop netpoll.EventLoop func main() { // stop server ... \tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() eventLoop.Shutdown(ctx) } 2. 使用 Dialer Netpoll 也支持在 Client 端使用，提供了 Dialer，类似于 net.Dialer。同样的，这里 展示了一个简单的 Client 端示例，接下来我们详细介绍一下：\n2.1 快速方式 与 Net 类似，Netpoll 提供了几个用于直接建立连接的公共方法，可以直接调用。 如：\nDialConnection(network, address string, timeout time.Duration) (connection Connection, err error) DialTCP(ctx context.Context, network string, laddr, raddr *TCPAddr) (*TCPConnection, error) DialUnix(network string, laddr, raddr *UnixAddr) (*UnixConnection, error) 2.2 创建 Dialer Netpoll 还定义了Dialer 接口。 用法如下：（通常推荐使用上一节的快速方式）\npackage main import ( \"github.com/cloudwego/netpoll\" ) func main() { // Dial a connection with Dialer. \tdialer := netpoll.NewDialer() conn, err := dialer.DialConnection(network, address, timeout) if err != nil { panic(\"dial netpoll connection failed\") } ... } 3. 使用 Nocopy API Connection 提供了 Nocopy API —— Reader 和 Writer，以避免频繁复制。下面介绍一下它们的简单用法。\npackage main type Connection interface { // Recommended nocopy APIs \tReader() Reader Writer() Writer ... // see code comments for more details } 3.1 简单用法 Nocopy API 设计为两步操作。\n使用 Reader 时，通过 Next、Peek、ReadString 等方法读取数据后，还需要主动调用 Release 方法释放 buffer（Nocopy 读取 buffer 的原地址，所以您必须主动再次确认 buffer 已经不再使用）。\n同样，使用 Writer 时，首先需要分配一个 []byte 来写入数据，然后调用 Flush 确认所有数据都已经写入。Writer 还提供了丰富的 API 来分配 buffer，例如 Malloc、WriteString 等。\n下面是一些简单的读写数据的例子。 更多详情请参考 说明 。\npackage main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection var reader, writer = conn.Reader(), conn.Writer() // reading \tbuf, _ := reader.Next(n) ... parse the read data ... reader.Release() // writing \tvar write_data []byte ... make the write data ... alloc, _ := writer.Malloc(len(write_data)) copy(alloc, write_data) // write data \twriter.Flush() } 3.2 高阶用法 如果你想使用单个连接来发送（或接收）多组数据（如连接多路复用），那么你将面临数据打包和分包。在 net 上，这种工作一般都是通过复制来完成的。一个例子如下：\npackage main import ( \"net\" ) func main() { var conn net.Conn var buf = make([]byte, 8192) // reading \tfor { n, _ := conn.Read(buf) ... unpacking \u0026 handling ... var i int for i = 0; i \u003c= n-pkgsize; i += pkgsize { pkg := append([]byte{}, buf[i:i+pkgsize]...) go func() { ... handling pkg ... } } buf = append(buf[:0], buf[i:n]...) } // writing \tvar write_datas \u003c-chan []byte ... packing write ... for { pkg := \u003c-write_datas conn.Write(pkg) } } 但是，Netpoll 不需要这样做，nocopy APIs 支持对 buffer 进行原地址操作（原地址组包和分包），并通过引用计数实现资源的自动回收和重用。\n示例如下（使用方法 Reader.Slice 和 Writer.Append）：\npackage main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection // reading \treader := conn.Reader() for { ... unpacking \u0026 handling ... pkg, _ := reader.Slice(pkgsize) go func() { ... handling pkg ... pkg.Release() } } // writing \tvar write_datas \u003c-chan netpoll.Writer ... packing write ... writer := conn.Writer() for { select { case pkg := \u003c-write_datas: writer.Append(pkg) default: if writer.MallocLen() \u003e 0 { writer.Flush() } } } } ","categories":"","description":"","excerpt":" 本教程通过一些简单的示例帮助您开始使用 Netpoll，包括如何使用 Server、Client 和 nocopy API。\n 1. …","ref":"/zh/docs/netpoll/getting-started/","tags":"","title":"快速开始"},{"body":"Hertz 提供对日志的扩展，接口定义在 pkg/common/hlog 中。\n接口定义 Hertz 在 pkg/common/hlog 里定义了 Logger、CtxLogger、FormatLogger 几个接口实现不同的打日志方式，并定义了一个 Control 接口实现 logger 的控制。 用户注入自己的 logger 实现时需要实现上面的所有接口( FullLogger )。Hertz提供了一个 FullLogger 默认实现。\n// FullLogger is the combination of Logger, FormatLogger, CtxLogger and Control. type FullLogger interface { Logger FormatLogger CtxLogger Control } 注意，由于默认 logger 底层使用标准库的 log.Logger 实现，其在日志里输出的调用位置依赖于设置的调用深度（call depth），因此封装 hlog 提供的实现可能会导致日志内容里文件名和行数不准确。\n注入自己的 logger 实现 Hertz 提供 SetLogger 接口用于注入用户自定义的 logger 实现，也可以使用 SetOutput 接口重定向默认的 logger 输出，随后的中间件以及框架的其他部分可以使用 hlog 中的全局方法来输出日志。 默认使用 hertz 默认实现的 logger。\n已支持日志拓展 目前在 Hertz 的开源版本支持的日志扩展都存放在 hertz-logger 中，欢迎大家参与项目贡献与维护。\nZap 用法示例：\nimport ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" hertzzap \"github.com/hertz-contrib/logger/zap\" ) func main() { h := server.Default() logger := hertzzap.NewLogger( hertzzap.WithZapOptions( // ... \t), ) hlog.SetLogger(logger) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { hlog.Info(\"Hello, hertz\") c.String(consts.StatusOK, \"Hello hertz!\") }) h.Spin() } 更多用法示例详见 hertz-contrib/logger/zap。\nLogrus 用法示例：\nimport ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" hertzlogrus \"github.com/hertz-contrib/logger/logrus\" \"github.com/sirupsen/logrus\" ) func main() { h := server.Default() logger := hertzlogrus.NewLogger( hertzlogrus.WithLogger(\u0026logrus.Logger{ // ... \t}), ) hlog.SetLogger(logger) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { hlog.Info(\"Hello, hertz\") c.String(consts.StatusOK, \"Hello hertz!\") }) h.Spin() } 更多用法示例详见 hertz-contrib/logger/logrus。\nZerolog 用法示例：\nimport ( \"context\" \"os\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" hertzZerolog \"github.com/hertz-contrib/logger/zerolog\" ) func main() { h := server.Default() logger := hertzZerolog.New( hertzZerolog.WithOutput(os.Stdout), // allows to specify output \thertzZerolog.WithLevel(hlog.LevelInfo), // option with log level \thertzZerolog.WithTimestamp(), // option with timestamp \thertzZerolog.WithCaller(), // option with caller \t// ... \t) hlog.SetLogger(logger) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { hlog.Info(\"Hello, hertz\") c.String(consts.StatusOK, \"Hello hertz!\") }) h.Spin() } 更多用法示例详见 hertz-contrib/logger/zerolog。\n","categories":"","description":"","excerpt":"Hertz 提供对日志的扩展，接口定义在 pkg/common/hlog 中。\n接口定义 Hertz 在 pkg/common/hlog 里 …","ref":"/zh/docs/hertz/tutorials/framework-exten/log/","tags":"","title":"日志扩展"},{"body":"案例介绍   近些年电商行业高速发展，森马电商线上业务激增，面临着高并发、高性能的业务场景需求。森马通过使用 Kitex 接入 Istio，极大地提高了对高并发需求的处理能力。\n本文将从四个方面为大家讲解 Kitex 在森马电商场景下的落地实践：\n 森马电商订单流转中心——天枢所面临的业务挑战； 项目的技术选型过程； 项目上线性能压测对比； CloudWeGo 团队的技术支持。  森马电商订单流转中心——天枢 业务增长 第一部分给大家介绍订单流转中心——天枢。天枢的主要功能是对接各大电商平台，把订单、商品、退单等信息统一处理后流转到下游系统，是下游系统和平台对接的中间枢纽。 目前森马电商在运营的电商平台几十家，如：天猫、抖店、京东、拼多多等，由于每个平台的接口和对接的方式不统一，我们专门开发了这套系统，去统一对接电商平台，然后把数据处理成统一的格式发到下游系统，如：OMS 和 WMS。 该系统在电商活动，如 6·18，双十一等订单峰值流量下发挥了重要作用。\n从 2015 年至 2021 年，森马的双十一业务量增长非常迅速。2015 年双十一的业绩有 3 亿+，而去年的双十一业绩为 20 亿+，2021 年商品交易总额（GMV） 更是突破百亿。 随着业务的增长，对订单系统的性能和稳定性要求越来越高。而且随着系统的规模增长，集群内的 Pod 数量和 Service 不断增加，对系统底层架构有很大的考验。 目前从旧系统迁移的平台有：有赞、抖音、拼多多、快手等，集群内的 Pod 数已经超过 200 个，后续会接入京东、唯品会、天猫等平台后，Pod 数会成倍的增长，更需要一个成熟的系统架构作为支撑。\n面临的问题 随着直播行业的兴起，我们请了一些网红主播和流量明星来直播带货。直播期间，订单量经常会出现几秒内突然爆发的情况，订单推送到系统后，如果系统处理较慢，订单就不能及时流入下游系统， 下游系统的 OMS 不知道已经产生如此大的订单量，就会出现不能同步的情况，即超卖现象。在电商行业，超卖是很严重的问题，如果用户下单后不能及时发货，不仅需要大量的人力去跟客户解释道歉， 也要以优惠券等形式赔偿用户遭受的损失，甚至会接到大量投诉，严重影响我们在电商平台的信誉，电商平台也会对我们进行处罚。我们经历过当 GMV 超过千万时，订单系统延迟超过半个小时的情况，对我们造成了极大的影响。 因此，当遇到如双十一，6·18 大促等活动时，特别是在直播时订单量短时间内暴增的情况下，我们原有的系统架构已经无法支撑，不能及时处理订单数据。这影响了我们发货及库存同步，间接地产生了不同类型的资损。\n技术挑战 我们在技术上面临的挑战主要有以下三个方面：\n 高并发。在电商业务场景下，不管是面向用户，比如秒杀，还是面向业务，比如订单处理，如果实现不了高并发，系统就很难做大，很难适应业务的增长。 高性能。除了用高并发来实现业务的快速处理外，性能也是一个挑战。例如在当前疫情状态下，各行各业都在降本增效，解决不了性能问题，就会不断地增加服务器资源，大大增加企业成本。 技术保障。我们电商行业的公司，大多资源和精力都在销售端，运营端，技术方面投入相对薄弱。因此在技术选型上需要从可靠、安全、支持等维度去考量。  项目的技术选型 如何选择 在开发语言的选择方面，开发语言没有好坏之分，只有这个语言在相关场景下合适不合适的问题。我们从性能、多线程、编译、效率等方面综合考虑，选择了 Golang。\n在微服务框架的选择方面，团队分别用 Google 开源的 gRPC 和字节跳动开源的 CloudWeGo-Kitex 做了技术评估和性能压测。经过专业测试同学的压力测试，最终选择了 CloudWeGo-Kitex 作为我们的微服务框架。\n选择 Kitex 的原因主要有两点。第一是 Kitex 背后有强大的技术团队提供及时有效的技术支持。第二是经过压力测试，Kitex 的性能优于其他微服务框架。\n关于微服务 使用微服务框架，一定会涉及到选择第三方开源的服务注册中心，那么是选择常用的开源注册中心（Zookeeper、Eureka、Nacos、Consul 和 ETCD）， 还是直接选择云原生的服务网格（Istio）？那么我从流量转发、服务注册和服务发现维度介绍一下微服务集群的两种形式。\n第一种是 Kubernetes Native，Kubernetes 集群中的每个节点都部署了一个 Kube-proxy 组件，该组件与 Kubernetes API Server 进行通信，观测服务和节点中的变化，进行负载均衡的转发。 这种开源注册中心默认使用 TCP 协议，由于 K8s 负载均衡不支持 RPC 协议（HTTP2），因而需要额外的第三方服务注册中心支持。\n第二种是基于 Istio 的服务网格，它并不需要额外的注册中心组件支持。Istio 接管了 K8s 的网络，通过 Sidecar Proxy 的方式将 Kubernetes 中的流量控制从服务层中抽离出来， Istio 基于 Enovy 的 xDS 协议扩展了其控制平面，每个 Pod 中放入原有的 Kube-proxy 路由转发功能。Istio 具备了流量管理、策略控制、可观察性等特点，将“应用程序”与“网络”解耦，因此不需要额外使用第三方注册中心。\n 那么这两种服务注册与发现的流程是怎样的呢？ 下图中左侧就是常用的服务注册中心使用流程。目标服务先把实例注册到服务注册中心，客户端从服务注册中心拿到目标实例的数据，根据负载均衡策略去选择一个服务实例，完成整个请求。 右侧是使用了基于 Istio 的服务网格。大概流程是 Client 访问目标服务的时候，流量先进入 Service 的 Proxy，被 Proxy 拦截，Proxy 会从服务发现（Pilot）拿到服务与服务实例的映射关系， 同时会拿到负载均衡的策略，去选择 Service 一个实例。总体来看，这两种流程大致相同，但实现方式有所差别，各有所长。\n天枢系统基本架构 像抖音、快手、拼多多和有赞等这样成熟的平台在产生订单时，都会将订单以消息推送的形式发送到服务网格中。我们先后通过 Ingress Gateway 网格入口管理程序、VirtualService 把订单转发到网格的不同服务中， 内部再通过不同服务之间进行调用。其中，Kitex 作为微服务的 RPC 框架，服务发现和服务注册均是基于云原生的服务网格 Istio。\nKitex 接入 Istio 那么 Kitex 接入 Istio 是怎么实现的呢？如下图所示，服务端注册服务之后，在创建客户端的时候，客户端的 Server-host 要写实际集群中的内网地址，例如：server-douyin.default.svc.cluster.local，如上文所说，不用再搭配第三方的服务注册中心。\n由于 Kitex 使用 gRPC 协议，在创建客户端的时候需指定使用 gRPC 协议：\n在 Istio 中怎么部署我们的客户端或者服务端呢？有以下两种方式：\n 为命名空间开启自动注入：kubectl label namespace default istio-injection=enabled。注入之后会产生两个重要的容器，第一个是 Istio-proxy，负责流量拦截和流量代理，比如做流量转发；第二个是 Server-douyin，是负责开发的应用容器。  把 Go 代码打包的镜像部署到集群中： 例如我们创建了一个 Deployment，名为 Server-douyin，另外作为服务端需要创建相应的 Service。  压测对比 我们将 Kitex 和 gRPC 在以下相同服务器硬件资源和网络环境下进行了压测对比：\n 压测工具：JMeter； 阿里云 ECS （8 vCPU，16 GiB，5 台）； 集群：Kubernetes 1.20.11； 服务网格：Istio v1.10.5.39。  通过对比发现，在指定时间相同的情况下，Kitex 在单位时间内处理订单数量更多。在指定订单数量的情况下，Kitex 对于处理相同数量的订单所需时间更短，且订单量越大，这种性能差别越明显。总体来看，Kitex 在处理大批订单时优势还是非常突出的。\nKitex 产生性能优势的原因 CloudWeGo 团队来森马做技术支持时讲到对自研网络库 Netpoll 做了一些性能优化，比如：\n 连接利用率； 调度延迟优化； 优化 I/O 调用； 序列化/反序列化优化； …….  更多资料可以查看 CloudWeGo 官网或参考官网博客\nCloudWeGo 团队的技术支持 我们选择 Kitex 之后，CloudWeGo 技术团队给予了足够的技术支持，包括现场支持和远程协助。这也让我们对使用 Kitex 有了信心，不管遇到什么样的技术难题，都会有强大的技术团队来协助解决。\n后续规划 Thrift 和 Protobuf 如何选择 我们在项目初期选择 gRPC 协议 Protobuf 是因为选择了 Istio 服务网格，而选择 Istio 服务网格主要是因为它有多流量转发和服务治理等功能，例如在电商场景下， 不同平台的推送消息都可以通过 VirtualService 转发到不同的服务，相当方便。但是目前每个 Pod 中放入原有的 Kube-proxy 路由转发功能，会增加响应延迟。由于 Sidecar 拦截流量时跳数更多，会消耗更多的资源。\n而对于 Thrift，它是 Kitex 默认支持的协议，字节官方对它做了很多性能上的优化，如：使用 SIMD 优化 Thrift 编码，减少函数调用，减少内存操作等，还开源了高性能 Thrift 编解码器 Frugal， Frugal 具有无需生成代码、高性能（在多核场景下，Frugal 的性能可以达到传统编解码方式的 5 倍）和稳定性等特点，进一步提升了性能和开发效率。\n因此，我们目前也在考虑在下一次系统版本的架构中改用 Thrift 协议。\n服务、合作共赢 我们开发的电商相关产品不仅可以为自己电商品牌所使用，产品成熟后还可以服务于其他相似的电商公司。后续我们也希望能够和 Kitex 官方有更深的技术合作，为社区带来更大价值。\n","categories":"","description":"","excerpt":"案例介绍   近些年电商行业高速发展，森马电商线上业务激增，面临着高并发、高性能的业务场景需求。森马通过使用 Kitex 接入 Istio， …","ref":"/zh/cooperation/semir/","tags":"","title":"Kitex 在森马电商场景的落地实践"},{"body":" SUPPORT 漏洞管理   # 漏洞响应   CloudWeGo 社区非常重视社区版本的安全性，CloudWeGo 安全委员会负责接收、调查和披露 CloudWeGo 社区相关的安全漏洞。我们鼓励漏洞研究人员和行业组织主动将 CloudWeGo 社区的疑似安全漏洞报告给 CloudWeGo 社区安全委员会。我们会快速的响应、分析和解决上报的安全问题或安全漏洞。\n# 支持版本 漏洞响应流程主要支持 CloudWeGo 社区各个子项目的最新版本，如果您还没有升级请尽快升级。\n# 漏洞处理流程 每个一个安全漏洞都会有一个指定的人员进行跟踪和处理，协调员是 CloudWeGo 安全委员会的成员，他将负责跟踪和推动漏洞的修复和披露。漏洞端到端的处理流程如下图。\n在这里我们主要介绍流程中漏洞上报、漏洞评估和漏洞披露这三部分内容。\n# 漏洞上报 如果您认为 CloudWeGo 产品存在一个疑似安全漏洞，我们希望您将漏洞上报给 CloudWeGo 社区，并与我们配合以负责任的方式修复和披露该问题。\n# 漏洞上报方式 您可以通过 email 将 CloudWeGo 产品的潜在安全漏洞发送到 CloudWeGo 安全团队邮箱（security@cloudwego.io）。 # 漏洞上报内容 为了便于快速的确认和验证疑似漏洞，请在漏洞上报邮件中包含但不限于以下内容：\n 基本信息：包括漏洞影响的模块、漏洞的触发条件和成功利用后对系统的影响等。\n 技术细节：包括系统配置、定位方法、Exploit 的描述、POC、问题重现方法和步骤等。\n 修复方案建议。\n 上报者的组织和联系方式。\n 上报者可能的漏洞披露计划。\n  # 邮件响应时间 我们将在48小时内响应通过邮箱上报的疑似安全漏洞，并向上报者反馈漏洞处理的进展。\n# 漏洞严重性评估  业界普遍使用 CVSS 标准评估漏洞的严重性，CloudWeGo 在使用 CVSSv3 进行漏洞评估时，需要设定漏洞攻击场景，基于在该攻击场景下的实际影响进行评估。漏洞严重等级评估是指针对漏洞利用难易程度，以及利用后对机密性、完整性、可用性的影响进行评估，并生成一个评分值。\n# 评估标准 CloudWeGo 社区采用 CVSS v3 对漏洞进行评估，CVSS V3 由通过对以下向量来评估一个漏洞的影响：\n 攻击向量（AV）-表示攻击的“远程性”以及如何利用此漏洞。\n 攻击复杂性（AC）-讲述攻击执行的难度以及成功进行攻击需要哪些因素。\n 用户交互（UI）-确定攻击是否需要用户参与。\n 所需的权限（PR）-记录成功进行攻击所需的用户身份验证级别。\n 范围（S）-确定攻击者是否可以影响具有不同权限级别的组件。\n 机密性（C）-衡量信息泄露给非授权方后导致的影响程度。\n 完整性（I）-衡量信息被篡改后导致的影响程度。\n 可用性（A）-衡量用户在需要访问数据或服务时受影响的程度。\n  # 评估原则  评估漏洞的严重等级，不是评估风险。\n 评估时必须基于攻击场景，且保证在该场景下，攻击者成功攻击后能对系统造成机密性、完整性、可用性影响。\n 当安全漏洞有多个攻击场景时，应以造成最大的影响，即 CVSS 评分最高的攻击场景为依据。\n 被嵌入调用的库存在漏洞，要根据该库在产品中的使用方式，确定漏洞的攻击场景后进行评估。\n 安全缺陷不能被触发或不影响 CIA(机密性/完整性/可用性)，CVSS 评分为0分。\n  # 评估步骤 对漏洞进行评估时，可根据下述步骤进行操作：\n 设定可能的攻击场景，基于攻击场景评分。\n 确定漏洞组件（Vulnerable Component）和受影响组件（Impact Component）。\n 选择基础评估指标的值：通过对可利用指标（攻击向量/攻击复杂度/所需权限/用户交互/范围）和受影响指标（机密性/完整性/可用性）给出漏洞影响评估。\n  # 严重等级划分   严重等级（Severity Rating） CVSS 评分（Score）   致命（Critical） 9.0 - 10.0   高（High） 7.0 - 8.9   中（Medium） 4.0 - 6.9   低（Low） 0.1 - 3.9   无（None） 0.0    # 漏洞披露  为了保护 CloudWeGo 用户的安全，在进行调查、修复和发布安全公告之前，CloudWeGo 社区不会公开披露、讨论或确认 CloudWeGo 产品的安全问题。安全漏洞修复后 CloudWeGo 社区会发布安全公告，安全公告内容包括该漏洞的技术细节、CVE编号、CVSS安全评分、严重性等级以及受到该漏洞影响的版本和修复版本等信息。   ","categories":"","description":"","excerpt":" SUPPORT 漏洞管理   # 漏洞响应   CloudWeGo 社区非常重视社区版本的安全性，CloudWeGo 安全委员会负责接收、 …","ref":"/zh/security/vulnerability-reporting/","tags":"","title":"漏洞管理"},{"body":"Hertz 遵从 语义化版本 2.0.0 发布版本。\n 主版本号：Hertz 提供的 API 出现不兼容的情况时，升级该版本号 次版本号：Hertz 提供新的功能特性同时保持向下兼容时，升级该版本号 修订号：Hertz 的代码提供小的特性或向下兼容的优化和问题修复时，升级该版本号  ","categories":"","description":"","excerpt":"Hertz 遵从 语义化版本 2.0.0 发布版本。\n 主版本号：Hertz 提供的 API 出现不兼容的情况时，升级该版本号 次版本 …","ref":"/zh/docs/hertz/reference/version/","tags":"","title":"版本说明"},{"body":"服务发现 Discover trait 提供了自定义服务发现的能力，其支持自定义静态或可订阅的服务发现能力。\nTrait 定义\n/// [`Instance`] contains information of an instance from the target service. #[derive(Debug, Clone, PartialEq, Eq)]pubstruct Instance{pubaddress: Address,pubweight: u32,pubtags: HashMap\u003cCow\u003c'static,str\u003e,Cow\u003c'static,str\u003e\u003e,}/// Change indicates the change of the service discover. /// /// Change contains the difference between the current discovery result and the previous one. /// It is designed for providing detail information when dispatching an event for service /// discovery result change. /// /// Since the loadbalancer may rely on caching the result of discover to improve performance, /// the discover implementation should dispatch an event when result changes. #[derive(Debug, Clone)]pubstruct Change\u003cK\u003e{/// `key` should be the same as the output of `WatchableDiscover::key`, /// which is often used by cache. pubkey: K,puball: Vec\u003cArc\u003cInstance\u003e\u003e,pubadded: Vec\u003cArc\u003cInstance\u003e\u003e,pubupdated: Vec\u003cArc\u003cInstance\u003e\u003e,pubremoved: Vec\u003cArc\u003cInstance\u003e\u003e,}/// [`Discover`] is the most basic trait for Discover. pubtraitDiscover: Send +Sync+'static{/// `Key` identifies a set of instances, such as the cluster name. type Key: Hash+PartialEq+Eq+Send+Sync+Clone+'static;/// `Error` is the discovery error. type Error: std::error::Error+Send+Sync;/// `DiscFut` is a Future object which returns a discovery result. type DiscFut\u003c'future\u003e: Future\u003cOutput=Result\u003cVec\u003cArc\u003cInstance\u003e\u003e,Self::Error\u003e\u003e+Send+'future;/// `discover` allows to request an endpoint and return a discover future. fn discover(\u0026self,endpoint: \u0026Endpoint)-\u003e Self::DiscFut\u003c'_\u003e;/// `key` should return a key suitable for cache. fn key(\u0026self,endpoint: \u0026Endpoint)-\u003e Self::Key;/// `watch` should return a [`async_broadcast::Receiver`] which can be used to subscribe /// [`Change`]. fn watch(\u0026self)-\u003e Option\u003cReceiver\u003cChange\u003cSelf::Key\u003e\u003e\u003e;}示例\npubstruct StaticDiscover{instances: Vec\u003cArc\u003cInstance\u003e\u003e,}implDiscoverforStaticDiscover{type Key=();type Error=Infallible;type DiscFut\u003c'a\u003e=implFuture\u003cOutput=Result\u003cVec\u003cArc\u003cInstance\u003e\u003e,Self::Error\u003e\u003e+'a;fn discover(\u0026self,_: \u0026Endpoint)-\u003e Self::DiscFut\u003c'_\u003e{async{Ok(self.instances.clone())}}fn key(\u0026self,_: \u0026Endpoint)-\u003e Self::Key{}fn watch(\u0026self)-\u003e Option\u003casync_broadcast::Receiver\u003cChange\u003cSelf::Key\u003e\u003e\u003e{None}}负载均衡 Volo 提供基于 LoadBalance trait 自定义负载均衡策略的能力：\n/// [`LoadBalance`] promise the feature of the load balance policy. pubtraitLoadBalance\u003cD\u003e: Send +Sync+'staticwhereD: Discover,{/// `InstanceIter` is an iterator of [`crate::discovery::Instance`]. type InstanceIter: Iterator\u003cItem=Address\u003e+Send;/// `GetFut` is the return type of `get_picker`. type GetFut\u003c'future\u003e: Future\u003cOutput=Result\u003cSelf::InstanceIter,LoadBalanceError\u003e\u003e+Send+'futurewhereSelf: 'future;/// `get_picker` allows to get an instance iterator of a specified endpoint from self or /// service discovery. fn get_picker\u003c'future\u003e(\u0026'futureself,endpoint: \u0026'futureEndpoint,discover: \u0026'futureD,)-\u003e Self::GetFut\u003c'future\u003ewhereSelf: 'future;/// `rebalance` is the callback method be used in service discovering subscription. fn rebalance(\u0026self,changes: Change\u003cD::Key\u003e);}示例\npubstruct InstancePicker{instances: Vec\u003cArc\u003cInstance\u003e\u003e,index: usize }implIteratorforInstancePicker{type Item=Address;fn next(\u0026mutself)-\u003e Option\u003cSelf::Item\u003e{leti=self.instances.get(self.index);self.index+=1;i.map(|i|i.clone().address.clone())}}#[derive(Clone)]pubstruct RoundRobin\u003cK\u003ewhereK: Hash+PartialEq+Eq+Send+Sync+'static,{router: DashMap\u003cK,Arc\u003cVec\u003cArc\u003cInstance\u003e\u003e\u003e\u003e,}impl\u003cD\u003eLoadBalance\u003cD\u003eforRoundRobin\u003cD::Key\u003ewhereD: Discover,{type InstanceIter=InstancePicker;type GetFut\u003c'future\u003e=implFuture\u003cOutput=Result\u003cSelf::InstanceIter,LoadBalanceError\u003e\u003e+Send+'futurewhereSelf: 'future;fn get_picker\u003c'future\u003e(\u0026'futureself,endpoint: \u0026'futureEndpoint,discover: \u0026'futureD,)-\u003e Self::GetFut\u003c'future\u003ewhereSelf: 'future,{async{letkey=discover.key(endpoint);letlist=matchself.router.entry(key){Entry::Occupied(e)=\u003ee.get().clone(),Entry::Vacant(e)=\u003e{letinstances=Arc::new(discover.discover(endpoint).await?);e.insert(instances).value().clone()}};Ok(InstancePicker{instances: list.to_vec(),index: 0})}}fn rebalance(\u0026self,changes: Change\u003cD::Key\u003e){ifletEntry::Occupied(entry)=self.router.entry(changes.key.clone()){entry.replace_entry(Arc::new(changes.all));}}}","categories":"","description":"","excerpt":"服务发现 Discover trait 提供了自定义服务发现的能力，其支持自定义静态或可订阅的服务发现能力。\nTrait 定义\n/// …","ref":"/zh/docs/volo/guide/discovery_lb/","tags":"","title":"自定义服务发现与负载均衡"},{"body":"在微服务中，链路追踪是一项很重要的能力，在快速定位问题，分析业务瓶颈，还原一次请求的链路情况等方面发挥重要作用。Hertz 提供了链路追踪的能力，也支持用户自定义链路跟踪。\nHertz 将 trace 抽象为以下接口：\n// Tracer is executed at the start and finish of an HTTP. type Tracer interface { Start(ctx context.Context, c *app.RequestContext) context.Context Finish(ctx context.Context, c *app.RequestContext) } 使用 server.WithTracer() 配置添加 tracer，可以添加多个 tracer。\nHertz 会在请求开始之前(读包之前)执行所有 tracer 的 Start 方法，在请求结束之后(写回数据之后)执行所有 tracer 的Finish 方法。这种实现时需要注意：\n Start 方法执行时，刚开始接受包，这个时候 requestContext 是一个“空”的 requestContext，并不能拿到这次请求的相关信息。如果想在解包后中拿到一些信息(如在 header 中的 traceID 等)再进行操作时，可以使用中间件能力将 traceID 注入到 span 中。 在中间件内对 context 的修改是无效的。  在 requestContext 内存有 traceInfo，其有以下信息\ntype HTTPStats interface { Record(event stats.Event, status stats.Status, info string) // 记录事件  GetEvent(event stats.Event) Event // 获取事件  SendSize() int // 获取 SendSize  RecvSize() int // 获取 RecvSize  Error() error // 获取 Error  Panicked() (bool, interface{}) // 获取 Panic  Level() stats.Level // 获取当前 trace 等级  SetLevel(level stats.Level) // 设置 trace 等级，当事件等级高于 trace 等级时不上报  ... } 事件包括：\nHTTPStart = newEvent(httpStart, LevelBase) // 请求开始 HTTPFinish = newEvent(httpFinish, LevelBase) // 请求结束  ServerHandleStart = newEvent(serverHandleStart, LevelDetailed) // 业务 handler 开始 ServerHandleFinish = newEvent(serverHandleFinish, LevelDetailed) // 业务 handler 结束 ReadHeaderStart = newEvent(readHeaderStart, LevelDetailed) // 读取 header 开始 ReadHeaderFinish = newEvent(readHeaderFinish, LevelDetailed) // 读取 header 结束 ReadBodyStart = newEvent(readBodyStart, LevelDetailed) // 读取 body 开始 ReadBodyFinish = newEvent(readBodyFinish, LevelDetailed) // 读取 body 结束 WriteStart = newEvent(writeStart, LevelDetailed) // 写 response 开始 WriteFinish = newEvent(writeFinish, LevelDetailed) // 写 response 结束 在 Finish 时可以获取到上述信息。\n同时，如果不希望记录这些信息，可以不注册任何 tracer ，则框架停止对这些信息的记录。\nhertz-contrib 中提供了 opentracing 的扩展方式，也在 hertz-examples 提供了可以从 http 到 rpc 调用的 demo。 仓库： https://github.com/hertz-contrib/tracer\n","categories":"","description":"","excerpt":"在微服务中，链路追踪是一项很重要的能力，在快速定位问题，分析业务瓶颈，还原一次请求的链路情况等方面发挥重要作用。Hertz 提供了链路追踪的 …","ref":"/zh/docs/hertz/tutorials/observability/tracing/","tags":"","title":"链路追踪"},{"body":"Create a project based on thrift IDL new: Create a new project  Create the thrift IDL file in the current directory  // idl/hello.thrift namespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");// Add api annotations for easier parameter binding }structHelloResp{1:stringRespBody;}serviceHelloService{HelloRespHelloMethod(1:HelloReqrequest)(api.get=\"/hello\");}Create a new project  // Execute under GOPATH hz new -idl idl/hello.thrift go mod init go mod edit -replace github.com/apache/thrift=github.com/apache/thrift@v0.13.0 // Tidy \u0026 get dependencies go mod tidy // Execute is not under GOPATH //option 1,you do not have a go.mod, add go mod name after \"-module\" hz new -module example.com/m -idl idl/hello.thrift // Tidy \u0026 get dependencies go mod tidy //option 2,you already have a go.mod go mod edit -replace github.com/apache/thrift=github.com/apache/thrift@v0.13.0 // Tidy \u0026 get dependencies go mod tidy Modify the handler and add your own logic  // handler path: biz/handler/hello/example/hello_service.go // where \"hello/example\" is the namespace of thrift IDL // \"hello_service.go\" is the name of the service in the thrift IDL, all methods defined by the service will be generated in this file  // HelloMethod . // @router /hello [GET] func HelloMethod(ctx context.Context, c *app.RequestContext) { var err error var req example.HelloReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(example.HelloResp) // You can modify the logic of the entire function, not just the current template  resp.RespBody = \"hello,\" + req.Name // added logic  c.JSON(200, resp) } Compile the project  go build Run the project and test it  Run the project:\n./{{your binary}} Test:\ncurl --location --request GET 'http://127.0.0.1:8888/hello?name=hertz' If it returns {\"RespBody\":\"hello,hertz\"}, it works.\nupdate: Update an existing project  If your thrift IDL is updated, for example:  // idl/hello.thrift namespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");}structHelloResp{1:stringRespBody;}structOtherReq{1:stringOther (api.body=\"other\");}structOtherResp{1:stringResp;}serviceHelloService{HelloRespHelloMethod(1:HelloReqrequest)(api.get=\"/hello\");OtherRespOtherMethod(1:OtherReqrequest)(api.post=\"/other\");}serviceNewService{HelloRespNewMethod(1:HelloReqrequest)(api.get=\"/new\");}Switch to the directory where the new command was executed and update the modified thrift IDL  hz update -idl idl/hello.thrift  As you can see\nAdd new method under “biz/handler/hello/example/hello_service.go”\nThe file “new_service.go” and the corresponding “NewMethod” method have been added under “biz/handler/hello/example”\n  Now let’s develop the “OtherMethod” interface\n// HelloMethod . // @router /hello [GET] func HelloMethod(ctx context.Context, c *app.RequestContext) { var err error var req example.HelloReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(example.HelloResp) // You can modify the logic of the entire function, not just the current template  resp.RespBody = \"hello,\" + req.Name // added logic  c.JSON(200, resp) } // OtherMethod . // @router /other [POST] func OtherMethod(ctx context.Context, c *app.RequestContext) { var err error // The model file corresponding to example.OtherReq will also be regenerated  var req example.OtherReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(example.OtherResp) // added logic  resp.Resp = \"Other method: \" + req.Other c.JSON(200, resp) } Compile the project  go build Run the project and test it  Run the project:\n./{{your binary}} Test：\ncurl --location --request POST 'http://127.0.0.1:8888/other' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"Other\": \"other method\" }' If it returns {\"Resp\":\"Other method: other method\"}, it works.\n","categories":"","description":"","excerpt":"Create a project based on thrift IDL new: Create a new project  Create …","ref":"/docs/hertz/tutorials/toolkit/usage/usage-thrift/","tags":"","title":"hz usage(thrift)"},{"body":"基于 thrift IDL 创建项目 new: 创建一个新项目  在当前目录下创建 thrift idl 文件  // idl/hello.thrift namespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");// 添加 api 注解为方便进行参数绑定 }structHelloResp{1:stringRespBody;}serviceHelloService{HelloRespHelloMethod(1:HelloReqrequest)(api.get=\"/hello\");}创建新项目  // GOPATH 下执行 hz new -idl idl/hello.thrift go mod init go mod edit -replace github.com/apache/thrift=github.com/apache/thrift@v0.13.0 // 整理 \u0026 拉取依赖 go mod tidy // 非GOPATH 下执行 //选择1，你没有一个go.mod ,在 \"-module\" 后添加 go mod 名 hz new -module example.com/m -idl idl/hello.thrift // 整理 \u0026 拉取依赖 go mod tidy //选择2，你已经有一个go.mod go mod edit -replace github.com/apache/thrift=github.com/apache/thrift@v0.13.0 // 整理 \u0026 拉取依赖 go mod tidy 修改 handler，添加自己的逻辑  // handler path: biz/handler/hello/example/hello_service.go // 其中 \"hello/example\" 是 thrift idl 的 namespace // \"hello_service.go\" 是 thrift idl 中 service 的名字，所有 service 定义的方法都会生成在这个文件中  // HelloMethod . // @router /hello [GET] func HelloMethod(ctx context.Context, c *app.RequestContext) { var err error var req example.HelloReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(example.HelloResp) // 你可以修改整个函数的逻辑，而不仅仅局限于当前模板  resp.RespBody = \"hello,\" + req.Name // 添加的逻辑  c.JSON(200, resp) } 编译项目  go build 运行项目并测试  运行项目：\n./{{your binary}} 测试：\ncurl --location --request GET 'http://127.0.0.1:8888/hello?name=hertz' 如果返回{\"RespBody\":\"hello,hertz\"}，说明接口调通。\nupdate: 更新一个已有的项目  如果你的 thrift idl 有更新，例如：  // idl/hello.thrift namespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");}structHelloResp{1:stringRespBody;}structOtherReq{1:stringOther (api.body=\"other\");}structOtherResp{1:stringResp;}serviceHelloService{HelloRespHelloMethod(1:HelloReqrequest)(api.get=\"/hello\");OtherRespOtherMethod(1:OtherReqrequest)(api.post=\"/other\");}serviceNewService{HelloRespNewMethod(1:HelloReqrequest)(api.get=\"/new\");}切换到执行 new 命令的目录，更新修改后的 thrift idl  hz update -idl idl/hello.thrift  可以看到\n在 “biz/handler/hello/example/hello_service.go” 下新增了新的方法\n在 “biz/handler/hello/example” 下新增了文件 “new_service.go” 以及对应的 “NewMethod” 方法。\n  下面我们来开发 “OtherMethod” 接口\n// HelloMethod . // @router /hello [GET] func HelloMethod(ctx context.Context, c *app.RequestContext) { var err error var req example.HelloReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(example.HelloResp) // 你可以修改整个函数的逻辑，而不仅仅局限于当前模板  resp.RespBody = \"hello,\" + req.Name // 添加的逻辑  c.JSON(200, resp) } // OtherMethod . // @router /other [POST] func OtherMethod(ctx context.Context, c *app.RequestContext) { var err error // example.OtherReq 对应的model文件也会重新生成  var req example.OtherReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(example.OtherResp) // 增加的逻辑  resp.Resp = \"Other method: \" + req.Other c.JSON(200, resp) } 编译项目  go build 运行项目并测试  运行项目：\n./{{your binary}} 测试：\ncurl --location --request POST 'http://127.0.0.1:8888/other' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"Other\": \"other method\" }' 如果返回{\"Resp\":\"Other method: other method\"}，说明接口调通。\n","categories":"","description":"","excerpt":"基于 thrift IDL 创建项目 new: 创建一个新项目  在当前目录下创建 thrift idl 文件  // …","ref":"/zh/docs/hertz/tutorials/toolkit/usage/usage-thrift/","tags":"","title":"hz 使用 (thrift)"},{"body":"Currently, hz code generation is based on the plugin model of “thriftgo” and “protoc”, which is a great help in accessing some third party plugins, especially for “protoc” which currently supports a rich plugin ecosystem.\nSo hz provides the means to extend third-party plug-ins.\nThriftGo Plugin Usage hz new --idl={YOUR-IDL.thrift} --thrift-plugins={PLUGIN-NAME} If the plugin needs to pass some options, they are as follows:\nhertztool new --idl={YOUR-IDL.thrift} --thrift-plugins={PLUGIN-NAME}:{YOUR-OPTION1,YOUR-OPTION2} Example Currently, thriftgo provides a plugin “thrift-gen-validator” for generating structural parameter validation functions that can be generated along with the model.\n  Install : go install github.com/cloudwego/thrift-gen-validator@latest\n  Use : hz new --idl=idl/hello.thrift --thrift-plugins=validator\n  Code : code\n  Protoc Plugin go_package Detail The path to the go file generated by the Protoc plugin depends on the definition of the “go_package” option. So let’s take a closer look at the role of “go_package”: “option go_package” in the proto file refers to the import location of the go file generated by this file, as follows\nIf the go_package option is defined this way:\noption go_package = \"github.com/a/b/c\";If you then want to cite the content that generated it, you can do so as follows:\nimport \"github.com/a/b/c\" var req c.XXXStruct In addition, the “option go_package” is also related to the path to the generated code. It is as follows:\nIf the option go_package is defined this way:\n// psm.proto option go_package = \"github.com/a/b/c\";The generated go file will be located at: github.com/a/b/c/psm.pb.go\nIn addition, “option go_package” can be used in conjunction with the go module as follows\nIf the option go_package is defined like this:\n// psm.proto option go_package = \"github.com/a/b/c\";Initialize the go module\ngo mod init github.com/a/b Generate code and specify module\nprotoc go_out=. --go_opt=module=github.com/a/b psm.proto Then the generated file will be: c/psm.pb.go\nHowever, since the module for this project is “github.com/a/b”; so, if you refer to the generated content of this file,\nthe import path would still be “github.com/a/b/c”\nUsage Currently, hz is doing some processing of “go_package” in order to unify the generated models, with the following rules:\nSuppose the current project is github.com/a/b:\n go_package=“github.com/a/b/c/d”: the code will be generated under “/biz/model/c/d”; (no change) go_package=“github.com/a/b/biz/model/c/d”: will generate the model under “/biz/model/c/d”, where “biz/model” is the default model generation path, which can be changed with the “-model_dir” option. go_package=“x/y/z”: will generate the code under “biz/model/x/y/z” (relative path completion) (no change). go_package=“google.com/whatever”: no code (external IDL) will be generated (no change). go_package=“github.com/a/b/c”: code will be generated under “biz/model/c” (no change).  So you can simply define a “go_package” such as “{$MODULE}/{$MODEL_DIR}/x/y/z” (where {$MODEL_DIR} defaults to “biz/model”, or you can use the “model_dir” option to define it) to enable access to third-party plugins on the hz side.\nUse the command :\nhertztool new --idl={YOUR-IDL.proto} --protoc-plugins={PLUGIN_NAME}:{OPTION1,OPTION2}:{OUT_DIR} --mod={YOUR_MODULE} Example Here is an example of using the Hz integration protoc-gen-openapi plugin to generate openapi 3.0 documentation.\n  Install :go install github.com/google/gnostic/cmd/protoc-gen-openapi@latest\n  Define go_package for idl: “middleware/hertz/biz/model/psm”\n  Usage : hz new -I=idl --idl=idl/hello/hello.proto --protoc-plugins=openapi::./docs --mod=middleware/hertz\n  Code : code\n  ","categories":"","description":"","excerpt":"Currently, hz code generation is based on the plugin model of …","ref":"/docs/hertz/tutorials/toolkit/plugin/","tags":"","title":"hz access plugin"},{"body":"目前，hz 的代码生成是基于 “thriftgo” 和 “protoc” 的插件模式生成的，这对于接入一些第三方的插件提供了很大的帮助，尤其是对于 “protoc” 来说，目前其支持的插件生态相当丰富。\n因此，hz 提供了拓展第三方插件的方法。\nThriftGo 插件扩展 使用方法 hz new --idl={YOUR-IDL.thrift} --thrift-plugins={PLUGIN-NAME} 如果插件需要传一些选项的话，如下\nhertztool new --idl={YOUR-IDL.thrift} --thrift-plugins={PLUGIN-NAME}:{YOUR-OPTION1,YOUR-OPTION2} 示例 目前， thriftgo 提供一个生成结构体参数验证函数的插件 “thrift-gen-validator”，可在生成 model 的时候一并生成结构体参数验证函数。\n  安装: go install github.com/cloudwego/thrift-gen-validator@latest\n  使用: hz new --idl=idl/hello.thrift --thrift-plugins=validator\n  代码: code\n  Protoc 插件拓展 go_package 详解 Protoc 插件生成的 go 文件路径与 “option go_package” 的定义相关。因此先来仔细介绍下 “go_package” 的作用: “option go_package” 在 proto 文件中指该文件生成的 go 文件的 import 位置，如下\n如果 option go_package 这么定义:\noption go_package = \"github.com/a/b/c\";那么如果要引用生成它的内容，则可按照如下方法:\nimport \"github.com/a/b/c\" var req c.XXXStruct 此外，“option go_package” 还和生成代码的路径有关系，如下\n如果 option go_package 这么定义:\n// psm.proto option go_package = \"github.com/a/b/c\";那么生成的 go 文件的位置为: github.com/a/b/c/psm.pb.go\n另外，“option go_package” 还可以和 go module 进行配合，如下\n如果 option go_package 这么定义:\n// psm.proto option go_package = \"github.com/a/b/c\";初始化 go module\ngo mod init github.com/a/b 生成代码并指定 module\nprotoc go_out=. --go_opt=module=github.com/a/b psm.proto 那么生成文件的位置为: c/psm.pb.go，不过，由于该项目的 module 为 “github.com/a/b”；所以如果引用该文件的生成内容的话，其 import 路径依然是 “github.com/a/b/c”\n使用方法 目前 hz 为统一管理生成的 model， 对 “go_package” 进行了一些处理， 其规则如下:\n假设当前项目是 github.com/a/b:\n go_package=“github.com/a/b/c/d”: 会在 “/biz/model/c/d” 下生成代码；(不变) go_package=“github.com/a/b/biz/model/c/d”: 会在 “/biz/model/c/d” 下生成 model ，其中 “biz/model” 是默认的 model 生成路径，可使用 “-model_dir” 选项修改。 go_package=“x/y/z”: 会在 “biz/model/x/y/z” 下生成代码（相对路径补全）（不变）； go_package=“google.com/whatever”: 不会生成代码（外部 IDL）（不变）； go_package=“github.com/a/b/c”: 会在\"biz/model/c\" 下生成代码（不变）；  因此，用户只需定义如 “{$MODULE}/{$MODEL_DIR}/x/y/z” 这样的 “go_package” (其中 {$MODEL_DIR} 默认为\"biz/model\", 用户也可使用 “model_dir” 选项来定义)，就可以完成 hz 侧的第三方插件接入。\n使用命令:\nhertztool new --idl={YOUR-IDL.proto} --protoc-plugins={PLUGIN_NAME}:{OPTION1,OPTION2}:{OUT_DIR} --mod={YOUR_MODULE} 示例 这里以使用 Hz 时集成 protoc-gen-openapi 插件用来生成 openapi 3.0 文档为例。\n  安装:go install github.com/google/gnostic/cmd/protoc-gen-openapi@latest\n  定义 idl 的 go_package:“middleware/hertz/biz/model/psm”\n  使用: hz new -I=idl --idl=idl/hello/hello.proto --protoc-plugins=openapi::./docs --mod=middleware/hertz\n  代码: code\n  ","categories":"","description":"","excerpt":"目前，hz 的代码生成是基于 “thriftgo” 和 “protoc” 的插件模式生成的，这对于接入一些第三方的插件提供了很大的帮助，尤其 …","ref":"/zh/docs/hertz/tutorials/toolkit/plugin/","tags":"","title":"hz 接入第三方生成代码插件"},{"body":"","categories":"","description":"Kitex Features Guide, including basic features, governance features, advanced features, code generation, framework extensions and options.","excerpt":"Kitex Features Guide, including basic features, governance features, …","ref":"/docs/kitex/tutorials/","tags":"","title":"Tutorials"},{"body":"","categories":"","description":"Kitex 功能特性指南，包含基本特性、治理特性、高级特性、代码生成、框架扩展与 Option。","excerpt":"Kitex 功能特性指南，包含基本特性、治理特性、高级特性、代码生成、框架扩展与 Option。","ref":"/zh/docs/kitex/tutorials/","tags":"","title":"指南"},{"body":"WebSocket is a type of full-duplex communication that can be performed on a single TCP connection and is located at the application layer of the OSI model. WebSocket makes data exchange between client and server easier, allowing the server to actively push data to the client. In the WebSocket API, the browser and the server only need to complete a handshake that a persistent connection can be created between the two, and two-way data transmission can be performed.\nHertz provides support for WebSocket and adapts it in Hertz by referring to gorilla/websocket using hijack. The usage and parameters are basically the same.\nInstall go get github.com/hertz-contrib/websocket Example package main import ( \"context\" \"flag\" \"html/template\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/websocket\" ) var addr = flag.String(\"addr\", \"localhost:8080\", \"http service address\") var upgrader = websocket.HertzUpgrader{} // use default options  func echo(_ context.Context, c *app.RequestContext) { err := upgrader.Upgrade(c, func(conn *websocket.Conn) { for { mt, message, err := conn.ReadMessage() if err != nil { log.Println(\"read:\", err) break } log.Printf(\"recv: %s\", message) err = conn.WriteMessage(mt, message) if err != nil { log.Println(\"write:\", err) break } } }) if err != nil { log.Print(\"upgrade:\", err) return } } func home(_ context.Context, c *app.RequestContext) { c.SetContentType(\"text/html; charset=utf-8\") homeTemplate.Execute(c, \"ws://\"+string(c.Host())+\"/echo\") } func main() { flag.Parse() h := server.Default(server.WithHostPorts(*addr)) // https://github.com/cloudwego/hertz/issues/121  h.NoHijackConnPool = true h.GET(\"/\", home) h.GET(\"/echo\", echo) h.Spin() } // Web client code details are available at: https://github.com/hertz-contrib/websocket/blob/main/examples/echo/server.go#L64 var homeTemplate = \"\" run websocket server:\ngo run server.go In the example code above, the server includes a simple web client. To use this client, open http://127.0.0.1:8080 in your browser and follow the instructions on the page.\nConfig The following is the optional configuration parameters for using Hertz WebSocket.\nThis section is organized around the websocket.HertzUpgrader structure.\n   Parameter Introduction     ReadBufferSize Used to set the size of the read buffer in bytes. If the buffer size is zero, then the size allocated by the HTTP server is used. The read buffer size does not limit the size of the messages that can be received.   WriteBufferSize Used to set the size of the write buffer in bytes. If the buffer size is zero, then the size allocated by the HTTP server is used. The write buffer size does not limit the size of the messages that can be sent.   WriteBufferPool Used to set the buffer pool for write operations.   Subprotocols Used to set the protocols supported by the server in order of preference. If this field is not nil, then the Upgrade method negotiates a sub-protocol by selecting the first match in this list to the protocol requested by the client. If there is no match, then no protocol is negotiated (the Sec-Websocket-Protocol header is not included in the handshake response).   Error Used to set a function the generation of HTTP error responses.   CheckOrigin Used to set a check function for Origin header for the request. If the Origin header of the request is acceptable, CheckOrigin returns true.   EnableCompression Used to set whether the server should attempt to negotiate compression for each message (RFC 7692). Setting this value to true does not guarantee that compression will be supported.    WriteBufferPool If this value is not set, an additional write buffer is initialized and allocated to the connection for the current lifetime. The buffer pool is most useful when the application has a moderate amount of writes on a large number of connections.\nApplications should use a single buffer pool to allocate buffers for different connections.\nInterface Description:\n// BufferPool represents a pool of buffers. The *sync.Pool type satisfies this // interface. The type of the value stored in a pool is not specified. type BufferPool interface { // Get gets a value from the pool or returns nil if the pool is empty.  Get() interface{} // Put adds a value to the pool.  Put(interface{}) } Sample Code:\ntype simpleBufferPool struct { v interface{} } func (p *simpleBufferPool) Get() interface{} { v := p.v p.v = nil return v } func (p *simpleBufferPool) Put(v interface{}) { p.v = v } var upgrader = websocket.HertzUpgrader{ WriteBufferPool: \u0026simpleBufferPool{}, } Subprotocols WebSocket simply defines a mechanism for exchanging arbitrary messages. What those messages mean, what kind of messages the client can expect at any given point in time, or what kind of messages they are allowed to send, depends entirely on the implementing application.\nSo you need an agreement between the server and the client about these things. The subprotocol parameters simply allow the client and server to formally exchange this information. You can make up any name for any protocol you want. The server can simply check that the client has followed that protocol during the handshake.\nError If Error is nil, then use the API provided by Hertz to generate the HTTP error response.\nFunction signatures:\nfunc(ctx *app.RequestContext, status int, reason error) Sample Code:\nvar upgrader = websocket.HertzUpgrader{ Error: func(ctx *app.RequestContext, status int, reason error) { ctx.Response.Header.Set(\"Sec-Websocket-Version\", \"13\") ctx.AbortWithMsg(reason.Error(), status) }, } CheckOrigin CheckOrigin returns true if the request Origin header is acceptable. If CheckOrigin is nil, then a safe default is used: return false if the Origin request header is present and the origin host is not equal to request Host header.\nA CheckOrigin function should carefully validate the request origin to prevent cross-site request forgery.\nFunction signatures:\nfunc(ctx *app.RequestContext) bool Default Implementation:\nfunc fastHTTPCheckSameOrigin(ctx *app.RequestContext) bool { origin := ctx.Request.Header.Peek(\"Origin\") if len(origin) == 0 { return true } u, err := url.Parse(b2s(origin)) if err != nil { return false } return equalASCIIFold(u.Host, b2s(ctx.Host())) } EnableCompression The server accepts one or more extension fields that are included in the Sec-WebSocket-Extensions header field extensions requested by the client. When EnableCompression is true, the server matches the extensions it currently supports with its extensions, and supports compression if the match is successful.\nCurrently only the “no context takeover” mode is supported, as described in the HertzUpgrader.Upgrade.\nSetReadTimeout/SetWriteTimeout When using websockets for reading and writing, the read timeout or write timeout can be set similarly as follows.\nSample Code:\nfunc echo(_ context.Context, c *app.RequestContext) { err := upgrader.Upgrade(c, func(conn *websocket.Conn) { defer conn.Close() // \"github.com/cloudwego/hertz/pkg/network\"  conn.NetConn().(network.Conn).SetReadTimeout(1 * time.Second) conn.NetConn().(network.Conn).SetWriteTimeout(1 * time.Second) ... }) if err != nil { log.Print(\"upgrade:\", err) return } } NoHijackConnPool  The hijack conn used for Hertz connection hijacking is pooled and therefore does not support asynchronous operations when the hijacked connection is used in a websocket.\n A hijacked connection can only be closed once, and a second closure will result in a null pointer exception.\nNoHijackConnPool will control whether invite pool to acquire/release the hijackConn or not.\nIf cache pooling is used, it will improve the performance of memory resource allocation, but it will not avoid the exception caused by closing the connection twice.\nIf it is difficult to guarantee that hijackConn will not be closed repeatedly, set it to true.\nSample Code:\nfunc main() { ... // https://github.com/cloudwego/hertz/issues/121  h.NoHijackConnPool = true ... } As for usage, you may refer to examples.\n","categories":"","description":"","excerpt":"WebSocket is a type of full-duplex communication that can be performed …","ref":"/docs/hertz/tutorials/basic-feature/protocol/websocket/","tags":"","title":"Websocket"},{"body":"WebSocket 是一种可以在单个 TCP 连接上进行全双工通信，位于 OSI 模型的应用层。WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就可以创建持久性的连接，并进行双向数据传输。\nHertz 提供了 WebSocket 的支持，参考 gorilla/websocket 库使用 hijack 的方式在 Hertz 进行了适配，用法和参数基本保持一致。\n安装 go get github.com/hertz-contrib/websocket 示例代码 package main import ( \"context\" \"flag\" \"html/template\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/websocket\" ) var addr = flag.String(\"addr\", \"localhost:8080\", \"http service address\") var upgrader = websocket.HertzUpgrader{} // use default options  func echo(_ context.Context, c *app.RequestContext) { err := upgrader.Upgrade(c, func(conn *websocket.Conn) { for { mt, message, err := conn.ReadMessage() if err != nil { log.Println(\"read:\", err) break } log.Printf(\"recv: %s\", message) err = conn.WriteMessage(mt, message) if err != nil { log.Println(\"write:\", err) break } } }) if err != nil { log.Print(\"upgrade:\", err) return } } func home(_ context.Context, c *app.RequestContext) { c.SetContentType(\"text/html; charset=utf-8\") homeTemplate.Execute(c, \"ws://\"+string(c.Host())+\"/echo\") } func main() { flag.Parse() h := server.Default(server.WithHostPorts(*addr)) // https://github.com/cloudwego/hertz/issues/121  h.NoHijackConnPool = true h.GET(\"/\", home) h.GET(\"/echo\", echo) h.Spin() } // 网络客户端代码详见：https://github.com/hertz-contrib/websocket/blob/main/examples/echo/server.go#L64，此处省略 var homeTemplate = \"\" 运行 server：\ngo run server.go 上述示例代码中，服务器包括一个简单的网络客户端。要使用该客户端，在浏览器中打开 http://127.0.0.1:8080，并按照页面上的指示操作。\n配置 以下是 Hertz WebSocket 使用过程中可选的配置参数。\n这部分将围绕 websocket.HertzUpgrader 结构展开说明。\n   参数 介绍     ReadBufferSize 用于设置输入缓冲区的大小，单位为字节。如果缓冲区大小为零，那么就使用 HTTP 服务器分配的大小。输入缓冲区大小并不限制可以接收的信息的大小。   WriteBufferSize 用于设置输出缓冲区的大小，单位为字节。如果缓冲区大小为零，那么就使用 HTTP 服务器分配的大小。输出缓冲区大小并不限制可以发送的信息的大小。   WriteBufferPool 用于设置写操作的缓冲池。   Subprotocols 用于按优先顺序设置服务器支持的协议。如果这个字段不是 nil，那么 Upgrade 方法通过选择这个列表中与客户端请求的协议的第一个匹配来协商一个子协议。如果没有匹配，那么就不协商协议（Sec-Websocket-Protocol 头不包括在握手响应中）。   Error 用于设置生成 HTTP 错误响应的函数。   CheckOrigin 用于设置针对请求的 Origin 头的校验函数， 如果请求的 Origin 头是可接受的，CheckOrigin 返回 true。   EnableCompression 用于设置服务器是否应该尝试协商每个消息的压缩（RFC 7692）。将此值设置为 true 并不能保证压缩会被支持。    WriteBufferPool 如果该值没有被设置，则额外初始化写缓冲区，并在当前生命周期内分配给该连接。当应用程序在大量的连接上有适度的写入量时，缓冲池是最有用的。\n应用程序应该使用一个单一的缓冲池来为不同的连接分配缓冲区。\n接口描述：\n// BufferPool represents a pool of buffers. The *sync.Pool type satisfies this // interface. The type of the value stored in a pool is not specified. type BufferPool interface { // Get gets a value from the pool or returns nil if the pool is empty.  Get() interface{} // Put adds a value to the pool.  Put(interface{}) } 示例代码：\ntype simpleBufferPool struct { v interface{} } func (p *simpleBufferPool) Get() interface{} { v := p.v p.v = nil return v } func (p *simpleBufferPool) Put(v interface{}) { p.v = v } var upgrader = websocket.HertzUpgrader{ WriteBufferPool: \u0026simpleBufferPool{}, } Subprotocols WebSocket 只是定义了一种交换任意消息的机制。这些消息是什么意思，客户端在任何特定的时间点可以期待什么样的消息，或者他们被允许发送什么样的消息，完全取决于实现应用程序。\n所以你需要在服务器和客户端之间就这些事情达成协议。子协议参数只是让客户端和服务端正式地交换这些信息。你可以为你想要的任何协议编造任何名字。服务器可以简单地检查客户在握手过程中是否遵守了该协议。\nError 如果 Error 为 nil，则使用 Hertz 提供的 API 来生成 HTTP 错误响应。\n函数签名：\nfunc(ctx *app.RequestContext, status int, reason error) 示例代码：\nvar upgrader = websocket.HertzUpgrader{ Error: func(ctx *app.RequestContext, status int, reason error) { ctx.Response.Header.Set(\"Sec-Websocket-Version\", \"13\") ctx.AbortWithMsg(reason.Error(), status) }, } CheckOrigin 如果 CheckOrigin 为nil，则使用一个安全的默认值：如果Origin请求头存在，并且源主机不等于请求主机头，则返回false。CheckOrigin 函数应该仔细验证请求的来源，以防止跨站请求伪造。\n函数签名：\nfunc(ctx *app.RequestContext) bool 默认实现：\nfunc fastHTTPCheckSameOrigin(ctx *app.RequestContext) bool { origin := ctx.Request.Header.Peek(\"Origin\") if len(origin) == 0 { return true } u, err := url.Parse(b2s(origin)) if err != nil { return false } return equalASCIIFold(u.Host, b2s(ctx.Host())) } EnableCompression 服务端接受一个或者多个扩展字段，这些扩展字段是包含客户端请求的 Sec-WebSocket-Extensions 头字段扩展中的。当 EnableCompression 为 true 时，服务端根据当前自身支持的扩展与其进行匹配，如果匹配成功则支持压缩。\n目前仅支持“无上下文接管”模式，详见 HertzUpgrader.Upgrade 的实现。\nSetReadTimeout/SetWriteTimeout 当使用 websocket 进行读写的时候，可以通过类似如下方式设置读超时或写超时的时间。\n示例代码：\nfunc echo(_ context.Context, c *app.RequestContext) { err := upgrader.Upgrade(c, func(conn *websocket.Conn) { defer conn.Close() // \"github.com/cloudwego/hertz/pkg/network\"  conn.NetConn().(network.Conn).SetReadTimeout(1 * time.Second) conn.NetConn().(network.Conn).SetWriteTimeout(1 * time.Second) ... }) if err != nil { log.Print(\"upgrade:\", err) return } } NoHijackConnPool  Hertz 连接劫持时所使用的 hijack conn 是池化管理的，因此被劫持的连接在 websocket 中使用的时候，不支持异步操作。\n 劫持的连接仅能被关闭一次，第二次关闭会导致空指针异常。\nNoHijackConnPool 将控制是否使用缓存池来获取/释放劫持连接。如果使用池，将提升内存资源分配的性能，但无法避免二次关闭连接导致的异常。\n如果很难保证 hijackConn 不会被反复关闭，可以将其设置为 true。\n示例代码：\nfunc main() { ... // https://github.com/cloudwego/hertz/issues/121  h.NoHijackConnPool = true ... } 更多用法示例详见 examples 。\n","categories":"","description":"","excerpt":"WebSocket 是一种可以在单个 TCP 连接上进行全双工通信，位于 OSI 模型的应用层。WebSocket 使得客户端和服务器之间的 …","ref":"/zh/docs/hertz/tutorials/basic-feature/protocol/websocket/","tags":"","title":"Websocket"},{"body":"Service Registration Extension Hertz supports custom registration extensions, you can extend it to integrate other registries, which are defined under pkg/app/server/registry.\nInterface and Info Definition  Interface Definition  // Registry is extension interface of service registry. type Registry interface { Register(info *Info) error Deregister(info *Info) error }  Info Definition  // Info is used for registry. // The fields are just suggested, which is used depends on design. type Info struct { ServiceName string Addr net.Addr Weight int // extend other infos with Tags. \tTags map[string]string } Work with Hertz  Specify your own registration extensions and custom registration information via server.WithRegistry.  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) Service Discovery Extension Interface Definition Hertz supports custom discovery extensions, you can extend it to integrate other registries, which are defined under pkg/app/server/discovery.\ntype Resolver interface { // Target should return a description for the given target that is suitable for being a key for cache. \tTarget(ctx context.Context, target *TargetInfo) string // Resolve returns a list of instances for the given description of a target. \tResolve(ctx context.Context, desc string) (Result, error) // Name returns the name of the resolver. \tName() string } type TargetInfo struct { Host string Tags map[string]string } type Result struct { CacheKey string // Unique key for cache  Instances []Instance // Service discovery result } Resolver is defined as follows:\n Resolve: Core function of Resolver, get the service discovery Result we need from the target key. Target: The unique target to be used by Resolve is resolved from the peer TargetInfo provided by Hertz, and this target is used as the unique key for the cache. Name: This is used to specify a unique name for the Resolver, and is used by Hertz to cache and reuse the Resolver.  Work with Hertz Specify custom service discovery extensions by using the Discovery middleware provided by Hertz.\ncli, err := client.NewClient() if err != nil { panic(err) } r := nacos_demo.NewNacosResolver() cli.Use(sd.Discovery(r)) Note  We improve performance by reusing Resolver in a way that requires the Resolver method implementation to be concurrency-safe.  Load Balancing Extension Hertz provides a WeightedRandom load balancing implementation by default, and also supports a custom load balancing implementation defined under pkg/app/client/loadbalance.\nInterface Definition // Loadbalancer picks instance for the given service discovery result.  type Loadbalancer interface { // Pick is used to select an instance according to discovery result  Pick(discovery.Result) discovery.Instance // Rebalance is used to refresh the cache of load balance's information  Rebalance(discovery.Result) // Delete is used to delete the cache of load balance's information when it is expired  Delete(string) // Name returns the name of the Loadbalancer.  Name() string } Work with Hertz By using the Discovery middleware provided by Hertz, custom service discovery extensions can be specified along with custom load balancing extensions using sd.WithLoadBalanceOptions.\ncli, err := client.NewClient() if err != nil { panic(err) } r := nacos_demo.NewNacosResolver() cli.Use(sd.Discovery(r, sd.WithLoadBalanceOptions(***,***))) ","categories":"","description":"","excerpt":"Service Registration Extension Hertz supports custom registration …","ref":"/docs/hertz/tutorials/framework-exten/service_discovery/","tags":"","title":"Service Registration and Service Discovery Extensions"},{"body":"服务注册扩展 Hertz 支持自定义注册模块，使用者可自行扩展集成其他注册中心，该扩展定义在 pkg/app/server/registry 下。\n接口定义与Info定义  接口定义  // Registry is extension interface of service registry. type Registry interface { Register(info *Info) error Deregister(info *Info) error }  Info定义  // Info is used for registry. // The fields are just suggested, which is used depends on design. type Info struct { ServiceName string Addr net.Addr Weight int // extend other infos with Tags. \tTags map[string]string } 集成到Hertz  通过 server.WithRegistry 指定自己的注册模块和自定义的注册信息。  h := server.Default( server.WithHostPorts(addr), server.WithRegistry(r, \u0026registry.Info{ ServiceName: \"hertz.test.demo\", Addr: utils.NewNetAddr(\"tcp\", addr), Weight: 10, Tags: nil, })) 服务发现扩展 接口定义 Hertz 支持自定义发现模块，使用者可自行扩展集成其他注册中心，该扩展定义在 pkg/app/client/discovery 下。\ntype Resolver interface { // Target should return a description for the given target that is suitable for being a key for cache. \tTarget(ctx context.Context, target *TargetInfo) string // Resolve returns a list of instances for the given description of a target. \tResolve(ctx context.Context, desc string) (Result, error) // Name returns the name of the resolver. \tName() string } type TargetInfo struct { Host string Tags map[string]string } type Result struct { CacheKey string // 缓存的唯一 key  Instances []Instance // 服务发现结果 } Resolver 接口定义如下:\n Resolve：作为 Resolver 的核心方法， 从 target key 中获取我们需要的服务发现结果 Result。 Target：从 Hertz 提供的对端 TargetInfo 中解析出 Resolve 需要使用的唯一 target, 同时这个 target 将作为缓存的唯一 key。 Name：用于指定 Resolver 的唯一名称， 同时 Hertz 会用它来缓存和复用 Resolver。  集成到Hertz 通过使用 Hertz 提供的 Discovery 中间件，指定自定义的服务发现扩展。\ncli, err := client.NewClient() if err != nil { panic(err) } r := nacos_demo.NewNacosResolver() cli.Use(sd.Discovery(r)) 注意事项  我们通过复用 Resolver 的方式来提高性能， 要求 Resolver 的方法实现需要是并发安全的。  负载均衡扩展 Hertz 默认提供了 WeightedRandom 负载均衡实现,同时也支持自定义负载均衡实现，该扩展定义在 pkg/app/client/loadbalance 下\n接口定义 // Loadbalancer picks instance for the given service discovery result.  type Loadbalancer interface { // Pick is used to select an instance according to discovery result  Pick(discovery.Result) discovery.Instance // Rebalance is used to refresh the cache of load balance's information  Rebalance(discovery.Result) // Delete is used to delete the cache of load balance's information when it is expired  Delete(string) // Name returns the name of the Loadbalancer.  Name() string } 集成到Hertz 通过使用 Hertz 提供的 Discovery 中间件，指定自定义的服务发现扩展的同时也可以使用 sd.WithLoadBalanceOptions 指定自定义负载均衡扩展。\ncli, err := client.NewClient() if err != nil { panic(err) } r := nacos_demo.NewNacosResolver() cli.Use(sd.Discovery(r, sd.WithLoadBalanceOptions(***,***))) ","categories":"","description":"","excerpt":"服务注册扩展 Hertz 支持自定义注册模块，使用者可自行扩展集成其他注册中心，该扩展定义在 pkg/app/server/registry …","ref":"/zh/docs/hertz/tutorials/framework-exten/service_discovery/","tags":"","title":"服务注册与发现扩展"},{"body":"An RPC protocol generally includes a transport protocol in the application layer and a message protocol that tells how to access the payload. Transport protocols come with rich mechanisms that let you deal with additional metadata, which can be helpful for service governance. And Kitex allows you to read or write metadata through a protocol based on MetaHandler. The capability of carrying metadata enables us to track requests in their entirety as it travels across services of a distributed system, and thus makes transport protocol indispensable in Microservices.\nKitex already supports TTHeader and HTTP2. Available options for transport protocol are TTHeader、GRPC、Framed、TTHeaderFramed、PurePayload.\nSome clarifications:\n Kitex supports Protobuf in two ways: Kitex Protobuf and gRPC. We include gRPC as a transport protocol to make it easy to distinguish. Internally, Kitex will identify the protocol based on whether gRPC was configured. Framed is not technically a transport protocol. It was just there for marking the extra 4 bytes header in Payload Size. But the message protocol does not enforce the need for Framed Header. For instance, PurePayload doesn’t have any Header. Therefore, we also include Framed as an option for the transport protocol. Framed and TTHeader could be used together, which leads to TTHeaderFramed.  Here are the available combination options of transport protocols and message protocols in Kitex:\n Thrift: TTHeader(recommend), Framed, TTHeaderFramed KitexProtobuf: TTHeader(recommend), Framed, TTHeaderFramed gRPC: HTTP2  If you want to use custom implementations for the message or transport protocol, you can find help here Extension of Codec.\nConfiguration You can configure the transport protocol when initializing the client:\n// client option client.WithTransportProtocol(transport.XXX) Kitex Server supports protocol detection for all supported protocols and doesn’t require explicit configuration.\nUsage Thrift + TTHeader // client side var opts []client.Option opts = append(opts, client.WithTransportProtocol(transport.TTHeader)) opts = append(opts, client.WithMetaHandler(transmeta.ClientTTHeaderHandler)) cli, err := xxxservice.NewClient(targetService, opts...) // server side no need to config transport protocol var opts []server.Option opts = append(opts, server.WithMetaHandler(transmeta.ServerTTHeaderHandler)) cli, err := xxxservice.NewServer(handler, opts...) gRPC // client side var opts []client.Option opts = append(opts, client.WithTransportProtocol(transport.GRPC)) opts = append(opts, client.WithMetaHandler(transmeta.ClientHTTP2Handler)) cli, err := xxxservice.NewClient(targetService, opts...) // server side no need to config transport protocol var opts []server.Option opts = append(opts, server.WithMetaHandler(transmeta.ServerHTTP2Handler)) cli, err := xxxservice.NewServer(handler, opts...) ","categories":"","description":"Kitex supports transport protocols of TTHeader、HTTP2.","excerpt":"Kitex supports transport protocols of TTHeader、HTTP2.","ref":"/docs/kitex/tutorials/basic-feature/transport_protocol/","tags":"","title":"Transport Protocol"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/tutorials/framework-exten/advanced-exten/","tags":"","title":"Advanced Extensions"},{"body":"The framework doesn’t provide any monitoring, but only provides a Tracer interface. This interface can be implemented by yourself and be injected via WithTracer Option.\n// Tracer is executed at the start and finish of an HTTP. type Tracer interface { Start(ctx context.Context, c *app.RequestContext) context.Context Finish(ctx context.Context, c *app.RequestContext) } hertz-contrib provides a default prometheus monitoring extension，which can be used to do:\n Server throughput monitoring Request latency monitoring  The default tags include: HTTP Method, statusCode. Requests related information are stored in RequestContext, and this variable can be accessed after monitoring metrics scraped. You can implement and extend the monitoring functions according to your own requirements. Usage example:\nServer\nimport ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/monitor-prometheus\" ) func main() { ··· h := server.Default(server.WithTracer(prometheus.NewServerTracer(\":9091\", \"/hertz\"))) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, utils.H{\"ping\": \"pong\"}) }) h.Spin() ··· } Currently, Client doesn’t expose Tracer interface, but monitoring capabilities can be implemented through middleware.\nRelated Repository https://github.com/hertz-contrib/monitor-prometheus\n","categories":"","description":"","excerpt":"The framework doesn’t provide any monitoring, but only provides a …","ref":"/docs/hertz/tutorials/observability/monitoring/","tags":"","title":"Monitoring"},{"body":"Usage When a client makes an RPC call, it adds an additional Option that takes precedence over client Option and overrides some configurations:\nresp, err := client.Call(ctx, req, callopt.WithXXX....) Options WithHostPort func WithHostPort(hostport string) Option Specifying a specific HostPort directly during this call phase will overwrite the resolver result for direct access. More\nWithURL func WithURL(url string) Option Specifying a specified URL during this call phase to initiate the call. More\nWithTag func WithTag(key, val string) Option Set some meta information for this RPC call, add it in the form of key-value, for example, if you want to add fields such as cluster and idc to the meta information for service governance, you can write it like this:\nresp, err := client.Call(ctx, req,callopt.WithTag(\"cluster\", cluster),callopt.WithTag(\"idc\", idc)) WithRPCTimeout func WithRPCTimeout(d time.Duration) Option Set RPC timeout. More\nWithConnectTimeout func WithConnectTimeout(d time.Duration) Option Set connection timeout. More\nWithHTTPHost func WithHTTPHost(host string) Option When using HTTP connection, the Option specifies the Host address in the HTTP header.\n","categories":"","description":"Kitex Call Option instructions.","excerpt":"Kitex Call Option instructions.","ref":"/docs/kitex/tutorials/options/call_options/","tags":"","title":"Call Option"},{"body":"用法 客户端发起 RPC 调用时，额外添加一些 Option，优先级比 Client Option 高，会覆盖某些配置：\nresp, err := client.Call(ctx, req, callopt.WithXXX....) Option 说明 IP 端口 - WithHostPort func WithHostPort(hostport string) Option 在本次调用阶段直接指定一个具体的 HostPort ，会覆盖掉 Resolver 的结果进行直接访问，详见直连访问-指定 IP 和 Port 进行调用。\n指定 URL - WithURL func WithURL(url string) Option 在本次调用阶段重新指定一个指定 URL 发起调用，详见直连访问-指定 URL 进行调用。\n添加标签 - WithTag func WithTag(key, val string) Option 为本次 RPC 调用设置一些 Tag 元信息，以 key-value 的形式添加，例如希望在元信息中加入 cluster、idc 等字段用来做服务治理，可以像下面这样写：\nresp, err := client.Call(ctx, req,callopt.WithTag(\"cluster\", cluster),callopt.WithTag(\"idc\", idc)) 超时设置 - WithRPCTimeout func WithRPCTimeout(d time.Duration) Option 指定本次 RPC 调用的超时时间，详见超时控制。\n超时设置 - WithConnectTimeout func WithConnectTimeout(d time.Duration) Option 为本次 RPC 调用设置连接超时时间，详见超时控制。\nHTTP Host 设置 - WithHTTPHost func WithHTTPHost(host string) Option 当使用 HTTP 连接的场景时，该 Option 会在 HTTP Header 中指定 Host 地址。\n","categories":"","description":"Kitex Call Option 使用说明。","excerpt":"Kitex Call Option 使用说明。","ref":"/zh/docs/kitex/tutorials/options/call_options/","tags":"","title":"Call Option"},{"body":"概述 通常 RPC 协议中包含 RPC 消息协议和应用层传输协议，RPC 消息协议看做是传输消息的 Payload，传输协议额外传递一些元信息通常会用于服务治理，框架的 MetaHandler 也是和传输协议搭配使用。 在微服务场景下，传输协议起到了重要的作用，如链路跟踪的透传信息通常由传输协议进行链路传递。\nKitex 目前支持两种传输协议：TTHeader、HTTP2，但实际提供配置的 Transport Protocol 是：TTHeader、GRPC、Framed、TTHeaderFramed、PurePayload。\n这里做一些说明：\n 因为 Kitex 对 Protobuf 的支持有 Kitex Protobuf 和 gRPC，为方便区分将 gRPC 作为传输协议的分类，框架会根据是否有配置 gRPC 决定使用哪个协议； Framed 严格意义上并不是传输协议，只是标记 Payload Size 额外增加的 4 字节头，但消息协议对是否有 Framed 头并不是强制的，PurePayload 即没有任何头部的，所以将 Framed 也作为传输协议的分类； Framed 和 TTHeader 也可以结合使用，所以有 TTHeaderFramed 。  消息协议可选的传输协议组合如下：\n Thrift: TTHeader(建议)、Framed、TTHeaderFramed KitexProtobuf: TTHeader(建议)、Framed、TTHeaderFramed gRPC: HTTP2  如果想自定义消息协议和传输协议参考：编解码(协议)扩展\n配置项 Client 初始化时通过 WithTransportProtocol 配置传输协议：\n// client option client.WithTransportProtocol(transport.XXX) Server 支持协议探测（在 Kitex 默认支持的协议内），无需配置传输协议。\n使用示例 Thrift + TTHeader // client side var opts []client.Option opts = append(opts, client.WithTransportProtocol(transport.TTHeader)) opts = append(opts, client.WithMetaHandler(transmeta.ClientTTHeaderHandler)) cli, err := xxxservice.NewClient(targetService, opts...) // server side no need to config transport protocol var opts []server.Option opts = append(opts, server.WithMetaHandler(transmeta.ServerTTHeaderHandler)) cli, err := xxxservice.NewServer(handler, opts...) gRPC // client side var opts []client.Option opts = append(opts, client.WithTransportProtocol(transport.GRPC)) opts = append(opts, client.WithMetaHandler(transmeta.ClientHTTP2Handler)) cli, err := xxxservice.NewClient(targetService, opts...) // server side no need to config transport protocol var opts []server.Option opts = append(opts, server.WithMetaHandler(transmeta.ServerHTTP2Handler)) cli, err := xxxservice.NewServer(handler, opts...) ","categories":"","description":"Kitex 支持 TTHeader、HTTP2 传输协议。","excerpt":"Kitex 支持 TTHeader、HTTP2 传输协议。","ref":"/zh/docs/kitex/tutorials/basic-feature/transport_protocol/","tags":"","title":"传输协议"},{"body":"JSON Web Token (JWT) is a lightweight authentication specification that allows us to use JWT to deliver secure and reliable information between users and servers. Essentially a token, it is a compact security method for passing between two sides of network communication. Hertz also provides an implementation of JWT, it uses gin implementation for reference.\nInstall go get github.com/hertz-contrib/jwt Example package main import ( \"context\" \"fmt\" \"log\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/jwt\" ) type login struct { Username string `form:\"username,required\" json:\"username,required\"` Password string `form:\"password,required\" json:\"password,required\"` } var identityKey = \"id\" func PingHandler(c context.Context, ctx *app.RequestContext) { user, _ := ctx.Get(identityKey) ctx.JSON(200, utils.H{ \"message\": fmt.Sprintf(\"username:%v\", user.(*User).UserName), }) } // User demo type User struct { UserName string FirstName string LastName string } func main() { h := server.Default() // the jwt middleware  authMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Realm: \"test zone\", Key: []byte(\"secret key\"), Timeout: time.Hour, MaxRefresh: time.Hour, IdentityKey: identityKey, PayloadFunc: func(data interface{}) jwt.MapClaims { if v, ok := data.(*User); ok { return jwt.MapClaims{ identityKey: v.UserName, } } return jwt.MapClaims{} }, IdentityHandler: func(ctx context.Context, c *app.RequestContext) interface{} { claims := jwt.ExtractClaims(ctx, c) return \u0026User{ UserName: claims[identityKey].(string), } }, Authenticator: func(ctx context.Context, c *app.RequestContext) (interface{}, error) { var loginVals login if err := c.BindAndValidate(\u0026loginVals); err != nil { return \"\", jwt.ErrMissingLoginValues } userID := loginVals.Username password := loginVals.Password if (userID == \"admin\" \u0026\u0026 password == \"admin\") || (userID == \"test\" \u0026\u0026 password == \"test\") { return \u0026User{ UserName: userID, LastName: \"Hertz\", FirstName: \"CloudWeGo\", }, nil } return nil, jwt.ErrFailedAuthentication }, Authorizator: func(data interface{}, ctx context.Context, c *app.RequestContext) bool { if v, ok := data.(*User); ok \u0026\u0026 v.UserName == \"admin\" { return true } return false }, Unauthorized: func(ctx context.Context, c *app.RequestContext, code int, message string) { c.JSON(code, map[string]interface{}{ \"code\": code, \"message\": message, }) }, }) if err != nil { log.Fatal(\"JWT Error:\" + err.Error()) } // When you use jwt.New(), the function is already automatically called for checking,  // which means you don't need to call it again.  errInit := authMiddleware.MiddlewareInit() if errInit != nil { log.Fatal(\"authMiddleware.MiddlewareInit() Error:\" + errInit.Error()) } h.POST(\"/login\", authMiddleware.LoginHandler) h.NoRoute(authMiddleware.MiddlewareFunc(), func(ctx context.Context, c *app.RequestContext) { claims := jwt.ExtractClaims(ctx, c) log.Printf(\"NoRoute claims: %#v\\n\", claims) c.JSON(404, map[string]string{\"code\": \"PAGE_NOT_FOUND\", \"message\": \"Page not found\"}) }) auth := h.Group(\"/auth\") // Refresh time can be longer than token timeout  auth.GET(\"/refresh_token\", authMiddleware.RefreshHandler) auth.Use(authMiddleware.MiddlewareFunc()) { auth.GET(\"/ping\", PingHandler) } h.Spin() } Note Two cores of JWT are Authentication and Authorization.\nWhen using Hertz’s jwt extensions, it is necessary to bind authMiddleware.LoginHandler to the /login interface dealing with user authentication, and inject authMiddleware.MiddlewareFunc() for the route group that requires authorized access.\nConfig Hertz provides jwt checks for routed requests by using middleware. Custom configuration of the HertzJWTMiddleware allows you to define the implementation details of jwt according to different scenarios.\nIn the Example above, only two necessary custom configurations are passed in. More common configurations for the HertzJWTMiddleware are as follows:\n   Parameter Introduction     Realm The property used to set the name of the realm, the default value is hertz jwt   SigningAlgorithm The property used to set the signature algorithm, which can be HS256, HS384, HS512, RS256, RS384, or RS512, etc. The default value is HS256   Key The property used to set the signature key (required configuration)   KeyFunc The property used to set a callback function to get the signature key, which will get the jwt signature key from KeyFunc when the token is parsed   Timeout The property used to set the token expiry time, the default value is one hour   MaxRefresh The property used to set the maximum token refresh time, allowing the client to refresh the token within TokenTime + MaxRefresh, appending a Timeout duration   Authenticator The property used to set the user information for authentication at login (required configuration)   Authorizator The property used to set the route access rights for authenticated users   PayloadFunc The property used to set additional payload information into the token at login   Unauthorized The property used to set the response for a failed jwt authentication process   LoginResponse The property used to set the response for login   LogoutResponse The property used to set the response for logout   RefreshResponse The property used to set the response after the token has been valid for a refreshed period   IdentityHandler The property used to set the function to get identity information, the function used with IdentityKey by default   IdentityKey The property used to set the key to retrieve the identity information, the default key is identity   TokenLookup The property used to set the source of the token, you can choose header, query, cookie, param, or form, the default value is header:Authorization   TokenHeadName The property used to set the prefix for getting the token from the header, the default value is Bearer   WithoutDefaultTokenHeadName The property used to set the TokenHeadName to null, the default value is false   TimeFunc The property used to set a function to get the current time, the default is time.Now()   HTTPStatusMessageFunc The property used to set the error message included in the response when an error occurs in the jwt validation process   SendCookie The property used to set the token to be returned as a cookie at the same time, the following cookie-related configurations work if this property is true, and the default value is false   CookieMaxAge The property used to set the validity of the cookie, the default value is one hour as defined by Timeout   SecureCookie The property used to set the cookie is not allowed to be passed through HTTPS, the default value is false   CookieHTTPOnly The property used to set allows clients to access the cookie for development purposes, the default value is false   CookieDomain The property used to set the domain to which the cookie belongs, the default value is empty   SendAuthorization The property used to set the token to be added to the response header of all requests, the default value is false   DisabledAbort The property used to set the request context to disable abort() calls if the jwt authentication process fails, the default value is false   CookieName The property used to set the name of the cookie   CookieSameSite The property used to set the value of the SameSite property of a cookie using the parameters declared in protocol.CookieSameSite   ParseOptions The property used to set the property values of jwt.Parser configured as a functional-style options argument declared with jwt.ParserOption    Key The property used to set the signature key\nSample Code:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Key: []byte(\"secret key\"), }) KeyFunc The program executes with KeyFunc as a parameter to jwt.Parse(), which is responsible for providing the signing key for token parsing. By customizing the logic of KeyFunc, you can perform some custom operations before parsing the token, such as checking the validity of the signing method, selecting the corresponding signing key, storing the token in the request context, etc.\nFunction signatures:\nfunc(t *jwt.Token) (interface{}, error) Default handling logic:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ KeyFunc: func(t *jwt.Token) (interface{}, error) { if jwt.GetSigningMethod(mw.SigningAlgorithm) != t.Method { return nil, ErrInvalidSigningAlgorithm } if mw.usingPublicKeyAlgo() { return mw.pubKey, nil } // save token string if valid  c.Set(\"JWT_TOKEN\", token) return mw.Key, nil }, }) Authenticator This function works with HertzJWTMiddleware.LoginHandler and is triggered on login, to authenticate the user’s login information.\nFunction signatures:\nfunc(ctx context.Context, c *app.RequestContext) (interface{}, error) Sample Code:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Authenticator: func(ctx context.Context, c *app.RequestContext) (interface{}, error) { var loginVals login if err := c.BindAndValidate(\u0026loginVals); err != nil { return \"\", jwt.ErrMissingLoginValues } userID := loginVals.Username password := loginVals.Password if (userID == \"admin\" \u0026\u0026 password == \"admin\") || (userID == \"test\" \u0026\u0026 password == \"test\") { return \u0026User{ UserName: userID, LastName: \"Hertz\", FirstName: \"CloudWeGo\", }, nil } return nil, jwt.ErrFailedAuthentication }, }) Authorizator The property used to set the function for authenticated user access to the route. The following function determines whether the user has access to the route by verifying that the username is admin.\nIf access is not available, the response for jwt process authentication failure declared in the Unauthorized parameter will be triggered.\nFunction signatures:\nfunc(data interface{}, ctx context.Context, c *app.RequestContext) bool Sample Code:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Authorizator: func(data interface{}, ctx context.Context, c *app.RequestContext) bool { if v, ok := data.(*User); ok \u0026\u0026 v.UserName == \"admin\" { return true } return false } }) PayloadFunc If this parameter is not passed, the payload part of the token stores the expiry time and creation time of the token by default, while the Sample Code below stores username information additionally.\nFunction signatures:\nfunc(data interface{}) jwt.MapClaims Sample Code:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ PayloadFunc: func(data interface{}) jwt.MapClaims { if v, ok := data.(*User); ok { return jwt.MapClaims{ identityKey: v.UserName, } } return jwt.MapClaims{} }, }) IdentityHandler The IdentityHandler function is used to set up the function that extracts the user information from the token in each request after a successful login. The user information mentioned here is already stored in the payload part of the token because the PayloadFunc function is triggered when the user successfully logs in.\nSpecifically: By using identityKey within IdentityHandler, the token storing the user information is acquired from the request context. And the required information is extracted from it, encapsulated into a User structure, and stored in the request context with identityKey as the key and User structure as the value for subsequent use.\nFunction signatures:\nfunc(ctx context.Context, c *app.RequestContext) interface{} Sample Code:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ IdentityHandler: func(ctx context.Context, c *app.RequestContext) interface{} { claims := jwt.ExtractClaims(ctx, c) return \u0026User{ UserName: claims[identityKey].(string), } } }) Unauthorized The property used to set the response when a jwt authorization fails. The following function returns the error code and error message from the parameter list encapsulated in a JSON response.\nFunction signatures:\nfunc(ctx context.Context, c *app.RequestContext, code int, message string) Default handling logic:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Unauthorized: func(ctx context.Context, c *app.RequestContext, code int, message string) { c.JSON(code, map[string]interface{}{ \"code\": code, \"message\": message, }) } }) LoginResponse The property used to set the login response binding with LoginHandler.\nFunction signatures:\nfunc(ctx context.Context, c *app.RequestContext, code int, token string, expire time.Time) Default handling logic:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ LoginResponse: func(ctx context.Context, c *app.RequestContext, code int, token string, expire time.Time) { c.JSON(http.StatusOK, map[string]interface{}{ \"code\": http.StatusOK, \"token\": token, \"expire\": expire.Format(time.RFC3339), }) } }) // be called within LoginHandler h.POST(\"/login\", authMiddleware.LoginHandler) LogoutResponse The property used to set the logout response binding with LogoutHandler.\nFunction signatures:\nfunc(ctx context.Context, c *app.RequestContext, code int) Default handling logic:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ LogoutResponse: func(ctx context.Context, c *app.RequestContext, code int) { c.JSON(http.StatusOK, map[string]interface{}{ \"code\": http.StatusOK, }) } }) // be called within LogoutHandler h.POST(\"/logout\", authMiddleware.LogoutHandler) RefreshResponse The property used to set the refresh response binding with RefreshHandler.\nFunction signatures:\nfunc(ctx context.Context, c *app.RequestContext, code int, token string, expire time.Time) Default handling logic:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ RefreshResponse: func(ctx context.Context, c *app.RequestContext, code int, token string, expire time.Time) { c.JSON(http.StatusOK, map[string]interface{}{ \"code\": http.StatusOK, \"token\": token, \"expire\": expire.Format(time.RFC3339), }) }, }) // be called within RefreshHandler auth.GET(\"/refresh_token\", authMiddleware.RefreshHandler) TokenLookup There are four options for declaring the source of a token as a key-value pair, with the default value being header:Authorization. If more than one token source is declared, the first that satisfies the input format is selected while the rest are ignored.\nSample Code:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ // - \"header:\u003cname\u003e\"  // - \"query:\u003cname\u003e\"  // - \"cookie:\u003cname\u003e\"  // - \"param:\u003cname\u003e\"  // - \"form:\u003cname\u003e\"  TokenLookup: \"header: Authorization, query: token, cookie: jwt\" }) TimeFunc The property used to set the function to get the current time, which defaults to time.Now(). In the jwt validation process, validation of the token’s expiry date needs to start with the time the token was created. TimeFunc provides a function for jwt to get the current time, and you can choose to override this default configuration for some cases where the time zone is different.\nFunction signatures:\nfunc() time.Time Default handling logic:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ TimeFunc: func() time.Time { return time.Now() } }) HTTPStatusMessageFunc If the jwt validation process generates an error, such as jwt authentication failure, token authentication failure, failure to refresh token validity, etc., the corresponding error is passed as a parameter to HTTPStatusMessageFunc, which extracts the error message and then passed as a string parameter to the jwt authentication failure response declared by Unauthorized.\nFunction signatures:\nfunc(e error, ctx context.Context, c *app.RequestContext) string Default handling logic:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ HTTPStatusMessageFunc: func(e error, ctx context.Context, c *app.RequestContext) string { return e.Error() } }) Cookie There are eight cookie-related configuration parameters. With SendCookie set to true and TokenLookup set to cookie: jwt, the token will be returned as a cookie at the same time, and will be fetched from the HTTP cookie in the next request.\nSample Code:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ SendCookie: true, TokenLookup: \"cookie: jwt\", CookieMaxAge: time.Hour, SecureCookie: false, CookieHTTPOnly: false, CookieDomain: \".test.com\", CookieName: \"jwt-cookie\", CookieSameSite: protocol.CookieSameSiteDisabled, }) ParseOptions There are three related configurations that can be enabled using ParseOptions:\n WithValidMethods: Used to supply algorithm methods that the parser will check. Only those methods will be considered valid WithJSONNumber: Used to configure the underlying JSON parser with UseNumber WithoutClaimsValidation: Used to disable claims validation  Sample Code:\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ ParseOptions: []jwt.ParserOption{ jwt.WithValidMethods([]string{\"HS256\"}), jwt.WithJSONNumber(), jwt.WithoutClaimsValidation(), }, }) Full Example As for usage, you may refer to hertz example\n","categories":"","description":"","excerpt":"JSON Web Token (JWT) is a lightweight authentication specification …","ref":"/docs/hertz/tutorials/basic-feature/middleware/jwt/","tags":"","title":"JWT"},{"body":"JSON Web Token（JWT）是一个轻量级的认证规范，这个规范允许我们使用 JWT 在用户和服务器之间传递安全可靠的信息。其本质是一个 token ，是一种紧凑的 URL 安全方法，用于在网络通信的双方之间传递。 Hertz 也提供了 jwt 的实现 ，参考了 gin 的实现 。\n安装 go get github.com/hertz-contrib/jwt 示例代码 package main import ( \"context\" \"fmt\" \"log\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/jwt\" ) type login struct { Username string `form:\"username,required\" json:\"username,required\"` Password string `form:\"password,required\" json:\"password,required\"` } var identityKey = \"id\" func PingHandler(c context.Context, ctx *app.RequestContext) { user, _ := ctx.Get(identityKey) ctx.JSON(200, utils.H{ \"message\": fmt.Sprintf(\"username:%v\", user.(*User).UserName), }) } // User demo type User struct { UserName string FirstName string LastName string } func main() { h := server.Default() // the jwt middleware  authMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Realm: \"test zone\", Key: []byte(\"secret key\"), Timeout: time.Hour, MaxRefresh: time.Hour, IdentityKey: identityKey, PayloadFunc: func(data interface{}) jwt.MapClaims { if v, ok := data.(*User); ok { return jwt.MapClaims{ identityKey: v.UserName, } } return jwt.MapClaims{} }, IdentityHandler: func(ctx context.Context, c *app.RequestContext) interface{} { claims := jwt.ExtractClaims(ctx, c) return \u0026User{ UserName: claims[identityKey].(string), } }, Authenticator: func(ctx context.Context, c *app.RequestContext) (interface{}, error) { var loginVals login if err := c.BindAndValidate(\u0026loginVals); err != nil { return \"\", jwt.ErrMissingLoginValues } userID := loginVals.Username password := loginVals.Password if (userID == \"admin\" \u0026\u0026 password == \"admin\") || (userID == \"test\" \u0026\u0026 password == \"test\") { return \u0026User{ UserName: userID, LastName: \"Hertz\", FirstName: \"CloudWeGo\", }, nil } return nil, jwt.ErrFailedAuthentication }, Authorizator: func(data interface{}, ctx context.Context, c *app.RequestContext) bool { if v, ok := data.(*User); ok \u0026\u0026 v.UserName == \"admin\" { return true } return false }, Unauthorized: func(ctx context.Context, c *app.RequestContext, code int, message string) { c.JSON(code, map[string]interface{}{ \"code\": code, \"message\": message, }) }, }) if err != nil { log.Fatal(\"JWT Error:\" + err.Error()) } // When you use jwt.New(), the function is already automatically called for checking,  // which means you don't need to call it again.  errInit := authMiddleware.MiddlewareInit() if errInit != nil { log.Fatal(\"authMiddleware.MiddlewareInit() Error:\" + errInit.Error()) } h.POST(\"/login\", authMiddleware.LoginHandler) h.NoRoute(authMiddleware.MiddlewareFunc(), func(ctx context.Context, c *app.RequestContext) { claims := jwt.ExtractClaims(ctx, c) log.Printf(\"NoRoute claims: %#v\\n\", claims) c.JSON(404, map[string]string{\"code\": \"PAGE_NOT_FOUND\", \"message\": \"Page not found\"}) }) auth := h.Group(\"/auth\") // Refresh time can be longer than token timeout  auth.GET(\"/refresh_token\", authMiddleware.RefreshHandler) auth.Use(authMiddleware.MiddlewareFunc()) { auth.GET(\"/ping\", PingHandler) } h.Spin() } 提示 因为 JWT 的核心是认证与授权，所以在使用 Hertz 的 jwt 扩展时，不仅需要为 /login 接口绑定认证逻辑 authMiddleware.LoginHandler。\n还要以中间件的方式，为需要授权访问的路由组注入授权逻辑 authMiddleware.MiddlewareFunc()。\n配置 Hertz 通过使用中间件，为路由请求提供了 jwt 的校验功能。其中 HertzJWTMiddleware 结构定义了 jwt 配置信息，并提供了默认配置，用户也可以依据业务场景进行定制。\n上述示例代码中，只传入了两项必要的自定义的配置。关于 HertzJWTMiddleware 的更多常用配置如下：\n   参数 介绍     Realm 用于设置所属领域名称，默认为 hertz jwt   SigningAlgorithm 用于设置签名算法，可以是 HS256、HS384、HS512、RS256、RS384 或者 RS512等，默认为 HS256   Key 用于设置签名密钥（必要配置）   KeyFunc 用于设置获取签名密钥的回调函数，设置后 token 解析时将从 KeyFunc 获取 jwt 签名密钥   Timeout 用于设置 token 过期时间，默认为一小时   MaxRefresh 用于设置最大 token 刷新时间，允许客户端在 TokenTime + MaxRefresh 内刷新 token 的有效时间，追加一个 Timeout 的时长   Authenticator 用于设置登录时认证用户信息的函数（必要配置）   Authorizator 用于设置授权已认证的用户路由访问权限的函数   PayloadFunc 用于设置登陆成功后为向 token 中添加自定义负载信息的函数   Unauthorized 用于设置 jwt 验证流程失败的响应函数   LoginResponse 用于设置登录的响应函数   LogoutResponse 用于设置登出的响应函数   RefreshResponse 用于设置 token 有效时长刷新后的响应函数   IdentityHandler 用于设置获取身份信息的函数，默认与 IdentityKey 配合使用   IdentityKey 用于设置检索身份的键，默认为 identity   TokenLookup 用于设置 token 的获取源，可以选择 header、query、cookie、param、form，默认为 header:Authorization   TokenHeadName 用于设置从 header 中获取 token 时的前缀，默认为 Bearer   WithoutDefaultTokenHeadName 用于设置 TokenHeadName 为空，默认为 false   TimeFunc 用于设置获取当前时间的函数，默认为 time.Now()   HTTPStatusMessageFunc 用于设置 jwt 校验流程发生错误时响应所包含的错误信息   SendCookie 用于设置 token 将同时以 cookie 的形式返回，下列 cookie 相关配置生效的前提是该值为 true，默认为 false   CookieMaxAge 用于设置 cookie 的有效期，默认为 Timeout 定义的一小时   SecureCookie 用于设置允许不通过 HTTPS 传递 cookie 信息，默认为 false   CookieHTTPOnly 用于设置允许客户端访问 cookie 以进行开发，默认为 false   CookieDomain 用于设置 cookie 所属的域，默认为空   SendAuthorization 用于设置为所有请求的响应头添加授权的 token 信息，默认为 false   DisabledAbort 用于设置在 jwt 验证流程出错时，禁止请求上下文调用 abort()，默认为 false   CookieName 用于设置 cookie 的 name 值   CookieSameSite 用于设置使用 protocol.CookieSameSite 声明的参数设置 cookie 的 SameSite 属性值   ParseOptions 用于设置使用 jwt.ParserOption 声明的函数选项式参数配置 jwt.Parser 的属性值    Key 用于设置 token 的签名密钥。\n示例代码：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Key: []byte(\"secret key\"), }) KeyFunc 程序执行时 KeyFunc 作为 jwt.Parse() 的参数，负责为 token 解析提供签名密钥，通过自定义 KeyFunc 的逻辑，可以在解析 token 之前完成一些自定义的操作，如：校验签名方法的有效性、选择对应的签名密钥、将 token 存入请求上下文等。\n函数签名：\nfunc(t *jwt.Token) (interface{}, error) 默认处理逻辑如下：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ KeyFunc: func(t *jwt.Token) (interface{}, error) { if jwt.GetSigningMethod(mw.SigningAlgorithm) != t.Method { return nil, ErrInvalidSigningAlgorithm } if mw.usingPublicKeyAlgo() { return mw.pubKey, nil } // save token string if valid  c.Set(\"JWT_TOKEN\", token) return mw.Key, nil }, }) Authenticator 配合 HertzJWTMiddleware.LoginHandler 使用，登录时触发，用于认证用户的登录信息。\n函数签名：\nfunc(ctx context.Context, c *app.RequestContext) (interface{}, error) 示例代码：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Authenticator: func(ctx context.Context, c *app.RequestContext) (interface{}, error) { var loginVals login if err := c.BindAndValidate(\u0026loginVals); err != nil { return \"\", jwt.ErrMissingLoginValues } userID := loginVals.Username password := loginVals.Password if (userID == \"admin\" \u0026\u0026 password == \"admin\") || (userID == \"test\" \u0026\u0026 password == \"test\") { return \u0026User{ UserName: userID, LastName: \"Hertz\", FirstName: \"CloudWeGo\", }, nil } return nil, jwt.ErrFailedAuthentication }, }) Authorizator 用于设置已认证的用户路由访问权限的函数，如下函数通过验证用户名是否为 admin，从而判断是否有访问路由的权限。\n如果没有访问权限，则会触发 Unauthorized 参数中声明的 jwt 流程验证失败的响应函数。\n函数签名：\nfunc(data interface{}, ctx context.Context, c *app.RequestContext) bool 示例代码：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Authorizator: func(data interface{}, ctx context.Context, c *app.RequestContext) bool { if v, ok := data.(*User); ok \u0026\u0026 v.UserName == \"admin\" { return true } return false } }) PayloadFunc 用于设置登录时为 token 添加自定义负载信息的函数，如果不传入这个参数，则 token 的 payload 部分默认存储 token 的过期时间和创建时间，如下则额外存储了用户名信息。\n函数签名：\nfunc(data interface{}) jwt.MapClaims 示例代码：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ PayloadFunc: func(data interface{}) jwt.MapClaims { if v, ok := data.(*User); ok { return jwt.MapClaims{ identityKey: v.UserName, } } return jwt.MapClaims{} }, }) IdentityHandler IdentityHandler 作用在登录成功后的每次请求中，用于设置从 token 提取用户信息的函数。这里提到的用户信息在用户成功登录时，触发 PayloadFunc 函数，已经存入 token 的负载部分。\n具体流程：通过在 IdentityHandler 内配合使用 identityKey ，将存储用户信息的 token 从请求上下文中取出并提取需要的信息，封装成 User 结构，以 identityKey 为 key，User 为 value 存入请求上下文当中以备后续使用。\n函数签名：\nfunc(ctx context.Context, c *app.RequestContext) interface{} 示例代码：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ IdentityHandler: func(ctx context.Context, c *app.RequestContext) interface{} { claims := jwt.ExtractClaims(ctx, c) return \u0026User{ UserName: claims[identityKey].(string), } } }) Unauthorized 用于设置 jwt 授权失败后的响应函数，如下函数将参数列表中的错误码和错误信息封装成 json 响应返回。\n函数签名：\nfunc(ctx context.Context, c *app.RequestContext, code int, message string) 默认处理逻辑如下：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ Unauthorized: func(ctx context.Context, c *app.RequestContext, code int, message string) { c.JSON(code, map[string]interface{}{ \"code\": code, \"message\": message, }) } }) LoginResponse 用于设置登录的响应函数，作为 LoginHandler 的响应结果。\n函数签名：\nfunc(ctx context.Context, c *app.RequestContext, code int, token string, expire time.Time) 默认处理逻辑如下：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ LoginResponse: func(ctx context.Context, c *app.RequestContext, code int, token string, expire time.Time) { c.JSON(http.StatusOK, map[string]interface{}{ \"code\": http.StatusOK, \"token\": token, \"expire\": expire.Format(time.RFC3339), }) } }) // 在 LoginHandler 内调用 h.POST(\"/login\", authMiddleware.LoginHandler) LogoutResponse 用于设置登出的响应函数，作为 LogoutHandler 的响应结果。\n函数签名：\nfunc(ctx context.Context, c *app.RequestContext, code int) 默认处理逻辑如下：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ LogoutResponse: func(ctx context.Context, c *app.RequestContext, code int) { c.JSON(http.StatusOK, map[string]interface{}{ \"code\": http.StatusOK, }) } }) // 在 LogoutHandler 内调用 h.POST(\"/logout\", authMiddleware.LogoutHandler) RefreshResponse 用于设置 token 有效时长刷新后的响应函数，作为 RefreshHandler 的响应结果。\n函数签名：\nfunc(ctx context.Context, c *app.RequestContext, code int, token string, expire time.Time) 默认处理逻辑如下：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ RefreshResponse: func(ctx context.Context, c *app.RequestContext, code int, token string, expire time.Time) { c.JSON(http.StatusOK, map[string]interface{}{ \"code\": http.StatusOK, \"token\": token, \"expire\": expire.Format(time.RFC3339), }) }, }) // 在 RefreshHandler 内调用 auth.GET(\"/refresh_token\", authMiddleware.RefreshHandler) TokenLookup 通过键值对的形式声明 token 的获取源，有四种可选的方式，默认值为 header:Authorization，如果同时声明了多个数据源则以 ， 为分隔线，第一个满足输入格式的数据源将被选择，其余忽略。\n示例代码：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ // - \"header:\u003cname\u003e\"  // - \"query:\u003cname\u003e\"  // - \"cookie:\u003cname\u003e\"  // - \"param:\u003cname\u003e\" \t// - \"form:\u003cname\u003e\"  TokenLookup: \"header: Authorization, query: token, cookie: jwt\" }) TimeFunc 用于设置获取当前时间的函数，默认为 time.Now()，在 jwt 校验过程中，关于 token 的有效期的验证需要以 token 创建时间为起点，TimeFunc 提供了 jwt 获取当前时间的函数，可以选择覆盖这个默认配置，应对一些时区不同的情况。\n函数签名：\nfunc() time.Time 默认处理逻辑如下：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ TimeFunc: func() time.Time { return time.Now() } }) HTTPStatusMessageFunc 一旦 jwt 校验流程产生错误，如 jwt 认证失败、token 鉴权失败、刷新 token 有效时长失败等，对应 error 将以参数的形式传递给 HTTPStatusMessageFunc，由其提取出需要响应的错误信息，最终以 string 参数形式传递给 Unauthorized 声明的 jwt 验证流程失败的响应函数返回。\n函数签名：\nfunc(e error, ctx context.Context, c *app.RequestContext) string 默认处理逻辑如下：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ HTTPStatusMessageFunc: func(e error, ctx context.Context, c *app.RequestContext) string { return e.Error() } }) Cookie cookie 相关的配置参数有八个，将 SendCookie 设置为 true、TokenLookup 设置为 cookie: jwt 后，token 将同时以 cookie 的形式返回，并在接下来的请求中从 HTTP Cookie 获取。\n示例代码：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ SendCookie: true, TokenLookup: \"cookie: jwt\", CookieMaxAge: time.Hour, SecureCookie: false, CookieHTTPOnly: false, CookieDomain: \".test.com\", CookieName: \"jwt-cookie\", CookieSameSite: protocol.CookieSameSiteDisabled, }) ParseOptions 利用 ParseOptions 可以开启相关配置有三个，分别为\n WithValidMethods: 用于提供解析器将检查的签名算法，只有被提供的签名算法才被认为是有效的 WithJSONNumber: 用于配置底层 JSON 解析器使用 UseNumber 方法 WithoutClaimsValidation: 用于禁用 claims 验证  示例代码：\nauthMiddleware, err := jwt.New(\u0026jwt.HertzJWTMiddleware{ ParseOptions: []jwt.ParserOption{ jwt.WithValidMethods([]string{\"HS256\"}), jwt.WithJSONNumber(), jwt.WithoutClaimsValidation(), }, }) 完整示例 完整用法示例详见 example\n","categories":"","description":"","excerpt":"JSON Web Token（JWT）是一个轻量级的认证规范，这个规范允许我们使用 JWT 在用户和服务器之间传递安全可靠的信息。其本质是一 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/jwt/","tags":"","title":"JWT认证"},{"body":"Overview Validator is a thrift plugin that supports struct validation.\nConstraints are described by annotations in IDL, and the plugin will generate the IsValid() error method according to the structure given by the annotation, which is generated in the xxx-validator.go file.\nAnnotation is described in the form vt.{ContType} = \"Value\".\nScope: Every field in struct/union.\nValidation form: User initiative (provided, consistent for all parameters/results).\nIDL example:\nenum MapKey { A, B, C, D, E, F } struct Request { 1: required string Message (vt.max_size = \"30\", vt.prefix = \"Debug\") 2: i32 ID (vt.gt = \"1000\", vt.lt = \"10000\") 3: list\u003cdouble\u003e Values (vt.elem.gt = \"0.25\") 4: map\u003cMapKey, binary\u003e KeyValues (vt.key.defined_only = \"true\", vt.min_size = \"1\") } struct Response { 1: required string Message (vt.in = \"Debug\", vt.in = \"Info\", vt.in = \"Warn\", vt.in = \"Error\") } Installation Before using the Validator plugin, you should install it first.\nOtherwise, an error message will be displayed stating that the thrift-gen-validator executable file cannot be found (exec: \"thrift-gen-validator\": executable file not found in $PATH).\nIf you have already installed Golang and Kitex command-line tools, please run the following command to install the thrift-gen-validator plugin:\n$ go install github.com/cloudwego/thrift-gen-validator@latest After executing go install, the compiled thrift-gen-validator binary file will be installed under $GOPATH/bin.\nYou can run the following command to verify that the installation was successful.\n$ cd $(go env GOPATH)/bin $ ls go1.20.1 goimports hz thrift-gen-validator godotenv golangci-lint kitex thriftgo $ cd ~/ \u0026\u0026 thrift-gen-validator --help Usage of thrift-gen-validator: -version Show the version of thrift-gen-validator (0x1232358,0x1370f70) cd ~/ command is used to verify that thrift-gen-validator can be called from any directory.\nIf an error message similar to the one above appears when executing this command, please check whether $GOPATH has been correctly set to $PATH.\nFor more information on installing and using thrift-gen-validator, please refer to thirft-gen-validator.\nUsage Take the project “Kitex Hello” in Getting Started as an example, add annotations inhello.thrift. For example, the code bellow requires the length and prefix for Request.message:\nstruct Request { 1: string message (vt.max_size = \"8\", vt.prefix = \"kitex-\") } When generating kitex code, add --thrift-plugin validator to generate the validator code.\nkitex --thrift-plugin validator -service a.b.c hello.thrift The code will be generated in the directory bellow:\n├── kitex_gen └── api ├── hello │ ├── client.go │ ├── hello.go │ ├── invoker.go │ └── server.go ├── hello.go --\u003e ├── hello_validator.go ├── k-consts.go └── k-hello.go For struct Request, IsValid() is like this：\nfunc (p *Request) IsValid() error { if len(p.Message) \u003e int(8) { return fmt.Errorf(\"field Message max_len rule failed, current value: %d\", len(p.Message)) } _src := \"kitex-\" if !strings.HasPrefix(p.Message, _src) { return fmt.Errorf(\"field Message prefix rule failed, current value: %v\", p.Message) } return nil } So just simply call IsValid() to verify the struct：\n req := \u0026api.Request{ //.... } err := req.IsValid() if err != nil { //invalid .... } //valid ... Supported Validators The verification order is subject to the definition order,‘in’ and ‘not_in’ can be defined multiple times, whichever occurs first.\nnumber Including i8, i16, i32, i64, double.\n const, must be the specified value. lt, le, gt, ge, represents less than, less than or equal to, greater than, greater than or equal to. in, not_in, represents values that can be used and values that cannot be used, and can be specified multiple times, one value at a time. not_nil, the field cannot be empty (only valid if the field is optional).  structNumericDemo{1:doubleValue (vt.gt=\"1000.1\",vt.lt=\"10000.1\")2:i8Type (vt.in=\"1\",vt.in=\"2\",vt.in=\"4\")3:i64MagicNumber (vt.const=\"0x5f3759df\")}string/binary  const, must be the specified value. min_size, max_size. pattern, is used for regular matching. prefix, suffix, contains, not_contains. in, not_in, respectively indicate that the numerical value used and the numerical value cannot be specified at the same time. It can be specified for one use, and one can be specified. not_nil, the field cannot be empty (only valid if the field is optional).  structStringDemo{1:stringUninitialized (vt.const=\"烫烫烫\")2:stringName (vt.min_size=\"6\",vt.max_size=\"12\")3:stringSomeStuffs (vt.pattern=\"[0-9A-Za-z]+\")4:stringDebugInfo (vt.prefix=\"[Debug]\")5:stringPanicInfo (vt.contains=\"panic\")6:stringEditor (vt.in=\"vscode\",vt.in=\"vim\",vt.in=\"goland\")}bool  const, must be the specified value. not_nil, the field cannot be empty (only valid if the field is optional).  structBoolDemo{1:boolAMD (vt.const=\"true\")2:optionalboolNvidia (vt.not_nil=\"false\")}enum  const, must be the specified value. defined_only, must be in the value defined in the enum. not_nil, the field cannot be empty (only valid if the field is optional).  enumType{Number,String,List,Map}structEnumDemo{1:TypeAddressType (vt.const=\"String\")2:TypeValueType (vt.defined_only=\"true\")3:optionalTypeOptType (vt.not_nil=\"true\")}set/list  min_size, max_size. elem, element constraints.  structSetListDemo{1:list\u003cstring\u003ePersons (vt.min_size=\"5\",vt.max_size=\"10\")2:set\u003cdouble\u003eHealthPoints (vt.elem.gt=\"0\")}map  min_size, max_size. no_sparse, means it can’t be nil when value is a pointer. key, value.  structMapDemo{1:map\u003ci32,string\u003eIdName (vt.min_size=\"5\",vt.max_size=\"10\")2:map\u003ci32,DemoTestRequest\u003eRequests (vt.no_sparse=\"true\")3:map\u003ci32,double\u003eSome,(vt.key.gt=\"0\",vt.value.lt=\"1000\")}struct/union/exception  skip, means skipping recursive checks for struct/union/exception. (Defaults to false when used as a separate field, true by default when used as an element). not_nil, the field cannot be empty (only valid if the field is optional).  structOuterRequest{1:SomeStructStruct (vt.skip=\"true\")2:SomeUnionUnion (vt.skip=\"true\")3:SomeStructNotNilStruct (vt.not_nil=\"true\")}variable reference The prefix ‘$’ represents a reference to a variable, which can be used for cross-field verification:\n $x represents a variable named x, the variable name is [a-zA-Z0-9_], and its scope rule is **current structure**. $ represents the current field where the validator is located.  structExample{1:stringA (vt.max_size=\"$C\")2:stringB (vt.not_in=\"$A\")3:i32C}utility function The prefix ‘@’ indicates the built-in tool function to calculate the check value. Currently supported tool functions:\n sprintf(fmt, $1, $2…), used to output specific characters. len($x), output variable size (string length, number of list elements).  structExample{1:stringA2:list\u003cstring\u003eB (vt.max_size=\"@len($D)\")3:map\u003cstring,int)C4:stringD (vt.const=\"@sprintf(\\\"%s_%s\\\", $A, \\\"mysuffix\\\")\")}","categories":"","description":"","excerpt":"Overview Validator is a thrift plugin that supports struct validation. …","ref":"/docs/kitex/tutorials/code-gen/validator/","tags":"","title":"Thrift Validator"},{"body":"概述 Validator 是用于支持结构体校验能力的 thriftgo 插件。\n在 IDL 中通过注解来描述约束，插件会根据注解给对应的 struct 生成 IsValid() error  方法，生成在 xxx-validator.go 文件。\n注解采用 vt.{ConstraintType} = \"Value\" 这种形式描述。\n适用范围：struct/union 中的每个 field 。\n校验形式：用户主动校验。（可提供中间件，统一对所有参数/结果校验）\nIDL 示例：\nenum MapKey { A, B, C, D, E, F } struct Request { 1: required string Message (vt.max_size = \"30\", vt.prefix = \"Debug\") 2: i32 ID (vt.gt = \"1000\", vt.lt = \"10000\") 3: list\u003cdouble\u003e Values (vt.elem.gt = \"0.25\") 4: map\u003cMapKey, binary\u003e KeyValues (vt.key.defined_only = \"true\", vt.min_size = \"1\") } struct Response { 1: required string Message (vt.in = \"Debug\", vt.in = \"Info\", vt.in = \"Warn\", vt.in = \"Error\") } 安装 使用 Validator 插件前需要先进行安装，才可以使用，否则会报找不到 thrift-gen-validator 可执行文件错误（ exec: \"thrift-gen-validator\": executable file not found in $PATH）。\n如果你已经安装好 Golang 和 Kitex 命令行工具，请执行如下命令安装 thrift-gen-validator 插件：\n$ go install github.com/cloudwego/thrift-gen-validator@latest 执行完 go install 之后，会将编译后的 thrift-gen-validator 二进制文件安装到 $GOPATH/bin 下。\n可以执行下面的命令，验证是否安装成功。\n$ cd $(go env GOPATH)/bin $ ls go1.20.1 goimports hz thrift-gen-validator godotenv golangci-lint kitex thriftgo $ cd ~/ \u0026\u0026 thrift-gen-validator --help Usage of thrift-gen-validator: -version Show the version of thrift-gen-validator (0x1232358,0x1370f70) cd ~/ 是为了验证在任意目录下都可以愉快地调用 thrift-gen-validator。如果在执行该命令时出现类似上述找不到 thrift-gen-validator 可执行文件错误，请检查 $GOPATH 是否被正确设置到 $PATH 中。\n关于 thrift-gen-validator 的安装及其他更多信息，可参阅 thrift-gen-validator\n使用 以快速开始里的 Kitex Hello 项目为例，进入示例仓库的 hello 目录，在 hello.thrift 中添加注解，例如我们对 Request 结构体的 message 字段进行约束，约束长度不超过8且要以 “kitex-” 前缀开头：\nstruct Request { 1: string message (vt.max_size = \"8\", vt.prefix = \"kitex-\") } 在生成 Kitex 代码时，加上 --thrift-plugin validator 参数，即可生成 validator 文件。\nkitex --thrift-plugin validator -service a.b.c hello.thrift 执行后，可以看见新生成的 Validator：\n├── kitex_gen └── api ├── hello │ ├── client.go │ ├── hello.go │ ├── invoker.go │ └── server.go ├── hello.go --\u003e ├── hello_validator.go ├── k-consts.go └── k-hello.go 其中对于 Request 结构体，新生成了 IsValid() 方法：\nfunc (p *Request) IsValid() error { if len(p.Message) \u003e int(8) { return fmt.Errorf(\"field Message max_len rule failed, current value: %d\", len(p.Message)) } _src := \"kitex-\" if !strings.HasPrefix(p.Message, _src) { return fmt.Errorf(\"field Message prefix rule failed, current value: %v\", p.Message) } return nil } 在后续的使用中，调用 IsValid() 方法对结构体进行校验即可：\n req := \u0026api.Request { //.... } err := req.IsValid() if err != nil { //invalid .... } //valid ... 支持的校验能力 校验顺序以定义顺序为准， ‘in’ 和 ‘not_in’ 这类可以定义多次的，以第一次出现的顺序为准。\n数字类型 包括 i8，i16，i32，i64，double。\n const，必须为指定值。 lt，le，gt，ge，分别表示小于，小于等于，大于，大于等于。 in，not_in，分别表示可以使用的值和不可以使用的值，可多次指定，一次指定一个值。 not_nil，该字段不能为空。（仅当字段为 optional 时合法）  structNumericDemo{1:doubleValue (vt.gt=\"1000.1\",vt.lt=\"10000.1\")2:i8Type (vt.in=\"1\",vt.in=\"2\",vt.in=\"4\")3:i64MagicNumber (vt.const=\"0x5f3759df\")}string/binary  const，必须为指定值。 min_size，max_size，最大长度，最小长度。 pattern，正则匹配。 prefix，suffix，contains，not_contains，限制前缀，限制后缀，必须包含，不能包含。 in，not_in，分别表示可以使用的值和不可以使用的值，二者不能同时使用，可多次指定，一次指定一个值。 not_nil，该字段不能为空。（仅当字段为 optional 时合法）  structStringDemo{1:stringUninitialized (vt.const=\"烫烫烫\")2:stringName (vt.min_size=\"6\",vt.max_size=\"12\")3:stringSomeStuffs (vt.pattern=\"[0-9A-Za-z]+\")4:stringDebugInfo (vt.prefix=\"[Debug]\")5:stringPanicInfo (vt.contains=\"panic\")6:stringEditor (vt.in=\"vscode\",vt.in=\"vim\",vt.in=\"goland\")}bool  const，必须为指定值。 not_nil，该字段不能为空。（仅当字段为 optional 时合法）  structBoolDemo{1:boolAMD (vt.const=\"true\")2:optionalboolNvidia (vt.not_nil=\"false\")}enum  const，必须为指定值。 defined_only，必须在 enum 中定义的值中。 not_nil，该字段不能为空。（仅当字段为 optional 时合法）  enumType{Number,String,List,Map}structEnumDemo{1:TypeAddressType (vt.const=\"String\")2:TypeValueType (vt.defined_only=\"true\")3:optionalTypeOptType (vt.not_nil=\"true\")}set/list  min_size，max_size，最小长度，最大长度。 elem，元素约束。  structSetListDemo{1:list\u003cstring\u003ePersons (vt.min_size=\"5\",vt.max_size=\"10\")2:set\u003cdouble\u003eHealthPoints (vt.elem.gt=\"0\")}map  min_size，max_size，最小键值对数，最大键值对数。 no_sparse，value 为指针时，不能为 nil 。 key，value，键约束，值约束。  structMapDemo{1:map\u003ci32,string\u003eIdName (vt.min_size=\"5\",vt.max_size=\"10\")2:map\u003ci32,DemoTestRequest\u003eRequests (vt.no_sparse=\"true\")3:map\u003ci32,double\u003eSome,(vt.key.gt=\"0\",vt.value.lt=\"1000\")}struct/union/exception  skip，跳过该 struct/union/exception 的递归校验。（作为单独字段时默认为 false，作为元素时默认为 true ） not_nil，该字段不能为空。  structOuterRequest{1:SomeStructStruct (vt.skip=\"true\")2:SomeUnionUnion (vt.skip=\"true\")3:SomeStructNotNilStruct (vt.not_nil=\"true\")}变量引用 前置符 $ 表示某个变量的引用，可用于跨字段校验：\n $x 代表名为 x 的变量，变量名为 \\[a-zA-Z0-9_]\\，其作用域规则为当前结构体。 $ 表示 validator 所处的当前字段。  structExample{1:stringA (vt.max_size=\"$C\")2:stringB (vt.not_in=\"$A\")3:i32C}工具函数 前置符 @ 表示内置的工具函数来计算校验值，目前支持的工具函数：\n sprintf(fmt, $1, $2...) 用于输出特定字符。 len($x) 输出变量大小。（字符串长度、list 元素个数）  structExample{1:stringA2:list\u003cstring\u003eB (vt.max_size=\"@len($D)\")3:map\u003cstring,int)C4:stringD (vt.const=\"@sprintf(\\\"%s_%s\\\", $A, \\\"mysuffix\\\")\")}","categories":"","description":"","excerpt":"概述 Validator 是用于支持结构体校验能力的 thriftgo 插件。\n在 IDL 中通过注解来描述约束， …","ref":"/zh/docs/kitex/tutorials/code-gen/validator/","tags":"","title":"Thrift Validator"},{"body":"There are various types of Hertz middleware, which are simply divided into two categories.\n Server-side middleware Client-side middleware  Server-side middleware Server-side middleware is a function in the HTTP request-response cycle that provides a convenient mechanism for inspecting and filtering HTTP requests entering your application, such as logging each request or enabling CORS.\n        Figure 1: middleware call chain    Middleware can perform tasks before or after passing the request deeper into the application:\n Middleware can be executed before the request reaches business processing, such as performing identity authentication and authorization authentication. When the middleware only has pre-handle logic and there is no requirement to be in a function call stack with real handler, the .Next can be omitted. Middleware can also be executed after business processing has been performed, such as logging response times and recovering from a panic. If there is other processing logic (post-handle) after the business handler, or there is a strong requirement for the function call chain (stack), then the .Next must be called explicitly, see middleware C in Figure 1.  Implement customized middleware // One way func MyMiddleware() app.HandlerFunc { return func(ctx context.Context, c *app.RequestContext) { // pre-handle  // ...  // if there is no 'post-handle' logic, the 'c.Next(ctx)' can be omitted.  c.Next(ctx) } } // The other way func MyMiddleware() app.HandlerFunc { return func(ctx context.Context, c *app.RequestContext) { c.Next(ctx) // call the next middleware(handler)  // post-handle  ... } } The middleware will be executed in the order defined, If you want to terminate the middleware call quickly, you can use the following methods, noting that the current middleware will still execute.\n Abort()：terminate subsequent calls AbortWithMsg(msg string, statusCode int)：terminates subsequent calls and sets the body and status code for the Response AbortWithStatus(code int)：terminates subsequent calls and sets the status code  Server-level middleware Server-level middleware will take effect on all routing of the server\nh := server.Default() h.Use(MyMiddleware()) Group-level middleware The group-level middleware takes effect on the paths under the current routing group\nh := server.Default() group := h.Group(\"/group\") group.Use(GroupMiddleware()) or\npackage main import ( \"context\" \"fmt\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" ) func GroupMiddleware() []app.HandlerFunc { return []app.HandlerFunc{func(ctx context.Context, c *app.RequestContext) { fmt.Println(\"group middleware\") c.Next(ctx) }} } func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8888\")) group := h.Group(\"/group\", append(GroupMiddleware(), func(ctx context.Context, c *app.RequestContext) { fmt.Println(\"group middleware 2\") c.Next(ctx) })...) // ... \th.Spin() } Route-level middleware A route-level middleware only takes effect on the current route\npackage main import ( \"context\" \"fmt\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" ) func PathMiddleware() []app.HandlerFunc { return []app.HandlerFunc{func(ctx context.Context, c *app.RequestContext) { fmt.Println(\"path middleware\") c.Next(ctx) }} } func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8888\")) h.GET(\"/path\", append(PathMiddleware(), func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"path\") })...) h.Spin() }  If you use the hz tool and IDL to develop a project, the router folder will automatically generate group-level middleware and route-level middleware templates based on services and methods. You can add corresponding logic to it and customize your own personalized middleware.\n Activate default middleware The Hertz framework already presets the commonly used Recover middleware, which can be registered by Default with server.Default().\nMiddlewares we provided Hertz provides frequently-used middlewares such as BasicAuth, CORS, JWT etc., more implementations can be found at hertz-contrib. If you need others, please make an issue.\nClient-side Middleware Client-side middleware can be executed before the request is made or after the response is obtained:\n Middleware can be executed before the request is sent, such as adding a signature or other fields to the request. Middleware can also be executed after receiving the response, such as modifying the response result to adapt to the business logic.  Implement customized middleware The middleware implementation on the Client side is different from that on the Server side. The Client side cannot get the index of the middleware to increase, so the Client middleware uses nested functions to build the middleware in advance. When implementing client-side customized middleware, you can refer to the following code.\nfunc MyMiddleware(next client.Endpoint) client.Endpoint { return func(ctx context.Context, req *protocol.Request, resp *protocol.Response) (err error) { // pre-handle  // ...  err = next(ctx, req, resp) if err != nil { return } // post-handle  // ...  } } Note: the next method must be executed to continue calls to the subsequent middleware. If you want to stop the middleware call, just return before next.\nRegister customized middleware Registering custom middleware is the same as on the server side.\nc, err := client.NewClient() c.Use(MyMiddleware) Full example package main import ( \"context\" \"fmt\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/protocol\" ) func MyMiddleware(next client.Endpoint) client.Endpoint { return func(ctx context.Context, req *protocol.Request, resp *protocol.Response) (err error) { // pre-handle \t// ... \tfmt.Println(\"before request\") req.AppendBodyString(\"k1=v1\u0026\") err = next(ctx, req, resp) if err != nil { return } // post-handle \t// ... \tfmt.Println(\"after request\") return nil } } func main() { client, _ := client.NewClient() client.Use(MyMiddleware) statusCode, body, err := client.Post(context.Background(), []byte{}, \"http://httpbin.org/redirect-to?url=http%3A%2F%2Fhttpbin.org%2Fpost\u0026status_code=302\", \u0026protocol.Args{}) fmt.Printf(\"%d, %s, %s\", statusCode, body, err) }  Middleware may be executed more than once, such as redirect, etc., idempotency needs to be considered\n ","categories":"","description":"","excerpt":"There are various types of Hertz middleware, which are simply divided …","ref":"/docs/hertz/tutorials/basic-feature/middleware/","tags":"","title":"Middleware Overview"},{"body":"Hertz中间件的种类是多种多样的，简单分为两大类：\n 服务端中间件 客户端中间件  服务端中间件 Hertz 服务端中间件是 HTTP 请求－响应周期中的一个函数，提供了一种方便的机制来检查和过滤进入应用程序的 HTTP 请求， 例如记录每个请求或者启用CORS。\n        图1：中间件调用链    中间件可以在请求更深入地传递到业务逻辑之前或之后执行：\n 中间件可以在请求到达业务逻辑之前执行，比如执行身份认证和权限认证，当中间件只有初始化（pre-handle）相关逻辑，且没有和 real handler 在一个函数调用栈中的需求时，中间件中可以省略掉最后的.Next，如图1的中间件 B。 中间件也可以在执行过业务逻辑之后执行，比如记录响应时间和从异常中恢复。如果在业务 handler 处理之后有其它处理逻辑（ post-handle ），或对函数调用链（栈）有强需求，则必须显式调用.Next，如图1的中间件 C。  实现一个中间件 // 方式一 func MyMiddleware() app.HandlerFunc { return func(ctx context.Context, c *app.RequestContext) { // pre-handle  // ...  c.Next(ctx) } } // 方式二 func MyMiddleware() app.HandlerFunc { return func(ctx context.Context, c *app.RequestContext) { c.Next(ctx) // call the next middleware(handler)  // post-handle  // ...  } } 中间件会按定义的先后顺序依次执行，如果想快速终止中间件调用，可以使用以下方法，注意当前中间件仍将执行。\n Abort()：终止后续调用 AbortWithMsg(msg string, statusCode int)：终止后续调用，并设置 response中body，和状态码 AbortWithStatus(code int)：终止后续调用，并设置状态码  Server 级别中间件 Server 级别中间件会对整个server的路由生效\nh := server.Default() h.Use(GlobalMiddleware()) 路由组级别中间件 路由组级别中间件对当前路由组下的路径生效\nh := server.Default() group := h.Group(\"/group\") group.Use(GroupMiddleware()) 或者\npackage main import ( \"context\" \"fmt\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" ) func GroupMiddleware() []app.HandlerFunc { return []app.HandlerFunc{func(ctx context.Context, c *app.RequestContext) { fmt.Println(\"group middleware\") c.Next(ctx) }} } func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8888\")) group := h.Group(\"/group\", append(GroupMiddleware(), func(ctx context.Context, c *app.RequestContext) { fmt.Println(\"group middleware 2\") c.Next(ctx) })...) // ... \th.Spin() } 单一路由级别中间件 单一路由级别中间件只对当前路径生效\npackage main import ( \"context\" \"fmt\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" ) func PathMiddleware() []app.HandlerFunc { return []app.HandlerFunc{func(ctx context.Context, c *app.RequestContext) { fmt.Println(\"path middleware\") c.Next(ctx) }} } func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8888\")) h.GET(\"/path\", append(PathMiddleware(), func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"path\") })...) h.Spin() }  如果你使用hz工具和IDL开发项目、router文件夹下会自动根据服务和方法生成路由组中间件和单一方法中间件模板，你可以在其中添加相应的逻辑，定制自己的个性化中间件。\n 使用默认中间件 Hertz 框架已经预置了常用的 recover 中间件，使用 server.Default() 默认可以注册该中间件。\n常用中间件 Hertz 提供了常用的 BasicAuth、CORS、JWT等中间件，更多实现可以在 hertz-contrib 查找，其他中间件如有需求，可提 issue 告诉我们。\n客户端中间件 客户端中间件可以在请求发出之前或获取响应之后执行：\n 中间件可以在请求发出之前执行，比如统一为请求添加签名或其他字段。 中间件也可以在收到响应之后执行，比如统一修改响应结果适配业务逻辑。  实现一个中间件 客户端中间件实现和服务端中间件不同。Client 侧无法拿到中间件 index 实现递增，因此 Client 中间件采用提前构建嵌套函数的形式实现，在实现一个中间件时，可以参考下面的代码。\nfunc MyMiddleware(next client.Endpoint) client.Endpoint { return func(ctx context.Context, req *protocol.Request, resp *protocol.Response) (err error) { // pre-handle  // ...  err = next(ctx, req, resp) if err != nil { return } // post-handle  // ...  } }  注意：必须执行 next 方法才能继续调用后续中间件。如果想停止中间件调用，在 next 之前返回就可以了。\n 注册一个中间件 注册中间件的方式和 Server 相同\nc, err := client.NewClient() c.Use(MyMiddleware) 完整示例 package main import ( \"context\" \"fmt\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/protocol\" ) func MyMiddleware(next client.Endpoint) client.Endpoint { return func(ctx context.Context, req *protocol.Request, resp *protocol.Response) (err error) { // pre-handle \t// ... \tfmt.Println(\"before request\") req.AppendBodyString(\"k1=v1\u0026\") err = next(ctx, req, resp) if err != nil { return } // post-handle \t// ... \tfmt.Println(\"after request\") return nil } } func main() { client, _ := client.NewClient() client.Use(MyMiddleware) statusCode, body, err := client.Post(context.Background(), []byte{}, \"http://httpbin.org/redirect-to?url=http%3A%2F%2Fhttpbin.org%2Fpost\u0026status_code=302\", \u0026protocol.Args{}) fmt.Printf(\"%d, %s, %s\", statusCode, body, err) }  中间件可能执行不止一次，比如发生跳转等，需要考虑幂等性\n ","categories":"","description":"","excerpt":"Hertz中间件的种类是多种多样的，简单分为两大类：\n 服务端中间件 客户端中间件  服务端中间件 Hertz 服务端中间件是 HTTP 请 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/","tags":"","title":"中间件概览"},{"body":"会议主题： CloudWeGo 社区会议 3.25\n参会人员： YangruiEmma, liu-song, baiyutang, yccpt, AshleeT, Authorixy, Dianjun Suo, bodhisatan, CoderPoet, Quan Hu, li-jin-gou, JZK-Keven, EastHorse, GuangmingLuo, Xiwen Li, joway, jasondeng1997, HeyJavaBean.\n会前必读： http://www.cloudwego.io/; https://github.com/cloudwego\n议程 1 ：新成员自我介绍 内容：社区新成员和首次参加社区会议的内部成员分别进行自我介绍，主要包含个人基本情况、历史贡献和个人未来规划。\n议程 2 ：Kitex 单测任务进展介绍   领取进度： 10/14。\n  如何认领任务： 在任务认领页面下方的评论中，留言你需要认领的项目，之后会分配给你。\n  提交 PR 注意事项 ：\na. 提交 PR 一定要关联 Issue (可以在 PR 描述里面进行 Issue 关联)。\nb. Kitex 单测任务的 PR 的描述前缀统一使用 Test，便于相关同学进行 review。\nc. 提交了 PR之后，可以将 PR 发送在群里，方便后续跟进。\n  提交 PR 时间要求： 认领之后半个月内提交 PR，便于后续的意见修改和调试。\n  议程 3：源码分析落地   参考案例： 具体可以参考 Go-zero 和 Kratos 开源社区。例如：对框架一些较好的设计进行解读，提供“扩展阅读”文档，目录可以涵盖“日志组件介绍”、“令牌桶限流”等文档内容。\n  后续规划：\na. 草拟源码分析目录大纲：① 目录结构和内容可以参考 CloudWeGo 官网目录；② 源码分析目录文档完成后，可以发在群里或者在 Github 上提交 Issue ，方便大家讨论修改；③ 认领单测任务的同学可以关注一下源码分析活动，助于更好地了解模块的功能。\nb. 宣传推广：后续会讨论宣传方案（例如征文比赛），也鼓励做出贡献的同学寻找渠道进行推广。\n  议程4：Q\u0026A Q：写 Retry 的单测时，Retry 的单测其实是要配合 Kitex 的 Client 一起使用的。但是如果要把单测写到 Retry 下面的话，就需要引一个 Client 才能去写，这样就导致 Client 单测下面可能也有 Retry ，会存在一个循环依赖的问题？\nA：确实存在循坏依赖的情况。对于这种情况，可以使用 mock，比如你需要用到 Client，那你可能要专门去 mock 一个 Client；除此之外，单测使用 xxx_test package，也可以解决循环依赖的问题。\n议程5：社区建议 欢迎大家将参与社区建设期间遇到的任何问题和想法发在群里，同社区成员一起沟通。内容不限于 Kitex、Netpoll 代码库、CloudWeGo 官网、宣传渠道等。\n","categories":"","description":"","excerpt":"会议主题： CloudWeGo 社区会议 3.25\n参会人员： YangruiEmma, liu-song, baiyutang, …","ref":"/zh/community/meeting_notes/2022-03-25/","tags":"","title":"CloudWeGo 社区会议 3.25"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/kitex/tutorials/advanced-feature/","tags":"","title":"Advanced Feature"},{"body":"message is used to start a call, you should use local and remote two net.Addr to initialize message. Which indicates local and remote address (used in logging and tracing). After initialization, you can use SetRequestBytes(buf []byte) error to setup request binary. Then call Call method of invoker to start a call. After call, you can use GetResponseBytes() ([]byte, error) of message to get response binary.\nimport ( ... \"github.com/cloudwego/kitex/server/invoke\" ... ) func main() { var reqPayload, respPayload []byte var local, remote net.Addr ... // init local/remote  ... ivk := echo.NewInvoker(new(EchoImpl)) msg := invoke.NewMessage(local, remote) // setup request payload  msg.SetRequestBytes(reqPayload) // start a call  err := ivk.Call(msg) if err != nil { ... } respPayload, err = msg.GetResponseBytes() if err != nil { ... } } ","categories":"","description":"SDK Mode（invoker）provides a way to call Kitex server just like a SDK.","excerpt":"SDK Mode（invoker）provides a way to call Kitex server just like a SDK.","ref":"/docs/kitex/tutorials/advanced-feature/invoker/","tags":"","title":"Server SDK Mode"},{"body":"OpenTelemetry Kitex’s OpenTelemetry extension provides support for tracing, metrics and logging.\nExample\nclient side:\nimport ( ... \"github.com/kitex-contrib/obs-opentelemetry/provider\" \"github.com/kitex-contrib/obs-opentelemetry/tracing\" ) func main(){ serviceName := \"echo-client\" p := provider.NewOpenTelemetryProvider( provider.WithServiceName(serviceName), provider.WithExportEndpoint(\"localhost:4317\"), provider.WithInsecure(), ) defer p.Shutdown(context.Background()) c, err := echo.NewClient( \"echo\", client.WithSuite(tracing.NewClientSuite()), // Please keep the same as provider.WithServiceName  client.WithClientBasicInfo(\u0026rpcinfo.EndpointBasicInfo{ServiceName: serviceName}), ) if err != nil { klog.Fatal(err) } } server side:\nimport ( ... \"github.com/kitex-contrib/obs-opentelemetry/provider\" \"github.com/kitex-contrib/obs-opentelemetry/tracing\" ) func main() { serviceName := \"echo\" p := provider.NewOpenTelemetryProvider( provider.WithServiceName(serviceName), provider.WithExportEndpoint(\"localhost:4317\"), provider.WithInsecure(), ) defer p.Shutdown(context.Background()) svr := echo.NewServer( new(EchoImpl), server.WithSuite(tracing.NewServerSuite()), // Please keep the same as provider.WithServiceName  server.WithServerBasicInfo(\u0026rpcinfo.EndpointBasicInfo{ServiceName: serviceName}), ) if err := svr.Run(); err != nil { klog.Fatalf(\"server stopped with error:\", err) } } For more information see obs-opentelemetry\nOpenTracing client side, use OpenTracing GlobalTracer by default\nimport ( \"github.com/cloudwego/kitex/client\" \"github.com/cloudwego/kitex-examples/kitex_gen/api/echo\" internal_opentracing \"github.com/kitex-contrib/tracer-opentracing\" ) ... tracer := internal_opentracing.NewDefaultClientSuite() client, err := echo.NewClient(\"echo\", client.WithSuite(tracer)) if err != nil { log.Fatal(err) } server side, use OpenTracing GlobalTracer by default\nimport ( \"github.com/cloudwego/kitex/server\" \"github.com/cloudwego/kitex-examples/kitex_gen/api/echo\" internal_opentracing \"github.com/kitex-contrib/tracer-opentracing\" ) ... tracer := internal_opentracing.NewDefaultServerSuite() svr, err := echo.NewServer(new(EchoImpl), server.WithSuite(tracer)) if err := svr.Run(); err != nil { log.Println(\"server stopped with error:\", err) } else { log.Println(\"server stopped\") } For more information see tracer-opentracing\nCustomize opentracing tracer and operation name client side:\nimport ( ... ko \"github.com/kitex-contrib/opentracing\" \"github.com/opentracing/opentracing-go\" \"github.com/cloudwego/kitex/pkg/endpoint\" \"github.com/cloudwego/kitex/pkg/rpcinfo\" ... ) ... myTracer := opentracing.GlobalTracer() operationNameFunc := func(ctx context.Context) string { endpoint := rpcinfo.GetRPCInfo(ctx).To() return endpoint.ServiceName() + \"::\" + endpoint.Method() } ... client, err := echo.NewClient(\"echo\", ko.ClientOption(myTracer, operationNameFunc)) if err != nil { log.Fatal(err) } server side:\nimport ( ... ko \"github.com/kitex-contrib/opentracing\" \"github.com/opentracing/opentracing-go\" \"github.com/cloudwego/kitex/pkg/endpoint\" \"github.com/cloudwego/kitex/pkg/rpcinfo\" ... ) ... myTracer := opentracing.GlobalTracer() operationNameFunc := func(ctx context.Context) string { endpoint := rpcinfo.GetRPCInfo(ctx).To() return endpoint.ServiceName() + \"::\" + endpoint.Method() } ... svr, err := echo.NewServer(ko.ClientOption(myTracer, operationNameFunc)) if err := svr.Run(); err != nil { log.Println(\"server stopped with error:\", err) } else { log.Println(\"server stopped\") } Customize tracer tracer interface:\ntype Tracer interface { Start(ctx context.Context) context.Context Finish(ctx context.Context) } Example\nclient side:\nimport \"github.com/cloudwego/kitex/client\" ... type myTracer struct {} func (m *myTracer) Start(ctx context.Context) context.Context { _, ctx = opentracing.StartSpanFromContextWithTracer(ctx, o.tracer, \"RPC call\") return ctx } func (m *myTracer) Finish(ctx context.Context) { span := opentracing.SpanFromContext(ctx) span.Finish() } ... client, err := echo.NewClient(\"echo\", client.WithTracer(\u0026myTracer{})) if err != nil { log.Fatal(err) } server side:\nimport \"github.com/cloudwego/kitex/server\" ... type myTracer struct {} func (m *myTracer) Start(ctx context.Context) context.Context { _, ctx = opentracing.StartSpanFromContextWithTracer(ctx, o.tracer, \"RPC handle\") return ctx } func (m *myTracer) Finish(ctx context.Context) { span := opentracing.SpanFromContext(ctx) span.Finish() } ... svr, err := echo.NewServer(server.WithTracer(\u0026myTracer{})) if err := svr.Run(); err != nil { log.Println(\"server stopped with error:\", err) } else { log.Println(\"server stopped\") } ","categories":"","description":"Kitex supports OpenTelemetry tracer, OpenTracing tracer and also customized tracer.","excerpt":"Kitex supports OpenTelemetry tracer, OpenTracing tracer and also …","ref":"/docs/kitex/tutorials/service-governance/tracing/","tags":"","title":"Tracing"},{"body":"Kitex supports user-defined registration module. Users can extend and integrate other registration centers by themselves. This extension is defined under pkg/registry.\nExtension API and Definition of Info Struct  Extension API  // Registry is extension interface of service registry. type Registry interface { Register(info *Info) error Deregister(info *Info) error }  Definition of Info Struct Kitex defines some registration information. Users can also expand the registration information into tags as needed.  // Info is used for registry. // The fields are just suggested, which is used depends on design. type Info struct { // ServiceName will be set in kitex by default \tServiceName string // Addr will be set in kitex by default \tAddr net.Addr // PayloadCodec will be set in kitex by default, like thrift, protobuf \tPayloadCodec string Weight int StartTime time.Time WarmUp time.Duration // extend other infos with Tags. \tTags map[string]string } Integrate into Kitex Specify your own registration module and customized registration information through option. Note that registration requires service information, which is also specified through option.\n  Specify Server Info\noption: WithServerBasicInfo\nebi := \u0026rpcinfo.EndpointBasicInfo{ ServiceName: \"yourServiceName\", Tags: make(map[string]string), } ebi.Tags[idc] = \"xxx\" svr := xxxservice.NewServer(handler, server.WithServerBasicInfo(ebi))   Specify Custom Registion module\noption: WithRegistry\nsvr := xxxservice.NewServer(handler, server.WithServerBasicInfo(ebi), server.WithRegistry(yourRegistry))   Custom RegistryInfo\nKitex sets ServiceName, Addr and PayloadCodec by default. If other registration information is required, you need to inject it by yourself. option: WithRegistryInfo.\nsvr := xxxservice.NewServer(handler, server.WithRegistry(yourRegistry), server.WithRegistryInfo(yourRegistryInfo))   ","categories":"","description":"","excerpt":"Kitex supports user-defined registration module. Users can extend and …","ref":"/docs/kitex/tutorials/framework-exten/registry/","tags":"","title":"Extension of Service Registry"},{"body":"调用通过 message 完成，初始化 message 需要 local 和 remote 两个 net.Addr ，分别表示本地地址和远端（客户端）地址（此处的地址主要用于日志监控），初始化后通过 SetRequestBytes(buf []byte) error 设置请求的二进制数据。 最后调用 invoker 的 Call 方法即可完成调用。调用完成后可通过 message 的 GetResponseBytes() ([]byte, error) 获取响应的二进制数据。\nimport ( ... \"github.com/cloudwego/kitex/server/invoke\" ... ) func main() { var reqPayload, respPayload []byte var local, remote net.Addr ... // init local/remote  ... ivk := echo.NewInvoker(new(EchoImpl)) msg := invoke.NewMessage(local, remote) // 装载payload  msg.SetRequestBytes(reqPayload) // 发起调用  err := ivk.Call(msg) if err != nil { ... } respPayload, err = msg.GetResponseBytes() if err != nil { ... } } ","categories":"","description":"SDK化（invoker）允许用户将 Kitex server 当作一个本地 SDK 调用。","excerpt":"SDK化（invoker）允许用户将 Kitex server 当作一个本地 SDK 调用。","ref":"/zh/docs/kitex/tutorials/advanced-feature/invoker/","tags":"","title":"Server SDK化"},{"body":"Kitex 支持自定义注册模块，使用者可自行扩展集成其他注册中心，该扩展定义在 pkg/registry 下。\n扩展接口和 Info 定义  扩展接口  // Registry is extension interface of service registry. type Registry interface { Register(info *Info) error Deregister(info *Info) error }  Info 定义 Kitex 定义了部分注册信息，使用者也可以根据需要自行扩展注册信息到 Tags 中。  // Info is used for registry. // The fields are just suggested, which is used depends on design. type Info struct { // ServiceName will be set in kitex by default  ServiceName string // Addr will be set in kitex by default  Addr net.Addr // PayloadCodec will be set in kitex by default, like thrift, protobuf  PayloadCodec string Weight int StartTime time.Time WarmUp time.Duration // extend other infos with Tags.  Tags map[string]string } 集成到 Kitex 通过 option 指定自己的注册模块和自定义的注册信息。注意注册需要服务信息，服务信息也是通过 option 指定。\n  指定服务信息\noption: WithServerBasicInfo\nebi := \u0026rpcinfo.EndpointBasicInfo{ ServiceName: \"yourServiceName\", Tags: make(map[string]string), } ebi.Tags[idc] = \"xxx\" svr := xxxservice.NewServer(handler, server.WithServerBasicInfo(ebi))   指定自定义注册模块\noption: WithRegistry\nsvr := xxxservice.NewServer(handler, server.WithServerBasicInfo(ebi), server.WithRegistry(yourRegistry))   自定义 RegistryInfo\nKitex 默认赋值 ServiceName、Addr 和 PayloadCodec，若需要其他注册信息需要使用者自行注入。option: WithRegistryInfo\nsvr := xxxservice.NewServer(handler, server.WithRegistry(yourRegistry), server.WithRegistryInfo(yourRegistryInfo))   ","categories":"","description":"","excerpt":"Kitex 支持自定义注册模块，使用者可自行扩展集成其他注册中心，该扩展定义在 pkg/registry 下。\n扩展接口和 Info …","ref":"/zh/docs/kitex/tutorials/framework-exten/registry/","tags":"","title":"服务注册扩展"},{"body":"OpenTelemetry Kitex 的 OpenTelemetry 扩展 提供了 tracing、metrics、logging 的支持。\n示例:\nclient 侧\nimport ( ... \"github.com/kitex-contrib/obs-opentelemetry/provider\" \"github.com/kitex-contrib/obs-opentelemetry/tracing\" ) func main(){ serviceName := \"echo-client\" p := provider.NewOpenTelemetryProvider( provider.WithServiceName(serviceName), provider.WithExportEndpoint(\"localhost:4317\"), provider.WithInsecure(), ) defer p.Shutdown(context.Background()) c, err := echo.NewClient( \"echo\", client.WithSuite(tracing.NewClientSuite()), // Please keep the same as provider.WithServiceName  client.WithClientBasicInfo(\u0026rpcinfo.EndpointBasicInfo{ServiceName: serviceName}), ) if err != nil { klog.Fatal(err) } } server 侧\nimport ( ... \"github.com/kitex-contrib/obs-opentelemetry/provider\" \"github.com/kitex-contrib/obs-opentelemetry/tracing\" ) func main() { serviceName := \"echo\" p := provider.NewOpenTelemetryProvider( provider.WithServiceName(serviceName), provider.WithExportEndpoint(\"localhost:4317\"), provider.WithInsecure(), ) defer p.Shutdown(context.Background()) svr := echo.NewServer( new(EchoImpl), server.WithSuite(tracing.NewServerSuite()), // Please keep the same as provider.WithServiceName  server.WithServerBasicInfo(\u0026rpcinfo.EndpointBasicInfo{ServiceName: serviceName}), ) if err := svr.Run(); err != nil { klog.Fatalf(\"server stopped with error:\", err) } } 更多信息参考 obs-opentelemetry\nOpenTracing client 侧，默认使用 OpenTracing GlobalTracer\nimport ( \"github.com/cloudwego/kitex/client\" \"github.com/cloudwego/kitex-examples/kitex_gen/api/echo\" internal_opentracing \"github.com/kitex-contrib/tracer-opentracing\" ) ... tracer := internal_opentracing.NewDefaultClientSuite() client, err := echo.NewClient(\"echo\", client.WithSuite(tracer)) if err != nil { log.Fatal(err) } server 侧，默认使用 OpenTracing GlobalTracer\nimport ( \"github.com/cloudwego/kitex/server\" \"github.com/cloudwego/kitex-examples/kitex_gen/api/echo\" internal_opentracing \"github.com/kitex-contrib/tracer-opentracing\" ) ... tracer := internal_opentracing.NewDefaultServerSuite() svr, err := echo.NewServer(new(EchoImpl), server.WithSuite(tracer)) if err := svr.Run(); err != nil { log.Println(\"server stopped with error:\", err) } else { log.Println(\"server stopped\") } 更多信息参考 tracer-opentracing\n自定义 opentracing tracer 和 operation name client 侧\nimport ( ... ko \"github.com/kitex-contrib/opentracing\" \"github.com/opentracing/opentracing-go\" \"github.com/cloudwego/kitex/pkg/endpoint\" \"github.com/cloudwego/kitex/pkg/rpcinfo\" ... ) ... myTracer := opentracing.GlobalTracer() operationNameFunc := func(ctx context.Context) string { endpoint := rpcinfo.GetRPCInfo(ctx).To() return endpoint.ServiceName() + \"::\" + endpoint.Method() } ... client, err := echo.NewClient(\"echo\", ko.ClientOption(myTracer, operationNameFunc)) if err != nil { log.Fatal(err) } server 侧\nimport ( ... ko \"github.com/kitex-contrib/opentracing\" \"github.com/opentracing/opentracing-go\" \"github.com/cloudwego/kitex/pkg/endpoint\" \"github.com/cloudwego/kitex/pkg/rpcinfo\" ... ) ... myTracer := opentracing.GlobalTracer() operationNameFunc := func(ctx context.Context) string { endpoint := rpcinfo.GetRPCInfo(ctx).To() return endpoint.ServiceName() + \"::\" + endpoint.Method() } ... svr, err := echo.NewServer(ko.ClientOption(myTracer, operationNameFunc)) if err := svr.Run(); err != nil { log.Println(\"server stopped with error:\", err) } else { log.Println(\"server stopped\") } 自定义 tracer tracer 的定义如下：\ntype Tracer interface { Start(ctx context.Context) context.Context Finish(ctx context.Context) } 示例：\nclient 侧\nimport \"github.com/cloudwego/kitex/client\" ... type myTracer struct {} func (m *myTracer) Start(ctx context.Context) context.Context { _, ctx = opentracing.StartSpanFromContextWithTracer(ctx, o.tracer, \"RPC call\") return ctx } func (m *myTracer) Finish(ctx context.Context) { span := opentracing.SpanFromContext(ctx) span.Finish() } ... client, err := echo.NewClient(\"echo\", client.WithTracer(\u0026myTracer{})) if err != nil { log.Fatal(err) } server 侧\nimport \"github.com/cloudwego/kitex/server\" ... type myTracer struct {} func (m *myTracer) Start(ctx context.Context) context.Context { _, ctx = opentracing.StartSpanFromContextWithTracer(ctx, o.tracer, \"RPC handle\") return ctx } func (m *myTracer) Finish(ctx context.Context) { span := opentracing.SpanFromContext(ctx) span.Finish() } ... svr, err := echo.NewServer(server.WithTracer(\u0026myTracer{})) if err := svr.Run(); err != nil { log.Println(\"server stopped with error:\", err) } else { log.Println(\"server stopped\") } ","categories":"","description":"Kitex 提供了对 OpenTelemetry 和 OpenTracing 的支持，也支持用户自定义链路跟踪。","excerpt":"Kitex 提供了对 OpenTelemetry 和 OpenTracing 的支持，也支持用户自定义链路跟踪。","ref":"/zh/docs/kitex/tutorials/service-governance/tracing/","tags":"","title":"链路跟踪"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/kitex/tutorials/advanced-feature/","tags":"","title":"高级特性"},{"body":"The cwgo tool supports generating the calling code of HTTP Client or RPC Client through IDL, which is convenient for users to develop.\nBasic commands Use cwgo client -h to view the help command for generating client code.\n$ cwgo client -h NAME: cwgo client - generate RPC or HTTP client Examples: # Generate RPR client code cwgo client --type RPC --idl {{path/to/IDL_file.thrift}} --service {{svc_name}} # Generate HTTP client code cwgo client --type HTTP --idl {{path/to/IDL_file.thrift}} --service {{svc_name}} USAGE: cwgo client [command options] [arguments...] OPTIONS: --service value Specify the service name. --type value Specify the generate type. (RPC or HTTP) (default: \"RPC\") --module value, --mod value Specify the Go module name to generate go.mod. --idl value Specify the IDL file path. (.thrift or .proto) --out_dir value, -o value Specify the output path. (default: biz/http) --registry value Specify the registry, default is None --proto_search_path value, -I value [ --proto_search_path value, -I value ] Add an IDL search path for includes. (Valid only if idl is protobuf) --pass value [ --pass value ] pass param to hz or kitex --help, -h show help (default: false) Specification --service specify service name --type specifies the generation type, supports parameters RPC, HTTP --module specifies the generated module name --idl specify IDL file path --out_dir specify the output path --registry specifies the service registration component, currently only useful for RPC type, supports parameters ZK, NACOS, ETCD, POLARIS --proto_search_path Add IDL search path, only valid for pb --pass value parameter passed to hz and kitex RPC Client Write IDL // hello. thrift namespace go hello.example struct HelloReq { 1: string Name } struct HelloResp { 1: string RespBody; } service HelloService { HelloResp HelloMethod(1: HelloReq request); HelloResp HelloMethod1(1: HelloReq request); HelloResp HelloMethod2(1: HelloReq request); } Order cwgo client --type RPC --idl hello.thrift --service hellotest Generate Code ├── hello. thrift # IDL file ├── kitex_gen # Generate code related to IDL content │ └── hello │ └── example │ ├── hello.go # The product of thriftgo, the go code containing the content defined by hello.thrift │ ├── helloservice │ │ ├── client.go # provides NewClient API │ │ ├── helloservice.go # Provides some definitions shared by client.go and server.go │ │ ├── invoker.go │ │ └── server.go # provides NewServer API │ ├── k-consts.go │ └── k-hello.go # code generated by kitex outside of thriftgo's product └── rpc └── hellotest ├── hellotest_client.go # client wrapper code ├── hellotest_default.go # client default implementation code └── hellotest_init.go # client initialization code HTTP Client Write IDL To write a simple IDL to generate HTTP Client, you need to add api.$method and api.base_domain to fill uri and host.\n// hello. thrift namespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");}structHelloResp{1:stringRespBody;}serviceHelloService{HelloRespHelloMethod1(1:HelloReqrequest)(api.get=\"/hello1\");HelloRespHelloMethod2(1:HelloReqrequest)(api.get=\"/hello2\");HelloRespHelloMethod3(1:HelloReqrequest)(api.get=\"/hello3\");}(api.base_domain=\"http://127.0.0.1:8888\";)Order Execute the following basic commands to generate the client\ncwgo client --type HTTP --idl hello.thrift --service hellotest Generate Code A default client implementation is provided in hello_service.go, and users can use it directly. If there is a need for custom configuration, you can use the options provided in hertz_client.go to customize the complex configuration of the Client.\n. ├── biz │ └── http │ └── hello_service │ ├── hello_service.go # client initialization and calling code │ └── hertz_client.go # client specific implementation code ├── hello. thrift # IDL file └── hertz_gen #IDL content-related generated code └── hello └── example └── hello.go client default implementation code\nvar defaultClient, _ = NewHelloServiceClient(\"http://127.0.0.1:8888\") func HelloMethod1(context context.Context, req *example.HelloReq, reqOpt ...config.RequestOption) (resp *example.HelloResp, rawResponse *protocol.Response, err error) { return defaultClient.HelloMethod1(context, req, reqOpt...) } func HelloMethod2(context context.Context, req *example.HelloReq, reqOpt ...config.RequestOption) (resp *example.HelloResp, rawResponse *protocol.Response, err error) { return defaultClient.HelloMethod2(context, req, reqOpt...) } func HelloMethod3(context context.Context, req *example.HelloReq, reqOpt ...config.RequestOption) (resp *example.HelloResp, rawResponse *protocol.Response, err error) { return defaultClient.HelloMethod3(context, req, reqOpt...) } ","categories":"","description":"","excerpt":"The cwgo tool supports generating the calling code of HTTP Client or …","ref":"/docs/cwgo/tutorials/client/","tags":"","title":"Client"},{"body":"cwgo 工具支持通过 IDL 生成 HTTP Client 或 RPC Client 的调用代码，方便用户开发。\n基础命令 使用 cwgo client -h 查看生成 client 代码的帮助命令。\n$ cwgo client -h NAME: cwgo client - generate RPC or HTTP client Examples: # Generate RPR client code cwgo client --type RPC --idl {{path/to/IDL_file.thrift}} --service {{svc_name}} # Generate HTTP client code cwgo client --type HTTP --idl {{path/to/IDL_file.thrift}} --service {{svc_name}} USAGE: cwgo client [command options] [arguments...] OPTIONS: --service value Specify the service name. --type value Specify the generate type. (RPC or HTTP) (default: \"RPC\") --module value, --mod value Specify the Go module name to generate go.mod. --idl value Specify the IDL file path. (.thrift or .proto) --out_dir value, -o value Specify the output path. (default: biz/http) --registry value Specify the registry, default is None --proto_search_path value, -I value [ --proto_search_path value, -I value ] Add an IDL search path for includes. (Valid only if idl is protobuf) --pass value [ --pass value ] pass param to hz or kitex --help, -h show help (default: false) 详细参数 --service 指定服务名称 --type 指定生成类型，支持参数 RPC、HTTP --module 指定生成 module 名称 --idl 指定 IDL 文件路径 --out_dir 指定输出路径 --registry 指定服务注册组件，目前仅对 RPC 类型有用, 支持参数 ZK、NACOS、ETCD、POLARIS --proto_search_path 添加 IDL 搜索路径，只对 pb 生效 --pass value 传递给 hz 和 kitex 的参数 RPC Client 编写 IDL // hello.thrift namespace go hello.example struct HelloReq { 1: string Name } struct HelloResp { 1: string RespBody; } service HelloService { HelloResp HelloMethod(1: HelloReq request); HelloResp HelloMethod1(1: HelloReq request); HelloResp HelloMethod2(1: HelloReq request); } 命令 cwgo client --type RPC --idl hello.thrift --service hellotest 生成代码 ├── hello.thrift # IDL 文件 ├── kitex_gen # IDL 内容相关的生成代码 │ └── hello │ └── example │ ├── hello.go # thriftgo 的产物，包含 hello.thrift 定义的内容的 go 代码 │ ├── helloservice │ │ ├── client.go # 提供了 NewClient API │ │ ├── helloservice.go # 提供了 client.go 和 server.go 共用的一些定义 │ │ ├── invoker.go │ │ └── server.go # 提供了 NewServer API │ ├── k-consts.go │ └── k-hello.go # kitex 在 thriftgo 的产物之外生成的代码 └── rpc └── hellotest ├── hellotest_client.go # client 包装代码 ├── hellotest_default.go # client 默认实现代码 └── hellotest_init.go # client 初始化代码 HTTP Client 编写 IDL 编写一个简单的 IDL 用于生成 HTTP Client，需要添加 api.$method 与 api.base_domain 用于填充 uri 与host。\n// hello.thrift namespacegohello.examplestructHelloReq{1:stringName (api.query=\"name\");}structHelloResp{1:stringRespBody;}serviceHelloService{HelloRespHelloMethod1(1:HelloReqrequest)(api.get=\"/hello1\");HelloRespHelloMethod2(1:HelloReqrequest)(api.get=\"/hello2\");HelloRespHelloMethod3(1:HelloReqrequest)(api.get=\"/hello3\");}(api.base_domain=\"http://127.0.0.1:8888\";)命令 执行如下基础命令生成客户端\ncwgo client --type HTTP --idl hello.thrift --service hellotest 生成代码 hello_service.go 中提供了一个默认 client 实现 ，用户可以直接使用它。如果有自定义配置需求，则可以使用 hertz_client.go 中提供的 options 用于自定义复杂配置的Client。\n. ├── biz │ └── http │ └── hello_service │ ├── hello_service.go # client 初始化以及调用代码 │ └── hertz_client.go # client 具体实现代码 ├── hello.thrift # IDL 文件 └── hertz_gen #IDL 内容相关的生成代码 └── hello └── example └── hello.go client 默认实现代码\nvar defaultClient, _ = NewHelloServiceClient(\"http://127.0.0.1:8888\") func HelloMethod1(context context.Context, req *example.HelloReq, reqOpt ...config.RequestOption) (resp *example.HelloResp, rawResponse *protocol.Response, err error) { return defaultClient.HelloMethod1(context, req, reqOpt...) } func HelloMethod2(context context.Context, req *example.HelloReq, reqOpt ...config.RequestOption) (resp *example.HelloResp, rawResponse *protocol.Response, err error) { return defaultClient.HelloMethod2(context, req, reqOpt...) } func HelloMethod3(context context.Context, req *example.HelloReq, reqOpt ...config.RequestOption) (resp *example.HelloResp, rawResponse *protocol.Response, err error) { return defaultClient.HelloMethod3(context, req, reqOpt...) } ","categories":"","description":"","excerpt":"cwgo 工具支持通过 IDL 生成 HTTP Client 或 RPC Client 的调用代码，方便用户开发。\n基础命令 使用 cwgo …","ref":"/zh/docs/cwgo/tutorials/client/","tags":"","title":"Client"},{"body":"1. How to configure the number of pollers ? NumLoops represents the number of epoll created by [Netpoll][Netpoll], which has been automatically adjusted according to the number of P (runtime.GOMAXPROCS(0)) by default, and users generally don’t need to care.\nBut if your service has heavy I/O, you may need the following configuration:\npackage main import ( \"runtime\" \"github.com/cloudwego/netpoll\" ) func init() { netpoll.SetNumLoops(runtime.GOMAXPROCS(0)) } 2. How to configure poller’s connection loadbalance ? When there are multiple pollers in Netpoll, the connections in the service process will be loadbalanced to each poller.\nThe following strategies are supported now:\n Random  The new connection will be assigned to a randomly picked poller.   RoundRobin  The new connection will be assigned to the poller in order.    Netpoll uses RoundRobin by default, and users can change it in the following ways:\npackage main import ( \"github.com/cloudwego/netpoll\" ) func init() { netpoll.SetLoadBalance(netpoll.Random) // or \tnetpoll.SetLoadBalance(netpoll.RoundRobin) } 3. How to configure gopool ? Netpoll uses gopool as the goroutine pool by default to optimize the stack growth problem that generally occurs in RPC services.\nIn the project gopool, it explains how to change its configuration, so won’t repeat it here.\nOf course, if your project does not have a stack growth problem, it is best to close gopool as follows:\npackage main import ( \"github.com/cloudwego/netpoll\" ) func init() { netpoll.DisableGopool() } 4. How to prepare a new connection ? There are different ways to prepare a new connection on the client and server.\n On the server side, OnPrepare is defined to prepare for the new connection, and it also supports returning a context, which can be reused in subsequent business processing. WithOnPrepare provides this registration. When the server accepts a new connection, it will automatically execute the registered OnPrepare function to complete the preparation work. The example is as follows:  package main import ( \"context\" \"github.com/cloudwego/netpoll\" ) func main() { // register OnPrepare \tvar onPrepare netpoll.OnPrepare = prepare evl, _ := netpoll.NewEventLoop(handler, netpoll.WithOnPrepare(onPrepare)) ... } func prepare(connection netpoll.Connection) (ctx context.Context) { ... prepare connection ... return } On the client side, the connection preparation needs to be completed by the user. Generally speaking, the connection created by Dialer can be controlled by the user, which is different from passively accepting the connection on the server side. Therefore, the user not relying on the trigger, just prepare a new connection like this:  package main import ( \"context\" \"github.com/cloudwego/netpoll\" ) func main() { conn, err := netpoll.DialConnection(network, address, timeout) if err != nil { panic(\"dial netpoll connection failed\") } ... prepare here directly ... prepare(conn) ... } func prepare(connection netpoll.Connection) (ctx context.Context) { ... prepare connection ... return } 5. How to configure connection timeout ? Netpoll now supports two timeout configurations:\n Read Timeout  In order to maintain the same operating style as net.Conn, Connection.Reader is also designed to block reading. So provide Read Timeout. Read Timeout has no default value(wait infinitely), it can be configured via Connection or EventLoop.Option, for example:    package main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection // 1. setting by Connection \tconn.SetReadTimeout(timeout) // or  // 2. setting with Option \tnetpoll.NewEventLoop(handler, netpoll.WithReadTimeout(timeout)) ... } Idle Timeout  Idle Timeout utilizes the TCP KeepAlive mechanism to kick out dead connections and reduce maintenance overhead. When using Netpoll, there is generally no need to create and close connections frequently, and idle connections have little effect. When the connection is inactive for a long time, in order to prevent dead connection caused by suspended animation, hang of the opposite end, abnormal disconnection, etc., the connection will be actively closed after the Idle Timeout. The default minimum value of Idle Timeout is 10min, which can be configured through Connection API or EventLoop.Option, for example:    package main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection // 1. setting by Connection \tconn.SetIdleTimeout(timeout) // or  // 2. setting with Option \tnetpoll.NewEventLoop(handler, netpoll.WithIdleTimeout(timeout)) ... } 6. How to configure connection read event callback ? OnRequest refers to the callback triggered by Netpoll when a read event occurs on the connection. On the Server side, when creating the EventLoop, you can register an OnRequest, which will be triggered when each connection data arrives and perform business processing. On the Client side, there is no OnRequest by default, and it can be set via API when needed. E.g:\npackage main import ( \"context\" \"github.com/cloudwego/netpoll\" ) func main() { var onRequest netpoll.OnRequest = handler // 1. on server side \tevl, _ := netpoll.NewEventLoop(onRequest, opts...) ... // 2. on client side \tconn, _ := netpoll.DialConnection(network, address, timeout) conn.SetOnRequest(handler) ... } func handler(ctx context.Context, connection netpoll.Connection) (err error) { ... handling ... return nil } 7. How to configure the connection close callback ? CloseCallback refers to the callback triggered by Netpoll when the connection is closed, which is used to perform additional processing after the connection is closed. Netpoll is able to perceive the connection status. When the connection is closed by peer or cleaned up by self, it will actively trigger CloseCallback instead of returning an error on the next Read or Write(the way of net.Conn). Connection provides API for adding CloseCallback, callbacks that have been added cannot be removed, and multiple callbacks are supported.\npackage main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection // add close callback \tvar cb netpoll.CloseCallback = callback conn.AddCloseCallback(cb) ... } func callback(connection netpoll.Connection) error { return nil } ","categories":"","description":"","excerpt":"1. How to configure the number of pollers ? NumLoops represents the …","ref":"/docs/netpoll/common-usage/","tags":"","title":"Common Usage"},{"body":"In the previous section, we wrote a server, now let’s write a client and call the server.\nFirst, create a file called src/bin/client.rs and type the following:\nuselazy_static::lazy_static;usestd::net::SocketAddr;lazy_static!{staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example\").address(addr).build()};}#[volo::main]asyncfn main(){tracing_subscriber::fmt::init();letreq=volo_gen::volo::example::GetItemRequest{id: 1024};letresp=CLIENT.get_item(req).await;matchresp{Ok(info)=\u003etracing::info!(\"{:?}\",info),Err(e)=\u003etracing::error!(\"{:?}\",e),}}Then add the required dependencies to the Cargo.toml file, which looks like this:\n[package] name = \"volo-example\" version = \"0.1.0\" edition = \"2021\" # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [dependencies] anyhow = \"1\" async-trait = \"0.1\" lazy_static = \"1\" tokio = { version = \"1\", features = [\"full\"] } tracing = \"0.1\" prost = \"0.11\" tracing-subscriber = \"0.3\" pilota = \"*\" volo = \"*\" # we recommend to use the latest framework version for new features and bug fixes volo-grpc = \"*\" # we recommend to use the latest framework version for new features and bug fixes volo-gen = { path = \"./volo-gen\" } [profile.release] opt-level = 3 debug = true debug-assertions = false overflow-checks = false lto = true panic = 'unwind' incremental = false codegen-units = 1 rpath = false [workspace] members = [\"volo-gen\"] resolver = \"2\" Then, create a new terminal and run the following command to start our server:\n$ cargo run --bin server Finally, we go back to the current directory and execute the following command, and we can see that the execution is successful:\n$ cargo run --bin client ","categories":"","description":"","excerpt":"In the previous section, we wrote a server, now let’s write a client …","ref":"/docs/volo/volo-grpc/getting-started/part_3/","tags":"","title":"Part 3. Create a Client "},{"body":"In the previous section, we wrote a server, now let’s write a client and call the server.\nFirst, create a file called src/bin/client.rs and type the following:\nuselazy_static::lazy_static;usestd::net::SocketAddr;lazy_static!{staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example\").address(addr).build()};}#[volo::main]asyncfn main(){tracing_subscriber::fmt::init();letreq=volo_gen::volo::example::GetItemRequest{id: 1024};letresp=CLIENT.get_item(req).await;matchresp{Ok(info)=\u003etracing::info!(\"{:?}\",info),Err(e)=\u003etracing::error!(\"{:?}\",e),}}Then add the required dependencies to the Cargo.toml file, which looks like this:\n[package] name = \"volo-example\" version = \"0.1.0\" edition = \"2021\" # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [dependencies] anyhow = \"1\" async-trait = \"0.1\" lazy_static = \"1\" tokio = { version = \"1\", features = [\"full\"] } tracing = \"0.1\" tracing-subscriber = \"0.3\" pilota = \"*\" volo = \"*\" # we recommend to use the latest framework version for new features and bug fixes volo-thrift = \"*\" # we recommend to use the latest framework version for new features and bug fixes volo-gen = { path = \"./volo-gen\" } [profile.release] opt-level = 3 debug = true debug-assertions = false overflow-checks = false lto = true panic = 'unwind' incremental = false codegen-units = 1 rpath = false [workspace] members = [\"volo-gen\"] resolver = \"2\" Then, create a new terminal and run the following command to start our server:\n$ cargo run --bin server Finally, we go back to the current directory and execute the following command, and we can see that the execution is successful:\n$ cargo run --bin client ","categories":"","description":"","excerpt":"In the previous section, we wrote a server, now let’s write a client …","ref":"/docs/volo/volo-thrift/getting-started/part_3/","tags":"","title":"Part 3. Create a Client"},{"body":"案例介绍   飞书管理后台是飞书套件专为企业管理员提供的信息管理平台，在单体应用架构下，它面临了一系列的挑战。 它通过引入 Kitex 泛化调用对飞书管理后台进行平台化改造，使之变为业务网关，提供一套统一的标准和通用服务，让有管控诉求的套件业务方能快速实现能力集成，并且提供一致的体验。最终实现了飞书管理后台作为企业统一数字化管理平台的愿景。\n本文将从三个方面为大家讲解 Kitex 泛化调用在飞书管理后台平台化改造过程中的落地实践：\n 架构和挑战，即飞书管理后台单体架构面临的各种挑战； 平台化构想，即飞书管理后台平台化构想和架构升级； 平台化实现，包括微前端技术架构、泛化调用实践和功能扩展。  架构和挑战 飞书是真正的一站式企业沟通与协作平台，整合视频会议、即时消息、日历、云文档、邮箱、工作台等功能于一体，立志打造高效的办公方式，加速企业成长。 飞书管理后台（以下简称 Admin）是飞书套件专为企业管理员提供的信息管理平台，企业管理员可通过后台管理企业设置、组织架构、工作台和会议室等功能。下图是飞书管理后台的界面。\n平台改造背景 飞书采用的是 all-in-one 的套件模式，Admin 作为整个套件统一的管理后台，承接了包括组织管理、云文档、视频会议、邮箱、开放平台等 10 多个业务线的管控需求。 一直以来的开发模式是各业务方直接在 Admin 的代码仓库提交代码或者由 Admin 团队负责 Web 层逻辑的开发。下图是目前飞书管理后台中包括的一些功能， 可以看到功能种类还是非常多的，之前的开发模式是业务方直接在 Admin 的代码仓库中提交代码，或者由业务方给 Admin 团队提供一些需求，由我们来负责 Web 层逻辑的开发。 从飞书初创开始，Admin 就是以单体应用的模式开发的，随着后续飞书整体的演进，我们的团队越来越多，不同业务线的团队也会有一些管控需求要接入 Admin 平台，因此他们就直接在代码仓库中提交代码。\nAdmin 架构 下图是 Admin 旧架构图。上面是 Admin 前端，它其实就是 Node 层的单体，中间是 Admin 后端，它基于我们内部单体 HTTP 的 Web 服务，会通过 RPC 调用到其他业务线的微服务。\n面临的问题 在这个架构下我们会面临一些问题，第一个问题是业务迭代慢，因为所有业务线都只能在 Admin 的代码仓库里进行开发和发版，因此这些业务线完全依赖 Admin 的研发资源和迭代流程， Admin 的研发资源被过多的耗在各业务的迭代中，无法快速支持自身的业务规划，如组织架构、安全、KA等因为我们是 To B 的产品，因此发版节奏不会很快。 如果各个业务线有一些比较紧急的需求，也只能跟 Admin 的节奏，这就会造成发版节奏不一致，研发资源不匹配，导致Admin会成为业务迭代的瓶颈。 第二个问题是研发效率低，因为各个业务线需要在 Admin 的代码仓库里进行修改，因此需要了解我们仓库的设计模式，我们在为各个业务线提供服务时，也需要了解各业务的上下文，双方都需要花费大量时间沟通。 联调、Oncall的链路也很长，双方的责任也划不清楚，导致整体的研发效率偏低。第三个问题是工程质量差，多个团队共同维护一个代码仓库，代码质量参差不齐，设计规范也各不相同，底层的代码的修改还会相互影响，造成线上问题。\n面临的挑战 此外，我们还会面临很多挑战。首先面临的是多环境互通与隔离的问题，我们需要解决不同环境的网络隔离、版本异构问题；其次是接入业务复杂性，Admin需要集成十几个业务线，接入诉求不统一。 接口协议包含 HTTP 协议和 Thrift 协议，还有各种自定义插件需求和权限校验需求；最后还有安全保障，Admin 作为飞书套件的管理配置中心，关系到整个企业的数据安全。 安全一直是 Admin 最重要的需求，为了保障Admin 的接口数据安全，需要提供鉴权中间件、管理员权限验证、参数校验、风控、频控等功能，提升业务方的安全能力。\n平台化构想 第二部分给大家介绍飞书平台化构想，即如何进行飞书管理后台平台化构想和架构升级。\n首先要明确的是目标，主要目标是通过提供一套统一的标准和通用服务，让有管控诉求的套件业务方能快速实现能力集成，并且能给客户带来一致的体验。 因为我们各个业务线的管控需求都是集成在 Admin，我们不希望每个业务线提供的 Web 页面展示、功能和 UI 等差别较大，希望他们是相对统一的，最终实现Admin作为企业统一数字化管理平台的愿景。 关于在技术上需要达到的效果，我们希望业务方不要继续在 Admin 代码仓库中进行代码开发，而是直接提供我们的后端接口和前端页面动态接入，Admin 无需代码改造和服务发布即可无缝上线，Admin 从单体应用进化为业务网关，是包含 UI 交互在内的独立产品模块的集成。\n我们并不是要做一个搭建系统。目前很多平台型产品都提供 Low Code / No Code 的工具方便开发者快速搭建所需要的功能。 但是目前通过我们对客户诉求的调研，没有相关的需求（但是不代表未来也没有，这块我们会持续保持关注）。 我们需要做的是制定相关的标准，比如 UI、交互、API 等，业务按照标准去实现。我们也不是要做一个 API Gateway 或者 Service Mesh。 API Gateway 的核心是Exposes your services as managed APIs，将内部的服务以更加可控可管理的方式暴露出去，可以认为是后端服务的一个代理。 Service Mesh 可以看成是 API Gateway 的去中心化实现方式，用来解决单点、隔离、耦合等问题。我们需要解决的不仅仅是服务路由、协议转换、安全管控等问题，而是包含 UI 交互在内的独立产品模块的集成。\n旧的框架 这是我们旧的架构。它的前端架构是前后端分离的 Node 单体项目。后端架构（Golang 实现）采用 Hertz 框架对前端暴露 HTTP 接口，Handler 层通过 Kitex 调用依赖的各个业务线的微服务。\n框架介绍 下面介绍一下 CloudWeGo 现有的两款框架。首先是 Hertz 框架，Hertz [həːts] 是一个 Golang 微服务 HTTP 框架，在设计之初参考了其他开源框架 Fasthttp、Gin、Echo 的优势，并结合字节跳动内部的需求，使其具有高易用性、高性能、高扩展性等特点，目前在字节跳动内部已广泛使用。如今越来越多的微服务选择使用 Golang，如果对微服务性能有要求，又希望框架能够充分满足内部的可定制化需求，Hertz 会是一个不错的选择。Kitex [kaɪt’eks] 字节跳动内部的 Golang 微服务 RPC 框架，具有高性能、强可扩展的特点，在字节内部已广泛使用。如果对微服务性能有要求，又希望定制扩展融入自己的治理体系，可以考虑选择 Kitex。\n新的框架 下面介绍一下我们的新架构，它主要包括：\n Gaia 控制面。我们增加了 Gaia 平台（基于 Hertz 框架的 Web 服务）来作为我们整个 Admin 的控制系统，负责整体的发布和管控需求，包括接口的生命周期管理、微应用生命周期管理、监控告警、业务线接入、多环境发布等。 前端架构。前端采用微前端架构，各个业务方通过构建微应用接入 Admin 基座，使用统一封装好的组件库实现前端页面。 后端架构。后端使用字节通用 BAM 规范，通过泛化调用的方式打通 Admin 和各接入业务方服务，并抽象公共组件以插件的方式进行功能扩展。  Admin 架构 下图就是新的 Admin 架构图。左上方是微前端，它包含前端里面各个业务线的微应用。微前端通过 HTTP 接口和 Admin 网关进行交互，Admin 网关把业务逻辑都剥离到下一层， 而自身只负责公共组件、登录鉴权、协议代理和通用配置等通用需求，同时它会通过泛化调用来调用下游的业务服务。业务服务包括组织管理、云文档、视频会议和邮箱等微服务。 右侧是 Gaia 控制面，包括一些管控功能，如接口生命周期管理、监控大盘、微应用管理、工单系统等等。另外如果我们有一些独立的自定义功能，会通过插件的方式集成。\nGaia 平台功能 Gaia 平台主要包括以下功能：\n 业务线管理。业务线是实现以业务为维度进行接入 Admin 而提出的概念。通过业务线来聚合业务为维度的所有资源，相关资源包括微应用、菜单、接口、监控等。图中就是业务线管理的菜单页面。  接口生命周期管理。包括接口创建、更新、编排、发布、上线、下线、删除等。同时维护接口 IDL 文件。 微应用生命周期管理。包括微应用的申请、接入、微应用版本创建、发布、下线等。 控制大盘。包括业务整体维度和单接口维度的 SLA 大盘，以及错误告警管理。 插件管理。包括默认插件和自定义插件的配置管理。  平台化实现 微前端技术架构 第三部分具体介绍飞书平台化实现，包括微前端技术架构、泛化调用实践和功能扩展。\n下图是微前端的技术架构。这里涉及到三个概念，第一个是基座，即指微前端入口模块，负责组装各个模块；第二个是微应用，指独立的业务模块；第三个是微应用市场，负责管理微应用的创建，管理，版本发布等。 通过微应用市场下发的配置进行微应用组合，将基础能力下放到各个业务方。例如，现有一个新的业务线需要接入，那么它需要开发自己的微应用，打包测试并发布到我们的微应用市场，我们的基座就会从微应用市场接收到这个微应用，最后进行发布之后，就可以从 Web 看到对应模块的页面。\n泛化调用方案调研 接下来说一下后端实现的细节，即如何通过泛化调用实现整体依赖的剥离？首先讲一下这个问题的背景，Admin 的前端和后端是通过 JSON实现序列化传递的， 如果把 Admin 变成一个平台化的网关，不再维护业务逻辑，只处理通用逻辑，泛化调用是我们最好的选择。因为通过泛化调用，Admin 的网关就不需要写各种业务代码， 直接通过 RPC 接口就可以把前端传过来的 JSON 序列化数据、请求参数再传递到微服务，然后通过微服务的返回值把 JSON 序列化数据返回前端，跟前端进行交互。\n我们通过调研现有框架，如网关与微服务之间使用 gRPC、Thrift 等协议进行通信，都是通过代码生成实现的协议解析和协议传输，不能动态更新，都需要生成代码，再重新发布。 而我们内部旧的 Kite 框架（Thrift 协议）不支持泛化调用，而新框架 Kitex 是字节跳动内部的 Golang 微服务 RPC 框架，具有高性能、强可扩展的特点。 在我们使用 Kitex 的泛化调用功能之前曾调研了一些泛化调用的方案，也基于 Kitex 实现了泛化调用的类似功能。但是我们认为飞书内部实现泛化调用不如推动 Kitex 的研发人员， 让他们把泛化调用变为一个通用的功能，这样不仅仅是我们团队，公司内部其余团队以及 Kitex 开源后其他外部团队都可以使用这个功能。目前 Kitex 已经支持基于 Thrift 协议的泛化调用。\n非泛化调用 那么非泛化调用的实现方式和泛化调用的实现方式有什么不同呢？这张图就是非泛化调用的实现方式，无论 gRPC、Thrift 还是 Kitex 都是基于 IDL 生成协议代码， 服务端和客户端都需要依赖 IDL 生成静态代码，接口的迭代意味着服务端和客户端都需要升级代码重新发布。在 Admin 场景下意味着其他业务方的业务迭代， 需要我们引入代码依赖并发布服务，这并不符合我们平台化的需求。\nKitex 泛化调用 在 Kitex 泛化调用中，服务端无需做任何改造。客户端只有一份通用的协议处理代码，基于已有的 IDL 信息来动态生成协议字节流，IDL 信息可以动态更新，以维护最新的接口协议，无需生成代码。 在 Admin场景下，网关作为客户端，动态维护业务方接口的 IDL，通过泛化调用来实现 HTTP 接口到 RPC 接口的转换，不再依赖业务服务客户端代码，实现了网关和业务在代码层面的解耦。\n相关地址：https://github.com/cloudwego/kitex/tree/develop/pkg/generic/thrift\nHTTP 协议映射 Admin 网关是基于 Hertz 对外暴露 HTTP 协议的接口，Hertz 路由支持运行时新增，通过自定义 Middleware 和 HandlerFunc 可以实现接口运行时的增删改，这样可以实现解析修改后的 IDL 来进行接口调用。 这段代码就是初始化客户端的 Client，其实就是泛化调用的 Client，可以看到它会读业务方的 IDL，假如业务方的 IDL 有接口更新，我们可以通过这个进行业务更新，动态实现接口的上下线。 然后再构造 HTTP 类型的泛化调用 Client，每个业务方都会构造一个 Client 实例，比如有十几个业务线，就会生成十几个业务线微服务的实例。\n下面是泛化调用的路由，它其实是 HandlerFunc 的实现，通过这个方式可以动态注册路由，注册之后将 Hertz Request 转化成泛化调用 Request， 再通过前一步生成的泛化调用 Client 实现泛化调用，最后得到 HTTPResponse，再将它写回 Hertz Response中，这就是简单的泛化调用路由的实现。通过这个可以做很多业务拓展，比如错误码处理等等。\n功能扩展 具体给大家讲一下功能扩展。功能扩展的第一类就是 Kitex 提供的自定义注解，Kitex 内置了 API 注解来实现路由解析、参数传递等功能。 这里面有三个接口，第一个是 HTTPMapping，实现了参数传递、返回值等等自定义注解；第二个是 Route，实现了 Kitex 路由解析的功能； 第三个是 ValueMapping，是指将参数进行映射，比如目前 JSON 不支持 Int64，但 Go 可以支持 Int64，在使用 JSON 序列化的时候就要把参数类型定义为 String， 因此从 JSON 到 Go 就有一个转换的过程，这就可以通过映射来实现。我们通过自定义注解方式实现了框架未提供的功能，例如文件上传和下载、自定义参数注入、参数校验、自定义鉴权等。\n功能扩展的第二类就是接口编排，已经实现的单接口泛化调用，不能完全满足我们一些复杂场景的使用需求，例如：简单组装两个接口的结果，比如同时调用接口 A 和 B，再将两个接口进行组装； 接口有顺序依赖，一个接口结果是其他接口的参数，比如先调用 A，A 的返回值作为参数去调用 B，再将 B 的返回值作为整体接口的返回值。 Kitex 和 Hertz 还不能支持接口编排的功能，所以我们通过自定义 DSL 引擎来对简单接口进行编排，以便实现一些复杂场景的接口调用需求。\n成果 最后给大家介绍一下我们的演进成果，主要有以下三点：\n 业务迭代加速。Admin 不再关注其他业务线的需求，更加专注于自身的迭代需求。各个业务方发布完全隔离，使得他们不再依赖 Admin，加快了 Admin 整体的业务功能迭代速度。 研发效率提升。丰富的前后端组件和简单的接入方式，业务方不需要再花费时间熟悉我们的代码仓库，使得业务方接入更加便捷，研发效率大大提升。 工程质量提高。  其他团队不再向 Admin 仓库提交代码，仓库代码风格趋向统一； 去除了大量的业务逻辑，聚焦网关通用逻辑，提高了单测覆盖率； Bug 率显著下降，服务 SLA 明显提升。    未来规划 我们目前制定了一些未来的发展规划，主要有以下四点：\n 开放更多的组件，让接入的业务方聚焦在业务逻辑本身，例如组织管理里面的选人组件，之前需要各个业务方自己内部实现，之后我们会提供一套公共组件，业务方可以直接使用，包括消息中心、任务管理、安全风控、短信邮件等； 完善服务治理和运维能力，包括灰度、降级、限流、精细化大盘等； 建设通用的静态页面托管解决方案，为开发者提供便捷、稳定、高扩展性的静态页面托管服务； 对接集成测试平台，闭环路由管理生命周期，保障接口稳定性和安全性。  ","categories":"","description":"","excerpt":"案例介绍   飞书管理后台是飞书套件专为企业管理员提供的信息管理平台，在单体应用架构下，它面临了一系列的挑战。 它通过引入 Kitex 泛化 …","ref":"/cooperation/feishu/","tags":"","title":"引入 CloudWeGo 后飞书管理后台平台化改造的演进史"},{"body":"By default, Hertz integrates with and uses Sonic for serializing ctx.JSON interface and deserialization requests as defined in the binding package. Sonic is an ultra-high performance golang json library, also see Sonic README for details.\nThe following are requirements to enable Sonic:\n Go 1.15/1.16/1.17/1.18 Linux / darwin OS / Windows Amd64 CPU with AVX instruction set  Sonic automatically fallback to golang’s encoding/json library when the above requirements have not been satisfied.\nCompatibility With encoding/json Currently, Hertz uses the default configuration for Sonic (i.e.sonic.ConfigDefault), which behaves different from JSON encoding/json. Specifically, by default, Sonic are configured to:\n disable html escape: Sonic will not escape HTML’s special characters disable key-sort by default: Sonic will not sort json in lexicographical order  To find more about the compatibility with encoding/json, you may want to see sonic#Compatibility. You may change Sonic’s behavior (e.g. behaving exactly the same way as encoding/json) by calling ResetJSONMarshaler for render.\nrender.ResetJSONMarshaler(sonic.ConfigStd.Marshal) Bringing Your Own JSON Marshal Library If Sonic does not meet your needs, you may provide your own implementation by calling ResetJSONMarshal for render and ResetJSONUnmarshaler for binding.\nimport ( \"encoding/json\" \"github.com/bytedance/go-tagexpr/v2/binding\" \"github.com/cloudwego/hertz/pkg/app/server/render\" ) func main() { // Render  render.ResetJSONMarshal(json.Marshal) // Binding  binding.ResetJSONUnmarshaler(json.Unmarshal) } Conditional Compilation Hertz supports conditional compilation to control the actual json library used, you can use -tags stdjson to choose to use the standard library.\ngo build -tags stdjson . Common FAQs Error when using Sonic on M1 Build constraints exclude all Go files in xxx Usually because the Go version or environment parameters do not meet Sonic requirements.\n  Go version: go1.15 or above, recommend go1.17 or above. For the currently supported versions of Sonic, please see Sonic#Requirement\n  Go environment parameters: set GOARCH=amd64. Because Sonic already supports the binary translation software Rosetta, with Rosetta, the programs compiled under the x86 environment can be run on the M1.\n  Unable to Debug If you want to debug, you can set GOARCH=arm64. Because the Rosetta will cause the binary of Sonic to fail to debug.\nNote that the performance of Sonic will be hurt, because Sonic will fallback to the standard library in this environment.\n","categories":"","description":"","excerpt":"By default, Hertz integrates with and uses Sonic for serializing …","ref":"/docs/hertz/reference/json/","tags":"","title":"JSON Marshal Library"},{"body":"Hertz 默认集成并使用 Sonic 用于序列化ctx.JSON接口，以及反序列化binding包中的请求。Sonic 是一款超高性能 golang json 库，详情参考 Sonic README 。\n开启 Sonic 需要满足以下条件：\n Go 1.15/1.16/1.17/1.18 Linux / darwin OS / Windows Amd64 CPU with AVX instruction set  当上述条件不能满足时，Sonic 会自动 fallback 到 golang 的 encoding/json 库。\n与 encoding/json 兼容性 当前 Hertz 使用 Sonic 的默认配置（即sonic.ConfigDefault），行为与标准库 encoding/json 有所差异，详见 sonic#Compatibility\n具体来说，默认情况下，Sonic：\n 禁用 html escape：Sonic 不会转义 HTML中的特殊字符 禁用 key-sort：Sonic 不会按照键对JSON排序  你可以通过调用 render 包中的ResetJSONMarshaler函数来修改Sonic的行为，比如保持和标准库兼容。\nrender.ResetJSONMarshaler(sonic.ConfigStd.Marshal) 自定义 JSON Marshall 库 如果 Sonic 不能够满足您的需求，你可以使用以下方式自定义 json marshal 库的实现:\nimport ( \"encoding/json\" \"github.com/bytedance/go-tagexpr/v2/binding\" \"github.com/cloudwego/hertz/pkg/app/server/render\" ) func main() { // Render render.ResetJSONMarshal(json.Marshal) // Binding  binding.ResetJSONUnmarshaler(json.Unmarshal) } 条件编译 Hertz 支持条件编译来控制实际使用的 json 库，你可以通过 -tags stdjson 来选择使用标准库。\ngo build -tags stdjson . 常见问题 Mac M1 上使用 Sonic 报错 Build constraints exclude all Go files in xxx 一般为是因为 Go 镜像版本或环境参数不符合 Sonic 要求。\n  Go 版本: go1.15 或以上，推荐 go1.17 以上版本。Sonic 目前支持的版本见 Sonic#Requirement\n  Go 环境参数：设置 GOARCH=amd64。 因为，Sonic 已经支持二进制翻译软件 Rosetta，借助 Rosetta，在 M1 上可运行 x86 环境下编译出来的程序。\n  无法 Debug 如果想调试，可设置 GOARCH=arm64。因为 Rosetta 技术会导致 Sonic 的编译产物无法调试。\n注意，设置为 arm64 后将损失 Sonic 的高性能，因为 Sonic 内部在此环境下，会 fallback 到性能较差的标准库。\n","categories":"","description":"","excerpt":"Hertz 默认集成并使用 Sonic 用于序列化ctx.JSON接口，以及反序列化binding包中的请求。Sonic …","ref":"/zh/docs/hertz/reference/json/","tags":"","title":"JSON Marshal 库"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/releases/netpoll/","tags":"","title":"Netpoll Release"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/blog/releases/netpoll/","tags":"","title":"Netpoll Release"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/tutorials/observability/","tags":"","title":"Observability"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/cwgo/tutorials/","tags":"","title":"Tutorials"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/tutorials/","tags":"","title":"Tutorials"},{"body":"Kitex complies with Semantic Versioning 2.0.0 release version.\n  Major Version: when Kitex provides incompatible API\n  Minor Version: when Kitex provides new features in a backward compatible manner\n  Patch Version: when Kitex makes backward compatible changes includes small features or makes bug fixes\n  ","categories":"","description":"Kitex Release conventions.","excerpt":"Kitex Release conventions.","ref":"/docs/kitex/reference/version/","tags":"","title":"Version Specification"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/volo/","tags":"","title":"Volo"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/volo/","tags":"","title":"Volo"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/volo/volo-grpc/","tags":"","title":"Volo-gRPC"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/volo/volo-grpc/","tags":"","title":"Volo-gRPC"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/tutorials/observability/","tags":"","title":"可观测性"},{"body":"1. 如何配置 poller 的数量 ？ NumLoops 表示 [Netpoll][Netpoll] 创建的 epoll 的数量，默认已经根据P的数量自动调整(runtime.GOMAXPROCS(0))，用户一般不需要关心。\n但是如果你的服务有大量的 I/O，你可能需要如下配置：\npackage main import ( \"runtime\" \"github.com/cloudwego/netpoll\" ) func init() { netpoll.SetNumLoops(runtime.GOMAXPROCS(0)) } 2. 如何配置 poller 的连接负载均衡 ？ 当 Netpoll 中有多个 poller 时，服务进程中的连接会负载均衡到每个 poller。\n现在支持以下策略：\n Random  新连接将分配给随机选择的轮询器。   RoundRobin  新连接将按顺序分配给轮询器。    Netpoll 默认使用 RoundRobin，用户可以通过以下方式更改：\npackage main import ( \"github.com/cloudwego/netpoll\" ) func init() { netpoll.SetLoadBalance(netpoll.Random) // or \tnetpoll.SetLoadBalance(netpoll.RoundRobin) } 3. 如何配置 gopool ？ Netpoll 默认使用 gopool 作为 goroutine 池来优化 栈扩张 问题（RPC 服务常见问题）。\ngopool 项目中已经详细解释了如何自定义配置，这里不再赘述。\n当然，如果你的项目没有 栈扩张 问题，建议最好关闭 gopool，关闭方式如下：\npackage main import ( \"github.com/cloudwego/netpoll\" ) func init() { netpoll.DisableGopool() } 4. 如何初始化新的连接 ？ Client 和 Server 端通过不同的方式初始化新连接。\n 在 Server 端，定义了 OnPrepare 来初始化新链接，同时支持返回一个 context，可以传递给后续的业务处理并复用。WithOnPrepare 提供方法注册。当 Server 接收新连接时，会自动执行注册的 OnPrepare 方法来完成准备工作。示例如下：  package main import ( \"context\" \"github.com/cloudwego/netpoll\" ) func main() { // register OnPrepare \tvar onPrepare netpoll.OnPrepare = prepare evl, _ := netpoll.NewEventLoop(handler, netpoll.WithOnPrepare(onPrepare)) ... } func prepare(connection netpoll.Connection) (ctx context.Context) { ... prepare connection ... return } 在 Client 端，连接初始化需要由用户自行完成。 一般来说，Dialer 创建的新连接是可以由用户自行控制的，这与 Server 端被动接收连接不同。因此，用户不需要依赖触发器，可以自行初始化，如下所示：  package main import ( \"context\" \"github.com/cloudwego/netpoll\" ) func main() { conn, err := netpoll.DialConnection(network, address, timeout) if err != nil { panic(\"dial netpoll connection failed\") } ... prepare here directly ... prepare(conn) ... } func prepare(connection netpoll.Connection) (ctx context.Context) { ... prepare connection ... return } 5. 如何配置连接超时 ？ Netpoll 现在支持两种类型的超时配置：\n 读超时（ReadTimeout）  为了保持与 net.Conn 相同的操作风格，Connection.Reader 也被设计为阻塞读取。 所以提供了读取超时（ReadTimeout）。 读超时（ReadTimeout）没有默认值（默认无限等待），可以通过 Connection 或 EventLoop.Option 进行配置，例如：    package main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection // 1. setting by Connection \tconn.SetReadTimeout(timeout) // or  // 2. setting with Option \tnetpoll.NewEventLoop(handler, netpoll.WithReadTimeout(timeout)) ... } 空闲超时（IdleTimeout）  空闲超时（IdleTimeout）利用 TCP KeepAlive 机制来踢出死连接并减少维护开销。使用 Netpoll 时，一般不需要频繁创建和关闭连接，所以通常来说，空闲连接影响不大。当连接长时间处于非活动状态时，为了防止出现假死、对端挂起、异常断开等造成的死连接，在空闲超时（IdleTimeout）后，netpoll 会主动关闭连接。 空闲超时（IdleTimeout）的默认配置为 10min，可以通过 Connection API 或 EventLoop.Option 进行配置，例如：    package main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection // 1. setting by Connection \tconn.SetIdleTimeout(timeout) // or  // 2. setting with Option \tnetpoll.NewEventLoop(handler, netpoll.WithIdleTimeout(timeout)) ... } 6. 如何配置连接的读事件回调 ？ OnRequest 是指连接上发生读事件时 Netpoll 触发的回调。在 Server 端，在创建 EventLoop 时，可以注册一个OnRequest，在每次连接数据到达时触发，进行业务处理。Client端默认没有 OnRequest，需要时可以通过 API 设置。例如：\npackage main import ( \"context\" \"github.com/cloudwego/netpoll\" ) func main() { var onRequest netpoll.OnRequest = handler // 1. on server side \tevl, _ := netpoll.NewEventLoop(onRequest, opts...) ... // 2. on client side \tconn, _ := netpoll.DialConnection(network, address, timeout) conn.SetOnRequest(handler) ... } func handler(ctx context.Context, connection netpoll.Connection) (err error) { ... handling ... return nil } 7. 如何配置连接的关闭回调 ？ CloseCallback 是指连接关闭时 Netpoll 触发的回调，用于在连接关闭后进行额外的处理。 Netpoll 能够感知连接状态。当连接被对端关闭或被自己清理时，会主动触发 CloseCallback，而不是由下一次调用 Read 或 Write 时返回错误（net.Conn 的方式）。 Connection 提供了添加 CloseCallback 的 API，已经添加的回调无法删除，支持多个回调。\npackage main import ( \"github.com/cloudwego/netpoll\" ) func main() { var conn netpoll.Connection // add close callback \tvar cb netpoll.CloseCallback = callback conn.AddCloseCallback(cb) ... } func callback(connection netpoll.Connection) error { return nil } ","categories":"","description":"","excerpt":"1. 如何配置 poller 的数量 ？ NumLoops 表示 [Netpoll][Netpoll] 创建的 epoll 的数量，默认已经 …","ref":"/zh/docs/netpoll/common-usage/","tags":"","title":"常见用法"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/tutorials/","tags":"","title":"开发指南"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/cwgo/tutorials/","tags":"","title":"指南"},{"body":"对于 RPC 框架来说，日志、监控和 trace 是很重要的组成部分，云原生环境下可观测性基本依赖这三件套。\nVolo 框架使用的是 tracing 库来记录 Volo 自己的日志，同时也鼓励用户使用 tracing 库来输出日志和 trace 信息，这样就可以直接复用 Rust 社区现有的相关生态了，比如 tracing-opentelemetry 等库。\n用户也可以通过编写自己的 Service 和 Layer 来给所有的请求加上日志信息或者监控打点信息，如：\npubstruct ClientLogLayer;impl\u003cS\u003eLayer\u003cS\u003eforClientLogLayer{type Service=LogService\u003cS\u003e;fn layer(self,inner: S)-\u003e Self::Service{LogService{inner,}}}#[derive(Clone)]pubstruct LogService\u003cS\u003e{inner: S,}impl\u003cCx,Req,S\u003eService\u003cCx,Req\u003eforLogService\u003cS\u003ewhereS: Service\u003cCx,Req\u003e+Send+'static+Sync,Cx: Context\u003cConfig=volo_thrift::context::Config\u003e+'static+Send,Req: Send +'static,{type Response=S::Response;type Error=S::Error;type Future\u003c'cx\u003e=implFuture\u003cOutput=Result\u003cSelf::Response,Self::Error\u003e\u003e+'cx;fn call\u003c'cx,'s\u003e(\u0026'sself,cx: \u0026'cxmutCx,req: Req)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx,{asyncmove{lettick=quanta::Instant::now();letret=self.inner.call(cx,req).await;letelapsed=quanta::Instant::now().duration_since(tick);tracing::info!(rpc_type=\"rpcCall\",cost=elapsed.as_micros()asi64,);ret}}}监控打点信息也是类似。\n","categories":"","description":"","excerpt":"对于 RPC 框架来说，日志、监控和 trace 是很重要的组成部分，云原生环境下可观测性基本依赖这三件套。\nVolo …","ref":"/zh/docs/volo/guide/observability/","tags":"","title":"自定义日志/监控打点/trace"},{"body":"Kitex 遵从语义化版本 2.0.0 发布版本。\n  主版本号：Kitex 提供的 API 出现不兼容的情况时，升级该版本号\n  次版本号：Kitex 提供新的功能特性同时保持向下兼容时，升级该版本号\n  修订号：Kitex 的代码提供小的特性或向下兼容的优化和问题修复时，升级该版本号\n  ","categories":"","description":"Kitex 版本发布约定说明。","excerpt":"Kitex 版本发布约定说明。","ref":"/zh/docs/kitex/reference/version/","tags":"","title":"版本说明"},{"body":"框架自身不带任何监控打点，只是提供了 Tracer 接口，用户可以根据需求实现该接口，并通过 WithTracer Option 来注入。\n// Tracer is executed at the start and finish of an HTTP. type Tracer interface { Start(ctx context.Context, c *app.RequestContext) context.Context Finish(ctx context.Context, c *app.RequestContext) } hertz-contrib 中提供了默认的 prometheus 的监控扩展，能够实现:\n 请求量监控 时延监控  默认的 tag 有： HTTP Method，statusCode。请求相关的信息存在 RequestContext，在打点上报时可以获取到该变量，用户可以根据自己的需要自行扩展打点功能。 使用方式：\nServer\nimport ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/monitor-prometheus\" ) func main() { ··· h := server.Default(server.WithTracer(prometheus.NewServerTracer(\":9091\", \"/hertz\"))) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, utils.H{\"ping\": \"pong\"}) }) h.Spin() ··· } 目前 Client 暂没有暴露 Tracer 接口，但是提供了中间件能力，可以通过中间件实现监控能力。\n仓库 https://github.com/hertz-contrib/monitor-prometheus\n","categories":"","description":"","excerpt":"框架自身不带任何监控打点，只是提供了 Tracer 接口，用户可以根据需求实现该接口，并通过 WithTracer Option 来注入。 …","ref":"/zh/docs/hertz/tutorials/observability/monitoring/","tags":"","title":"监控"},{"body":"上一节中，我们编写完成了 server 端，现在让我们来编写我们的 client 端并调用我们的 server 端。\n首先，创建一个文件 src/bin/client.rs，输入以下内容：\nuselazy_static::lazy_static;usestd::net::SocketAddr;lazy_static!{staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example\").address(addr).build()};}#[volo::main]asyncfn main(){tracing_subscriber::fmt::init();letreq=volo_gen::volo::example::GetItemRequest{id: 1024};letresp=CLIENT.get_item(req).await;matchresp{Ok(info)=\u003etracing::info!(\"{:?}\",info),Err(e)=\u003etracing::error!(\"{:?}\",e),}}然后，在 Cargo.toml 文件中加入所需的依赖，加入后的文件如下：\n[package] name = \"volo-example\" version = \"0.1.0\" edition = \"2021\" # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [dependencies] anyhow = \"1\" async-trait = \"0.1\" lazy_static = \"1\" tokio = { version = \"1\", features = [\"full\"] } tracing = \"0.1\" prost = \"0.11\" tracing-subscriber = \"0.3\" pilota = \"*\" volo = \"*\" # we recommend to use the latest framework version for new features and bug fixes volo-grpc = \"*\" # we recommend to use the latest framework version for new features and bug fixes volo-gen = { path = \"./volo-gen\" } [profile.release] opt-level = 3 debug = true debug-assertions = false overflow-checks = false lto = true panic = 'unwind' incremental = false codegen-units = 1 rpath = false [workspace] members = [\"volo-gen\"] resolver = \"2\" 接着，新建一个 terminal，执行以下命令，把我们的 server 端跑起来：\n$ cargo run --bin server 最后，我们再回到当前目录，执行以下命令，即可看到执行成功：\n$ cargo run --bin client 大功告成！\n","categories":"","description":"","excerpt":"上一节中，我们编写完成了 server 端，现在让我们来编写我们的 client 端并调用我们的 server 端。\n首先， …","ref":"/zh/docs/volo/volo-grpc/getting-started/part_3/","tags":"","title":"Part 3. 编写 Client 端"},{"body":"上一节中，我们编写完成了 server 端，现在让我们来编写我们的 client 端并调用我们的 server 端。\n首先，创建一个文件 src/bin/client.rs，输入以下内容：\nuselazy_static::lazy_static;usestd::net::SocketAddr;lazy_static!{staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example\").address(addr).build()};}#[volo::main]asyncfn main(){tracing_subscriber::fmt::init();letreq=volo_gen::volo::example::GetItemRequest{id: 1024};letresp=CLIENT.get_item(req).await;matchresp{Ok(info)=\u003etracing::info!(\"{:?}\",info),Err(e)=\u003etracing::error!(\"{:?}\",e),}}然后，在 Cargo.toml 文件中加入所需的依赖，加入后的文件如下：\n[package] name = \"volo-example\" version = \"0.1.0\" edition = \"2021\" # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [dependencies] anyhow = \"1\" async-trait = \"0.1\" lazy_static = \"1\" tokio = { version = \"1\", features = [\"full\"] } tracing = \"0.1\" tracing-subscriber = \"0.3\" pilota = \"*\" volo = \"*\" # we recommend to use the latest framework version for new features and bug fixes volo-thrift = \"*\" # we recommend to use the latest framework version for new features and bug fixes volo-gen = { path = \"./volo-gen\" } [profile.release] opt-level = 3 debug = true debug-assertions = false overflow-checks = false lto = true panic = 'unwind' incremental = false codegen-units = 1 rpath = false [workspace] members = [\"volo-gen\"] resolver = \"2\" 接着，新建一个 terminal，执行以下命令，把我们的 server 端跑起来：\n$ cargo run --bin server 最后，我们再回到当前目录，执行以下命令，即可看到执行成功：\n$ cargo run --bin client 大功告成！\n","categories":"","description":"","excerpt":"上一节中，我们编写完成了 server 端，现在让我们来编写我们的 client 端并调用我们的 server 端。\n首先， …","ref":"/zh/docs/volo/volo-thrift/getting-started/part_3/","tags":"","title":"Part 3. 编写 Client 端"},{"body":"案例介绍   飞书管理后台是飞书套件专为企业管理员提供的信息管理平台，在单体应用架构下，它面临了一系列的挑战。 它通过引入 Kitex 泛化调用对飞书管理后台进行平台化改造，使之变为业务网关，提供一套统一的标准和通用服务，让有管控诉求的套件业务方能快速实现能力集成，并且提供一致的体验。最终实现了飞书管理后台作为企业统一数字化管理平台的愿景。\n本文将从三个方面为大家讲解 Kitex 泛化调用在飞书管理后台平台化改造过程中的落地实践：\n 架构和挑战，即飞书管理后台单体架构面临的各种挑战； 平台化构想，即飞书管理后台平台化构想和架构升级； 平台化实现，包括微前端技术架构、泛化调用实践和功能扩展。  架构和挑战 飞书是真正的一站式企业沟通与协作平台，整合视频会议、即时消息、日历、云文档、邮箱、工作台等功能于一体，立志打造高效的办公方式，加速企业成长。 飞书管理后台（以下简称 Admin）是飞书套件专为企业管理员提供的信息管理平台，企业管理员可通过后台管理企业设置、组织架构、工作台和会议室等功能。下图是飞书管理后台的界面。\n平台改造背景 飞书采用的是 all-in-one 的套件模式，Admin 作为整个套件统一的管理后台，承接了包括组织管理、云文档、视频会议、邮箱、开放平台等 10 多个业务线的管控需求。 一直以来的开发模式是各业务方直接在 Admin 的代码仓库提交代码或者由 Admin 团队负责 Web 层逻辑的开发。下图是目前飞书管理后台中包括的一些功能， 可以看到功能种类还是非常多的，之前的开发模式是业务方直接在 Admin 的代码仓库中提交代码，或者由业务方给 Admin 团队提供一些需求，由我们来负责 Web 层逻辑的开发。 从飞书初创开始，Admin 就是以单体应用的模式开发的，随着后续飞书整体的演进，我们的团队越来越多，不同业务线的团队也会有一些管控需求要接入 Admin 平台，因此他们就直接在代码仓库中提交代码。\nAdmin 架构 下图是 Admin 旧架构图。上面是 Admin 前端，它其实就是 Node 层的单体，中间是 Admin 后端，它基于我们内部单体 HTTP 的 Web 服务，会通过 RPC 调用到其他业务线的微服务。\n面临的问题 在这个架构下我们会面临一些问题，第一个问题是业务迭代慢，因为所有业务线都只能在 Admin 的代码仓库里进行开发和发版，因此这些业务线完全依赖 Admin 的研发资源和迭代流程， Admin 的研发资源被过多的耗在各业务的迭代中，无法快速支持自身的业务规划，如组织架构、安全、KA等因为我们是 To B 的产品，因此发版节奏不会很快。 如果各个业务线有一些比较紧急的需求，也只能跟 Admin 的节奏，这就会造成发版节奏不一致，研发资源不匹配，导致Admin会成为业务迭代的瓶颈。 第二个问题是研发效率低，因为各个业务线需要在 Admin 的代码仓库里进行修改，因此需要了解我们仓库的设计模式，我们在为各个业务线提供服务时，也需要了解各业务的上下文，双方都需要花费大量时间沟通。 联调、Oncall的链路也很长，双方的责任也划不清楚，导致整体的研发效率偏低。第三个问题是工程质量差，多个团队共同维护一个代码仓库，代码质量参差不齐，设计规范也各不相同，底层的代码的修改还会相互影响，造成线上问题。\n面临的挑战 此外，我们还会面临很多挑战。首先面临的是多环境互通与隔离的问题，我们需要解决不同环境的网络隔离、版本异构问题；其次是接入业务复杂性，Admin需要集成十几个业务线，接入诉求不统一。 接口协议包含 HTTP 协议和 Thrift 协议，还有各种自定义插件需求和权限校验需求；最后还有安全保障，Admin 作为飞书套件的管理配置中心，关系到整个企业的数据安全。 安全一直是 Admin 最重要的需求，为了保障Admin 的接口数据安全，需要提供鉴权中间件、管理员权限验证、参数校验、风控、频控等功能，提升业务方的安全能力。\n平台化构想 第二部分给大家介绍飞书平台化构想，即如何进行飞书管理后台平台化构想和架构升级。\n首先要明确的是目标，主要目标是通过提供一套统一的标准和通用服务，让有管控诉求的套件业务方能快速实现能力集成，并且能给客户带来一致的体验。 因为我们各个业务线的管控需求都是集成在 Admin，我们不希望每个业务线提供的 Web 页面展示、功能和 UI 等差别较大，希望他们是相对统一的，最终实现Admin作为企业统一数字化管理平台的愿景。 关于在技术上需要达到的效果，我们希望业务方不要继续在 Admin 代码仓库中进行代码开发，而是直接提供我们的后端接口和前端页面动态接入，Admin 无需代码改造和服务发布即可无缝上线，Admin 从单体应用进化为业务网关，是包含 UI 交互在内的独立产品模块的集成。\n我们并不是要做一个搭建系统。目前很多平台型产品都提供 Low Code / No Code 的工具方便开发者快速搭建所需要的功能。 但是目前通过我们对客户诉求的调研，没有相关的需求（但是不代表未来也没有，这块我们会持续保持关注）。 我们需要做的是制定相关的标准，比如 UI、交互、API 等，业务按照标准去实现。我们也不是要做一个 API Gateway 或者 Service Mesh。 API Gateway 的核心是Exposes your services as managed APIs，将内部的服务以更加可控可管理的方式暴露出去，可以认为是后端服务的一个代理。 Service Mesh 可以看成是 API Gateway 的去中心化实现方式，用来解决单点、隔离、耦合等问题。我们需要解决的不仅仅是服务路由、协议转换、安全管控等问题，而是包含 UI 交互在内的独立产品模块的集成。\n旧的框架 这是我们旧的架构。它的前端架构是前后端分离的 Node 单体项目。后端架构（Golang 实现）采用 Hertz 框架对前端暴露 HTTP 接口，Handler 层通过 Kitex 调用依赖的各个业务线的微服务。\n框架介绍 下面介绍一下 CloudWeGo 现有的两款框架。首先是 Hertz 框架，Hertz [həːts] 是一个 Golang 微服务 HTTP 框架，在设计之初参考了其他开源框架 Fasthttp、Gin、Echo 的优势，并结合字节跳动内部的需求，使其具有高易用性、高性能、高扩展性等特点，目前在字节跳动内部已广泛使用。如今越来越多的微服务选择使用 Golang，如果对微服务性能有要求，又希望框架能够充分满足内部的可定制化需求，Hertz 会是一个不错的选择。Kitex [kaɪt’eks] 字节跳动内部的 Golang 微服务 RPC 框架，具有高性能、强可扩展的特点，在字节内部已广泛使用。如果对微服务性能有要求，又希望定制扩展融入自己的治理体系，可以考虑选择 Kitex。\n新的框架 下面介绍一下我们的新架构，它主要包括：\n Gaia 控制面。我们增加了 Gaia 平台（基于 Hertz 框架的 Web 服务）来作为我们整个 Admin 的控制系统，负责整体的发布和管控需求，包括接口的生命周期管理、微应用生命周期管理、监控告警、业务线接入、多环境发布等。 前端架构。前端采用微前端架构，各个业务方通过构建微应用接入 Admin 基座，使用统一封装好的组件库实现前端页面。 后端架构。后端使用字节通用 BAM 规范，通过泛化调用的方式打通 Admin 和各接入业务方服务，并抽象公共组件以插件的方式进行功能扩展。  Admin 架构 下图就是新的 Admin 架构图。左上方是微前端，它包含前端里面各个业务线的微应用。微前端通过 HTTP 接口和 Admin 网关进行交互，Admin 网关把业务逻辑都剥离到下一层， 而自身只负责公共组件、登录鉴权、协议代理和通用配置等通用需求，同时它会通过泛化调用来调用下游的业务服务。业务服务包括组织管理、云文档、视频会议和邮箱等微服务。 右侧是 Gaia 控制面，包括一些管控功能，如接口生命周期管理、监控大盘、微应用管理、工单系统等等。另外如果我们有一些独立的自定义功能，会通过插件的方式集成。\nGaia 平台功能 Gaia 平台主要包括以下功能：\n 业务线管理。业务线是实现以业务为维度进行接入 Admin 而提出的概念。通过业务线来聚合业务为维度的所有资源，相关资源包括微应用、菜单、接口、监控等。图中就是业务线管理的菜单页面。  接口生命周期管理。包括接口创建、更新、编排、发布、上线、下线、删除等。同时维护接口 IDL 文件。 微应用生命周期管理。包括微应用的申请、接入、微应用版本创建、发布、下线等。 控制大盘。包括业务整体维度和单接口维度的 SLA 大盘，以及错误告警管理。 插件管理。包括默认插件和自定义插件的配置管理。  平台化实现 微前端技术架构 第三部分具体介绍飞书平台化实现，包括微前端技术架构、泛化调用实践和功能扩展。\n下图是微前端的技术架构。这里涉及到三个概念，第一个是基座，即指微前端入口模块，负责组装各个模块；第二个是微应用，指独立的业务模块；第三个是微应用市场，负责管理微应用的创建，管理，版本发布等。 通过微应用市场下发的配置进行微应用组合，将基础能力下放到各个业务方。例如，现有一个新的业务线需要接入，那么它需要开发自己的微应用，打包测试并发布到我们的微应用市场，我们的基座就会从微应用市场接收到这个微应用，最后进行发布之后，就可以从 Web 看到对应模块的页面。\n泛化调用方案调研 接下来说一下后端实现的细节，即如何通过泛化调用实现整体依赖的剥离？首先讲一下这个问题的背景，Admin 的前端和后端是通过 JSON实现序列化传递的， 如果把 Admin 变成一个平台化的网关，不再维护业务逻辑，只处理通用逻辑，泛化调用是我们最好的选择。因为通过泛化调用，Admin 的网关就不需要写各种业务代码， 直接通过 RPC 接口就可以把前端传过来的 JSON 序列化数据、请求参数再传递到微服务，然后通过微服务的返回值把 JSON 序列化数据返回前端，跟前端进行交互。\n我们通过调研现有框架，如网关与微服务之间使用 gRPC、Thrift 等协议进行通信，都是通过代码生成实现的协议解析和协议传输，不能动态更新，都需要生成代码，再重新发布。 而我们内部旧的 Kite 框架（Thrift 协议）不支持泛化调用，而新框架 Kitex 是字节跳动内部的 Golang 微服务 RPC 框架，具有高性能、强可扩展的特点。 在我们使用 Kitex 的泛化调用功能之前曾调研了一些泛化调用的方案，也基于 Kitex 实现了泛化调用的类似功能。但是我们认为飞书内部实现泛化调用不如推动 Kitex 的研发人员， 让他们把泛化调用变为一个通用的功能，这样不仅仅是我们团队，公司内部其余团队以及 Kitex 开源后其他外部团队都可以使用这个功能。目前 Kitex 已经支持基于 Thrift 协议的泛化调用。\n非泛化调用 那么非泛化调用的实现方式和泛化调用的实现方式有什么不同呢？这张图就是非泛化调用的实现方式，无论 gRPC、Thrift 还是 Kitex 都是基于 IDL 生成协议代码， 服务端和客户端都需要依赖 IDL 生成静态代码，接口的迭代意味着服务端和客户端都需要升级代码重新发布。在 Admin 场景下意味着其他业务方的业务迭代， 需要我们引入代码依赖并发布服务，这并不符合我们平台化的需求。\nKitex 泛化调用 在 Kitex 泛化调用中，服务端无需做任何改造。客户端只有一份通用的协议处理代码，基于已有的 IDL 信息来动态生成协议字节流，IDL 信息可以动态更新，以维护最新的接口协议，无需生成代码。 在 Admin场景下，网关作为客户端，动态维护业务方接口的 IDL，通过泛化调用来实现 HTTP 接口到 RPC 接口的转换，不再依赖业务服务客户端代码，实现了网关和业务在代码层面的解耦。\n相关地址：https://github.com/cloudwego/kitex/tree/develop/pkg/generic/thrift\nHTTP 协议映射 Admin 网关是基于 Hertz 对外暴露 HTTP 协议的接口，Hertz 路由支持运行时新增，通过自定义 Middleware 和 HandlerFunc 可以实现接口运行时的增删改，这样可以实现解析修改后的 IDL 来进行接口调用。 这段代码就是初始化客户端的 Client，其实就是泛化调用的 Client，可以看到它会读业务方的 IDL，假如业务方的 IDL 有接口更新，我们可以通过这个进行业务更新，动态实现接口的上下线。 然后再构造 HTTP 类型的泛化调用 Client，每个业务方都会构造一个 Client 实例，比如有十几个业务线，就会生成十几个业务线微服务的实例。\n下面是泛化调用的路由，它其实是 HandlerFunc 的实现，通过这个方式可以动态注册路由，注册之后将 Hertz Request 转化成泛化调用 Request， 再通过前一步生成的泛化调用 Client 实现泛化调用，最后得到 HTTPResponse，再将它写回 Hertz Response中，这就是简单的泛化调用路由的实现。通过这个可以做很多业务拓展，比如错误码处理等等。\n功能扩展 具体给大家讲一下功能扩展。功能扩展的第一类就是 Kitex 提供的自定义注解，Kitex 内置了 API 注解来实现路由解析、参数传递等功能。 这里面有三个接口，第一个是 HTTPMapping，实现了参数传递、返回值等等自定义注解；第二个是 Route，实现了 Kitex 路由解析的功能； 第三个是 ValueMapping，是指将参数进行映射，比如目前 JSON 不支持 Int64，但 Go 可以支持 Int64，在使用 JSON 序列化的时候就要把参数类型定义为 String， 因此从 JSON 到 Go 就有一个转换的过程，这就可以通过映射来实现。我们通过自定义注解方式实现了框架未提供的功能，例如文件上传和下载、自定义参数注入、参数校验、自定义鉴权等。\n功能扩展的第二类就是接口编排，已经实现的单接口泛化调用，不能完全满足我们一些复杂场景的使用需求，例如：简单组装两个接口的结果，比如同时调用接口 A 和 B，再将两个接口进行组装； 接口有顺序依赖，一个接口结果是其他接口的参数，比如先调用 A，A 的返回值作为参数去调用 B，再将 B 的返回值作为整体接口的返回值。 Kitex 和 Hertz 还不能支持接口编排的功能，所以我们通过自定义 DSL 引擎来对简单接口进行编排，以便实现一些复杂场景的接口调用需求。\n成果 最后给大家介绍一下我们的演进成果，主要有以下三点：\n 业务迭代加速。Admin 不再关注其他业务线的需求，更加专注于自身的迭代需求。各个业务方发布完全隔离，使得他们不再依赖 Admin，加快了 Admin 整体的业务功能迭代速度。 研发效率提升。丰富的前后端组件和简单的接入方式，业务方不需要再花费时间熟悉我们的代码仓库，使得业务方接入更加便捷，研发效率大大提升。 工程质量提高。  其他团队不再向 Admin 仓库提交代码，仓库代码风格趋向统一； 去除了大量的业务逻辑，聚焦网关通用逻辑，提高了单测覆盖率； Bug 率显著下降，服务 SLA 明显提升。    未来规划 我们目前制定了一些未来的发展规划，主要有以下四点：\n 开放更多的组件，让接入的业务方聚焦在业务逻辑本身，例如组织管理里面的选人组件，之前需要各个业务方自己内部实现，之后我们会提供一套公共组件，业务方可以直接使用，包括消息中心、任务管理、安全风控、短信邮件等； 完善服务治理和运维能力，包括灰度、降级、限流、精细化大盘等； 建设通用的静态页面托管解决方案，为开发者提供便捷、稳定、高扩展性的静态页面托管服务； 对接集成测试平台，闭环路由管理生命周期，保障接口稳定性和安全性。  ","categories":"","description":"","excerpt":"案例介绍   飞书管理后台是飞书套件专为企业管理员提供的信息管理平台，在单体应用架构下，它面临了一系列的挑战。 它通过引入 Kitex 泛化 …","ref":"/zh/cooperation/feishu/","tags":"","title":"引入 CloudWeGo 后飞书管理后台平台化改造的演进史"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/tutorials/framework-exten/advanced-exten/","tags":"","title":"高级扩展"},{"body":"Hertz provides response writer extension, if users need to hijack the writer of the response, they can implement the corresponding interfaces according to their needs.\nInterface Definition interface is defined in pkg/network/writer.\ntype ExtWriter interface { io.Writer Flush() error // Finalize will be called by framework before the writer is released. \t// Implementations must guarantee that Finalize is safe for multiple calls. \tFinalize() error } Hijack Your Own Response Writer Hertz provides Response.HijackWriter in app.RequestContext to allow users to hijack their own response writer, which provides another way for response writing process.\nExample:\nh.GET(\"/hijack\", func(c context.Context, ctx *app.RequestContext) { // Hijack the writer of response \tctx.Response.HijackWriter(yourResponseWriter) } Supported Response Writer Extension Hertz provides NewChunkedBodyWriter to create a response writer which allow users to flush chunk immediately during the handler process, it is defined under pkg/protocol/http1/resp/writer, and you can implement your own response writer.\nChunkedBodyWriter Example:\nh.GET(\"/flush/chunk\", func(c context.Context, ctx *app.RequestContext) { // Hijack the writer of response \tctx.Response.HijackWriter(resp.NewChunkedBodyWriter(\u0026ctx.Response, ctx.GetWriter())) for i := 0; i \u003c 10; i++ { ctx.Write([]byte(fmt.Sprintf(\"chunk %d: %s\", i, strings.Repeat(\"hi~\", i)))) // nolint: errcheck \tctx.Flush() // nolint: errcheck \ttime.Sleep(200 * time.Millisecond) } }) ","categories":"","description":"","excerpt":"Hertz provides response writer extension, if users need to hijack the …","ref":"/docs/hertz/tutorials/framework-exten/response_writer/","tags":"","title":"Response Writer Extension"},{"body":"Hertz 提供了 response 的 writer 扩展， 用户可以根据自己的需要实现相应的接口去劫持 response 的 writer。\n接口定义 接口定义在 pkg/network/writer.\ntype ExtWriter interface { io.Writer Flush() error // Finalize will be called by framework before the writer is released. \t// Implementations must guarantee that Finalize is safe for multiple calls. \tFinalize() error } 劫持 Response 的 Writer Hertz 在 app.RequestContext 中提供了 Response.HijackWriter 方法让用户劫持 response 的 writer.\n用法示例：\nh.GET(\"/hijack\", func(c context.Context, ctx *app.RequestContext) { // Hijack the writer of response \tctx.Response.HijackWriter(yourResponseWriter) } 已支持 Response 的 Writer 扩展 Hertz 在 pkg/protocol/http1/resp/writer 下提供了 NewChunkedBodyWriter 方法来创建一个 response 的 writer，它允许用户在 handler 中立即刷新分块，用户也可以实现自己的 response 的 writer。\nChunkedBodyWriter 用法示例：\nh.GET(\"/flush/chunk\", func(c context.Context, ctx *app.RequestContext) { // Hijack the writer of response \tctx.Response.HijackWriter(resp.NewChunkedBodyWriter(\u0026ctx.Response, ctx.GetWriter())) for i := 0; i \u003c 10; i++ { ctx.Write([]byte(fmt.Sprintf(\"chunk %d: %s\", i, strings.Repeat(\"hi~\", i)))) // nolint: errcheck \tctx.Flush() // nolint: errcheck \ttime.Sleep(200 * time.Millisecond) } }) ","categories":"","description":"","excerpt":"Hertz 提供了 response 的 writer 扩展， 用户可以根据自己的需要实现相应的接口去劫持 response …","ref":"/zh/docs/hertz/tutorials/framework-exten/response_writer/","tags":"","title":"Response 的 Writer 扩展"},{"body":"Create a project based on protobuf IDL new: Create a new project   Create the protobuf IDL file in the current directory\nNote: In order to support api annotations in protobuf, please import the following file in the proto file where the annotation is used\n  // idl/api.proto; Annotation extension syntax = \"proto2\";package api;import \"google/protobuf/descriptor.proto\";option go_package = \"/api\";extend google.protobuf.FieldOptions { optional string raw_body = 50101; optional string query = 50102; optional string header = 50103; optional string cookie = 50104; optional string body = 50105; optional string path = 50106; optional string vd = 50107; optional string form = 50108; optional string go_tag = 51001; optional string js_conv = 50109;}extend google.protobuf.MethodOptions { optional string get = 50201; optional string post = 50202; optional string put = 50203; optional string delete = 50204; optional string patch = 50205; optional string options = 50206; optional string head = 50207; optional string any = 50208; optional string gen_path = 50301; optional string api_version = 50302; optional string tag = 50303; optional string name = 50304; optional string api_level = 50305; optional string serializer = 50306; optional string param = 50307; optional string baseurl = 50308;}extend google.protobuf.EnumValueOptions { optional int32 http_code = 50401;}Main IDL definition\n// idl/hello/hello.proto syntax = \"proto3\";package hello;option go_package = \"hertz/hello\";import \"api.proto\";message HelloReq { string Name = 1[(api.query)=\"name\"];}message HelloResp { string RespBody = 1;}service HelloService { rpc Method1(HelloReq) returns(HelloResp) { option (api.get) = \"/hello\"; }}Create a new project  // Execute under GOPATH, if the dependencies of the main IDL and the main IDL are not in the same path, you need to add the \"-I\" option, its meaning is IDL search path, equivalent to the option \"-I\" for protoc hz new -I idl -idl idl/hello/hello.proto go mod init // Tidy \u0026 get dependencies go mod tidy // Execute is not under GOPATH, add go mod name after \"-module\", if the dependencies of the main IDL and the main IDL are not in the same path, you need to add the \"-I\" option, its meaning is IDL search path, equivalent to the option \"-I\" for protoc hz new -module example/m -I idl -idl idl/hello/hello.proto // Tidy \u0026 get dependencies go mod tidy Modify the handler and add your own logic  // handler path: biz/handler/hello/hello_service.go // where \"/hello\" is the last level of go_package in protobuf IDL // \"hello_service.go\" is the name of the service in protobuf IDL, all methods defined by the service will be generated in this file  // Method1 . // @router /hello [GET] func Method1(ctx context.Context, c *app.RequestContext) { var err error var req hello.HelloReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(hello.HelloResp) // You can modify the logic of the entire function, not just the current template  resp.RespBody = \"hello,\" + req.Name // added logic  c.JSON(200, resp) } Compile the project  go build Run the project and test it  Run the project：\n./{{your binary}} Test：\ncurl --location --request GET 'http://127.0.0.1:8888/hello?name=hertz' If it returns {\"RespBody\":\"hello,hertz\"}, it works.\nupdate: Update an existing Hertz project  If your protobuf IDL is updated, for example:  // idl/hello/hello.proto syntax = \"proto3\";package hello;option go_package = \"hertz/hello\";import \"api.proto\";message HelloReq { string Name = 1[(api.query)=\"name\"];}message HelloResp { string RespBody = 1;}message OtherReq { string Other = 1[(api.body)=\"other\"];}message OtherResp { string Resp = 1;}service HelloService { rpc Method1(HelloReq) returns(HelloResp) { option (api.get) = \"/hello\"; } rpc Method2(OtherReq) returns(OtherResp) { option (api.post) = \"/other\"; }}service NewService { rpc Method3(OtherReq) returns(OtherResp) { option (api.get) = \"/new\"; }}Switch to the directory where the new command was executed and update the modified IDL  hz update -I idl -idl idl/hello/hello.proto  As you can see\nAdd new method under “biz/handler/hello/hello_service.go”\nThe file “new_service.go” and the corresponding “Method3” method have been added under “biz/handler/hello”\n  Now let’s develop the “Method2” interface\n// Method1 . // @router /hello [GET] func Method1(ctx context.Context, c *app.RequestContext) { var err error var req hello.HelloReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(hello.HelloResp) // You can modify the logic of the entire function, not just the current template  resp.RespBody = \"hello,\" + req.Name // added logic  c.JSON(200, resp) } // Method2 . // @router /other [POST] func Method2(ctx context.Context, c *app.RequestContext) { var err error var req hello.OtherReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(hello.OtherResp) // added logic  resp.Resp = \"Other method: \" + req.Other c.JSON(200, resp) } Compile the project  go build Run the project and test it  Run the project:\n./{{your binary}} Test：\ncurl --location --request POST 'http://127.0.0.1:8888/other' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"Other\": \"other method\" }' If it returns {\"Resp\":\"Other method: other method\"}, it works.\n","categories":"","description":"","excerpt":"Create a project based on protobuf IDL new: Create a new project …","ref":"/docs/hertz/tutorials/toolkit/usage/usage-protobuf/","tags":"","title":"hz usage(protobuf)"},{"body":"基于 protobuf IDL 创建项目 new: 创建一个新项目   在当前目录下创建 protobuf idl 文件\n注：为在 protobuf 中支持 api 注解，请在使用了注解的 proto 文件中，import 下面的文件\n  // idl/api.proto; 注解拓展 syntax = \"proto2\";package api;import \"google/protobuf/descriptor.proto\";option go_package = \"/api\";extend google.protobuf.FieldOptions { optional string raw_body = 50101; optional string query = 50102; optional string header = 50103; optional string cookie = 50104; optional string body = 50105; optional string path = 50106; optional string vd = 50107; optional string form = 50108; optional string go_tag = 51001; optional string js_conv = 50109;}extend google.protobuf.MethodOptions { optional string get = 50201; optional string post = 50202; optional string put = 50203; optional string delete = 50204; optional string patch = 50205; optional string options = 50206; optional string head = 50207; optional string any = 50208; optional string gen_path = 50301; optional string api_version = 50302; optional string tag = 50303; optional string name = 50304; optional string api_level = 50305; optional string serializer = 50306; optional string param = 50307; optional string baseurl = 50308;}extend google.protobuf.EnumValueOptions { optional int32 http_code = 50401;}主 idl 定义：\n// idl/hello/hello.proto syntax = \"proto3\";package hello;option go_package = \"hertz/hello\";import \"api.proto\";message HelloReq { string Name = 1[(api.query)=\"name\"];}message HelloResp { string RespBody = 1;}service HelloService { rpc Method1(HelloReq) returns(HelloResp) { option (api.get) = \"/hello\"; }}创建新项目  // GOPATH 下执行, 如果主IDL的依赖和主IDL不在同一路径下，需要加入 \"-I\" 选项，其含义为IDL搜索路径，等同于 protoc 的 \"-I\" 命令 hz new -I idl -idl idl/hello/hello.proto go mod init // 整理 \u0026 拉取依赖 go mod tidy // 非GOPATH 下执行, 需要指定 go mod 名, 如果主IDL的依赖和主IDL不在同一路径下，需要加入 \"-I\" 选项，其含义为IDL搜索路径，等同于 protoc 的 \"-I\" 命令 hz new -module example.com/m -I idl -idl idl/hello/hello.proto // 整理 \u0026 拉取依赖 go mod tidy 修改 handler，添加自己的逻辑  // handler path: biz/handler/hello/hello_service.go // 其中 \"/hello\" 是 protobuf idl 中 go_package 的最后一级 // \"hello_service.go\" 是 protobuf idl 中 service 的名字，所有 service 定义的方法都会生成在这个文件中  // Method1 . // @router /hello [GET] func Method1(ctx context.Context, c *app.RequestContext) { var err error var req hello.HelloReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(hello.HelloResp) // 你可以修改整个函数的逻辑，而不仅仅局限于当前模板  resp.RespBody = \"hello,\" + req.Name // 添加的逻辑  c.JSON(200, resp) } 编译项目  go build 运行项目并测试  运行项目：\n./{{your binary}} 测试：\ncurl --location --request GET 'http://127.0.0.1:8888/hello?name=hertz' 如果返回{\"RespBody\":\"hello,hertz\"}，说明接口调通。\nupdate: 更新一个已有的项目  如果你的 protobuf idl 有更新，例如：  // idl/hello/hello.proto syntax = \"proto3\";package hello;option go_package = \"hertz/hello\";import \"api.proto\";message HelloReq { string Name = 1[(api.query)=\"name\"];}message HelloResp { string RespBody = 1;}message OtherReq { string Other = 1[(api.body)=\"other\"];}message OtherResp { string Resp = 1;}service HelloService { rpc Method1(HelloReq) returns(HelloResp) { option (api.get) = \"/hello\"; } rpc Method2(OtherReq) returns(OtherResp) { option (api.post) = \"/other\"; }}service NewService { rpc Method3(OtherReq) returns(OtherResp) { option (api.get) = \"/new\"; }}切换到执行 new 命令的目录，更新修改后的 protobuf idl  hz update -I idl -idl idl/hello/hello.proto 可以看到 在\"biz/handler/hello/hello_service.go\" 下新增了新的方法 在\"biz/handler/hello\" 下新增了文件 “new_service.go” 以及对应的 “Method3” 方法。  下面我们来开发 “Method2” 接口\n// Method1 . // @router /hello [GET] func Method1(ctx context.Context, c *app.RequestContext) { var err error var req hello.HelloReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(hello.HelloResp) // 你可以修改整个函数的逻辑，而不仅仅局限于当前模板  resp.RespBody = \"hello,\" + req.Name // 添加的逻辑  c.JSON(200, resp) } // Method2 . // @router /other [POST] func Method2(ctx context.Context, c *app.RequestContext) { var err error var req hello.OtherReq err = c.BindAndValidate(\u0026req) if err != nil { c.String(400, err.Error()) return } resp := new(hello.OtherResp) // 增加的逻辑  resp.Resp = \"Other method: \" + req.Other c.JSON(200, resp) } 编译项目  go build 运行项目并测试  运行项目：\n./{{your binary}} 测试：\ncurl --location --request POST 'http://127.0.0.1:8888/other' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"Other\": \"other method\" }' 如果返回{\"Resp\":\"Other method: other method\"}，说明接口调通。\n","categories":"","description":"","excerpt":"基于 protobuf IDL 创建项目 new: 创建一个新项目   在当前目录下创建 protobuf idl 文件\n注： …","ref":"/zh/docs/hertz/tutorials/toolkit/usage/usage-protobuf/","tags":"","title":"hz 使用 (protobuf)"},{"body":"Introduction Based on IDL, it generates RPC-like http requests code with a single click, which can block the tedious operation of creating and initializing hertz client and interoperate directly with the server code generated by hz.\nGenerated code examples can be found at code .\nUsage $ hz client -h NAME: hz client - Generate hertz client based on IDL USAGE: hz client [command options] [arguments...] OPTIONS: --idl value [ --idl value ] Specify the IDL file path. (.thrift or .proto) --module value, --mod value Specify the Go module name to generate go.mod. --base_domain value Specify the request domain. --model_dir value Specify the model path. --client_dir value Specify the client path. If not specified, IDL generated path is used for 'client' command; no client code is generated for 'new' command --proto_path value, -I value [ --proto_path value, -I value ] Add an IDL search path for includes. (Valid only if idl is protobuf) --thriftgo value, -t value [ --thriftgo value, -t value ] Specify arguments for the thriftgo. ({flag}={value}) --protoc value, -p value [ --protoc value, -p value ] Specify arguments for the protoc. ({flag}={value}) --no_recurse Generate master model only. (default: false) --json_enumstr Use string instead of num for json enums when idl is thrift. (default: false) --unset_omitempty Remove 'omitempty' tag for generated struct. (default: false) --pb_camel_json_tag Convert Name style for json tag to camel(Only works protobuf). (default: false) --snake_tag Use snake_case style naming for tags. (Only works for 'form', 'query', 'json') (default: false) --exclude_file value, -E value [ --exclude_file value, -E value ] Specify the files that do not need to be updated. --protoc-plugins value [ --protoc-plugins value ] Specify plugins for the protoc. ({plugin_name}:{options}:{out_dir}) --thrift-plugins value [ --thrift-plugins value ] Specify plugins for the thriftgo. ({plugin_name}:{options}) --help, -h show help (default: false) When generating code, simply use the following five options:\n idl: Specify the idl path module: Specify the go module of the project, if not specified, it defaults to the path relative to the “go path”. model_dir: Specify the path to the model generated by the project, default is “biz/model” client_dir: Specify the path to generate the client stub code, default is “biz/model/{Namespace}” base_domain: Specify the domain to be accessed, it can be domain name, IP:PORT, service name (with service discovery), or can be declared in IDL by annotation  hz client --idl=../idl/psm.thrift --model_dir=hertz_gen -t=template=slim --client_dir=hz_client Example Generate client based on thrift IDL Define IDL  The definition and semantics of the IDL are exactly the same as the current definition, so it is basically possible to generate client code without modifying the original IDL But for the client scenario, two annotations have been added api.file_name: Specify the file api.base_domain: specifies the default request domain to access\n namespacegotoutiao.middleware.hertz_clientstructFormReq{1:stringFormValue (api.form=\"form1\");// form annotation is used to declare the form parameter (\"multipart/form-data\") 2:stringFileValue (api.file_name=\"file1\");// file_name is used to declare the key of the file to be uploaded, its actual value is the file name }structQueryReq{1:stringQueryValue (api.query=\"query1\");// query annotation is used to declare the query parameters of the request }structPathReq{1:stringPathValue (api.path=\"path1\");// path annotation is used to declare the routing parameters in the url }structBodyReq{1:stringBodyValue (api.body=\"body\");// body annotation sets the entire structure to the body as a json, regardless of whether it is declared or not. 2:stringQueryValue (api.query=\"query2\");}structResp{1:stringResp;}serviceHelloService{// api.post is used to declare the route of the request RespFormMethod(1:FormReqrequest)(api.post=\"/form\",api.handler_path=\"post\");RespQueryMethod(1:QueryReqrequest)(api.get=\"/query\",api.handler_path=\"get\");RespPathMethod(1:PathReqrequest)(api.post=\"/path:path1\",api.handler_path=\"post\");RespBodyMethod(1:BodyReqrequest)(api.post=\"/body\",api.handler_path=\"post\");}(// api.base_domain is used to specify the default domain for client requests api.base_domain=\"http://127.0.0.1:8888\";)Generate client code hz client --mod=a/b/c --idl=../idl/psm.thrift --model_dir=model --client_dir=hertz_client -t=template=slim Advanced Settings Request-level configuration  Take the code generated by thrift IDL as an example\n func main() { generatedClient, err := hello_service.NewHelloServiceClient( \"http://toutiao.hertz.testa\", ) // The request level configuration can be specified when the call is initiated  resp, rawResp, err := generatedClient.QueryMethod( context.Background(), QueryReq, config.WithSD(true), // Specify the request level setting to enable service discovery  config.WithReadTimeout(), // Specify the request read timeout  ) if err != nil { fmt.Println(err) return } } Set client middleware  Take the code generated by thrift IDL as an example\n func main() { generatedClient, err := hello_service.NewHelloServiceClient( \"http://toutiao.hertz.testa\", hello_service.WithHertzClientMiddleware(), // Specify the client's middleware \t) } Set global header  Take the code generated by thrift IDL as an example\n There are some generic header that may need to be carried in every request, or some header that cannot be defined in IDL, then we can inject these header with “WithHeader” so that every request sent will carry these header.\nfunc main() { generatedClient, err := hello_service.NewHelloServiceClient( \"http://toutiao.hertz.testa\", hello_service.WithHeader(), // Specify the header that needs to be carried for each request sent \t) } Configure TLS  Take the code generated by thrift IDL as an example\n Hertz client’s TLS goes through the standard network library, so you need to configure it for the standard network library when using the generated one-click calls\nfunc main() { generatedClient, err := hello_service.NewHelloServiceClient(\"https://www.example.com\"), hello_service.WithHertzClientOption( client.WithDialer(standard.NewDialer()), // Use of standard libraries \tclient.WithTLSConfig(clientCfg), // TLS Configuration \t), ) } ","categories":"","description":"","excerpt":"Introduction Based on IDL, it generates RPC-like http requests code …","ref":"/docs/hertz/tutorials/toolkit/client/","tags":"","title":"hz client code generation"},{"body":"介绍 基于 IDL 生成类似 RPC 形式的 http 请求一键调用，屏蔽掉创建和初始化 hertz client 的繁琐操作，并且实现和 hz 生成的 server 代码直接互通。\n生成代码示例可以参考 code 。\n使用说明 $ hz client -h NAME: hz client - Generate hertz client based on IDL USAGE: hz client [command options] [arguments...] OPTIONS: --idl value [ --idl value ] Specify the IDL file path. (.thrift or .proto) --module value, --mod value Specify the Go module name to generate go.mod. --base_domain value Specify the request domain. --model_dir value Specify the model path. --client_dir value Specify the client path. If not specified, IDL generated path is used for 'client' command; no client code is generated for 'new' command --proto_path value, -I value [ --proto_path value, -I value ] Add an IDL search path for includes. (Valid only if idl is protobuf) --thriftgo value, -t value [ --thriftgo value, -t value ] Specify arguments for the thriftgo. ({flag}={value}) --protoc value, -p value [ --protoc value, -p value ] Specify arguments for the protoc. ({flag}={value}) --no_recurse Generate master model only. (default: false) --json_enumstr Use string instead of num for json enums when idl is thrift. (default: false) --unset_omitempty Remove 'omitempty' tag for generated struct. (default: false) --pb_camel_json_tag Convert Name style for json tag to camel(Only works protobuf). (default: false) --snake_tag Use snake_case style naming for tags. (Only works for 'form', 'query', 'json') (default: false) --exclude_file value, -E value [ --exclude_file value, -E value ] Specify the files that do not need to be updated. --protoc-plugins value [ --protoc-plugins value ] Specify plugins for the protoc. ({plugin_name}:{options}:{out_dir}) --thrift-plugins value [ --thrift-plugins value ] Specify plugins for the thriftgo. ({plugin_name}:{options}) --help, -h show help (default: false) 在生成代码的时候，只要使用以下五个选项即可:\n idl： 指定 idl 路径 module： 指定项目的 go module，如果不指定则默认为相对于 “go path” 的路径 model_dir： 指定项目生成的 model 路径，默认为 “biz/model” client_dir： 指定生成 client 桩代码的路径，默认为 “biz/model/{Namespace}” base_domain： 指定要访问的 domain，可以是 域名、 IP:PORT、service name(配合服务发现)，也可以在 IDL 中通过注解声明  hz client --idl=../idl/psm.thrift --model_dir=hertz_gen -t=template=slim --client_dir=hz_client 示例 基于 thrift IDL 生成 client 定义 IDL  IDL 的定义和语义与目前的定义完全相同，所以基本不用修改原先的 IDL 即可生成 client 代码 但是为针对 client 的场景，增加了两种注解 api.file_name： 指定文件 api.base_domain： 指定默认访问的请求 domain\n namespacegotoutiao.middleware.hertz_clientstructFormReq{1:stringFormValue (api.form=\"form1\");// form 注解用来声明 form 参数(\"multipart/form-data\") 2:stringFileValue (api.file_name=\"file1\");// file_name 用来声明要上传文件的 key，其实际的值为文件名 }structQueryReq{1:stringQueryValue (api.query=\"query1\");// query 注解用来声明请求的 query 参数 }structPathReq{1:stringPathValue (api.path=\"path1\");// path 注解用来声明url中的路由参数 }structBodyReq{1:stringBodyValue (api.body=\"body\");// body 注解不管是否声明都将整个结构体以 json 的形式设置到 body 2:stringQueryValue (api.query=\"query2\");}structResp{1:stringResp;}serviceHelloService{// api.post 用来声明请求的路由 RespFormMethod(1:FormReqrequest)(api.post=\"/form\",api.handler_path=\"post\");RespQueryMethod(1:QueryReqrequest)(api.get=\"/query\",api.handler_path=\"get\");RespPathMethod(1:PathReqrequest)(api.post=\"/path:path1\",api.handler_path=\"post\");RespBodyMethod(1:BodyReqrequest)(api.post=\"/body\",api.handler_path=\"post\");}(// api.base_domain 用来指定默认的 client 请求的 domain api.base_domain=\"http://127.0.0.1:8888\";)生成 client 代码 hz client --mod=a/b/c --idl=../idl/psm.thrift --model_dir=model --client_dir=hertz_client -t=template=slim 高级设置 请求级别的配置  以 thrift IDL 生成的代码为例\n func main() { generatedClient, err := hello_service.NewHelloServiceClient( \"http://toutiao.hertz.testa\", // 指定 psm 作为域名 \t) // 在发起调用的时候可指定请求级别的配置  resp, rawResp, err := generatedClient.QueryMethod( context.Background(), QueryReq, config.WithSD(true), // 指定请求级别的设置，用来开启服务发现  config.WithReadTimeout(), // 指定请求读超时  ) if err != nil { fmt.Println(err) return } } 设置 client 中间件  以 thrift IDL 生成的代码为例\n func main() { generatedClient, err := hello_service.NewHelloServiceClient( \"http://toutiao.hertz.testa\", // 指定 psm 作为域名 \thello_service.WithHertzClientMiddleware(), // 指定 client 的中间件 \t) } 设置全局 header  以 thrift IDL 生成的代码为例\n 有一些通用的 header 可能每次请求都需要携带，或者是一些不能定义到 IDL 中的 header，这时我们就可以通过 “WithHeader” 注入这些 header，使得每次发送请求都会携带这些header。\nfunc main() { generatedClient, err := hello_service.NewHelloServiceClient( \"http://toutiao.hertz.testa\", // 指定 psm 作为域名 \thello_service.WithHeader(), // 指定每次发送请求都需要携带的header \t) } 配置 TLS  以 thrift IDL 生成的代码为例\n Hertz client 的 TLS 走的是标准网络库，因此在使用生成的一键调用时需要配置为了标准网络库\nfunc main() { generatedClient, err := hello_service.NewHelloServiceClient(\"https://www.example.com\"), hello_service.WithHertzClientOption( client.WithDialer(standard.NewDialer()), // 使用标准库 \tclient.WithTLSConfig(clientCfg), // TLS 配置 \t), ) } ","categories":"","description":"","excerpt":"介绍 基于 IDL 生成类似 RPC 形式的 http 请求一键调用，屏蔽掉创建和初始化 hertz client 的繁琐操作， …","ref":"/zh/docs/hertz/tutorials/toolkit/client/","tags":"","title":"hz client 代码生成"},{"body":"Hertz supports TLS secure transmission, helping users achieve data confidentiality and integrity.\n If you need TLS, Please use go net lib instead. netpoll is now working on it but not ready yet.\n In tls.Config, the parameters that the server and client both can use are as follows:\n   Parameter Introduce     Certificates Used to add certificates, multiple certificates can be configured.  Both ends automatically select the first certificate for verification.   VerifyPeerCertificate Used to verify the peer certificate. Called after certificate verification on either side.   VerifyConnection After both certificates are verified, TLS connection verification is performed.   NextProtos Used to set supported application layer protocols.   CipherSuites Used to negotiate encryption policies, supports TLS 1.0-1.2.   MaxVersion Used to set the maximum version supported by TLS, currently 1.3.    Server Hertz provides the WithTLS Option in the server package for configuring TLS services. But currently Hertz only supports TLS in the standard network library, Netpoll network library support is still on the way. The Transporter of WithTLS is set by default to the Transporter of the standard library.\n// WithTLS sets TLS config to start a tls server. // NOTE: If a tls server is started, it won't accept non-tls request. func WithTLS(cfg *tls.Config) config.Option { return config.Option{F: func(o *config.Options) { route.SetTransporter(standard.NewTransporter) o.TLS = cfg }} } Parameter In tls.Config, in addition to the above basic parameters, the parameters that can be configured by the server are as follows:\n   Parameter Introduce     GetCertificate Returns a certificate based on client SNI information or when the certificate set is empty.   GetClientCertificate It is used to return the client certificate when the server requires to verify the client certificate.   GetConfigForClient When the server receives ClientHello from the client, it returns the configuration information. If non-empty configuration information is returned, it will be used for this TLS connection.   ClientAuth Used for client authentication policy settings, defaults to NoClientCert.   ClientCAs When ClientAuth is enabled, used to verify the authenticity of the client certificate.    The main process of server-side TLS:\n Load the root certificate to verify the authenticity of the client. Load the server certificate to send to the client to verify the authenticity of the server. Configure tls.Config. Use WithTLS to configure server-side TLS. By default, the standard library’s Transporter is used.  Sample Code ca.key, ca.crt, server.key and server.crt in this example are all generated by openssl. First generate the CA’s private key and certificate, the command is as follows:\nopenssl ecparam -genkey -name prime256v1 -out ca.key openssl req -new -key ca.key -out ca.req # country=cn, common name=ca.example.com openssl x509 -req -in ca.req -signkey ca.key -out ca.crt -days 365 Generate the private key and certificate of the server through CA signature, the command is as follows:\nopenssl ecparam -genkey -name prime256v1 -out server.key openssl req -new -key server.key -out server.req # country=cn, common name=server.example.com openssl x509 -req -in server.req -CA ca.crt -CAkey ca.key -out server.crt -CAcreateserial -days 365 Server-side sample code:\npackage main // ...  func main() { // load server certificate \tcert, err := tls.LoadX509KeyPair(\"./tls/server.crt\", \"./tls/server.key\") if err != nil { fmt.Println(err.Error()) } // load root certificate \tcertBytes, err := ioutil.ReadFile(\"./tls/ca.crt\") if err != nil { fmt.Println(err.Error()) } caCertPool := x509.NewCertPool() ok := caCertPool.AppendCertsFromPEM(certBytes) if !ok { panic(\"Failed to parse root certificate.\") } // set server tls.Config \tcfg := \u0026tls.Config{ // add certificate \tCertificates: []tls.Certificate{cert}, MaxVersion: tls.VersionTLS13, // enable client authentication \tClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: caCertPool, // cipher suites supported \tCipherSuites: []uint16{ tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, }, // set application protocol http2 \tNextProtos: []string{http2.NextProtoTLS}, } // set TLS server \t// default is standard.NewTransporter \th := server.Default(server.WithTLS(cfg), server.WithHostPorts(\":8443\")) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"TLS test\\n\") }) h.Spin() } For a complete usage example, see example .\nClient Parameter In tls.Config, in addition to the above basic parameters, the parameters that can be configured by the client are as follows:\n   Parameter Introduce     ServerName Validate the hostname against the returned certificate information.   InsecureSkipVerify It is used for whether the client enables server-side certificate verification.   RootCAs The certificate used by the client to authenticate the server.    The main process of client-side TLS:\n Load the root certificate to verify the authenticity of the server. Load the client certificate for sending to the server to verify the authenticity of the client. Configure tls.Config. Use WithTLS to configure client-side TLS, which uses the standard library’s Dialer by default.  Sample Code Generate the client’s private key and certificate through CA signature, the command is as follows:\nopenssl ecparam -genkey -name prime256v1 -out client.key openssl req -new -key client.key -out client.req # country=cn, common name=client.example.com openssl x509 -req -in client.req -CA ca.crt -CAkey ca.key -out client.crt -CAcreateserial -days 365 Client sample code:\npackage main // ...  func main() { // load root certificate to verify the client validity \tcertBytes, err := ioutil.ReadFile(\"./tls/ca.crt\") if err != nil { fmt.Println(err.Error()) } caCertPool := x509.NewCertPool() ok := caCertPool.AppendCertsFromPEM(certBytes) if !ok { panic(\"Failed to parse root certificate.\") } // load client certificate to send to server \tcert, err := tls.LoadX509KeyPair(\"./tls/client.crt\", \"./tls/client.key\") if err != nil { fmt.Println(err.Error()) } // set TLS configuration \tcfg := \u0026tls.Config{ MaxVersion: tls.VersionTLS13, Certificates: []tls.Certificate{cert}, // verify the server certificate \tRootCAs: caCertPool, // ignored the server certificate \tInsecureSkipVerify: true, } c, err := client.NewClient( // default dialer is standard \tclient.WithTLSConfig(cfg), client.WithDialer(standard.NewDialer()), ) if err != nil { fmt.Println(err.Error()) } // ... }  Note：Currently, Hertz TLS server is not supported Netpoll network library temporarily. c, err := client.NewClient(client.WithTLSConfig(cfg), client.WithDialer(netpoll.NewDialer()) support is still on the way.\n For a complete usage example, see example .\nAutotls Middleware Hertz provides autotls extension adaptation Let’s Encrypt, which is convenient for users to automatically configure TLS services.\nInstallation go get github.com/hertz-contrib/autotls Configuration NewTlsConfig The autotls extension provides NewTlsConfig to help users support LetsEncrypt HTTPS servers with one line of code.\nThe NewTlsConfig function signature is as follows:\nfunc NewTlsConfig(domains ...string) *tls.Config sample code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/autotls\" ) func main() { h := server.Default( server.WithTLS(autotls.NewTlsConfig(\"example1.com\", \"example2.com\")), server.WithHostPorts(\":https\"), ) // Ping handler \th.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]interface{}{ \"ping\": \"pong\", }) }) hlog.Fatal(autotls.Run(h)) } RunWithContext The autotls extension provides RunWithContext to help users support LetsEncrypt HTTPS servers with a single line of code while enabling graceful shutdown of the service.\nThe RunWithContext function signature is as follows:\nfunc RunWithContext(ctx context.Context, h *server.Hertz) error sample code:\npackage main import ( \"context\" \"os/signal\" \"syscall\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/autotls\" ) func main() { // Create context that listens for the interrupt signal from the OS. \tctx, stop := signal.NotifyContext( context.Background(), syscall.SIGINT, syscall.SIGTERM, ) defer stop() h := server.Default( server.WithTLS(autotls.NewTlsConfig(\"example1.com\", \"example2.com\")), server.WithHostPorts(\":https\"), ) // Ping handler \th.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]interface{}{ \"ping\": \"pong\", }) }) hlog.Fatal(autotls.RunWithContext(ctx, h)) } NewServerWithManagerAndTlsConfig The autotls extension provides NewServerWithManagerAndTlsConfig to help users automate certificate management and TLS configuration.\nThe NewServerWithManagerAndTlsConfig function signature is as follows:\nfunc NewServerWithManagerAndTlsConfig(m *autocert.Manager, tlsc *tls.Config, opts ...config.Option) *server.Hertz sample code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/autotls\" \"golang.org/x/crypto/acme/autocert\" ) func main() { m := autocert.Manager{ Prompt: autocert.AcceptTOS, HostPolicy: autocert.HostWhitelist(\"example1.com\", \"example2.com\"), Cache: autocert.DirCache(\"/var/www/.cache\"), } h := autotls.NewServerWithManagerAndTlsConfig(\u0026m, nil) // Ping handler \th.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]interface{}{ \"ping\": \"pong\", }) }) hlog.Fatal(autotls.Run(h)) } For a complete usage example, see example .\nNote Client raise error not support tls Hertz uses netpoll as the network library by default and currently netpoll does not support TLS. To use TLS you need to switch to the standard network library with the following code:\nimport ( \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/network/standard\" \"github.com/cloudwego/hertz/pkg/protocol\" ) func main() { clientCfg := \u0026tls.Config{ InsecureSkipVerify: true, } c, err := client.NewClient( client.WithTLSConfig(clientCfg), client.WithDialer(standard.NewDialer()), ) } ","categories":"","description":"","excerpt":"Hertz supports TLS secure transmission, helping users achieve data …","ref":"/docs/hertz/tutorials/basic-feature/protocol/tls/","tags":"","title":"TLS"},{"body":"Hertz 支持 TLS 安全传输，帮助用户实现了数据的保密性和完整性。\n 如果有 TLS 的需求，请使用 go net 网络库。netpoll 正在实现对 TLS 的支持。\n 在 tls.Config中，服务端和客户端都可使用的参数如下：\n   参数名 介绍     Certificates 用于添加证书，可以配置多个证书。 两端自动选择第一个证书进行验证。   VerifyPeerCertificate 用于验证对端证书。在任意一端证书验证后调用。   VerifyConnection 在两端证书均验证后，进行 TLS 连接验证。   NextProtos 用于设置支持的应用层协议。   CipherSuites 用于协商加密策略，支持 TLS 1.0-1.2 。   MaxVersion 用于设置 TLS 支持的最大版本，目前是 1.3。    服务端 Hertz 在 server 包提供了 WithTLS Option 用于配置 TLS 服务。但是目前 Hertz 只有 标准网络库 支持 TLS，Netpoll 网络库的支持还在路上。 WithTLS 的 Transporter 默认设置为标准库的 Transporter 。\n// WithTLS sets TLS config to start a tls server. // NOTE: If a tls server is started, it won't accept non-tls request. func WithTLS(cfg *tls.Config) config.Option { return config.Option{F: func(o *config.Options) { route.SetTransporter(standard.NewTransporter) o.TLS = cfg }} } 参数 在 tls.Config 中，除了上述基本参数，服务端可以配置的参数如下：\n   参数名 介绍     GetCertificate 基于客户端 SNI 信息或证书集为空时，返回证书。   GetClientCertificate 用于服务端要求验证客户端证书时，返回客户端证书。   GetConfigForClient 当服务端从客户端接收了 ClientHello 后，返回配置信息。 如果返回的是非空的配置信息，将会被用于这次 TLS 连接。   ClientAuth 用于客户端验证策略设置，默认为 NoClientCert。   ClientCAs 当启用了 ClientAuth, 用于验证客户端证书的真实性。    服务器端 TLS 主要流程：\n 载入根证书，用于验证客户端的真实性。 载入服务器证书，用于发送给客户端以验证服务器真实性。 配置 tls.Config。 使用 WithTLS 配置服务端 TLS，默认使用标准库的 Transporter。  示例代码 本次示例中的 ca.key、ca.crt、server.key 和 server.crt 均通过 openssl 生成。 首先生成 CA 的私钥和证书，命令如下：\nopenssl ecparam -genkey -name prime256v1 -out ca.key openssl req -new -key ca.key -out ca.req # country=cn, common name=ca.example.com openssl x509 -req -in ca.req -signkey ca.key -out ca.crt -days 365 通过CA签名，生成服务端的私钥和证书，命令如下：\nopenssl ecparam -genkey -name prime256v1 -out server.key openssl req -new -key server.key -out server.req # country=cn, common name=server.example.com openssl x509 -req -in server.req -CA ca.crt -CAkey ca.key -out server.crt -CAcreateserial -days 365 服务端示例代码：\npackage main // ...  func main() { // load server certificate \tcert, err := tls.LoadX509KeyPair(\"./tls/server.crt\", \"./tls/server.key\") if err != nil { fmt.Println(err.Error()) } // load root certificate \tcertBytes, err := ioutil.ReadFile(\"./tls/ca.crt\") if err != nil { fmt.Println(err.Error()) } caCertPool := x509.NewCertPool() ok := caCertPool.AppendCertsFromPEM(certBytes) if !ok { panic(\"Failed to parse root certificate.\") } // set server tls.Config \tcfg := \u0026tls.Config{ // add certificate \tCertificates: []tls.Certificate{cert}, MaxVersion: tls.VersionTLS13, // enable client authentication \tClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: caCertPool, // cipher suites supported \tCipherSuites: []uint16{ tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, }, // set application protocol http2 \tNextProtos: []string{http2.NextProtoTLS}, } // set TLS server \t// default is standard.NewTransporter \th := server.Default(server.WithTLS(cfg), server.WithHostPorts(\":8443\")) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(consts.StatusOK, \"TLS test\\n\") }) h.Spin() } 完整用法示例详见 example 。\n客户端 参数 在 tls.Config 中，除了上述基本参数，客户端可以配置的参数如下：\n   参数名 介绍     ServerName 根据返回的证书信息验证主机名。   InsecureSkipVerify 用于客户端是否开启服务端的证书验证。   RootCAs 用于客户端验证服务端的证书。    客户端 TLS 主要流程：\n 载入根证书，用于验证服务器端的真实性。 载入客户证书，用于发送给服务器端以验证客户端的真实性。 配置 tls.Config。 使用 WithTLS 配置客户端 TLS，默认使用标准库的 Dialer。  示例代码 通过CA签名，生成客户端的私钥和证书，命令如下：\nopenssl ecparam -genkey -name prime256v1 -out client.key openssl req -new -key client.key -out client.req # country=cn, common name=client.example.com openssl x509 -req -in client.req -CA ca.crt -CAkey ca.key -out client.crt -CAcreateserial -days 365 客户端示例代码：\npackage main // ...  func main() { // load root certificate to verify the client validity \tcertBytes, err := ioutil.ReadFile(\"./tls/ca.crt\") if err != nil { fmt.Println(err.Error()) } caCertPool := x509.NewCertPool() ok := caCertPool.AppendCertsFromPEM(certBytes) if !ok { panic(\"Failed to parse root certificate.\") } // load client certificate to send to server \tcert, err := tls.LoadX509KeyPair(\"./tls/client.crt\", \"./tls/client.key\") if err != nil { fmt.Println(err.Error()) } // set TLS configuration \tcfg := \u0026tls.Config{ MaxVersion: tls.VersionTLS13, Certificates: []tls.Certificate{cert}, // verify the server certificate \tRootCAs: caCertPool, // ignored the server certificate \tInsecureSkipVerify: true, } c, err := client.NewClient( // default dialer is standard \tclient.WithTLSConfig(cfg), client.WithDialer(standard.NewDialer()), ) if err != nil { fmt.Println(err.Error()) } // ... } 完整用法示例详见 example 。\nAutotls 中间件 Hertz 提供了 autotls 扩展适配 Let’s Encrypt ，方便用户进行 TLS 服务自动配置。\n安装 go get github.com/hertz-contrib/autotls 配置 NewTlsConfig autotls 扩展提供了 NewTlsConfig 用于帮助用户使用一行代码支持 LetsEncrypt HTTPS servers。\nNewTlsConfig 函数签名如下：\nfunc NewTlsConfig(domains ...string) *tls.Config 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/autotls\" ) func main() { h := server.Default( server.WithTLS(autotls.NewTlsConfig(\"example1.com\", \"example2.com\")), server.WithHostPorts(\":https\"), ) // Ping handler \th.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]interface{}{ \"ping\": \"pong\", }) }) hlog.Fatal(autotls.Run(h)) } RunWithContext autotls 扩展提供了 RunWithContext 用于帮助用户使用一行代码支持 LetsEncrypt HTTPS servers 的同时能够让服务优雅关机。\nRunWithContext 函数签名如下：\nfunc RunWithContext(ctx context.Context, h *server.Hertz) error 示例代码：\npackage main import ( \"context\" \"os/signal\" \"syscall\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/autotls\" ) func main() { // Create context that listens for the interrupt signal from the OS. \tctx, stop := signal.NotifyContext( context.Background(), syscall.SIGINT, syscall.SIGTERM, ) defer stop() h := server.Default( server.WithTLS(autotls.NewTlsConfig(\"example1.com\", \"example2.com\")), server.WithHostPorts(\":https\"), ) // Ping handler \th.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]interface{}{ \"ping\": \"pong\", }) }) hlog.Fatal(autotls.RunWithContext(ctx, h)) } NewServerWithManagerAndTlsConfig autotls 扩展提供了 NewServerWithManagerAndTlsConfig 用于帮助用户自动证书管理和 TLS 配置。\nNewServerWithManagerAndTlsConfig 函数签名如下：\nfunc NewServerWithManagerAndTlsConfig(m *autocert.Manager, tlsc *tls.Config, opts ...config.Option) *server.Hertz 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/hertz-contrib/autotls\" \"golang.org/x/crypto/acme/autocert\" ) func main() { m := autocert.Manager{ Prompt: autocert.AcceptTOS, HostPolicy: autocert.HostWhitelist(\"example1.com\", \"example2.com\"), Cache: autocert.DirCache(\"/var/www/.cache\"), } h := autotls.NewServerWithManagerAndTlsConfig(\u0026m, nil) // Ping handler \th.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]interface{}{ \"ping\": \"pong\", }) }) hlog.Fatal(autotls.Run(h)) } 完整用法示例详见 example 。\n注意 Client 报错 not support tls Hertz 默认使用了 netpoll 作为网络库并且目前 netpoll 不支持 TLS 。使用 TLS 需要切换到标准网络库，代码如下:\nimport ( \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/network/standard\" \"github.com/cloudwego/hertz/pkg/protocol\" ) func main() { clientCfg := \u0026tls.Config{ InsecureSkipVerify: true, } c, err := client.NewClient( client.WithTLSConfig(clientCfg), client.WithDialer(standard.NewDialer()), ) } ","categories":"","description":"","excerpt":"Hertz 支持 TLS 安全传输，帮助用户实现了数据的保密性和完整性。\n 如果有 TLS 的需求，请使用 go net 网络 …","ref":"/zh/docs/hertz/tutorials/basic-feature/protocol/tls/","tags":"","title":"TLS"},{"body":"In HTTP, GNUzip(Gzip) compression coding is a way to optimize the performance of Web applications, and Hertz also provides an implementation of Gzip.\nInstall go get github.com/hertz-contrib/gzip Example package main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.Use(gzip.Gzip(gzip.DefaultCompression)) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } Config Gzip Gzip provides four compression options: BestCompression, BestSpeed, DefaultCompression, NoCompression for user-defined compression modes\n   Options Description     BestCompression Provides the best file compression ratio   BestSpeed Provides the best compression speed   DefaultCompression Default compression rate   NoCompression No compression    Function Signature:\nfunc Gzip(level int, options ...Option) app.HandlerFunc Sample Code:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) // BestCompression option \th.Use(gzip.Gzip(gzip.BestCompression)) // BestSpeed option \th.Use(gzip.Gzip(gzip.BestSpeed)) // DefaultCompression option \th.Use(gzip.Gzip(gzip.DefaultCompression)) // NoCompression option \th.Use(gzip.Gzip(gzip.NoCompression)) h.GET(\"/api/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } WithExcludedExtensions gzip provides WithExcludeExtensions to help users set file extensions that do not require gzip compression, the default values are .png, .gif, .jpeg, .jpg\nFunction Signature:\nfunc WithExcludedPaths(args []string) Option Sample Code:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.Use( gzip.Gzip( gzip.DefaultCompression, gzip.WithExcludedExtensions([]string{\".pdf\", \".mp4\"}), ), ) h.GET(\"/api/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } WithExcludedPaths gzip provides WithExcludedPaths to help users set the paths of files they do not want to compress with gzip\nFunction Signature:\nfunc WithExcludedPaths(args []string) Option Sample Code:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.Use( gzip.Gzip( gzip.DefaultCompression, // This WithExcludedPaths takes as its parameter the file path \tgzip.WithExcludedPaths([]string{\"/api/\"}), ), ) // This is No compression \th.GET(\"/api/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) // This is the compressed \th.GET(\"/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } WithExcludedPathRegexes gzip provides WithExcludedPathRegexes to help users set custom regular expressions to filter out files that do not need to be compressed by gzip\nFunction Signature\nfunc WithExcludedPathRegexes(args []string) Option Sample Code:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.Use( gzip.Gzip( gzip.DefaultCompression, // This WithExcludedPathRegexes takes as an argument a regular expression that describes the path to be excluded \tgzip.WithExcludedPathRegexes([]string{\"/api.*\"}), ), ) // This is No compression \th.GET(\"/api/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) // This is the compressed \th.GET(\"/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } Refer to the gzip for more usage examples\n","categories":"","description":"","excerpt":"In HTTP, GNUzip(Gzip) compression coding is a way to optimize the …","ref":"/docs/hertz/tutorials/basic-feature/middleware/gzip/","tags":"","title":"Gzip Compress"},{"body":"OpenTelemetry is an open source observability framework from CNCF that consist of a series of tools, APIs and SDKs, and it enables IT teams to detect, generate, collect, and export remote monitoring data for analysis and understanding of software performance and behavior.\nThe obs-opentelemetry extension is available in the hertz-contrib, which allows hertz to integrate OpenTelemetry with a simple setup.\nFeatures Tracing Tracing provides a full view of the entire lifecycle from the time a request is received to the time it is processed.\nWhat obs-opentelemetry implements:\n Support server and client hertz http tracing Support automatic transparent transmission of peer service through http headers  Examples:\nServer:\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" hertztracing \"github.com/hertz-contrib/obs-opentelemetry/tracing\" ) func main() { tracer, cfg := hertztracing.NewServerTracer() h := server.Default(tracer) h.Use(hertztracing.ServerMiddleware(cfg)) // ... \th.Spin() } Client:\npackage main import ( hertztracing \"github.com/hertz-contrib/obs-opentelemetry/tracing\" \"github.com/cloudwego/hertz/pkg/app/client\" ) func main() { c, _ := client.NewClient() c.Use(hertztracing.ClientMiddleware()) // ... } Code\nMetric Metric contains a wide variety of methods and implementations.\nMetric includes tracing samples and automatically associates metrics with them. Manually linking metrics to tracing is often a tedious and error-prone task, and OpenTelemetry automating it will save Ops a lot of time.\nWhat obs-opentelemetry implements:\n Support hertz http metrics: [Rate, Errors, Duration] Support service topology map metrics [Service Topology Map] Support go runtime metrics  More\nLogging OpenTelemetry combines a highly structured logging API with a high-speed log processing system. Existing logging APIs can be connected to OpenTelemetry to avoid re-measurement of applications.\nWhat obs-opentelemetry implements:\n Extend hertz logger based on logrus Implement tracing auto associated logs  import ( hertzlogrus \"github.com/hertz-contrib/obs-opentelemetry/logging/logrus\" ) func main() { hlog.SetLogger(hertzlogrus.NewLogger()) // ... } Code\nProvider  Out-of-the-box default opentelemetry provider Support setting via environment variables:  Exporter SDK    Examples:\npackage main import ( \"context\" hertztracing \"github.com/hertz-contrib/obs-opentelemetry/tracing\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/obs-opentelemetry/provider\" ) func main() { serviceName := \"echo\" p := provider.NewOpenTelemetryProvider( provider.WithServiceName(serviceName), provider.WithExportEndpoint(\"localhost:4317\"), provider.WithInsecure(), ) defer p.Shutdown(context.Background()) tracer, cfg := hertztracing.NewServerTracer() h := server.Default(tracer) h.Use(hertztracing.ServerMiddleware(cfg)) // ... \th.Spin() } Code\nOptions    Function Description     WithServiceName Configure the resource properties of service.name   WithDeploymentEnvironment Configure the resource properties of deployment.environment   WithServiceNamespace Configure the resource properties of service.namespace   WithResourceAttributes Configure the resource properties   WithResource Configure resources (resource.Resource)   WithEnableTracing Enable tracing   WithEnableMetrics Enable metrics   WithTextMapPropagator Configure  propagation.TextMapPropagator   WithResourceDetector Configure resource.Detector   WithHeaders Configure the gRPC request header for exporting telemetry data   WithInsecure Configure whether to use secure authentication for exported gRPC clients    Full Examples For a full usage: example\n","categories":"","description":"","excerpt":"OpenTelemetry is an open source observability framework from CNCF that …","ref":"/docs/hertz/tutorials/observability/open-telemetry/","tags":"","title":"OpenTelemetry"},{"body":"在 HTTP 中，GNUzip(Gzip) 压缩编码是一种用来优化 Web 应用程序性能的方式，并且 Hertz 也提供了 Gzip 的实现 。\n安装 go get github.com/hertz-contrib/gzip 示例代码 package main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.Use(gzip.Gzip(gzip.DefaultCompression)) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } 配置 Gzip Gzip提供了四种压缩选项:BestCompression,BestSpeed,DefaultCompression,NoCompression 用于用户自定义压缩模式\n   选项 描述     BestCompression 提供最佳的文件压缩率   BestSpeed 提供了最佳的压缩速度   DefaultCompression 默认压缩率   NoCompression 不进行压缩    函数签名如下:\nfunc Gzip(level int, options ...Option) app.HandlerFunc 示例代码如下:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) // BestCompression option \th.Use(gzip.Gzip(gzip.BestCompression)) // BestSpeed option \th.Use(gzip.Gzip(gzip.BestSpeed)) // DefaultCompression option \th.Use(gzip.Gzip(gzip.DefaultCompression)) // NoCompression option \th.Use(gzip.Gzip(gzip.NoCompression)) h.GET(\"/api/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } WithExcludedExtensions gzip 提供 WithExcludeExtensions  用于帮助用户设置不需要 gzip 压缩的文件后缀，默认值为.png, .gif, .jpeg, .jpg\n函数签名如下:\nfunc WithExcludedPaths(args []string) Option 示例代码如下:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.Use( gzip.Gzip( gzip.DefaultCompression, gzip.WithExcludedExtensions([]string{\".pdf\", \".mp4\"}), ), ) h.GET(\"/api/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } WithExcludedPaths gzip 提供了 WithExcludedPaths用于帮助用户设置其不需要进行 gzip 压缩的文件路径\n函数签名如下:\nfunc WithExcludedPaths(args []string) Option 示例代码如下:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.Use( gzip.Gzip( gzip.DefaultCompression, // This WithExcludedPaths takes as its parameter the file path \tgzip.WithExcludedPaths([]string{\"/api/\"}), ), ) // This is No compression \th.GET(\"/api/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) // This is the compressed \th.GET(\"/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } WithExcludedPathRegexes gzip 提供了WithExcludedPathRegexes用于帮助用户设置自定义的正则表达式来过滤掉不需要 gzip 压缩的文件\n函数签名如下:\nfunc WithExcludedPathRegexes(args []string) Option 示例代码如下:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/gzip\" ) func main() { h := server.Default(server.WithHostPorts(\":8080\")) h.Use( gzip.Gzip( gzip.DefaultCompression, // This WithExcludedPathRegexes takes as an argument a regular expression that describes the path to be excluded \tgzip.WithExcludedPathRegexes([]string{\"/api.*\"}), ), ) // This is No compression \th.GET(\"/api/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) // This is the compressed \th.GET(\"/book\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong \"+fmt.Sprint(time.Now().Unix())) }) h.Spin() } 更多用法示例详见 gzip\n","categories":"","description":"","excerpt":"在 HTTP 中，GNUzip(Gzip) 压缩编码是一种用来优化 Web 应用程序性能的方式，并且 Hertz 也提供了 Gzip …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/gzip/","tags":"","title":"Gzip 压缩"},{"body":"OpenTelemetry 是 CNCF 的一个开源可观测能力框架， 是由一系列工具，API 和 SDK 组成的。可以使 IT 团队能够检测、生成、收集和导出远程监测数据以进行分析和了解软件性能和行为。\nhertz-contrib 中提供了 obs-opentelemetry 扩展， 可以使 hertz 通过简易设置就能集成 OpenTelemetry。\n特性 Tracing Tracing 提供了从请求开始接收到处理完毕的整个生命周期的全貌。\nobs-opentelemetry 实现了什么:\n 支持在 hertz 服务端和客户端之间启用 http 链路追踪 支持通过设置 http header 以启动自动透明地传输对端服务  使用示例\n服务端:\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" hertztracing \"github.com/hertz-contrib/obs-opentelemetry/tracing\" ) func main() { tracer, cfg := hertztracing.NewServerTracer() h := server.Default(tracer) h.Use(hertztracing.ServerMiddleware(cfg)) // ...  h.Spin() } 客户端:\npackage main import ( hertztracing \"github.com/hertz-contrib/obs-opentelemetry/tracing\" \"github.com/cloudwego/hertz/pkg/app/client\" ) func main() { c, _ := client.NewClient() c.Use(hertztracing.ClientMiddleware()) // ... } 代码地址\nMetric 度量指标（Metric）包含了各种各样的方法和实现。\nMetric 包括了追踪样本以及自动将指标与产生它们的追踪样本联系起来。手动将指标和追踪联系起来往往是一项繁琐且容易出错的任务。OpenTelemetry 自动执行这项任务将为运维人员节省大量的时间。\nobs-opentelemetry 实现了什么:\n 支持的 hertz http 指标有 [Rate, Errors, Duration] 支持服务拓扑图指标 [服务拓扑图] 支持 go runtime 指标  更多详细的说明\nLogging OpenTelemetry 结合了高度结构化的日志 API 以及高速日志处理系统。现有的日志 API 可以通过连接到 OpenTelemetry，以避免对应用程序进行重新测量。\nobs-opentelemetry 实现了什么:\n 在 logrus 的基础上适配了 hertz 日志工具 实现了链路追踪自动关联日志的功能  import ( hertzlogrus \"github.com/hertz-contrib/obs-opentelemetry/logging/logrus\" ) func main() { hlog.SetLogger(hertzlogrus.NewLogger()) // ... } 代码地址\nProvider  通过集成默认的 OpenTelemetry 程序，使其达到开箱即用的程度 支持设置环境变量:  Exporter SDK    使用示例\npackage main import ( \"context\" hertztracing \"github.com/hertz-contrib/obs-opentelemetry/tracing\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/obs-opentelemetry/provider\" ) func main() { serviceName := \"echo\" p := provider.NewOpenTelemetryProvider( provider.WithServiceName(serviceName), provider.WithExportEndpoint(\"localhost:4317\"), provider.WithInsecure(), ) defer p.Shutdown(context.Background()) tracer, cfg := hertztracing.NewServerTracer() h := server.Default(tracer) h.Use(hertztracing.ServerMiddleware(cfg)) // ...  h.Spin() } 代码地址\nOptions    函数名 描述     WithServiceName 配置 service.name 的资源属性   WithDeploymentEnvironment 配置deployment.environment资源属性   WithServiceNamespace 配置了service.namespace资源属性   WithResourceAttributes 配置资源属性   WithResource 配置资源 (resource.Resource)   WithEnableTracing 是否启用 tracing   WithEnableMetrics 是否启用 metrics   WithTextMapPropagator 设置  propagation.TextMapPropagator   WithResourceDetector 配置 resource.Detector   WithHeaders 配置导出 telemetry 数据的 gRPC 请求头   WithInsecure 配置是否对导出的 gRPC 客户端使用安全认证    完整使用示例 完整的使用示例详见 example\n","categories":"","description":"","excerpt":"OpenTelemetry 是 CNCF 的一个开源可观测能力框架， 是由一系列工具，API 和 SDK 组成的。可以使 IT 团队能够检 …","ref":"/zh/docs/hertz/tutorials/observability/open-telemetry/","tags":"","title":"OpenTelemetry"},{"body":"Version Requirements kitex version \u003e= v0.4.0\nOverview Fastpb is a protobuf enhancement plugin developed by ByteDance. It uses the new generated code and API to complete the protobuf encoding and decoding process. Compared to the official sdk, it avoids go-reflect and thus has better performance.\nPerformance comparison with the official protobuf please refer to here. More Fastpb details see here.\nUsage (enabled by default) Kitex integrates Fastpb by default. When using the kitex command-tool to generate code, an additional xx.pb.fast.go file will be added next to the official generated code file xx.pb.go for Fastpb faster codec.\nHow to Disable ? When using the kitex command line to generate code, add -no-fast-api to disable Fastpb.\nDeleting the xx.pb.fast.go files can also disable Fastpb. After deleting these files, the Kitex framework will automatically adapt to the official sdk for encoding/decoding.\n","categories":"","description":"","excerpt":"Version Requirements kitex version \u003e= v0.4.0\nOverview Fastpb is a …","ref":"/docs/kitex/tutorials/code-gen/fastpb/","tags":"","title":"Fastpb"},{"body":"版本要求 kitex version \u003e= v0.4.0\n概述 Fastpb 是字节跳动研发的 protobuf 增强插件，使用新的生成代码和 API 来完成 protobuf 的编解码过程，相比于官方库规避了反射，具有更好的性能。\n和官方 protobuf 的性能对比 参考这里。 更多 Fastpb 信息 参考这里。\n使用 (默认开启) Kitex 默认集成了 Fastpb，使用 kitex 命令生成代码时，会在官方的生成代码文件 xx.pb.go 旁边额外增加一份 xx.pb.fast.go 文件，用于 Fastpb 快速编解码。\n如何关闭 在使用 kitex 命令行生成代码时，加上 -no-fast-api 参数，即可关闭 Fastpb。\n删除 xx.pb.fast.go 文件也可以实质上关闭 Fastpb 能力，删除文件后，Kitex 框架会自动适配为官方库编解码。\n","categories":"","description":"","excerpt":"版本要求 kitex version \u003e= v0.4.0\n概述 Fastpb 是字节跳动研发的 protobuf 增强插件，使用新的生成代码 …","ref":"/zh/docs/kitex/tutorials/code-gen/fastpb/","tags":"","title":"Fastpb"},{"body":"Some users will ask how to let the client-side receive the corresponding error type of the server-side, here to explain, RPC communicates through the protocol, and error handling is also based on the protocol. Usually when the server returns Error, the framework will unify the Error encoding and return it to the client side. If you want the client to return the same error as the server-side, you need to define a set of error codes for handling. However, considering that RPC does not have a unified error code specification, and internal error codes are not necessarily applicable to external users, so the open source part of Kitex does not expose the error code definition, and users can customize their own error handler by using the provided ErrorHandler.\nRecommended Usage ErrorHandler is configured via the client/server Option, but usually, a microservice system will have a unified error handler specification, if you are an enterprise user, it is recommended to customize the Option through the Suite, so that the service developer does not need to pay attention to the configuration of error handler.\nServer-side Configuration // server option server.WithErrorHandler(yourServerErrorHandler) This function is executed after the server-side handler and before the middleware is executed, and can be used to return custom error codes and messages to the client-side. Note that although this is supported, business-level custom error codes are still not recommended to be handled by ErrorHandler, because we want to distinguish RPC errors from business errors, which indicate a failed RPC request, such as timeout, circuit breaker, rate limiting, which is a failed request at the RPC level, but business errors are at the business logic level, which is actually a successful request at the RPC level. Kitex will develop a custom exception specification to distinguish between business errors and RPC level errors.\n  ErrorHandler example：\nKitex wraps the error returned by the handler as kerrors.ErrBiz, if you want to get the original error you need to Unwrap it first.\n  // convert errors that can be serialized func ServerErrorHandler(err error) error { if errors.Is(err, kerrors.ErrBiz) { err = errors.Unwrap(err) } if errCode, ok := GetErrorCode(err); ok { // for Thrift、KitexProtobuf  return remote.NewTransError(errCode, err) } return err } // convert errors that can be serialized func ServerErrorHandler(err error) error { if errors.Is(err, kerrors.ErrBiz) { err = errors.Unwrap(err) } if errCode, ok := GetErrorCode(err); ok { // for gRPC  // status use github.com/cloudwego/kitex/pkg/remote/trans/nphttp2/status  return status.Errorf(errCode, err.Error()) } return err } Client-side Configuration // client option client.WithErrorHandler(yourClientErrorHandler) The handler is executed after the remote call and before the middleware is executed. The framework has a default ClientErrorHandler, it will be used by default if no ClientErrorHandler is configured. The behavior of the default Handler is to return ErrRemoteOrNetwork when an error is received from the server-side or when an exception occurs at the transport layer on the client side. In addition, for Thrift and KitexProtobuf, the error msg contains a ‘[remote]’ message to identify that it is an error on the other side; for gRPC, if the other side returns an error constructed by status.Error, use status.FromError(err) on the local side to get *status.Status, note that Status needs to be provided by Kitex, the package path is github.com/cloudwego/kitex/pkg/remote/trans/nphttp2/status.\n ErrorHandler example：  func ClientErrorHandler(err error) error { // for thrift、KitexProtobuf  if e, ok := err.(*remote.TransError); ok { // TypeID is error code  return buildYourError(e.TypeID(), e) } // for gRPC  if s, ok := status.FromError(err); ok { return buildYourErrorWithStatus(s.Code(), s) } return kerrors.ErrRemoteOrNetwork.WithCause(err) } Error Code Definition Range Because some of the error codes are built-in to the framework, users should avoid using the built-in error codes, currently built-in error codes:\n  Thrift、KitexProtobuf：0 - 10。\n  gRPC：0 - 17。\n  ErrorHandler Execution Mechanism The ErrorHandler is executed in the Middleware, either on the client-side or on the server-side ErrorHandler is executed as the innermost Middleware, as shown below:\n","categories":"","description":"RPC is based on the protocol and there is no unified error code specification, so Kitex provides ErrorHandler to customize error handling.","excerpt":"RPC is based on the protocol and there is no unified error code …","ref":"/docs/kitex/tutorials/advanced-feature/error_handler/","tags":"","title":"Customize Error Handler"},{"body":"Hertz uses the open source library go-tagexpr for parameter binding and validation. The following describes the usage of parameter binding and parameter validation.\nUsage func main() { r := server.New() r.GET(\"/hello\", func(c context.Context, ctx *app.RequestContext) { // Parameter binding needs to be used with a specific go tag \ttype Test struct { A string `query:\"a\" vd:\"$!='Hertz'\"` } // BindAndValidate  var req Test err := ctx.BindAndValidate(\u0026req) ... // Bind  req = Test{} err = ctx.Bind(\u0026req) ... // Validate, need to use \"vd\" tag  err = ctx.Validate(\u0026req) ... }) ... } Supported tags and parameter binding priorities Supported tags    go tag description     path This tag is used to bind parameters on url like {:param} or {*param}. For example: if we defined route is: /v:version/example, you can specify the path parameter as the route parameter: path:\"version\". In this case if url is http://127.0.0.1:8888/v1/ , you can bind the path parameter “1”.   form This tag is used to bind the key-value of the form in request body which content-type is multipart/form-data or application/x-www-form-urlencoded   query This tag is used to bind query parameter in request   header This tag is used to bind header parameters in request   json This tag is used to bind json parameters in the request body which content-type is application/json   raw_body This tag is used to bind the original body (bytes type) of the request, and parameters can be bound even if the bound field name is not specified. (Note: raw_body has the lowest binding priority. When multiple tags are specified, once other tags successfully bind parameters, the body content will not be bound)   vd vd short for validator, The grammar of validation parameter    Parameter binding precedence path \u003e form \u003e query \u003e cookie \u003e header \u003e json \u003e raw_body  Note: If the request content-type is application/json, json unmarshal processing will be done by default before parameter binding\n Required parameter You can specify a parameter as required with keyword required in tag. Both Bind and BindAndValidate returns error when a required parameter is missing. When multiple tags contain therequired keyword, parameter with be bound in order of precedence defined above. If none of the tags bind, an error will be returned.\ntype TagRequiredReq struct { // when field hertz is missing in JSON, a required error will be return: binding: expr_path=hertz, cause=missing required parameter \tHertz string `json:\"hertz,required\"` // when field hertz is missing in both query and JSON, a required error will be return: binding: expr_path=hertz, cause=missing required parameter \tKitex string `query:\"kitex,required\" json:\"kitex,required\" ` } Common uses Customize the error of binding and validation When an error occurs in the binding parameter and the parameter validation fails, user can customize the Error（demo）For example：\n// Error implements error interface. func (e *BindError) Error() string { if e.Msg != \"\" { return e.ErrType + \": expr_path=\" + e.FailField + \", cause=\" + e.Msg } return e.ErrType + \": expr_path=\" + e.FailField + \", cause=invalid\" } type ValidateError struct { ErrType, FailField, Msg string } // Error implements error interface. func (e *ValidateError) Error() string { if e.Msg != \"\" { return e.ErrType + \": expr_path=\" + e.FailField + \", cause=\" + e.Msg } return e.ErrType + \": expr_path=\" + e.FailField + \", cause=invalid\" } func init() { CustomBindErrFunc := func(failField, msg string) error { err := BindError{ ErrType: \"bindErr\", FailField: \"[bindFailField]: \" + failField, Msg: \"[bindErrMsg]: \" + msg, } return \u0026err } CustomValidateErrFunc := func(failField, msg string) error { err := ValidateError{ ErrType: \"validateErr\", FailField: \"[validateFailField]: \" + failField, Msg: \"[validateErrMsg]: \" + msg, } return \u0026err } binding.SetErrorFactory(CustomBindErrFunc, CustomValidateErrFunc) } Customize type resolution In parameter binding, all request parameters to string or []string by default. When some field types are non-basic types or cannot be converted directly through string, you can customize type resolution（demo). For example：\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" type Nested struct { B string C string } type TestBind struct { A Nested `query:\"a,required\"` } func init() { binding.MustRegTypeUnmarshal(reflect.TypeOf(Nested{}), func(v string, emptyAsZero bool) (reflect.Value, error) { if v == \"\" \u0026\u0026 emptyAsZero { return reflect.ValueOf(Nested{}), nil } val := Nested{ B: v[:5], C: v[5:], } return reflect.ValueOf(val), nil }) } Customize the validation function You can implement complex validation logic in the vd tag by registering a custom validation function（demo)，For example：\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" func init() { binding.MustRegValidateFunc(\"test\", func(args ...interface{}) error { if len(args) != 1 { return fmt.Errorf(\"the args must be one\") } s, _ := args[0].(string) if s == \"123\" { return fmt.Errorf(\"the args can not be 123\") } return nil }) } Configure “looseZero” In some cases, the information sent from the front end is only the key but value empty, which causes cause=parameter type does not match binding data when binding a numeric type. At this time, you need to configure looseZero mode (demo). For example：\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" func init() { // Default false, take effect globally  binding.SetLooseZeroMode(true) } Configure other json unmarshal libraries When binding parameters, if the request body is json, a json unmarshal will be performed. If users need to use other json libraries (hertz uses the open source json library sonic by default), they can configure it themselves. For example:\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" func init() { // use the standard library  binding.UseStdJSONUnmarshaler() // use gjson  binding.UseGJSONUnmarshaler() // use other json unmarshal methods  binding.UseThirdPartyJSONUnmarshaler() } Set default values The parameter supports the default tag to configure the default value. For example:\n// generate code type UserInfoResponse struct { NickName string `default:\"Hertz\" json:\"NickName\" query:\"nickname\"` } Bind files Parameter binding supports binding files. For example:\n// content-type: multipart/form-data type FileParas struct { F *multipart.FileHeader `form:\"F1\"` } h.POST(\"/upload\", func(ctx context.Context, c *app.RequestContext) { var req FileParas err := binding.BindAndValidate(c, \u0026req) }) Analysis of common problems 1. string to int error: json: cannot unmarshal string into Go struct field xxx of type intxx\nReason: string and int conversion is not supported by default\nSolution：\n  We are recommended to use the string tag of the standard package json. For example：\nA int `json:\"A, string\"`   Configure other json libraries that support this operation.\n  ","categories":"","description":"","excerpt":"Hertz uses the open source library go-tagexpr for parameter binding …","ref":"/docs/hertz/tutorials/basic-feature/binding-and-validate/","tags":"","title":"Binding and validate"},{"body":"部分用户会问如何让调用端收到服务端对应的错误类型，这里解释一下，RPC 是通过协议进行通信，错误的处理也是基于协议，通常服务端返回 Error，RPC 框架统一进行错误编码返回回调用端，如果要让调用端返回和服务端一样的错误，需要定义一套错误码进行处理。但考虑到 RPC 并没有统一的错误码规范且内部的错误码不一定适用于外部用户，所以 Kitex 的开源部分没有暴露错误码定义，用户可以通过提供 ErrorHandler 来定制自己的错误处理。\n建议使用方式 ErrorHandler 通过 client/server 的 Option 配置，但通常一个微服务体系会有统一的异常处理规范，如果是企业用户建议通过 Suite 封装定制 Option，服务开发者就不用具体关注异常处理的配置。\n服务端配置 // server option server.WithErrorHandler(yourServerErrorHandler) 该函数会在服务端 handler 执行后，中间件执行前被执行，可以用于给调用端返回自定义的错误码和信息。注意，虽然对此提供了支持，但业务层面自定义的错误码依然不建议通过 ErrorHandler 处理，因为我们希望将 RPC 错误和业务的错误能够区分开，RPC 错误表示一次RPC 请求失败，比如超时、熔断、限流，从 RPC 层面是失败的请求，但业务错误属于业务逻辑层面，在 RPC 层面其实是请求成功。Kitex 会制定一个业务自定义异常规范用于区分业务错误和RPC层面错误。\n  ErrorHandler 示例：\nKitex 对 handler 返回的 error 统一封装为 kerrors.ErrBiz，如果要获取原始的 error 需要先进行 Unwrap。\n  // convert errors that can be serialized func ServerErrorHandler(err error) error { if errors.Is(err, kerrors.ErrBiz) { err = errors.Unwrap(err) } if errCode, ok := GetErrorCode(err); ok { // for Thrift、KitexProtobuf  return remote.NewTransError(errCode, err) } return err } // convert errors that can be serialized func ServerErrorHandler(err error) error { if errors.Is(err, kerrors.ErrBiz) { err = errors.Unwrap(err) } if errCode, ok := GetErrorCode(err); ok { // for gRPC  // status use github.com/cloudwego/kitex/pkg/remote/trans/nphttp2/status  return status.Errorf(errCode, err.Error()) } return err } 调用端配置 // client option client.WithErrorHandler(yourClientErrorHandler) 该 handler 在远程调用结束，中间件执行前被执行。框架有默认的 ClientErrorHandler，如果未配置将使用默认的，默认 Handler 的行为是：接收到服务端的错误返回或者调用端在传输层出现了异常，统一返回 ErrRemoteOrNetwork。另外，对于 Thrift 和 KitexProtobuf，error msg 会包含 ‘[remote]’ 信息用来标识这是对端的错误；对于 gRPC 如果对端通过 status.Error 构造的错误返回，本端使用 status.FromError(err) 可以获取 *status.Status，注意 Status 需使用 Kitex 提供的，包路径是 github.com/cloudwego/kitex/pkg/remote/trans/nphttp2/status。\n ErrorHandler 示例：  func ClientErrorHandler(err error) error { // for thrift、KitexProtobuf \tif e, ok := err.(*remote.TransError); ok { // TypeID is error code \treturn buildYourError(e.TypeID(), e) } // for gRPC  if s, ok := status.FromError(err); ok { return buildYourErrorWithStatus(s.Code(), s) } return kerrors.ErrRemoteOrNetwork.WithCause(err) } 错误码定义范围 因为部分错误码是框架内置的，所以使用者应当避开内置错误码，目前内置的错误码：\n  Thrift、KitexProtobuf：0 - 10。\n  gRPC：0 - 17。\n  ErrorHandler 执行机制 ErrorHandler 在 Middleware 中被执行，无论是调用端还是服务端 ErrorHandler 都作为最里层的 Middleware 被执行，如图所示：\n","categories":"","description":"RPC 基于协议进行通信，且 RPC 并没有统一的错误码规范，因此 Kitex 提供 ErrorHandler 来定制错误处理。","excerpt":"RPC 基于协议进行通信，且 RPC 并没有统一的错误码规范，因此 Kitex 提供 ErrorHandler 来定制错误处理。","ref":"/zh/docs/kitex/tutorials/advanced-feature/error_handler/","tags":"","title":"定制框架错误处理"},{"body":"TLS Hertz Server \u0026 Client currently only supports TLS for the standard network library, and the support for the Netpoll network library is still on the way. Usage Reference: Hertz Example and Hertz Config\nALPN ALPN can be switched on or off with a switch after TLS is enabled.(depending on whether all required protocol Servers are currently registered via Protocol Suite)\nWebSocket Hertz implements support for WebSocket based on hijack.\nHTTP2 HTTP2 is already in use in internal production environments, so please look forward to hearing from us. Please feel free to raise an issue if you need it.\n","categories":"","description":"","excerpt":"TLS Hertz Server \u0026 Client currently only supports TLS for the standard …","ref":"/docs/hertz/tutorials/basic-feature/protocol/","tags":"","title":"Protocol"},{"body":"TLS Hertz Server \u0026 Client 目前只有 标准网络库 支持 TLS，Netpoll 网络库的支持还在路上。 使用参考： Hertz 示例 和 Hertz 配置\nALPN 开启 TLS 之后，可以通过开关控制 ALPN 是否开启（依赖当前是否通过 Protocol Suite 注册了所需要的所有协议 Servers）\nWebsocket Hertz 基于hijack的方式实现了对 WebSocket 的支持。\nHTTP2 内部生产环境已在使用，如有需求可提 issue，敬请期待。\n","categories":"","description":"","excerpt":"TLS Hertz Server \u0026 Client 目前只有 标准网络库 支持 TLS，Netpoll 网络库的支持还在路上。 使用参考： …","ref":"/zh/docs/hertz/tutorials/basic-feature/protocol/","tags":"","title":"协议"},{"body":"hertz 使用开源库 go-tagexpr 进行参数的绑定及验证，下面分别介绍参数绑定和参数验证的用法。\n使用方法 func main() { r := server.New() r.GET(\"/hello\", func(c context.Context, ctx *app.RequestContext) { // 参数绑定需要配合特定的go tag使用 \ttype Test struct { A string `query:\"a\" vd:\"$!='Hertz'\"` } // BindAndValidate  var req Test err := ctx.BindAndValidate(\u0026req) ... // Bind  req = Test{} err = ctx.Bind(\u0026req) ... // Validate，需要使用 \"vd\" tag  err = ctx.Validate(\u0026req) ... }) ... } 支持的 tag 及参数绑定优先级 支持的 tag    go tag 说明     path 绑定 url 上的路径参数，相当于 hertz 路由{:param}或{*param}中拿到的参数。例如：如果定义的路由为: /v:version/example，可以把 path 的参数指定为路由参数：path:\"version\"，此时，url: http://127.0.0.1:8888/v1/example，可以绑定path参数\"1\"   form 绑定请求的 body 内容。content-type -\u003e multipart/form-data 或 application/x-www-form-urlencoded，绑定 form 的 key-value   query 绑定请求的 query 参数   header 绑定请求的 header 参数   json 绑定请求的 body 内容 content-type -\u003e application/json，绑定 json 参数   raw_body 绑定请求的原始 body(bytes)，绑定的字段名不指定，也能绑定参数。（注：raw_body 绑定优先级最低，当指定多个 tag 时，一旦其他 tag 成功绑定参数，则不会绑定 body 内容。）   vd 参数校验，校验语法    参数绑定优先级 path \u003e form \u003e query \u003e cookie \u003e header \u003e json \u003e raw_body  注：如果请求的 content-type 为 application/json，那么会在参数绑定前做一次 json unmarshal 处理作为兜底。\n 必传参数 通过在 tag 中添加 required，可以将参数标记为必传。当绑定失败时 Bind 和 BindAndValidate 将会返回错误。当多个 tag 包含 required 时，将会按照优先级绑定。如果所有 tag 都没有绑定上，则会返回错误。\ntype TagRequiredReq struct { // 当 JSON 中没有 hertz 字段时，会返回 required 错误：binding: expr_path=hertz, cause=missing required parameter \tHertz string `json:\"hertz,required\"` // 当 query 和 JSON 中同时没有 kitex 字段时，会返回 required 错误：binding: expr_path=hertz, cause=missing required parameter\" \tKitex string `query:\"kitex,required\" json:\"kitex,required\" ` } 常见用法 自定义 bind 和 validate 的 Error 绑定参数发生错误和参数校验失败的时候，用户可以自定义的 Error（demo ），使用方法如下：\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" type BindError struct { ErrType, FailField, Msg string } // Error implements error interface. func (e *BindError) Error() string { if e.Msg != \"\" { return e.ErrType + \": expr_path=\" + e.FailField + \", cause=\" + e.Msg } return e.ErrType + \": expr_path=\" + e.FailField + \", cause=invalid\" } type ValidateError struct { ErrType, FailField, Msg string } // Error implements error interface. func (e *ValidateError) Error() string { if e.Msg != \"\" { return e.ErrType + \": expr_path=\" + e.FailField + \", cause=\" + e.Msg } return e.ErrType + \": expr_path=\" + e.FailField + \", cause=invalid\" } func init() { CustomBindErrFunc := func(failField, msg string) error { err := BindError{ ErrType: \"bindErr\", FailField: \"[bindFailField]: \" + failField, Msg: \"[bindErrMsg]: \" + msg, } return \u0026err } CustomValidateErrFunc := func(failField, msg string) error { err := ValidateError{ ErrType: \"validateErr\", FailField: \"[validateFailField]: \" + failField, Msg: \"[validateErrMsg]: \" + msg, } return \u0026err } binding.SetErrorFactory(CustomBindErrFunc, CustomValidateErrFunc) } 自定义类型解析 在参数绑定的时候，所有的 request 参数都是 string 或者 []string；当有一些 field 的类型为非基础类型或者无法直接通过 string 转换，则可以自定义类型解析（demo ）。使用方法如下:\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" type Nested struct { B string C string } type TestBind struct { A Nested `query:\"a,required\"` } func init() { binding.MustRegTypeUnmarshal(reflect.TypeOf(Nested{}), func(v string, emptyAsZero bool) (reflect.Value, error) { if v == \"\" \u0026\u0026 emptyAsZero { return reflect.ValueOf(Nested{}), nil } val := Nested{ B: v[:5], C: v[5:], } return reflect.ValueOf(val), nil }) } 自定义验证函数 可以通过注册自定义验证函数，在’vd’注解中实现复杂的验证逻辑（demo ），使用方法如下：\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" func init() { binding.MustRegValidateFunc(\"test\", func(args ...interface{}) error { if len(args) != 1 { return fmt.Errorf(\"the args must be one\") } s, _ := args[0].(string) if s == \"123\" { return fmt.Errorf(\"the args can not be 123\") } return nil }) } 配置 looseZero 在一些场景下，前端有时候传来的信息只有 key 没有 value，这会导致绑定数值类型的时候，会报错 cause=parameter type does not match binding data。 这时需要配置 looseZero 模式（demo ），使用方法如下：\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" func init() { // 默认false，全局生效  binding.SetLooseZeroMode(true) } 配置其他 json unmarshal 库 在绑定参数的时候，如果请求体为 json，会进行一次 json 的 unmarshal，如果用户需要使用特定的 json 库可以自己配置（hertz 默认使用开源 json 库 sonic ）。使用方法如下：\nimport \"github.com/cloudwego/hertz/pkg/app/server/binding\" func init() { // 使用标准库  binding.UseStdJSONUnmarshaler() // 使用gjson  binding.UseGJSONUnmarshaler() // 使用第三方json unmarshal方法  binding.UseThirdPartyJSONUnmarshaler() } 设置默认值 参数支持 “default” tag 进行默认值的配置，使用方法如下：\n// 生成的代码 type UserInfoResponse struct { NickName string `default:\"Hertz\" json:\"NickName\" query:\"nickname\"` } 绑定文件 参数绑定支持绑定文件，使用方法如下：\n// 需要请求的content-type为：multipart/form-data type FileParas struct { F *multipart.FileHeader `form:\"F1\"` } h.POST(\"/upload\", func(ctx context.Context, c *app.RequestContext) { var req FileParas err := binding.BindAndValidate(c, \u0026req) }) 常见问题分析 1. string 转 int 报错：json: cannot unmarshal string into Go struct field xxx of type intxx\n原因：默认不支持 string 和 int 互转\n解决方法：\n 建议使用标准包 json 的 string tag, 例如： A int `json:\"A, string\"`  配置其他支持这种行为的 json 库  ","categories":"","description":"","excerpt":"hertz 使用开源库 go-tagexpr 进行参数的绑定及验证，下面分别介绍参数绑定和参数验证的用法。\n使用方法 func main() …","ref":"/zh/docs/hertz/tutorials/basic-feature/binding-and-validate/","tags":"","title":"绑定与校验"},{"body":"会议主题： CloudWeGo 社区会议 4.8\n参会人员： YangruiEmma, liu-song, yccpt, AshleeT, GuangmingLuo, CoderPoet, HeyJavaBean, jayantxie, JZK-Keven, Xiwen Li, joway, bodhisatan\n会前必读： http://www.cloudwego.io/; https://github.com/cloudwego\n议程 1 ：新成员自我介绍 内容：一位社区新成员进行简要的自我介绍，主要包含个人基本情况、个人未来规划。\n议程 2 ：Kitex 单测任务进展介绍  没有提交 PR 的同学可以尽早提交 PR，便于后续相关同学进行 review。 后期会为大家邮寄礼品。  议程 3 ：Kitex 4月发版计划  发版时间：4 月 28 日，发布中版本。 4 月 20 日前，各变更需完成独立的功能验证和性能测试；如无特殊情况， 4 月 22 日前，完成所有变更合并，然后进入整体的功能验证和性能测试阶段。  议程 4 ：Q\u0026A Q：社区后续工作规划有哪些？\nA：可以参考前期的会议纪要：https://github.com/cloudwego/community/tree/main/meeting_notes ， 以及 Kitex 的 RoadMap: https://github.com/cloudwego/kitex/blob/develop/ROADMAP.md 。 其它的规划还包括：1. 推进 xDS 的对接实现； 2. Kitex 对接支持业界开源服务治理能力和云平台。\n","categories":"","description":"","excerpt":"会议主题： CloudWeGo 社区会议 4.8\n参会人员： YangruiEmma, liu-song, yccpt, AshleeT, …","ref":"/zh/community/meeting_notes/2022-04-08/","tags":"","title":"CloudWeGo 社区会议 4.8"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/kitex/tutorials/code-gen/","tags":"","title":"Code Generation"},{"body":"Below is a simple example that randomly rejects 1% of all requests through self-defined access control logic:\npackage myaccesscontrol import ( \"math/rand\" \"github.com/cloudwego/kitex/pkg/acl\" ) var errRejected = errors.New(\"1% rejected\") // Implements a judge function. func reject1percent(ctx context.Context, request interface{}) (reason error) { if rand.Intn(100) == 0 { return errRejected // an error should be returned when a request is rejected  } return nil } var MyMiddleware = acl.NewACLMiddleware(reject1percent) // create the middleware Then, you can enable this middleware with WithMiddleware(myaccesscontrol.MyMiddleware) at the creation of a client or a server.\n","categories":"","description":"Kitex provides a simple middleware builder that supports self-defined access control logic to reject requests under certain conditions.","excerpt":"Kitex provides a simple middleware builder that supports self-defined …","ref":"/docs/kitex/tutorials/service-governance/access_control/","tags":"","title":"Customized Access Control"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/kitex/reference/","tags":"","title":"Reference"},{"body":"kitex-contrib has provided multiple service discovery extensions: DNS, ETCD, ZooKeeper, Eureka, Consul, Nacos, Polaris.\nIf you want to adopt other service discovery protocol, you can implement the Resolver interface, and clients can inject it by WithResolver Option.\nInterface Definition The interface is defined in pkg/discovery/discovery.go and is defined as follows:\ntype Resolver interface { Target(ctx context.Context, target rpcinfo.EndpointInfo) string Resolve(ctx context.Context, key string) (Result, error) Diff(key string, prev, next Result) (Change, bool) Name() string } type Result struct { Cacheable bool // if can be cached  CacheKey string // the unique key of cached result  Instances []Instance // the result of service discovery } // the diff result type Change struct { Result Result Added []Instance Updated []Instance Removed []Instance } Resolver interface detail:\n Resolve: as the core method of Resolver, it obtains the service discovery result from target key Target: it resolves the unique target endpoint that from the downstream endpoints provided by Resolve, and the result will be used as the unique key of the cache Diff: it is used to compare the discovery results with the last time. The differences in results are used to notify other components, such as loadbalancer and circuitbreaker, etc Name: it is used to specify a unique name for Resolver, and will use it to cache and reuse Resolver  Usage Example You need to implement the the Resolver interface, and using it by Option:\nimport ( \"xx/kitex/client\" ) func main() { opt := client.WithResolver(YOUR_RESOLVER) // new client  xxx.NewClient(\"destServiceName\", opt) } Attention To improve performance, Kitex reusing Resolver, so the Resolver method implementation must be concurrent security.\n","categories":"","description":"","excerpt":"kitex-contrib has provided multiple service discovery extensions: DNS, …","ref":"/docs/kitex/tutorials/framework-exten/service_discovery/","tags":"","title":"Service Discovery Extension"},{"body":"Specify RPC Host and Port You can use callopt.WithHostPort to specify host and port, supports two parameters:\n Normal IP address, in the form of host:port, support IPv6 Sock file address, communicating with UDS (Unix Domain Socket)  import \"github.com/cloudwego/kitex/client/callopt\" ... resp, err := cli.Echo(context.Background(), req, callopt.WithHostPort(\"127.0.0.1:8888\")) if err != nil { log.Fatal(err) } Specify RPC URL You can use callopt.WithURL to specify a URL, which will be resolved by default DNS resolver to get host and port. It’s functionally equal to callopt.WithHostPort.\nimport \"github.com/cloudwego/kitex/client/callopt\" ... url := callopt.WithURL(\"http://myserverdomain.com:8888\") resp, err := cli.Echo(context.Background(), req, url) if err != nil { log.Fatal(err) } Customized DNS resolver You can also use your own DNS resolver\nresolver interface(pkg/http)：\ntype Resolver interface { Resolve(string) (string, error) } The only parameter is URL，return value should be “host:port”.\nYou can use client.WithHTTPResolver to specify DNS resolver.\nimport \"github.com/cloudwego/kitex/client/callopt\" ... dr := client.WithHTTPResolver(myResolver) cli, err := echo.NewClient(\"echo\", dr) if err != nil { log.Fatal(err) } ","categories":"","description":"Kitex can opt for direct access without service discovery when the downstream address is clear.","excerpt":"Kitex can opt for direct access without service discovery when the …","ref":"/docs/kitex/tutorials/basic-feature/visit_directly/","tags":"","title":"Visit Directly"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/kitex/reference/","tags":"","title":"参考"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/kitex/tutorials/code-gen/","tags":"","title":"代码生成"},{"body":"kitex-contrib 中已经提供了多种服务发现扩展：DNS, ETCD, ZooKeeper, Eureka, Consul, Nacos, Polaris。\n用户如果需要更换其他的服务发现，用户可以根据需求实现 Resolver  接口，client 通过 WithResolver Option 来注入。\n接口定义 接口在 pkg/discovery/discovery.go 中，具体定义如下：\n// 服务发现接口定义 type Resolver interface { Target(ctx context.Context, target rpcinfo.EndpointInfo) string Resolve(ctx context.Context, key string) (Result, error) Diff(key string, prev, next Result) (Change, bool) Name() string } type Result struct { Cacheable bool // 是否可以缓存  CacheKey string // 缓存的唯一 key  Instances []Instance // 服务发现结果 } // diff 的结果 type Change struct { Result Result Added []Instance Updated []Instance Removed []Instance } Resolver 接口定义如下:\n Resolve：作为 Resolver 的核心方法， 从 target key 中获取我们需要的服务发现结果 Result。 Target：从 Kitex 提供的对端 EndpointInfo 中解析出 Resolve 需要使用的唯一 target, 同时这个 target 将作为缓存的唯一 key。 Diff：用于计算两次服务发现的变更， 计算结果一般用于通知其他组件， 如 loadbalancer 和熔断等， 返回的是变更 Change。 Name：用于指定 Resolver 的唯一名称， 同时 Kitex 会用它来缓存和复用 Resolver。  自定义 Resolver 首先需要实现 Resolver 接口需要的方法， 通过配置项指定 Resolver。\nKitex 提供了 Client 初始化配置项 :\nimport ( \"xx/kitex/client\" ) func main() { opt := client.WithResolver(YOUR_RESOLVER) // new client  xxx.NewClient(\"destServiceName\", opt) } 注意事项  我们通过复用 Resolver 的方式来提高性能， 要求 Resolver 的方法实现需要是并发安全的。  ","categories":"","description":"","excerpt":"kitex-contrib 中已经提供了多种服务发现扩展：DNS, ETCD, ZooKeeper, Eureka, Consul, …","ref":"/zh/docs/kitex/tutorials/framework-exten/service_discovery/","tags":"","title":"服务发现扩展"},{"body":"指定 IP 和 Port 进行调用 在进行调用时，可以通过 callopt.WithHostPort 指定，支持两种参数:\n 普通 IP 地址，形式为 “host:port”，支持 IPv6 sock 文件地址，通过 UDS (Unix Domain Socket) 通信  import \"github.com/cloudwego/kitex/client/callopt\" ... resp, err := cli.Echo(context.Background(), req, callopt.WithHostPort(\"127.0.0.1:8888\")) if err != nil { log.Fatal(err) } 指定 URL 进行调用 在进行调用时，可以通过 callopt.WithURL 指定，通过该 option 指定的 URL，会经过默认的 DNS resolver 解析后拿到 host 和 port，此时其等效于 callopt.WithHostPort。\nimport \"github.com/cloudwego/kitex/client/callopt\" ... url := callopt.WithURL(\"http://myserverdomain.com:8888\") resp, err := cli.Echo(context.Background(), req, url) if err != nil { log.Fatal(err) } 自定义 DNS resolver 此外也可以自定义 DNS resolver\nresolver 定义如下 (pkg/http)：\ntype Resolver interface { Resolve(string) (string, error) } 参数为 URL，返回值为访问的 server 的 “host:port”。\n通过 client.WithHTTPResolver 指定用于 DNS 解析的 resolver。\nimport \"github.com/cloudwego/kitex/client/callopt\" ... dr := client.WithHTTPResolver(myResolver) cli, err := echo.NewClient(\"echo\", dr) if err != nil { log.Fatal(err) } ","categories":"","description":"在明确要访问某个下游地址时，Kitex 可以选择直连访问的方式，不需要经过服务发现。","excerpt":"在明确要访问某个下游地址时，Kitex 可以选择直连访问的方式，不需要经过服务发现。","ref":"/zh/docs/kitex/tutorials/basic-feature/visit_directly/","tags":"","title":"直连访问"},{"body":"下面是一个简单的例子，通过自定义访问控制的逻辑，随机拒绝 1% 的请求：\npackage myaccesscontrol import ( \"math/rand\" \"github.com/cloudwego/kitex/pkg/acl\" ) var errRejected = errors.New(\"1% rejected\") // 实现一个判断函数 func reject1percent(ctx context.Context, request interface{}) (reason error) { if rand.Intn(100) == 0 { return errRejected // 拒绝请求时，需要返回一个错误  } return nil } var MyMiddleware = acl.NewACLMiddleware(reject1percent) // 创建中间件 随后，你可以在创建 client 或者 server 的时候，通过 WithMiddleware(myaccesscontrol.MyMiddleware) 启用该中间件。\n","categories":"","description":"Kitex 框架提供了一个简单的中间件构造器，可以支持用户自定义访问控制的逻辑，在特定条件下拒绝请求。","excerpt":"Kitex 框架提供了一个简单的中间件构造器，可以支持用户自定义访问控制的逻辑，在特定条件下拒绝请求。","ref":"/zh/docs/kitex/tutorials/service-governance/access_control/","tags":"","title":"自定义访问控制"},{"body":"Next, let’s look at how to add middleware to Volo.\nFor example, if we need a middleware that prints out the received requests, the returned responses and the elapsed time, we could write a Service in lib.rs:\n#[derive(Clone)]pubstruct LogService\u003cS\u003e(S);#[volo::service]impl\u003cCx,Req,S\u003evolo::Service\u003cCx,Req\u003eforLogService\u003cS\u003ewhereReq: Send +'static,S: Send +'static+volo::Service\u003cCx,Req\u003e+Sync,Cx: Send +'static,{asyncfn call(\u0026self,cx: \u0026mutCx,req: Req)-\u003e Result\u003cS::Response,S::Error\u003e{letnow=std::time::Instant::now();letresp=self.0.call(cx,req).await;tracing::info!(\"Request took {}ms\",now.elapsed().as_millis());resp}}Then we wrap a Layer around the Service:\npubstruct LogLayer;impl\u003cS\u003evolo::Layer\u003cS\u003eforLogLayer{type Service=LogService\u003cS\u003e;fn layer(self,inner: S)-\u003e Self::Service{LogService(inner)}}Finally, we add this Layer to client and server:\nusevolo_example::LogLayer;// client.rs staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example\").layer_outer(LogLayer).address(addr).build()};// server.rs Server::new().add_service(ServiceBuilder::new(volo_gen::volo::example::ItemServiceServer::new(S)).build()).layer_front(LogLayer).run(addr).await.unwrap();At this point, it prints out how long the request took at the INFO log level.\n","categories":"","description":"","excerpt":"Next, let’s look at how to add middleware to Volo.\nFor example, if we …","ref":"/docs/volo/volo-grpc/getting-started/part_4/","tags":"","title":"Part 4. Add a Middleware"},{"body":"Next, let’s look at how to add middleware to Volo.\nFor example, if we need a middleware that prints out the received requests, the returned responses and the elapsed time, we could write a Service in lib.rs:\n#[derive(Clone)]pubstruct LogService\u003cS\u003e(S);#[volo::service]impl\u003cCx,Req,S\u003evolo::Service\u003cCx,Req\u003eforLogService\u003cS\u003ewhereReq: std::fmt::Debug+Send+'static,S: Send +'static+volo::Service\u003cCx,Req\u003e+Sync,S::Response: std::fmt::Debug,S::Error: std::fmt::Debug,Cx: Send +'static,{asyncfn call(\u0026self,cx: \u0026mutCx,req: Req)-\u003e Result\u003cS::Response,S::Error\u003e{letnow=std::time::Instant::now();tracing::debug!(\"Received request {:?}\",\u0026req);letresp=self.0.call(cx,req).await;tracing::debug!(\"Sent response {:?}\",\u0026resp);tracing::info!(\"Request took {}ms\",now.elapsed().as_millis());resp}}Then we wrap a Layer around the Service:\npubstruct LogLayer;impl\u003cS\u003evolo::Layer\u003cS\u003eforLogLayer{type Service=LogService\u003cS\u003e;fn layer(self,inner: S)-\u003e Self::Service{LogService(inner)}}Finally, we add this Layer to client and server:\nusevolo_example::LogLayer;// client.rs staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example\").layer_outer(LogLayer).address(addr).build()};// server.rs volo_gen::volo::example::ItemServiceServer::new(S).layer_front(LogLayer).run(addr).await.unwrap();At this point, at the INFO log level, it prints out how long the request took; At the DEBUG logging level, it also types the details of the request and response.\n","categories":"","description":"","excerpt":"Next, let’s look at how to add middleware to Volo.\nFor example, if we …","ref":"/docs/volo/volo-thrift/getting-started/part_4/","tags":"","title":"Part 4. Add a Middleware"},{"body":"Wrong setting of NumLoops If your server is running on a physical machine, the number of P created by the Go process is equal to the number of CPUs of the machine. But the server may not use so many cores. In this case, too many pollers will cause performance degradation.\nThere are several solutions:\n Use the taskset command to limit CPU usage, such as:  taskset -c 0-3 $run_your_server Actively set the number of P, for instance:  package main import ( \"runtime\" ) func init() { runtime.GOMAXPROCS(num_you_want) } Actively set the number of pollers, e.g:  package main import ( \"github.com/cloudwego/netpoll\" ) func init() { netpoll.SetNumLoops(num_you_want) } ","categories":"","description":"","excerpt":"Wrong setting of NumLoops If your server is running on a physical …","ref":"/docs/netpoll/caution/","tags":"","title":"Caution"},{"body":"cwgo integrates gorm/gen to help users generate Model code and basic CURD code.\nBasic commands Use cwgo model -h to view usage details\nNAME: cwgo model-generate DB model Examples: # Generate DB model code cwgo model --db_type mysql --dsn \"gorm:gorm@tcp(localhost:9910)/gorm?charset=utf8\u0026parseTime=True\u0026loc=Local\" USAGE: cwgo model [command options] [arguments...] OPTIONS: --dsn value Specify the database source name. (https://gorm.io/docs/connecting_to_the_database.html) --db_type value Specify database type. (mysql or sqlserver or sqlite or postgres) (default: mysql) --out_dir value Specify output directory (default: biz/dao/query) --out_file value Specify output filename (default: gen.go) --tables value [ --tables value ] Specify databases tables --unittest Specify generate unit test (default: false) --only_model Specify only generate model code (default: false) --model_pkg value Specify model package name --nullable Specify generate with pointer when field is nullable (default: false) --type_tag Specify generate field with gorm column type tag (default: false) --index_tag Specify generate field with gorm index tag (default: false) --help, -h show help (default: false) Specification  --dsn value specify database DSN --db_type value specifies the database type (mysql or sqlserver or sqlite or postgres) (default mysql) --out_dir value specifies the output directory path, the default is biz/dao/query --out_file value specify the output file name, the default is gen.go --tables value specifies the database table, the default is the full table --unittest specifies whether to generate unit tests, the default is false --only_model specifies whether to generate only model, default is false --model_pkg value specifies the package name of the model --nullable specifies whether the generated field is a pointer when the field is nullable, the default is false --type_tag specifies whether to generate gorm's type tag for the specified field, the default is false --index_tag specifies whether to generate gorm's index tag for the specified field, the default is false Example cwgo model --db_type mysql --dsn \"gorm:gorm@tcp(localhost:9910)/gorm?charset=utf8\u0026parseTime=True\u0026loc=Local\" ","categories":"","description":"","excerpt":"cwgo integrates gorm/gen to help users generate Model code and basic …","ref":"/docs/cwgo/tutorials/db/","tags":"","title":"DB"},{"body":"cwgo 集成了 gorm/gen 用于帮助用户生成 Model 代码以及基础的 CURD 代码。\n基础命令 使用 cwgo model -h 查看使用详情\nNAME: cwgo model - generate DB model Examples: # Generate DB model code cwgo model --db_type mysql --dsn \"gorm:gorm@tcp(localhost:9910)/gorm?charset=utf8\u0026parseTime=True\u0026loc=Local\" USAGE: cwgo model [command options] [arguments...] OPTIONS: --dsn value Specify the database source name. (https://gorm.io/docs/connecting_to_the_database.html) --db_type value Specify database type. (mysql or sqlserver or sqlite or postgres) (default: mysql) --out_dir value Specify output directory (default: biz/dao/query) --out_file value Specify output filename (default: gen.go) --tables value [ --tables value ] Specify databases tables --unittest Specify generate unit test (default: false) --only_model Specify only generate model code (default: false) --model_pkg value Specify model package name --nullable Specify generate with pointer when field is nullable (default: false) --type_tag Specify generate field with gorm column type tag (default: false) --index_tag Specify generate field with gorm index tag (default: false) --help, -h show help (default: false) 详细参数  --dsn value 指定数据库DSN --db_type value 指定数据库类型(mysql or sqlserver or sqlite or postgres) (默认 mysql) --out_dir value 指定输出目录路径，默认为 biz/dao/query --out_file value 指定输出文件名，默认为 gen.go --tables value 指定数据库表，默认为全表 --unittest 指定是否生成单测，默认为 false --only_model 指定是否生成仅 model，默认为 false --model_pkg value 指定 model 的包名 --nullable 指定生成字段是否为指针当字段为 nullable，默认为 false --type_tag 指定字段是否生成 gorm 的 type tag，默认为 false --index_tag 指定字段是否生成 gorm 的 index tag，默认为 false 用法示例 cwgo model --db_type mysql --dsn \"gorm:gorm@tcp(localhost:9910)/gorm?charset=utf8\u0026parseTime=True\u0026loc=Local\" ","categories":"","description":"","excerpt":"cwgo 集成了 gorm/gen 用于帮助用户生成 Model 代码以及基础的 CURD 代码。\n基础命令 使用 cwgo model …","ref":"/zh/docs/cwgo/tutorials/db/","tags":"","title":"DB"},{"body":"High Memory Usage Connections not Closing due to Client Non-standard Usage If the client initiates a large number of connections without closing them, there will be a large waste of resources in extreme cases, which can cause high memory usage problems over time.\nSolution\nConfigure idleTimeout reasonably. Hertz Server will close the connection to ensure the stability of the server after the timeout. The default configuration is 3 minutes.\nVast Request/Response  If the request and response are very large, the data will all enter the memory, causing great pressure on it, when stream and chunk are not used. The streaming under the netpoll network library is a fake streaming. Since netpoll uses the LT trigger mode, it will trigger netpoll to read data when data arrives. The Reader interface is not implemented in terms of interface design. To enable streaming, Hertz encapsulates netpoll as a Reader, but the data still enters memory uncontrollably, so in a case of very vast streaming requests, memory pressure can result.  Solution\nFor very vast requests cases, use a combination of streaming and go net.\nCommon Error Code Checking If the framework reports the following error codes, you can check it for possible causes. If there is an error code other than the following, the error code is not caused by the framework and needs to be located by the user to see whether it is set by itself or by some middleware.\n404  Access to the wrong port, commonly access to the debug port.  Solution: Distinguish between listening port for framework service and listening port for debug server, the default is 8888.   No routes matched  Check whether all expected routes are registered correctly based on the startup log. Check that the access method is correct.    417 The server returns false after executing the custom ContinueHandler (the server actively rejects the subsequent body of the 100 Continue).\n500  Throwing the panic in middleware or in handlerFunc.  Solution: Locate specific problems with panic stack information.   In the fs case, the path carries /../, and unexpected files may be accessed. The error log in server app log: cannot serve path with '/../' at position %d due to security reasons: %q.  Solution: Check for illegal requests.    Context Guide Description Hertz also provides a standard context.Content and a request context as input arguments to the function in the HandleFunc Design. The handler/middleware function signature is:\ntype HandlerFunc func(c context.Context, ctx *RequestContext) Metadata Storage Both contexts have the ability to store values, which is a simple principle for choosing which one to use: the life cycle of the stored value and the selected context to match.\nSpecifics\nThe ctx is primarily used to store request-level variables, which are recycled after the request ends. It is characterized by high query efficiency (the bottom is map), unsafe coroutines and the context.Context Interface is not implemented. c is passed as the context between middleware /handler. With all the semantics of context.Content and safe coroutine. All that requires the context.Content interface as input arguments, just pass c directly.\nIn addition, Hertz also provides the ctx.Copy() interface to make it easier for businesses to obtain a copy of the safe coroutine if they are faced with cases where they must pass ctx asynchronously.\nNumeric Precision Problem Description  JavaScript’s numeric type will lose precision once the number exceeds the limit, which will lead to inconsistencies between the front and back end values.  var s = '{\"x\":6855337641038665531}'; var obj = JSON. parse(s); alert(obj.x); // Output 6855337641038666000 In the JSON specification, integers and floating-point types are not distinguished for numeric types.When using json.Unmarshal for JSON deserialization, if no data type is specified, interface{} is used as the receiving variable, and float64 is used as the accepted type of the number by default. When the precision of the number exceedsWhen the precision range that float can represent, it will cause the problem of loss of precision.  Solution  Use the string tag of the json standard package.  package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) type User struct { ID int `json:\"id,string\"` } func main() { h := server.Default() h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { var u User u.ID = 6855337641038665531 c.JSON(consts.StatusOK, u) }) h.Spin() } Using json.Number  package main import ( \"context\" \"encoding/json\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) type User struct { ID json.Number `json:\"id\"` } func main() { h := server.Default() h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { var u User err := json.Unmarshal([]byte(`{\"id\":6855337641038665531}`), \u0026u) if err != nil { panic(err) } c.JSON(consts.StatusOK, u) }) h.Spin() } ","categories":"","description":"","excerpt":"High Memory Usage Connections not Closing due to Client Non-standard …","ref":"/docs/hertz/faq/","tags":"","title":"FAQ"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/volo/guide/","tags":"","title":"Guide"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/netpoll/","tags":"","title":"Netpoll"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/netpoll/","tags":"","title":"Netpoll"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/tutorials/service-governance/","tags":"","title":"Service Governance"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/releases/volo/","tags":"","title":"Volo Release"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/blog/releases/volo/","tags":"","title":"Volo Release"},{"body":"前言 基于 TTHeader，我们提供了在协议头传递一些元信息的能力。\n尽管这种能力很方便，我们仍然不推荐业务使用这种能力进行大量信息的传递或者作为通用的参数传递方式，原因如下：\n 这并不符合 API 的规范，纯粹是实现强相关的行为； 这样的话，使用 Thrift / Protobuf IDL 定义并约束 RPC API 就没有意义了； TTHeader 对于头部信息总大小有限制（64K），如果略大就可能导致传输直接失败，而如果大量采用这个方法进行传递，早晚有一天会达到上限，并导致所有 RPC 请求均失败； 这种方式性能差，无论是实现上的性能还是传递时每一跳都会额外消耗的资源； 可以想象一下如果\u0008所有业务都通过这种方式来透传字段，未来的可维护性几乎为零，且无法收敛。  方案介绍 针对正向传递（从上游往下游传递），我们提供了两种方式：\n Persistent：这类元信息会沿着调用链路一直向下透传，直到被某一跳中主动删除（不推荐大量使用） Transient：这类元信息仅会透传一跳，也即到当前服务的下游（首选这种方式）  针对反向传递（从下游返回给上游），我们仅提供一种方式：Transient（也就是仅会返回一跳）。我们不认为从最底层的服务一直返回并透传给最上层服务某个元信息是合理的需求和场景。 如果真的有这种需求，请直接把相关字段定义在 IDL 中并显式返回。\n使用 Volo-Thrift 使用这个功能，需要使用 TTHeader 协议；Volo-gRPC 没有额外要求。\n如果你的场景中，是由 Volo-Thrift server 生成的脚手架代码作为入口的，那么你可以直接引入对应的 Trait 并进行获取或者设置：\nusemetainfo::{Backward,Forward};pubstruct S;#[volo::async_trait]implvolo_gen::volo::example::ItemServiceforS{asyncfn get_item(\u0026self,req: volo_gen::volo::example::GetItemRequest,)-\u003e Result\u003cvolo_gen::volo::example::GetItemResponse,pilota::AnyhowError\u003e{metainfo::METAINFO.with(|mi|{letmutmi=mi.borrow_mut();println!(\"{:?}, {:?}\",mi.get_all_persistents(),mi.get_all_upstreams());mi.set_backward_transient(\"test_backward\",\"test_backward_value\");});Ok(Default::default())}}如果你是自己写的 main 函数并使用 client 调用，那么首先你需要把 MetaInfo 塞到 task local 中：\nuselazy_static::lazy_static;usemetainfo::{Backward,Forward,MetaInfo,METAINFO};usestd::{cell::RefCell,net::SocketAddr};usevolo_example::LogLayer;lazy_static!{staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example-item\").layer_outer(LogLayer).address(addr).build()};}#[volo::main]asyncfn main(){letmutmi=MetaInfo::new();mi.set_persistent(\"test_persistent_key\",\"test_persistent\");mi.set_transient(\"test_transient_key\",\"test_transient\");METAINFO.scope(RefCell::new(mi),asyncmove{letreq=volo_gen::volo::example::GetItemRequest{id: 1024};letresp=CLIENT.get_item(req).await;matchresp{Ok(info)=\u003etracing::info!(\"{:?}\",info),Err(e)=\u003etracing::error!(\"{:?}\",e),}METAINFO.with(|mi|{println!(\"{:?}\",mi.borrow().get_all_backward_downstreams());})}).await;}当然，如果你的 client 调用是从 server 接收到请求之后进行的，那么不用自己进行 metainfo task local 的设置，Volo-Thrift 框架会自动帮你设置好这些值。\n总结 简单来说，步骤分为以下几步：\n 确定你当前有 METAINFO 的 task local（server 的方法中默认就有，不需要自己创建）； 引入 metainfo 中的 trait； 调用对应的方法设置、获取值。  第三方框架接入 如果想与其它的框架（如 HTTP 框架）集成元信息传递功能，只需要遵守 metainfo 包中定义的 header 常量字符串即可。\nCloudWeGo 开源的 Kitex、Hertz 框架默认支持也支持元信息传递的规范。\n","categories":"","description":"","excerpt":"前言 基于 TTHeader，我们提供了在协议头传递一些元信息的能力。\n尽管这种能力很方便，我们仍然不推荐业务使用这种能力进行大量信息的传递 …","ref":"/zh/docs/volo/guide/metadata/","tags":"","title":"元信息传递"},{"body":"内存使用率高 客户端不规范使用没有关连接 如果 Client 侧发起大量连接而不关闭的话，极端情况下会有较大的资源浪费，随着时间的增长，可能会造成内存使用率高的问题。\n解决办法\n合理配置 idleTimeout，超时后 Hertz Server 会把连接关掉保证 Server 侧的稳定性。默认配置为3分钟。\n超大请求/响应  如果请求和响应非常大，并且没有使用一些其他发送模式如 stream、chunk 时，数据会全部进入内存，给内存造成较大压力。 netpoll 网络库下的流式为假流式。由于 netpoll 使用 LT 触发模式，当数据到达时，会触发 netpoll 读取数据；在接口设计上，也因此没有实现 Reader 接口。为了实现流式的能力，Hertz 将 netpoll 封装为 Reader，但其本身数据仍然不可控的进入了内存，所以在超大流式请求的情况下，可能会造成内存压力。  解决办法\n超大请求的场景下，使用流式 + go net 的组合。\n常见错误码排查 如果框架报以下的错误码，可以按照可能原因进行排查。如果出现非以下错误码，则不是框架打出来的，需要由使用方定位一下是否自行设置或者由某些中间件设置了错误码。\n404  访问到了错误的端口上了，常见访问到了 debug 端口  解决方案：区分框架服务的监听端口和 debug server 的监听端口，默认:8888   未匹配到路由  根据启动日志查看是否所有预期路由都正常注册 查看访问方法是否正确    417 server 在执行完自定义的 ContinueHandler 之后返回 false（server 主动拒绝掉 100 Continue 后续的 body）。\n500  中间件或者 handlerFunc 中抛 panic  解决方案：panic 栈信息定位具体问题   fs 场景 path 携带 /../，可能出现访问预期之外的文件，server 端 app log 中伴随错误日志：cannot serve path with '/../' at position %d due to security reasons: %q。  解决方案：检查是否存在非法请求    上下文使用指南 说明 Hertz 在 HandlerFunc 设计上，同时提供了一个标准 context.Context 和一个请求上下文作为函数的入参。 handler/middleware 函数签名为：\ntype HandlerFunc func(c context.Context, ctx *RequestContext) 元数据存储方面 两个上下文都有储值能力，使用时具体选择哪一个的简单依据：所储存值的生命周期和所选择的上下文要匹配。\n具体细节\nctx 主要用来存储请求级别的变量,请求结束就回收了，特点是查询效率高（底层是 map），协程不安全，且未实现 context.Context 接口。 c 作为上下文在中间件 /handler 之间传递。拥有 context.Context 的所有语义，协程安全。所有需要 context.Context 接口作为入参的地方，直接传递 c 即可。\n除此之外，如果面对一定要异步传递 ctx 的场景，hertz 也提供了 ctx.Copy() 接口，方便业务能够获取到一个协程安全的副本。\n精度丢失问题 说明  JavaScript 的数字类型一旦数字超过限值时将会丢失精度，进而导致前后端的值出现不一致。  var s = '{\"x\":6855337641038665531}'; var obj = JSON.parse(s); alert (obj.x); // Output 6855337641038666000 在 JSON 的规范中，对于数字类型是不区分整形和浮点型的。 在使用 json.Unmarshal 进行 JSON 的反序列化的时候，如果没有指定数据类型，使用 interface{} 作为接收变量，将默认采用 float64 作为其数字的接受类型，当数字的精度超过float能够表示的精度范围时就会造成精度丢失的问题。  解决办法  使用 json 标准包的 string tag。  package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) type User struct { ID int `json:\"id,string\"` } func main() { h := server.Default() h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { var u User u.ID = 6855337641038665531 c.JSON(consts.StatusOK, u) }) h.Spin() } 使用 json.Number  package main import ( \"context\" \"encoding/json\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) type User struct { ID json.Number `json:\"id\"` } func main() { h := server.Default() h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { var u User err := json.Unmarshal([]byte(`{\"id\":6855337641038665531}`), \u0026u) if err != nil { panic(err) } c.JSON(consts.StatusOK, u) }) h.Spin() } ","categories":"","description":"","excerpt":"内存使用率高 客户端不规范使用没有关连接 如果 Client 侧发起大量连接而不关闭的话，极端情况下会有较大的资源浪费，随着时间的增长，可能 …","ref":"/zh/docs/hertz/faq/","tags":"","title":"常见问题"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/tutorials/service-governance/","tags":"","title":"治理特性"},{"body":"错误设置 NumLoops 如果你的服务器运行在物理机上，Go 进程创建的 P 个数就等于机器的 CPU 核心数。 但是 Server 可能不会使用这么多核心。在这种情况下，过多的 poller 会导致性能下降。\n这里提供了以下几种解决方案：\n 使用 taskset 命令来限制 CPU 个数，例如：  taskset -c 0-3 $run_your_server 主动设置 P 的个数，例如：  package main import ( \"runtime\" ) func init() { runtime.GOMAXPROCS(num_you_want) } 主动设置 poller 的个数，例如：  package main import ( \"github.com/cloudwego/netpoll\" ) func init() { netpoll.SetNumLoops(num_you_want) } ","categories":"","description":"","excerpt":"错误设置 NumLoops 如果你的服务器运行在物理机上，Go 进程创建的 P 个数就等于机器的 CPU 核心数。 但是 Server 可能 …","ref":"/zh/docs/netpoll/caution/","tags":"","title":"注意事项"},{"body":"接下来，让我们来看下如何给 Volo 添加一个中间件。\n例如，我们需要一个中间件，打印出我们收到的请求、返回的响应以及消耗的时间，那我们可以在 lib.rs 中写这么一个 Service：\n#[derive(Clone)]pubstruct LogService\u003cS\u003e(S);#[volo::service]impl\u003cCx,Req,S\u003evolo::Service\u003cCx,Req\u003eforLogService\u003cS\u003ewhereReq: Send +'static,S: Send +'static+volo::Service\u003cCx,Req\u003e+Sync,Cx: Send +'static,{asyncfn call(\u0026self,cx: \u0026mutCx,req: Req)-\u003e Result\u003cS::Response,S::Error\u003e{letnow=std::time::Instant::now();letresp=self.0.call(cx,req).await;tracing::info!(\"Request took {}ms\",now.elapsed().as_millis());resp}}随后，我们给这个 Service 包装一层 Layer：\npubstruct LogLayer;impl\u003cS\u003evolo::Layer\u003cS\u003eforLogLayer{type Service=LogService\u003cS\u003e;fn layer(self,inner: S)-\u003e Self::Service{LogService(inner)}}最后，我们在 client 和 server 里面加一下这个 Layer：\nusevolo_example::LogLayer;// client.rs staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example\").layer_outer(LogLayer).address(addr).build()};// server.rs Server::new().add_service(ServiceBuilder::new(volo_gen::volo::example::ItemServiceServer::new(S)).build()).layer_front(LogLayer).run(addr).await.unwrap();这时候，在 info 日志级别下，我们会打印出请求的耗时。\n","categories":"","description":"","excerpt":"接下来，让我们来看下如何给 Volo 添加一个中间件。\n例如，我们需要一个中间件，打印出我们收到的请求、返回的响应以及消耗的时间，那我们可以 …","ref":"/zh/docs/volo/volo-grpc/getting-started/part_4/","tags":"","title":"Part 4. 添加一个中间件"},{"body":"接下来，让我们来看下如何给 Volo 添加一个中间件。\n例如，我们需要一个中间件，打印出我们收到的请求、返回的响应以及消耗的时间，那我们可以在 lib.rs 中写这么一个 Service：\n#[derive(Clone)]pubstruct LogService\u003cS\u003e(S);#[volo::service]impl\u003cCx,Req,S\u003evolo::Service\u003cCx,Req\u003eforLogService\u003cS\u003ewhereReq: std::fmt::Debug+Send+'static,S: Send +'static+volo::Service\u003cCx,Req\u003e+Sync,S::Response: std::fmt::Debug,S::Error: std::fmt::Debug,Cx: Send +'static,{asyncfn call(\u0026self,cx: \u0026mutCx,req: Req)-\u003e Result\u003cS::Response,S::Error\u003e{letnow=std::time::Instant::now();tracing::debug!(\"Received request {:?}\",\u0026req);letresp=self.0.call(cx,req).await;tracing::debug!(\"Sent response {:?}\",\u0026resp);tracing::info!(\"Request took {}ms\",now.elapsed().as_millis());resp}}随后，我们给这个 Service 包装一层 Layer：\npubstruct LogLayer;impl\u003cS\u003evolo::Layer\u003cS\u003eforLogLayer{type Service=LogService\u003cS\u003e;fn layer(self,inner: S)-\u003e Self::Service{LogService(inner)}}最后，我们在 client 和 server 里面加一下这个 Layer：\nusevolo_example::LogLayer;// client.rs staticrefCLIENT: volo_gen::volo::example::ItemServiceClient={letaddr: SocketAddr=\"127.0.0.1:8080\".parse().unwrap();volo_gen::volo::example::ItemServiceClientBuilder::new(\"volo-example\").layer_outer(LogLayer).address(addr).build()};// server.rs volo_gen::volo::example::ItemServiceServer::new(S).layer_front(LogLayer).run(addr).await.unwrap();这时候，在 info 日志级别下，我们会打印出请求的耗时；在 debug 日志级别下，我们还会打出请求和响应的详细数据。\n","categories":"","description":"","excerpt":"接下来，让我们来看下如何给 Volo 添加一个中间件。\n例如，我们需要一个中间件，打印出我们收到的请求、返回的响应以及消耗的时间，那我们可以 …","ref":"/zh/docs/volo/volo-thrift/getting-started/part_4/","tags":"","title":"Part 4. 添加一个中间件"},{"body":"迁移脚本 Hertz-contrib 下提供了其他框架( FastHTTP、Gin ) 迁移至 Hertz 的脚本，具体使用方式如下\ncd your_project_path sh -c \"$(curl -fsSL https://raw.github.com/hertz-contrib/migrate/main/migrate.sh)\" 脚本处理后，仍有小部分无法自动迁移，需要手动迁移。 迁移小 tip：比如要修改 Header 的 API，那 Header 是在 Request（Response）中，那 Hertz 中的 Api 就是 ctx.Request.Header.XXX()，其他 API 同理。为了方便用户使用，Hertz 也在 ctx 上添加了高频使用的 API，比如获取 Body 时使用 ctx.Body 就可以，不用使用 ctx.Request.Body() 了。\n其他迁移注意事项如下\nFastHTTP 处理函数   相对于 FastHTTP 的 RequestHandler ，Hertz 的 HandlerFunc 接受两个参数：context.Context 和 RequestContext 。context.Context 用于解决请求上下文无法按需延长的问题，同时请求上下文不再需要实现上下文接口，降低了维护难度。详细可以参考：字节跳动开源 Go HTTP 框架 Hertz 设计实践\n  具体例子如下：\n  // fasthttp request handler type RequestHandler = func(ctx *fasthttp.RequestCtx) // the corresponding Hertz request handler type HandlerFunc = func(c context.Context, ctx *app.RequestContext) UserValue   Hertz 提供了两个接口来存储 UserValue，分别是请求上下文 RequestContext.Keys 和标准库的 context.Value。requestContext.Keys 在请求中使用，请求结束就会回收。context.Value 不会在请求结束时就回收，可以用于异步场景(如 log，协程等)。\n  fasthttp 中 Value 和 UserValue 是等价的，但在 Hertz 中 RequestContext.Keys 和 context.Value 分别对应了不同的接口，两者数据不同。\n  路由   Hertz 提供了一套完整高效的路由，且提供了 ctx.Param 方法来获取路由参数。\n  具体例子如下：\n  // fasthttp + fasthttp router example func Hello(ctx *fasthttp.RequestCtx) { fmt.Fprintf(ctx, \"Hello, %s!\\n\", ctx.UserValue(\"name\")) } func main() { r := router.New() r.GET(\"/hello/{name}\", Hello) ... } // the corresponding hertz example func Hello(c context.Context, ctx *app.RequestContext) { fmt.Fprintf(ctx, \"Hello, %s!\\n\", ctx.Param(\"name\")) } func main() { r := server.Default() r.GET(\"/hello/:name\", Hello) ... } ListenAndServe  Hertz 不提供 ListenAndServe 等方法，具体监听端口等参数需要在初始化参数中确定，详细参数参考 server package - github.com/cloudwego/hertz/pkg/app/server - Go Packages  // fasthttp ListenAndServe func main() { ... fasthttp.ListenAndServe(\":8080\", myHandler) } // Hertz example func main() { r := server.Default(server.WithHostPorts(\":8080\")) ... r.Spin() } Gin 处理函数  相对于 Gin 的 RequestHandler ，Hertz 的 HandlerFunc 接受两个参数：context.Context 和 RequestContext context.Context 即 Gin 中的 ctx.Request.Context() 。详细可以参考：字节跳动开源 Go HTTP 框架 Hertz 设计实践 具体例子如下  // Gin request handler type RequestHandler = func(ctx *gin.Context) // the corresponding Hertz request handler type HandlerFunc = func(c context.Context, ctx *app.RequestContext) 参数绑定  Hertz 目前只支持 Bind 绑定所有的数据，不支持单独绑定 Query 或是 Body 中的数据，详细内容请参考绑定与校验  设置 Response 数据  Hertz 支持乱序设置 Response 的 Header 和 Body，不像 Gin 必须要求先设置 Header，再设置 Body。 具体例子如下  // The example is valid on Hertz func Hello(c context.Context, ctx *app.RequestContext) { // First, Set a body  fmt.Fprintf(ctx, \"Hello, World\\n\") // Then, Set a Header  ctx.Header(\"Hertz\", \"test\") } ListenAndServe  Hertz 没有实现 http.Handler，不能使用 http.Server 来监听端口。同时，Hertz 具体的监听参数要在初始化参数中确定，详细参数参考 server package - github.com/cloudwego/hertz/pkg/app/server - Go Packages。  // Gin Run or use http.Server func main() { r := gin.Default() ... r.Run(\":8080\") // or use http.Server  srv := \u0026http.Server{ Addr: \":8080\", Handler: r, } } // Hertz example func main() { r := server.Default(server.WithHostPorts(\":8080\")) ... r.Spin() } 附录   FastHTTP -\u003e Hertz conversion table\n  Gin -\u003e Hertz conversion table\n  Hertz API Doc\n  ","categories":"","description":"","excerpt":"迁移脚本 Hertz-contrib 下提供了其他框架( FastHTTP、Gin ) 迁移至 Hertz 的脚本，具体使用方式如下\ncd …","ref":"/zh/docs/hertz/reference/migration/","tags":"","title":"迁移文档"},{"body":"The structure of the generated code The structure of the code generated by hz is similar. The following is an example of the structure of the code generated by the section “Create a project based on thrift IDL” to illustrate the meaning of the code generated by hz.\n. ├── biz // business layer, which stores business logic related processes │ ├── handler // store handler file │ │ ├── hello // hello/example corresponds to the namespace defined in thrift IDL; for protobuf IDL, it corresponds to the last level of go_package │ │ │ └── example │ │ │ ├── hello_service.go // the handler file, the user will implement the method defined by the IDL service in this file, it will search for the existing handler in the current file when \"update\" command, and append a new handler to the end │ │ │ └── new_service.go // same as above, each service defined in IDL corresponds to a file │ │ └── ping.go // ping handler carried by default, used to generate code for quick debugging, no other special meaning │ ├── model // IDL content-related generation code │ │ └── hello // hello/example corresponds to the namespace defined in thrift IDL; for protobuf IDL, it corresponds to the last level of go_package │ │ └── example │ │ └── hello.go // the product of thriftgo, It contains go code generated from the contents of hello.thrift definition. And it will be regenerated when use \"update\" command. │ └── router // generated code related to the definition of routes in IDL │ ├── hello // hello/example corresponds to the namespace defined in thrift IDL; for protobuf IDL, it corresponds to the last level of go_package │ │ └── example │ │ ├── hello.go // the route registration code generated for the routes defined in hello.thrift by hz; this file will be regenerated each time the relevant IDL is updated │ │ └── middleware.go // default middleware function, hz adds a middleware for each generated route group by default; when updating, it will look for the existing middleware in the current file and append new middleware at the end │ └── register.go // call and register the routing definition in each IDL file; when a new IDL is added, the call of its routing registration will be automatically inserted during the update; do not edit ├── go.mod // go.mod file, if not specified on the command line, defaults to a relative path to GOPATH as the module name ├── idl // user defined IDL, location can be arbitrary │ └── hello.thrift ├── main.go // program entry ├── router.go // user defined routing methods other than IDL └── router_gen.go // the route registration code generated by hz, for calling user-defined routes and routes generated by hz ","categories":"","description":"","excerpt":"The structure of the generated code The structure of the code …","ref":"/docs/hertz/tutorials/toolkit/usage/layout/","tags":"","title":"hz layout"},{"body":"生成代码的结构 hz 生成的代码结构都类似，下面以\"基于 thrift IDL 创建项目\"小节生成的代码结构为例，说明 hz 生成的代码的含义。\n. ├── biz // business 层，存放业务逻辑相关流程 │ ├── handler // 存放 handler 文件 │ │ ├── hello // hello/example 对应 thrift idl 中定义的 namespace；而对于 protobuf idl，则是对应 go_package 的最后一级 │ │ │ └── example │ │ │ ├── hello_service.go // handler 文件，用户在该文件里实现 IDL service 定义的方法，update 时会查找 当前文件已有的 handler 在尾部追加新的 handler │ │ │ └── new_service.go // 同上，idl 中定义的每一个 service 对应一个文件 │ │ └── ping.go // 默认携带的 ping handler，用于生成代码快速调试，无其他特殊含义 │ ├── model // IDL 内容相关的生成代码 │ │ └── hello // hello/example 对应 thrift idl 中定义的 namespace；而对于 protobuf idl，则是对应 go_package │ │ └── example │ │ └── hello.go // thriftgo 的产物，包含 hello.thrift 定义的内容的 go 代码，update 时会重新生成 │ └── router // idl 中定义的路由相关生成代码 │ ├── hello // hello/example 对应 thrift idl 中定义的namespace；而对于 protobuf idl，则是对应 go_package 的最后一级 │ │ └── example │ │ ├── hello.go // hz 为 hello.thrift 中定义的路由生成的路由注册代码；每次 update 相关 idl 会重新生成该文件 │ │ └── middleware.go // 默认中间件函数，hz 为每一个生成的路由组都默认加了一个中间件；update 时会查找当前文件已有的 middleware 在尾部追加新的 middleware │ └── register.go // 调用注册每一个 idl 文件中的路由定义；当有新的 idl 加入，在更新的时候会自动插入其路由注册的调用；勿动 ├── go.mod // go.mod 文件，如不在命令行指定，则默认使用相对于GOPATH的相对路径作为 module 名 ├── idl // 用户定义的idl，位置可任意 │ └── hello.thrift ├── main.go // 程序入口 ├── router.go // 用户自定义除 idl 外的路由方法 └── router_gen.go // hz 生成的路由注册代码，用于调用用户自定义的路由以及 hz 生成的路由 ","categories":"","description":"","excerpt":"生成代码的结构 hz 生成的代码结构都类似，下面以\"基于 thrift IDL 创建项目\"小节生成的代码结构为例，说明 hz 生成的代码的含 …","ref":"/zh/docs/hertz/tutorials/toolkit/usage/layout/","tags":"","title":"hz 生成代码的结构"},{"body":"Introduction From version v0.4.3, Kitex tool provides a new flag named -template-extension, to support extending the templates of Service generated code.\n Usage: kitex -template-extension extensions.yaml YOUR_IDL.  The extensions.yaml is a YAML file, which contains the serialization result of a TemplateExtension object. The fields of this object will be injected into the backend of the Kitex code generation tool, to insert certain codes at specific points.\nKitex will generate a package for each service definition in the IDL under the folder kitex_gen, in which the APIs NewClient, NewServer, etc. are provided.\nThe content provided by extensions.yaml will apply to all packages of all service definitions, the fields extend_client, extend_server, extend_invoker are extensions for file client.go, server.go, invoker.go.\nApplication Scenario It is applicable to the scenario for customizing the unified suite.\nEnterprise users have a unified customization of the framework, thus there is a set of fixed option configurations normally. We suggest that these options be encapsulated in suite, so that only one option needs to be configured during initialization. However, business developers still need to configure this suite option. Actually, business developers do not need to pay attention to this configuration, because business developers do not need to pay attention to infrastructure capabilities.\nIn ByteDance, a bytedSuite will be injected into the generated code. In order to facilitate the use of the external framework customization, the configuration customization capability is provided. Of course, if you want to further shield this detail from business developers, you can also encapsulate the Kitex tool and make this unified configuration built-in.\nExample Assume we have an extensions.yaml file:\n---dependencies:example.com/my/pkg:pkgextend_client:import_paths:- example.com/my/pkgextend_option:options = append(options, client.WithSuite(pkg.MyClientSuite()))extend_file:|-func Hello() { println(\"hello world\") }extend_server:import_paths:- example.com/my/pkgextend_option:options = append(options, server.WithSuite(pkg.MyServerSuite()))extend_file:|-func Hello() { println(\"hello world\") }  dependencies: Defines a set of packages that may be used in the template and the names they should be aliased as.\n  extend_client: Customization for client.go\n  import_paths: Declare the package list that the code injected into client.go needs to import. Those packages must be declared in the dependencies.\n  extend_option: The code snippet will be injected into the NewClient function, where the default options are constructed. Thus, you can inject your own suite option.\n  extend_file: The code snippet will be directly appended to client.go. You can add extra functions or constants here.\n    extend_server field works like the extend_client field.\n  An IDL that applied the extensions.yaml above may produce a cient.go like this (the injected part is highlighted):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  // Code generated by Kitex v0.4.2. DO NOT EDIT.  package demoservice import ( \"context\" demo \"example.com/demo/kitex_gen/demo\" pkg \"example.com/my/pkg\" \tclient \"github.com/cloudwego/kitex/client\" callopt \"github.com/cloudwego/kitex/client/callopt\" ) // Client is designed to provide IDL-compatible methods with call-option parameter for kitex framework. type Client interface { Test(ctx context.Context, request *demo.DemoTestRequest, callOptions ...callopt.Option) (r *demo.DemoTestResponse, err error) } // NewClient creates a client for the service defined in IDL. func NewClient(destService string, opts ...client.Option) (Client, error) { var options []client.Option options = append(options, client.WithDestService(destService)) options = append(options, client.WithSuite(pkg.MyClientSuite()))  options = append(options, opts...) kc, err := client.NewClient(serviceInfo(), options...) if err != nil { return nil, err } return \u0026kDemoServiceClient{ kClient: newServiceClient(kc), }, nil } // MustNewClient creates a client for the service defined in IDL. It panics if any error occurs. func MustNewClient(destService string, opts ...client.Option) Client { kc, err := NewClient(destService, opts...) if err != nil { panic(err) } return kc } type kDemoServiceClient struct { *kClient } func (p *kDemoServiceClient) Test(ctx context.Context, request *demo.DemoTestRequest, callOptions ...callopt.Option) (r *demo.DemoTestResponse, err error) { ctx = client.NewCtxWithCallOptions(ctx, callOptions) return p.kClient.Test(ctx, request) } func Hello() { println(\"hello world\") }   ","categories":"","description":"","excerpt":"Introduction From version v0.4.3, Kitex tool provides a new flag named …","ref":"/docs/kitex/tutorials/code-gen/template_extension/","tags":"","title":"Extend the Templates of Service Generated Code"},{"body":"介绍 从 v0.4.3 版本开始，Kitex 代码生成工具新增一个名为 -template-extension 的参数，支持了对 Service 生成模板进行一定程度的扩展。\n 用法：kitex -template-extension extensions.yaml YOUR_IDL。  其中 extensions.yaml 是一个 YAML 文件，其内容必须是一个 TemplateExtension 对象的序列化结果。这个对象的各个字段将被注入到 Kitex 的代码生成器后端，以在特定位置插入指定的代码。\nKitex 会在 kitex_gen 目录下面为 IDL 里出现的每一个 service 定义生成一个对应的 package，在其中包含了 NewClient、NewServer 等 API。\nextensions.yaml 文件提供的内容将会被应用到所有 service 定义对应的 package，其中 extend_client、extend_server、extend_invoker 字段分别对应 client.go 、 server.go 、invoker.go 的扩展。\n应用场景 适用于统一定制 suite 场景。\n企业用户对框架有统一的定制，即有一套固定的 option 配置，我们建议这些 option 封装在 suite 中，这样初始化时只需要配置一个 option。但对于内部的业务开发者来说依然需要配置这个 suite option，实际业务开发者并不需要关注这个配置，因为业务开发者不需要关注基础设施的能力。\n字节内部会在生成代码中注入 bytedSuite，为了方便外部框架定制者也能这么使用，所以提供了这个配置化定制能力。当然，如果要进一步对业务开发者屏蔽这个细节，也可以对 Kitex 代码生成工具做一个封装，内置这个统一的配置。\n示例 有这么一个 extensions.yaml 文件：\n---dependencies:example.com/my/pkg:pkgextend_client:import_paths:- example.com/my/pkgextend_option:options = append(options, client.WithSuite(pkg.MyClientSuite()))extend_file:|-func Hello() { println(\"hello world\") }extend_server:import_paths:- example.com/my/pkgextend_option:options = append(options, server.WithSuite(pkg.MyServerSuite()))extend_file:|-func Hello() { println(\"hello world\") }  dependencies：字段定义了在模板里可能会被使用到的包的列表，以及它们被引用的名字。\n  extend_client：对 client.go 的扩展定制\n  import_paths：声明了对 client.go 文件注入的代码需要导入的包的列表，其内容必须是 dependencies 字段里声明过的。\n  extend_option：提供的代码片段会被注入到 NewClient 函数里，构造默认的选项的位置，可以在这个地方注入你自己定义的 suite 之类的选项。\n  extend_file：提供的代码片段将会被直接添加到 client.go 文件的末尾，因此可以在这里提供额外的函数、常量定义等。\n    extend_server 的作用和 extend_client 是类似的，这里不再赘述。\n  一个应用了 extensions.yaml 的 IDL，生成的 client.go 可能是这样的（高亮的就是插入的部分）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  // Code generated by Kitex v0.4.2. DO NOT EDIT.  package demoservice import ( \"context\" demo \"example.com/demo/kitex_gen/demo\" pkg \"example.com/my/pkg\" \tclient \"github.com/cloudwego/kitex/client\" callopt \"github.com/cloudwego/kitex/client/callopt\" ) // Client is designed to provide IDL-compatible methods with call-option parameter for kitex framework. type Client interface { Test(ctx context.Context, request *demo.DemoTestRequest, callOptions ...callopt.Option) (r *demo.DemoTestResponse, err error) } // NewClient creates a client for the service defined in IDL. func NewClient(destService string, opts ...client.Option) (Client, error) { var options []client.Option options = append(options, client.WithDestService(destService)) options = append(options, client.WithSuite(pkg.MyClientSuite()))  options = append(options, opts...) kc, err := client.NewClient(serviceInfo(), options...) if err != nil { return nil, err } return \u0026kDemoServiceClient{ kClient: newServiceClient(kc), }, nil } // MustNewClient creates a client for the service defined in IDL. It panics if any error occurs. func MustNewClient(destService string, opts ...client.Option) Client { kc, err := NewClient(destService, opts...) if err != nil { panic(err) } return kc } type kDemoServiceClient struct { *kClient } func (p *kDemoServiceClient) Test(ctx context.Context, request *demo.DemoTestRequest, callOptions ...callopt.Option) (r *demo.DemoTestResponse, err error) { ctx = client.NewCtxWithCallOptions(ctx, callOptions) return p.kClient.Test(ctx, request) } func Hello() { println(\"hello world\") }   ","categories":"","description":"","excerpt":"介绍 从 v0.4.3 版本开始，Kitex 代码生成工具新增一个名为 -template-extension 的参数， …","ref":"/zh/docs/kitex/tutorials/code-gen/template_extension/","tags":"","title":"扩展 Service 代码生成模板"},{"body":"Hertz provides the middleware extension for internationalization (i18n), which references Gin’s implementation.\nRefer to the below for usage example\nInstallation go get github.com/hertz-contrib/i18n Sample code package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" hertzI18n \"github.com/hertz-contrib/i18n\" \"github.com/nicksnyder/go-i18n/v2/i18n\" ) func main() { h := server.New(server.WithHostPorts(\":3000\")) h.Use(hertzI18n.Localize()) h.GET(\"/:name\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\u0026i18n.LocalizeConfig{ MessageID: \"welcomeWithName\", TemplateData: map[string]string{ \"name\": ctx.Param(\"name\"), }, })) }) h.GET(\"/\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\"welcome\")) }) h.Spin() } Configuration Localize Localize for integrating the i18n extension into the hertz server\nFunction Signature：\nfunc Localize(opts ...Option) app.HandlerFunc Sample code：\npackage main import ( \"context\" _ \"embed\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" hertzI18n \"github.com/hertz-contrib/i18n\" \"github.com/nicksnyder/go-i18n/v2/i18n\" \"golang.org/x/text/language\" \"gopkg.in/yaml.v3\" ) func main() { h := server.New() h.Use(hertzI18n.Localize()) h.GET(\"/:name\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\u0026i18n.LocalizeConfig{ MessageID: \"welcomeWithName\", TemplateData: map[string]string{ \"name\": ctx.Param(\"name\"), }, })) }) h.GET(\"/\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\"welcome\")) }) h.Spin() } MustGetMessage MustGetMessage get the i18n message without error handling\nFunction Signature：\nfunc MustGetMessage(param interface{}) string Sample code：\nh.GET(\"/:name\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\u0026i18n.LocalizeConfig{ MessageID: \"welcomeWithName\", TemplateData: map[string]string{ \"name\": ctx.Param(\"name\"), }, })) }) h.GET(\"/\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\"welcome\")) }) LocalizeConfig Configuration item\nThis configuration item can be viewed by moving to go-i18n \nWithBundle WithBundle is used to load custom configurations into the middleware\nFunction Signature：\nfunc WithBundle(cfg *BundleCfg) Option Sample code：\npackage main import ( \"context\" _ \"embed\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" hertzI18n \"github.com/hertz-contrib/i18n\" \"github.com/nicksnyder/go-i18n/v2/i18n\" \"golang.org/x/text/language\" \"gopkg.in/yaml.v3\" ) func main() { h := server.New( server.WithHostPorts(\":3000\"), server.WithExitWaitTime(time.Second), ) h.Use(hertzI18n.Localize( hertzI18n.WithBundle(\u0026hertzI18n.BundleCfg{ RootPath: \"./localize\", AcceptLanguage: []language.Tag{language.Chinese, language.English}, DefaultLanguage: language.Chinese, FormatBundleFile: \"yaml\", UnmarshalFunc: yaml.Unmarshal, }), )) h.GET(\"/:name\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\u0026i18n.LocalizeConfig{ MessageID: \"welcomeWithName\", TemplateData: map[string]string{ \"name\": ctx.Param(\"name\"), }, })) }) h.GET(\"/\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\"welcome\")) }) h.Spin() } Configuration item\n   Configuration items Type Default value Description     DefaultLanguage language.Tag language.English Default conversion language type   FormatBundleFile string “yaml” Convert file template types，For example yaml, json   AcceptLanguage []language.Tag []language.Tag{defaultLanguage,language.Chinese} Receiving conversion type   RootPath string defaultRootPath Template file directory   UnmarshalFunc i18n.UnmarshalFunc yaml.Unmarshal Template file decoding functions，For example: yaml.Unmarshal   Loader Loader LoaderFunc(ioutil.ReadFile) File reading functions, For example : LoaderFunc(ioutil.ReadFile)    WithGetLangHandle WithGetLangHandle is used to configure the i18n template trigger conditions, which can be retrieved from the parameters, request headers\nFunction Signature：\nfunc WithGetLangHandle(handler GetLangHandler) Sample code：\nfunc main() { h := server.New() h.Use(hertzI18n.Localize( hertzI18n.WithGetLangHandle( func(c context.Context, ctx *app.RequestContext, defaultLang string) string { lang := ctx.Query(\"lang\") if lang == \"\" { return defaultLang } return lang }, ), )) // ...  h.Spin() } Refer to the i18n for more usage examples\n","categories":"","description":"","excerpt":"Hertz provides the middleware extension for internationalization …","ref":"/docs/hertz/tutorials/basic-feature/middleware/i18n/","tags":"","title":"Internationalization"},{"body":"Hertz 提供了国际化 (i18n) 的中间件扩展 ，它参考了 Gin 的实现 。\n使用方法可参考如下 example\n安装 go get github.com/hertz-contrib/i18n 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" hertzI18n \"github.com/hertz-contrib/i18n\" \"github.com/nicksnyder/go-i18n/v2/i18n\" ) func main() { h := server.New(server.WithHostPorts(\":3000\")) h.Use(hertzI18n.Localize()) h.GET(\"/:name\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\u0026i18n.LocalizeConfig{ MessageID: \"welcomeWithName\", TemplateData: map[string]string{ \"name\": ctx.Param(\"name\"), }, })) }) h.GET(\"/\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\"welcome\")) }) h.Spin() } 配置 Localize 用于将 i18n 扩展集成进 hertz server\n函数标签如下：\nfunc Localize(opts ...Option) app.HandlerFunc 示例代码：\npackage main import ( \"context\" _ \"embed\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" hertzI18n \"github.com/hertz-contrib/i18n\" \"github.com/nicksnyder/go-i18n/v2/i18n\" \"golang.org/x/text/language\" \"gopkg.in/yaml.v3\" ) func main() { h := server.New() h.Use(hertzI18n.Localize()) h.GET(\"/:name\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\u0026i18n.LocalizeConfig{ MessageID: \"welcomeWithName\", TemplateData: map[string]string{ \"name\": ctx.Param(\"name\"), }, })) }) h.GET(\"/\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\"welcome\")) }) h.Spin() } MustGetMessage MustGetMessage 用于获取 i18n 信息，但不做错误处理。\n函数签名如下：\nfunc MustGetMessage(param interface{}) string 示例代码如下：\nh.GET(\"/:name\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\u0026i18n.LocalizeConfig{ MessageID: \"welcomeWithName\", TemplateData: map[string]string{ \"name\": ctx.Param(\"name\"), }, })) }) h.GET(\"/\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\"welcome\")) }) LocalizeConfig 配置项\n该配置项移步 go-i18n 自行查看\nWithBundle WithBundle用于将自定义配置加载进入中间件\n函数标签如下：\nfunc WithBundle(cfg *BundleCfg) Option 示例代码如下：\npackage main import ( \"context\" _ \"embed\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" hertzI18n \"github.com/hertz-contrib/i18n\" \"github.com/nicksnyder/go-i18n/v2/i18n\" \"golang.org/x/text/language\" \"gopkg.in/yaml.v3\" ) func main() { h := server.New( server.WithHostPorts(\":3000\"), server.WithExitWaitTime(time.Second), ) h.Use(hertzI18n.Localize( hertzI18n.WithBundle(\u0026hertzI18n.BundleCfg{ RootPath: \"./localize\", AcceptLanguage: []language.Tag{language.Chinese, language.English}, DefaultLanguage: language.Chinese, FormatBundleFile: \"yaml\", UnmarshalFunc: yaml.Unmarshal, }), )) h.GET(\"/:name\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\u0026i18n.LocalizeConfig{ MessageID: \"welcomeWithName\", TemplateData: map[string]string{ \"name\": ctx.Param(\"name\"), }, })) }) h.GET(\"/\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, hertzI18n.MustGetMessage(\"welcome\")) }) h.Spin() } 配置项\n   配置项 类型 默认值 描述     DefaultLanguage language.Tag language.English 默认转换语言类型   FormatBundleFile string “yaml” 转换文件模板类型，例如: yaml, json   AcceptLanguage []language.Tag []language.Tag{defaultLanguage,language.Chinese} 接收转换类型   RootPath string defaultRootPath 模板文件目录   UnmarshalFunc i18n.UnmarshalFunc yaml.Unmarshal 模板文件解码函数，例如: yaml.Unmarshal   Loader Loader LoaderFunc(ioutil.ReadFile) 文件读取函数, 例如 LoaderFunc(ioutil.ReadFile)    WithGetLangHandle WithGetLangHandle 用于配置 i18n 模板触发条件, 可以通过从参数，请求头中取出信息\n函数标签如下：\nfunc WithGetLangHandle(handler GetLangHandler) 示例代码如下：\nfunc main() { h := server.New() h.Use(hertzI18n.Localize( hertzI18n.WithGetLangHandle( func(c context.Context, ctx *app.RequestContext, defaultLang string) string { lang := ctx.Query(\"lang\") if lang == \"\" { return defaultLang } return lang }, ), )) // ...  h.Spin() } 完整用法示例详见 i18n\n","categories":"","description":"","excerpt":"Hertz 提供了国际化 (i18n) 的中间件扩展 ，它参考了 Gin 的实现 。\n使用方法可参考如下 example\n安装 go get …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/i18n/","tags":"","title":"国际化"},{"body":"Kitex provides a global Hook for injecting your processing logic on the server-side after triggering startup and before exiting.\nAlso, you can modify the main function to customize some processing logic before the server-side starts and after it exits (listening for port closures).\nAfter the server-side start and before exit Since the server-side logic after startup and before exit is processed inside the framework, users who want to customize the business logic need to use Hook for injection.\nInject StartHook triggered after startup After triggering Server startup, the framework executes StartHooks and performs service registration. Note that since the Server starts asynchronously, the Hook is not guaranteed to be executed after the fully ready status of the server.\n  Usage\nimport \"github.com/cloudwego/kitex/server\" server.RegisterStartHooks(yourStartHook) // support for injecting multiple Hooks // server.RegisterStartHooks(hook)   Inject ShutdownHook triggered before exit After receiving an exit signal or when the user initiates a stop command, the framework executes ShutdownHooks first, followed by service deregistration (from the registry) and Shutdown of the service.\n Usage  import \"github.com/cloudwego/kitex/server\" server.RegisterShutdownHook(yourShundownHook) // support inject multiple Hooks // server.RegisterShutdownHook(hook) Before the server-side startup and after exit Customizing the logic before the server-side startup and after exit is easier for users. What you need to do is adding your processing logic before and after the execution of the Run() method in the main.go generated by the framework.\nNote: The logic after Run() is not executed until the Server has finished exiting. If you want to execute your logic before Server exits, you should use ShutdownHook.\nThe following is an example of the main function generated by the framework, you may write your own logic in the position of comments.\nfunc main() { svr := greetservice.NewServer(new(GreetServiceImpl)) // yourLogicBeforeServerRun()  err := svr.Run() // yourLogicAfterServerRun()  if err != nil { log.Println(err.Error()) } } ","categories":"","description":"Kitex supports customizing business logic before and after server startup and exit respectively.","excerpt":"Kitex supports customizing business logic before and after server …","ref":"/docs/kitex/tutorials/advanced-feature/start_shutdown_hook/","tags":"","title":"Customize Hook for Start/Shutdown of Server-side"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/tutorials/framework-exten/","tags":"","title":"Framework Extension"},{"body":"Hertz supports both server and client stream processing to improve the usability of the framework.\nServer For example:\nimport ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/network/standard\" ) func main() { h := server.New( server.WithStreamBody(), server.WithTransport(standard.NewTransporter), ) ... } Due to different trigger modes of netpoll and go net, netpoll streams are “pseudo” streams (Due to Level Triggered in epoll, the network library will read the data into the buffer of the network library).In the case of processing large data packets (eg: updating files), there may be memory problems when using netpoll, so we recommend using the go net method above.\nClient For example:\nc, err := client.NewClient(client.WithResponseBodyStream(true)) Since the client has the problem of multiplexing connections, if streaming is used, the connection will be handled by the user(resp.BodyStream() is encapsulated by connection) once streaming is used. There are some differences in the management of connections in the above case:\n  If the user doesn’t close the connection, the connection will eventually be closed by the GC without causing a connection leak. However, due to the need to wait for 2 Round-Trip Time to close the connection, in the case of high concurrency, the consequence is that there will be too many open files and creating a new connection will be impossible.\n  Users can recycle the connection by calling the relevant interface. After recycling, the connection will be put into the connection pool for reuse, so as to achieve higher resource utilization and better performance. The following methods will recycle the connection. Warning: Recycling can only be done once\n Show call: protocol.ReleaseResponse(), resp.Reset(), resp.ResetBody() Implicit call: The server side will also recycle the response. Assign the client side response to the server side or pass the server side response to the client (eg: client uses reverse proxy), there is no need to display the method of calling the recovery.    ","categories":"","description":"","excerpt":"Hertz supports both server and client stream processing to improve the …","ref":"/docs/hertz/tutorials/basic-feature/stream/","tags":"","title":"Stream"},{"body":"Kitex 提供了全局的 Hook 注入能力，用于在服务端触发启动后和退出前注入自己的处理逻辑。\n同时，你也可以修改启动 main 方法在服务启动前和退出后（监听端口关闭）定制一些业务逻辑。\n服务启动后和退出前 由于服务端启动后和退出前都在框架内部处理，用户如果想定制业务逻辑需要通过 Hook 注入。\n注入触发启动后的 StartHook 触发 Server 启动后，框架会执行 StartHooks，然后进行服务注册。注意，由于 Server 启动是异步执行，所以该 Hook 的执行不保证在 Server 完全就绪后。\n  使用方式\nimport \"github.com/cloudwego/kitex/server\" server.RegisterStartHooks(yourStartHook) // 支持注入多个 Hook // server.RegisterStartHooks(hook)   注入退出前的 ShutdownHook 接收到退出信号后或用户主动通过 Stop 退出时，框架会先执行 ShutdownHooks，然后执行服务注销（从注册中心注销）和服务的Shutdown。\n  使用方式\nimport \"github.com/cloudwego/kitex/server\" server.RegisterShutdownHook(yourShundownHook) // support inject multiple Hooks // server.RegisterShutdownHook(hook)   服务启动前和退出后 服务启动前和退出后的定制逻辑会更简单些，可以完全由用户自行控制，只需在框架生成的 main.go 中 Run() 方法执行前后添加你的逻辑即可。\n注意：Run() 后面是在 Server 完成退出后才会执行，如果希望在 Server 退出前执行你的逻辑应该使用 ShutdownHook。\n如下是框架生成的 main 方法示例，注释的位置写入你的逻辑：\nfunc main() { svr := greetservice.NewServer(new(GreetServiceImpl)) // yourLogicBeforeServerRun()  err := svr.Run() // yourLogicAfterServerRun()  if err != nil { log.Println(err.Error()) } } ","categories":"","description":"Kitex 支持分别在服务端启动和退出前后定制业务逻辑。","excerpt":"Kitex 支持分别在服务端启动和退出前后定制业务逻辑。","ref":"/zh/docs/kitex/tutorials/advanced-feature/start_shutdown_hook/","tags":"","title":"服务端 启动/退出 前后定制业务逻辑"},{"body":"Hertz 同时支持 Server 和 Client 的流式处理，提高框架的可用性。\nServer 开启流式:\nimport ( \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/network/standard\" ) func main() { h := server.New( server.WithStreamBody(), server.WithTransport(standard.NewTransporter), ) ... } 由于 netpoll 和 go net 触发模式不同，netpoll 流式为“伪”流式（由于 LT 触发，会由网络库将数据读取到网络库的 buffer 中），在大包的场景下（如：上传文件等）可能会有内存问题，推荐使用 go net，使用方式如上。\nClient 开启流式:\nc, err := client.NewClient(client.WithResponseBodyStream(true)) 由于 client 有复用连接的问题，但是如果使用了流式，那连接就会交由用户处理( resp.BodyStream() 底层是对 connection 的封装)，这个时候对连接的管理会有一些不同：\n 如果用户不关闭连接，连接最终会被 GC 关掉，不会造成连接泄漏。但是，由于关闭连接需要等待 2RTT，在高并发情况下可能会出现 fd 被打满导致无法新建连接的情况。 用户可以调用相关接口回收连接，回收后，该连接会放入连接池中复用，资源使用率更好，性能更高。以下几种方式都会回收连接，注意回收只能回收一次。  显示调用 protocol.ReleaseResponse(), resp.Reset(), resp.ResetBody() 非显示调用：server 侧也会有回收 resp 的逻辑。如果将 client 的 response 赋值给 server或者直接把 server 的 response 传递给 client 的情况下（如： client 作为反向代理 ）就不需要显示调用回收的方法了。    ","categories":"","description":"","excerpt":"Hertz 同时支持 Server 和 Client 的流式处理，提高框架的可用性。\nServer 开启流式:\nimport ( …","ref":"/zh/docs/hertz/tutorials/basic-feature/stream/","tags":"","title":"流式处理"},{"body":"会议主题： CloudWeGo 社区会议 4.21\n参会人员： YangruiEmma, liu-song, baiyutang, yccpt, AshleeT, CoderPoet, Quan Hu, li-jin-gou, JZK-Keven, EastHorse, GuangmingLuo, HeyJavaBean, jayantxie, ppzqh, Shizheng Hou, andrewshan, simon0-o, yiyun, Wanqi Su, Zheming Li, Xianjie Yao, LoveScotty.\n会前必读： http://www.cloudwego.io/; https://github.com/cloudwego\n议程 1 ：新成员自我介绍 内容：社区新成员分别进行自我介绍，主要包含个人基本情况、开源贡献经历和后续参与社区规划。\n议程 2 ：Kitex 单测任务回顾、总结、建议 (@GuangmingLuo 负责介绍)\n  完成进度： 2/14\n  提交 PR 注意事项 ：\na. 写 PR 描述：直接写 Issue 的编号即可，不要写 Fix 和 Resolve。\nb. 提交 PR 前：完成本地 Coding 后，运行gofumpt -l -extra -w .，检测代码是否存在语法、 License等问题。Contributor 在本地 Fix 这些问题后，能够顺利通过 CI 流程检测，顺利进入 review 环节。\nc. 提交 PR 时：若 PR 处于 Working In Progress 状态，大家在提交 PR 时可以选择 Draft PR ，或者在 PR 描述中加入 WIP 标识，便于 Reviewer 优先处理完成状态的 PR。\nd. 单测描述：需要在描述部分清晰、详细说明单测方法的场景，便于后续快速、准确地 Review 代码逻辑。\n  后续安排： 将完成的 PR 正式地 Release 在 Kitex V0.3.0 中，并在 Release Notes 中公示。\n  议程 3：Kitex 源码解析活动介绍与讨论 （@baiyutang 负责介绍）\n  介绍： 源码解析活动方案草案主要包含六大模块：学习资料、设计理念、目标、课题、解读思路、产出形式。\na. “目标”：① 作为 Contributor 的学习产出；② 作为框架新人的学习资料；③ 丰富社区资源和内容，提高 Kitex 的知名度。\nb. “课题”：包括 Kitex 模块设计及调用链路、服务治理、框架公共模块等内容。\nc. “解读思路”：包括代码设计现状、设计背景、Q\u0026A、最佳实践等内容。\n  后续安排： 确定源码解读的优先级，继续补充、优化文档内容。\n  议程 4：Kitex 与阿里云 Nacos + Trace 对接工作进展介绍与讨论 （@li-jin-gou 负责介绍）\n  背景介绍： 我们希望将 Demo(Easy-Note) 部署到阿里云，主要的工作是验证 Kitex 接入阿里云的 ARMS 的链路追踪 和 MSE 的 Nacos 注册中心。\n  工作开展： 目前主要进行了 Kitex Nacos 扩展改造，包括改造初始化方式、设置环境变量和默认值、自定义 Logger 注入等。\n  后续安排： 相关实践文档在完成正式验证和完善后，将通过官方渠道，对外发布。\n  议程 5：Kitex 对接开源服务治理 SDK 方案介绍与讨论 （@jayantxie 负责介绍)\n  背景介绍： 为方便 Kitex 用户上云，计划对接腾讯的开源服务治理平台 Polaris，通过集成 go sdk，满足诸如熔断限流和动态路由等 Polaris 平台的治理能力。\n  方案介绍： 目前存在两种方案设计，二者之间的区别主要体现在接入方式的不同。由于我们需要结合两个框架，此时必然会有一个框架的接口需要被调整改动。其中，方案一，倾向于保留 Kitex 现有框架的设计；方案二，倾向于保留 Polaris 的接口。经过讨论，决定采用方案一，详见 Issue。\n  议程 6：社区建议 大家围绕源码解析文章的收集、发布形式展开了讨论。\n  收集形式： ① 建议将其以“ RPC 框架学习百科全书”，或者“框架学习指南”的形式，作为开源活动放在社区里，由大家进行内容补充；② 也可以以任务认领的形式发布社区，邀请社区成员参与源码解析。\n  发布形式： ① 可以考虑通过公众号宣传；② 也可以发布在 CloudWeGo 官网 和 Github 的 Wiki 里面。\n  议程 7：Q\u0026A Q：我们是否也要把对接阿里云的相关基础设施统一放在一个 Suite 里面？\nA：目前还没有对接服务治理，我们的规划是：第一阶段支持注册中心和可观测系统的接入。比如，对Nacos 注册中心这块做了一些无侵入式配置的扩展对接，然后我们通过 OpenTelemetry 去接入阿里云的可观测系统；第二阶段，我们准备通过 Middleware 或 Suite 的方式对接开放服务治理的能力。现阶段的工作主要是对 Kitex 的 Nacos registry 展开了优化，然后结合 OpenTelemetry 这一扩展，去重构 Kitex Easy-Note Demo。\nQ：单测每次 CI 都会出报告吗？上次想加到 awesome go ，但是他们对覆盖度有要求。\nA：可以点进 CI 的 Show all checks 查看测试报告，同时，在单测新手任务完成之后，项目整体的单测覆盖率提高之后，我们也可以去设置覆盖率的门禁，后续 CI 检测会去检查单测覆盖率，并且输出到 PR 评论中。\n相关资讯 截至 4 月 21 日，历时 5 个月，CloudWeGo-Kitex 完成了 3000 Stars 到 4000 Stars 的跨越，来到新的里程碑！\n","categories":"","description":"","excerpt":"会议主题： CloudWeGo 社区会议 4.21\n参会人员： YangruiEmma, liu-song, baiyutang, …","ref":"/zh/community/meeting_notes/2022-04-21/","tags":"","title":"CloudWeGo 社区会议 4.21"},{"body":"Kitex provides Short Connection, Long Connection Pool and Connection Multiplexing for different business scenarios. Kitex uses Long Connection Pool by default after v0.0.2, but adjusting the Pool Config according to your need is suggested.\nShort Connection Every request needs to create a connection, the performance is bad, so it is not suggested normally.\nEnable Short Connection：\nxxxCli := xxxservice.NewClient(\"destServiceName\", client.WithShortConnection()) Long Connection Pool Kitex enable Long Connection Pool after \u003e= v0.0.2, default config params are as below：\nconnpool2.IdleConfig{ MaxIdlePerAddress: 10, MaxIdleGlobal: 100, MaxIdleTimeout: time.Minute, MinIdlePerAddress: 2, } Adjusting the Pool Config according to your need is suggested, config as below:\nxxxCli := xxxservice.NewClient(\"destServiceName\", client.WithLongConnection(connpool.IdleConfig{10, 1000, time.Minute})) Parameter description:\n MaxIdlePerAddress: the maximum number of idle connections per downstream instance MaxIdleGlobal: the global maximum number of idle connections MaxIdleTimeout: the idle duration of the connection. A connection that has been idle for more than MaxIdleTimeout will be closed (minimum value is 3s, the default value is 30s) MinIdlePerAddress(Kitex \u003e= v0.4.3)  the minimum number of idle connections per downstream instance, which will not be cleaned up even if the idle time exceeds the MaxIdleTimeout. For now, MinIdlePerAddress should be less than 5.    Internal Implementation Each downstream address corresponds to a connection pool, the connection pool is a ring composed of connections, and the size of the ring is MaxIdlePerAddress.\nWhen getting a connection of downstream address, proceed as follows:\n Try to fetch a connection from the ring, if fetching failed (no idle connections remained), then try to establish a new connection. In other words, the number of connections may exceed MaxIdlePerAddress If fetching succeed, then check whether the idle time of the connection (since the last time it was placed in the connection pool) has exceeded MaxIdleTimeout. If yes, this connection will be closed and a new connection will be created.  When the connection is ready to be returned after used, proceed as follows:\n Check whether the connection is normal, if not, close it directly Check whether the idle connection number exceeds MaxIdleGlobal, and if yes, close it directly Check whether free space remained in the ring of the target connection pool, if yes, put it into the pool, otherwise close it directly  Parameter Setting Suggestion The setting of parameters is suggested as follows:\n MaxIdlePerAddress: the minimum value is 1, otherwise long connections would degenerate to short connections  What value should be set should be determined according to the throughput of downstream address. The approximate estimation formula is: MaxIdlePerAddress = qps_per_dest_host*avg_response_time_sec For example, the cost of each request is 100ms, and the request spread to each downstream address is 100QPS, the value is suggested to set to 10, because each connection handles 10 requests per second, 100QPS requires 10 connections to handle In the actual scenario, the fluctuation of traffic is also necessary to be considered. Pay attention, the connection within MaxIdleTimeout will be recycled if it is not used Summary: this value be set too large or too small would lead to degenerating to the short connection   MinIdlePerAddress: Assuming that there are periodic requests and the period is greater than MaxIdleTimeout, setting this parameter can avoid creating a new connection every time.  The parameter consideration is similar to MaxIdlePerAddress and can be set according to the average latency of requests and the throughput. For example, if MinIdlePerAddress is set to 5 and the response time of each request is 100ms. 50 requests can be processed per second (50QPS) without creating a new connection.   MaxIdleGlobal: should be larger than the total number of downstream targets number * MaxIdlePerAddress  Notice: this value is not very valuable, it is suggested to set it to a super large value. In subsequent versions, considers discarding this parameter and providing a new interface   MaxIdleTimeout: since the server will clean up inactive connections within 10min, the client also needs to clean up long-idle connections in time to avoid using invalid connections. This value cannot exceed 10min when the downstream is also a Kitex service  Connection Multiplexing The client invokes the Server only need one connection normally when enabling Connection Multiplexing. Connection Multiplexing not only reduces the number of connections but also performs better than Connection Pool.\nSpecial Note:\n Connection Multiplexing here is just for Thrift and Kitex Protobuf protocol. If you choose the gRPC protocol, it utilizes Connection Multiplexing mode by default. When the client enables connection multiplexing, the server must also be enabled, otherwise, it will lead to request timeout. The server side has no restrictions on the client to enable connection multiplexing, it can accept requests for short connection, long connection pool, and connection multiplexing.    Server Side Enable:\noption: WithMuxTransport\nsvr := xxxservice.NewServer(handler, server.WithMuxTransport())   Client Side Enable: option: WithMuxConnection\n1-2 connection is enough normally, it is no need to config more.\nxxxCli := NewClient(\"destServiceName\", client.WithMuxConnection(1))    Status Monitoring Connection pooling defines the Reporter interface for connection pool status monitoring, such as the reuse rate of long connections. Users should implement the interface themselves and inject it by SetReporter.\n// Reporter report status of the connection pool. type Reporter interface { ConnSucceed(poolType ConnectionPoolType, serviceName string, addr net.Addr) ConnFailed(poolType ConnectionPoolType, serviceName string, addr net.Addr) ReuseSucceed(poolType ConnectionPoolType, serviceName string, addr net.Addr) } // SetReporter set the common reporter of a connection pool, that can only be set once. func SetReporter(r Reporter) ","categories":"","description":"Kitex supports short connections, long connection pool, connection multiplexing and connection pool status monitoring.","excerpt":"Kitex supports short connections, long connection pool, connection …","ref":"/docs/kitex/tutorials/basic-feature/connection_type/","tags":"","title":"Connection Type"},{"body":"用户可以根据自己的业务场景来选择短连接、长连接池、连接多路复用。Kitex 自 v0.0.2 版本默认配置了连接池，但建议用户还是根据实际情况调整连接池的大小。\n短连接 每次请求都会创建一次连接，性能不佳，通常不建议使用。但部分场景必须使用短连接，如上游实例数过多时，会增加下游服务的负担，请根据情况来选择。\n配置短连接：\nxxxCli := xxxservice.NewClient(\"destServiceName\", client.WithShortConnection()) 长连接池 Kitex \u003e= v0.0.2 默认配置了连接池，配置参数如下：\nconnpool2.IdleConfig{ MaxIdlePerAddress: 10, MaxIdleGlobal: 100, MaxIdleTimeout: time.Minute, MinIdlePerAddress: 2, } 建议用户根据实际情况调整连接池大小，配置方式如下：\nxxxCli := xxxservice.NewClient(\"destServiceName\", client.WithLongConnection(connpool.IdleConfig{10, 1000, time.Minute})) 其中：\n MaxIdlePerAddress 表示每个后端实例可允许的最大闲置连接数 MaxIdleGlobal 表示全局最大闲置连接数 MaxIdleTimeout 表示连接的闲置时长，超过这个时长的连接会被关闭（最小值 3s，默认值 30s ） MinIdlePerAddress(Kitex \u003e= v0.4.3)  表示对每个后端实例维护的最小空闲连接数，这部分连接即使空闲时间超过 MaxIdleTimeout 也不会被清理。 当前版本的MinIdlePerAddress的值不能超过5。    实现 长连接池的实现方案是每个 address 对应一个连接池，这个连接池是一个由连接构成的 ring，ring 的大小为 MaxIdlePerAddress。\n当选择好目标地址并需要获取一个连接时，按以下步骤处理 :\n 首先尝试从这个 ring 中获取，如果获取失败（没有空闲连接），则发起新的连接建立请求，即连接数量可能会超过 MaxIdlePerAddress 如果从 ring 中获取成功，则检查该连接的空闲时间（自上次放入连接池后）是否超过了 MaxIdleTimeout，如果超过则关闭该连接并新建 全部成功后返回给上层使用  在连接使用完毕准备归还时，按以下步骤依次处理：\n 检查连接是否正常，如果不正常则直接关闭 查看空闲连接是否超过全局的 MaxIdleGlobal，如果超过则直接关闭 待归还到的连接池的 ring 中是否还有空闲空间，如果有则直接放入，否则直接关闭  参数设置建议 下面是参数设置的一些建议：\n MaxIdlePerAddress 表示池化的连接数量，最小为 1，否则长连接会退化为短连接  具体的值与每个目标地址的吞吐量有关，近似的估算公式为：MaxIdlePerAddress = qps_per_dest_host*avg_response_time_sec  举例如下，假设每个请求的响应时间为 100ms，平摊到每个下游地址的请求为 100QPS，该值建议设置为10，因为每条连接每秒可以处理 10 个请求, 100QPS 则需要 10 个连接进行处理 在实际场景中，也需要考虑到流量的波动。需要特别注意的是，即 MaxIdleTimeout 内该连接没有被使用则会被回收 总而言之，该值设置过大或者过小，都会导致连接复用率低，长连接退化为短连接   MinIdlePerAddress  假设有周期性请求的场景，且周期大于 MaxIdleTimeout，设置此参数可避免每次新建连接。 与 MaxIdlePerAddress 类似，可根据请求的响应时间和 qps 进行设置。 以最大值5个连接为例，假设每个请求的响应时间为100ms，在不新建连接的情况下可以处理 50QPS。   MaxIdleGlobal 表示总的空闲连接数应大于 下游目标总数*MaxIdlePerAddress，超出部分是为了限制未能从连接池中获取连接而主动新建连接的总数量  注意：该值存在的价值不大，建议设置为一个较大的值，在后续版本中考虑废弃该参数并提供新的接口   MaxIdleTimeout 表示连接空闲时间，由于 server 在 10min 内会清理不活跃的连接，因此 client 端也需要及时清理空闲较久的连接，避免使用无效的连接，该值在下游也为 Kitex 时不可超过 10min  连接多路复用 开启连接多路复用，Client 访问 Server 常规只需要1个连接即可，相比连接池极限测试吞吐表现更好（目前的极限测试配置了2个连接），且能大大减少连接数量。\n特别说明：\n 这里的连接多路复用是针对于 Thrift 和 Kitex Protobuf，如果配置 gRPC 协议，默认是连接多路复用。 Client 开启连接多路复用，Server 必须也开启，否则会导致请求超时；Server 开启连接多路复用对 Client 没有限制，可以接受短连接、长连接池、连接多路复用的请求。    Server 配置\noption: WithMuxTransport\nsvr := xxxservice.NewServer(handler, server.WithMuxTransport())   Client 配置 option: WithMuxConnection\n建议配置1-2 个连接\nxxxCli := NewClient(\"destServiceName\", client.WithMuxConnection(1))   状态监控 连接池定义了 Reporter 接口，用于连接池状态监控，例如长连接的复用率。\n如有需求，用户需要自行实现该接口，并通过 SetReporter 注入。\n// Reporter report status of connection pool. type Reporter interface { ConnSucceed(poolType ConnectionPoolType, serviceName string, addr net.Addr) ConnFailed(poolType ConnectionPoolType, serviceName string, addr net.Addr) ReuseSucceed(poolType ConnectionPoolType, serviceName string, addr net.Addr) } // SetReporter set the common reporter of connection pool, that can only be set once. func SetReporter(r Reporter) ","categories":"","description":"Kitex 支持短连接、长连接池、连接多路复用以及连接池状态监控。","excerpt":"Kitex 支持短连接、长连接池、连接多路复用以及连接池状态监控。","ref":"/zh/docs/kitex/tutorials/basic-feature/connection_type/","tags":"","title":"连接类型"},{"body":"Kitex provides two LoadBalancers:\n WeightedRandom ConsistentHash  These two LoadBalancers can cover most of the use cases, but you can also customize your own LoadBalancer if they doesn’t meet your needs.\nInterface Loadbalancer is defined at pkg/loadbalance/loadbalancer.go:\n// Loadbalancer generates pickers for the given service discovery result. type Loadbalancer interface { GetPicker(discovery.Result) Picker // Name should be unique  Name() string } As you see, LoadBalancer gets a Result and generates a Picker for the current request, the Picker is defined as follows:\n// Picker picks an instance for next RPC call. type Picker interface { Next(ctx context.Context, request interface{}) discovery.Instance } In a single rpc request, the selected instance may not be connected and should to be retried, that’s why it’s been designed like that.\nIf there are no more instances to retry, the Next method should return nil.\nThere are another special interface, defined as follows:\n// Rebalancer is a kind of Loadbalancer that performs rebalancing when the result of service discovery changes. type Rebalancer interface { Rebalance(discovery.Change) Delete(discovery.Change) } If LoadBalancer supports Cache, make sure to implement the Rebalancer interface, otherwise the service will not be notified when discovery results changes.\nKitex client will execute the following code during initialization to ensure that the Rebalancer is notified when discovery results changes.\nif rlb, ok := balancer.(loadbalance.Rebalancer); ok \u0026\u0026 bus ! = nil { bus.Watch(discovery.DiscoveryChangeEventName, func(e *event.Event) { change := e.Extra.(*discovery.Change) rlb.Rebalance(*change) }) } Attention  If you are using dynamic service discovery, you should implement caching which can improve performance. If you are using cache, you should be better to implement the Rebalancer interface, otherwise you will not be notified when discovery results changes. LoadBalancer customization is not being supported in the case of Proxy.  Example You can refer to the implementation of WeightedRandom.\n","categories":"","description":"","excerpt":"Kitex provides two LoadBalancers:\n WeightedRandom ConsistentHash …","ref":"/docs/kitex/tutorials/framework-exten/loadbalance/","tags":"","title":"Customize LoadBalancer"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/kitex/tutorials/framework-exten/","tags":"","title":"Framework Extension"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/kitex/tutorials/framework-exten/","tags":"","title":"框架扩展"},{"body":"在 Kitex 中，提供了两种 LoadBalancer：\n WeightedRandom ConsistentHash  这两种 LoadBalancer 能覆盖绝大多数的应用场景，如果业务有一些 Corner Case 无法覆盖到，可以选择自己自定义 LoadBalancer。\n接口 LoadBalancer 接口在 pkg/loadbalance/loadbalancer.go 中，具体定义如下：\n// Loadbalancer generates pickers for the given service discovery result. type Loadbalancer interface { GetPicker(discovery.Result) Picker // 名称需要唯一  Name() string } 可以看到 LoadBalancer 获取到一个 Result 并且生成一个针对当次请求的 Picker，Picker 定义如下：\n// Picker picks an instance for next RPC call. type Picker interface { Next(ctx context.Context, request interface{}) discovery.Instance } 有可能在一次的 rpc 请求中，所选择的实例连接不上，而要进行重试，所以设计成这样。\n如果说已经没有实例可以重试了，Next 方法应当返回 nil。\n除了以上接口之外，还有一个比较特殊的接口，定义如下：\n// Rebalancer is a kind of Loadbalancer that performs rebalancing when the result of service discovery changes. type Rebalancer interface { Rebalance(discovery.Change) Delete(discovery.Change) } 如果 LoadBalancer 支持 Cache，务必实现 Rebalancer 接口，否则服务发现变更就无法被通知到了。\nKitex client 会在初始化的时候执行以下代码来保证当服务发现变更时，能通知到 Rebalancer：\nif rlb, ok := balancer.(loadbalance.Rebalancer); ok \u0026\u0026 bus != nil { bus.Watch(discovery.DiscoveryChangeEventName, func(e *event.Event) { change := e.Extra.(*discovery.Change) rlb.Rebalance(*change) }) } 注意事项  如果是动态服务发现，那么尽可能实现缓存，可以提高性能； 如果使用了缓存，那么务必实现 Rebalancer 接口，否则当服务发现变更时无法收到通知； 使用了 Proxy 场景下，不支持自定义 LoadBalancer。  Example 可以参考一下 Kitex 默认的 WeightedRandom 实现。\n","categories":"","description":"","excerpt":"在 Kitex 中，提供了两种 LoadBalancer：\n WeightedRandom ConsistentHash …","ref":"/zh/docs/kitex/tutorials/framework-exten/loadbalance/","tags":"","title":"负载均衡扩展"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/cwgo/","tags":"","title":"Cwgo"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/cwgo/","tags":"","title":"Cwgo"},{"body":"Kitex Framework Q1: Does Kitex support Windows？\n Kitex has already supported to compile and run in Windows since v0.4.0 version. But the code generation tool does not support the Windows environment yet.  Q2: Does Kitex support HTTP？\n Kitex does not specifically provide HTTP request support. For API gateway scenario, Kitex provides a HTTP mapping generic call regarding Thrift and sends the Thrift encoding of the HTTP request to the server. For related support, please refer to another CloudWeGo HTTP framework Hertz.  Q3: How to configure multiplexing?\n If you are using Thrift or Kitex Protobuf, to configure multiplexing:  Configure WithMuxTransport() on your server. Configure WithMuxConnection(1) on your client   If you are using gRPC, multiplexing is configured by default.  Q4: In the scenario of direct local call, why does the configuration of connection pool not take effect?\n The ip of your local test needs to be 127.0.0.1. For example, “client.WithHostPorts(“127.0.0.1:8888”)”.  Q5: What are the differences between “Kitex Protobuf” and “gRPC” protocol?\n Kitex Protobuf is a Protobuf Message Protocol defined by Kitex framework, with similar structure to Thrift. gRPC provides support to gRPC message protocol and enables Kitex to interact with gRPC framework.  Q6: Issues regarding Thrift interface compiling, such as “not enough arguments in call to iprot.ReadStructBegin”\n Based on Thrift v0.13, Kitex cannot be upgraded directly, as there is a breaking change in the interface of Apache Thrift v0.14. The reason for such problems could be that a new version of Thrift is pulled during upgrades. The use of -u parameters is not recommended during upgrades, you can run the following command to fix the version: “go mod edit -replace github.com/apache/thrift=github.com/apache/thrift@v0.13.0”  Kitex Code Generation Tool Q1:‘not enough arguments’ problem when installing the code generation tool\n Please try: “go mod：GO111MODULE=on go get github.com/cloudwego/kitex/tool/cmd/kitex@latest”  Q2: Why ‘set’ in IDL becomes slice in generated codes?\n Considering from JSON serialization, Starting from v0.11.0, Apache Thrift officially changes the generation type of set from map to slice. From a compatibility perspective, Kitex also follows the same rule.  Q3: Why is there an underscore after some field names?\n The official implementation of Thrift restricts identifiers ending in “Result” and “Args” to avoid naming conflicts. The official Thrift conflict avoidance strategy: when the type name, service name and method name in the Thrift file start with New or end with Result or with Args, Thrift will automatically add an underscore at the end of the name. Referring to https://jira.apache.org/jira/browse/THRIFT-4410, Kitex uses Thriftgo for code generation. Thriftgo adopts a similar strategy in order to be as consistent as possible with the official implementation.  Q4: Would code generated by new interface overwrite handler.go\n Generated code under kitex_gen/ will be overwritten. But handler.go of server will not be overwritten, only new methods will be added correspondingly.  Q5: Do the templates of the code generator support customization?\n We have no plan to support template customization at present, because it will make the design for parameter passing much more complex. And the plugin mechanism can achieve almost any functionality equivalent to a customized template.  Q6: Is it possible for the ‘-type’ argument of the code generator to be determined automatically by IDL filename extension?\n Kitex already supports automatic file suffix determination in v0.4.0, there’s no need to add the -type parameter.  ","categories":"","description":"Kitex Frequently Asked Questions and corresponding Answers.","excerpt":"Kitex Frequently Asked Questions and corresponding Answers.","ref":"/docs/kitex/faq/","tags":"","title":"FAQ"},{"body":"Kitex 框架 Q1: 支持 Windows 吗？\n Kitex 在 v0.4.0 版本已支持在 Windows 环境下编译运行了。但代码生成工具暂未支持 Windows 环境。  Q2: 是否支持 HTTP？\n 目前 Kitex 没有支持 HTTP 请求，如果是 API 网关场景，针对 Thrift 提供了 HTTP 映射的泛化调用，Kitex 会将 HTTP 请求做 Thrift 编码发给服务端。 HTTP 可以使用 CloudWeGo 开源的 HTTP 框架 Hertz。  Q3: 如何配置开启连接多路复用？\n 如果使用 Thrift 或 Kitex Protobuf ，开启连接多路复用：服务端配置 WithMuxTransport()，调用端配置 WithMuxConnection(1)。 如果使用 gRPC， 默认是连接多路复用。  Q4: 本地直连场景下，配置长连接池为什么没有生效？\n 本地测试 ip 需要改成 127.0.0.1，如 client.WithHostPorts(“127.0.0.1:8888”)。  Q5: Kitex Protobuf 和 gRPC 协议区别\n Kitex Protobuf 是 Kitex 自定义的 Protobuf 消息协议，协议格式类似 Thrift。 gRPC 是对 gRPC 消息协议的支持，可以与 gRPC 框架互通。  Q6: 出现 Thrift 接口编译问题，如 not enough arguments in call to iprot.ReadStructBegin\n Kitex 依赖 Thrift v0.13，因为Apache Thrift v0.14 接口有 breaking change，无法直接升级。出现该问题是拉到了新版本的 Thrift，升级版本时建议不使用 -u 参数，可以执行命令固定版本 go mod edit -replace github.com/apache/thrift=github.com/apache/thrift@v0.13.0  Kitex 代码生成工具 Q1: 安装代码生成工具，出现了 ‘not enough arguments’ 问题\n 请开启go mod：GO111MODULE=on go get github.com/cloudwego/kitex/tool/cmd/kitex@latest  Q2: 为什么 IDL 里的 set 生成了 slice?\n Apache Thrift 官方从 JSON 序列化的角度考虑，v0.11.0 开始，将 set 的生成类型从 map 改为了 slice，Kitex 从兼容性角度考虑，对齐了该行为。  Q3: 为什么有些字段名字后面多了条下划线?\n Thrift 的官方实现为了避免命名冲突，限制了以「Result」和「Args」结尾的标识符。 官方 Thrift 的冲突规避策略：当 Thrift 文件中的类型名、Service 名和方法名，以 New 开头 或者 以 Result 或者 以 Args 结尾时，Thrift 会自动在名字末尾添加下划线。参考 https://jira.apache.org/jira/browse/THRIFT-4410，Kitex 使用了 Thriftgo 进行代码生成，Thriftgo 为了尽可能和官方实现保持一致，采取了类似的策略。  Q4: 新增接口重新生成代码，是否会覆盖handler.go\n kitex_gen/ 下的生成代码会重新生成覆盖，但服务端的 handler.go 不会覆盖，只会新增对应方法。  Q5: 请问目前代码生成工具中的模板是否支持用户自定义?\n 目前没有支持自定义模板的打算，因为传参设计会复杂很多。现在的插件机制完全可以实现任意等价的功能  Q6: 代码生成工具中的 –type 是否可以通过 IDL 文件扩展名自动确定？\n Kitex 在 v0.4.0 版本已支持根据文件后缀生成代码，无需再添加 -type 参数。  ","categories":"","description":"Kitex 常见问题解答。","excerpt":"Kitex 常见问题解答。","ref":"/zh/docs/kitex/faq/","tags":"","title":"FAQ"},{"body":"为什么 Client 端中间件使用 Arc？ 细心的你会发现，我们在 Client 端的生成代码中，会把用户传入的 Req 包装成 Arc 再真正执行 volo_thrift 的 client 的 call 方法，而在 server 端则是直接使用 Req。\n这么设计的原因是因为，Client 端相比 Server 端，需要做更多复杂的服务治理逻辑，特别是有一些服务治理的逻辑和 Rust 的所有权模型是相悖的，比如：如果连接失败，那么就换个节点重试；甚至更复杂的超时重试等逻辑。如果我们直接使用 Req，那么当我们第一次执行 inner service 的 call 时，所有权就已经被 move 了，我们没有办法做重试逻辑。\n同时，使用 Arc 还能帮助我们规避在 middleware 下并发访问带来的问题（如做 mirror/diff 等场景），在此不过多赘述。\n并且，client 端本身不应该修改 Req，所以也不需要拿到可变的权限。\n而在 server 端，不会有这么复杂的使用场景，并且最终是要把所有权给到用户的 handler 的，因此 server 端直接使用 Req 所有权即可。\n为什么 volo-cli 生成的代码中要单独分拆成出 volo-gen crate？ 因为 Rust 的编译是以 crate 为单元的，把生成代码单独作为一个 crate 可以更好地利用编译缓存（idl 一般不会经常变动）。\n和 Kitex 的兼容性如何？ Volo 与 Kitex 完全兼容，包括元信息传递等功能。\n","categories":"","description":"","excerpt":"为什么 Client 端中间件使用 Arc？ 细心的你会发现，我们在 Client 端的生成代码中，会把用户传入的 Req 包装成 Arc  …","ref":"/zh/docs/volo/faq/","tags":"","title":"FAQ"},{"body":"概述 根据 Hertz 的分层设计原则将 QUIC 和 HTTP3 的实现集成到框架中来，对外提供灵活的多协议支持，对内保持足够灵活的扩展性和清晰的架构。 要从头实现一个完整的 QUIC 协议涉及到的工作量比较大且投入产出比相对较低，目前采取更合理的方式：首先定义标准网络传输层接口，之后将开源社区主流的一个或多个成熟的 QUIC 协议实现经过简单的适配和封装通过模块化的方式接入到 Hertz 中来，同时也保留未来独立实现 QUIC 协议的空间。类似目前的网络传输层架构。HTTP/3 同理。 明确了实现路径之后，本文档讨论的主题也就基本上清晰了，主要为：\n 网络传输层现状和 QUIC 设计层面统一：明确加入 QUIC 的网络传输层接口形态 协议层扩展 HTTP/3：在明确网络传输层形态之后，基于网络传输层接口实现 HTTP/3  设计 网络传输层 现状 当前的网络传输层设计主要还是基于 TCP 协议，基本语义为：当连接建立完成（包括 TLS）后为上层提供一个处理协议的回调函数：\n// Callback when data is ready on the connection type Serve func(ctx context.Context, conn Conn) error 当前网络传输层提供的标准网络库和 Netpoll 都是在这套接口下面展开的；因此协议层只需要依赖这个接口进行实现，而无需关心网络传输层具体正在提供的实现是什么。 在 TCP 协议提供的框架和语义下面，这套接口是完全够用的，目前 Hertz 基于此接口构建的 HTTP/1.1、HTTP/2 足以证明这一点。\n详细描述 Conn 的定义为：\ntype Conn interface { net.Conn Reader Writer // SetReadTimeout should work for every Read process  SetReadTimeout(t time.Duration) error } 主体由 Reader（提供从连接上读数据的能力）/Writer（提供往连接上写数据的能力）构成。 同时也是当前 Hertz 网络传输层高性能库实现的承载，具体定义为：\ntype Reader interface { // Peek returns the next n bytes without advancing the reader.  Peek(n int) ([]byte, error) // Skip discards the next n bytes.  Skip(n int) error // Release the memory space occupied by all read slices. This method needs to be executed actively to  // recycle the memory after confirming that the previously read data is no longer in use.  // After invoking Release, the slices obtained by the method such as Peek will  // become an invalid address and cannot be used anymore.  Release() error // Len returns the total length of the readable data in the reader.  Len() int // ReadByte is used to read one byte with advancing the read pointer.  ReadByte() (byte, error) // ReadBinary is used to read next n byte with copy, and the read pointer will be advanced.  ReadBinary(n int) (p []byte, err error) } type Writer interface { // Malloc will provide a n bytes buffer to send data.  Malloc(n int) (buf []byte, err error) // WriteBinary will use the user buffer to flush.  // NOTE: Before flush successfully, the buffer b should be valid.  WriteBinary(b []byte) (n int, err error) // Flush will send data to the peer end.  Flush() error } 引入 QUIC UDP + QUIC 大致可以对应到 TCP + TLS（严格的层级关系可以参考下图），按照当前的分层结构，同属于 Hertz 的网络传输层。不过 QUIC 的编程模型天然基于流（Stream）来进行的，而当前基于 TCP 的网络传输层提供的Reader /Writer本质上是基于字节流的编程模型。虽然 HTTP/2 非常类似地拥有流（Stream）的概念，但实际上是在 TCP 的字节流之上（应用协议层中）进行的封装，并非如 QUIC 这样原生实现到了传输协议内部。我们无法要求 TCP 直接内置流（Stream）的实现（这可能也是 HTTP/2 的愿望），换句话说，要想把 HTTP/2 和 HTTP/3 中流的概念在当下 Hertz 的某一层中统一起来，逻辑上其实是办不到的（虽然它们本质上是那么的相似）。\n明确了上述问题之后，引入 QUIC 后的网络库形态其实也就比较清晰了：基于 TCP 的网络抽象接口仍然保持原样，新增一套基于 QUIC（UDP）的网络传输层抽象，协议层对应提供一个基于 QUIC（UDP）网络抽象的处理接口。关键点在于，不强制将 QUIC（UDP） 融合至当前基于 TCP 的网络/协议层抽象当中来。\n接口设计 与当前 TCP 的抽象接口类似，QUIC 和 HTTP/3 的分界其实就是：\n 网络传输层语义覆盖 QUIC 协议的连接准备、连接建立过程；请求对应的流完成准备之后就达到网络传输层的边界 协议层关注从 QUIC 连接上打开的流（Stream）开始，通过这个打开的流完成请求的解析，handler 的处理，到将相应通过这条流写回对端（Server 视角，Client 同理，对调即可）  网络传输层和协议层拆分的优势非常明显，目前的 Hertz 支持 ET/LT 触发方式、标准网络库和 Netpoll 相互补充，丰富应用场景等都是很好的例子。\n方案 A 基于上述分层思想，一个和网络传输层 Serve 相对应的 QUIC 抽象其实就出具雏形了，命名为 OnStream，语义和 Serve 基本一致* ：当流完成准备。具体需要提供的实现就是上层协议（这里是 HTTP/3）。\ntype ServeStream func(ctx context.Context, stream Stream) error *注：ServeStream 语义和 Serve 一致具体指 HTTP/1 的 Serve 对应的其实就是“下一个请求的数据已经准备好”； 通过实现该接口就可以完成协议处理。 如果进一步深入，其实和当前 Hertz HTTP/2 的实现其实并不完全对应，究其原因在于：\n HTTP/2 的流实现在协议层上，本质上其实只是对引入的更小传输单元帧（Frame）的逻辑承载； 理想形态应该是将 HTTP/2 的实现进行拆分：流（Stream）准备逻辑下层到网络传输层 \u0026 基于流（Stream）的协议处理逻辑保留在协议层。  详细设计 暂略\n优点 方案 A 最大的特点是理想化的将应用协议和网络协议进行分离。 由于各种历史原因的叠加，TCP、HTTP/1、Websocket、HTTP/2、QUIC、HTTP/3 各自的架构设计存在很多重叠和职责界定不清晰的地方，且当下的很多实现可能还并未形成标准，通过合理的解构，能够帮助 Hertz 在面对未来可能的协议变迁、实现变迁的过程中仍然能够聚焦在 HTTP 本身这个核心问题之上，最终达成“泛 HTTP 框架”的终极目标。\n缺点 方案 A 的缺点其实就是伴随清晰的边界产生的，这也是协议设计和发展中的妥协和不彻底带来的一个现实问题。 其中，基于流（Stream）的协议层能很好的处理一个流（Stream）上的消息交互，但是同时也是由于对于协议层来说，仅仅显示暴露了流（Stream）这样一个请求级别的接口，但类似 HTTP/2，HTTP/3 这样基于流（Stream）的应用层协议，一个核心特点在于连接本身的多路复用，换句话说，底层连接和流的对应关系往往是 1:N 的。因此，如果是在协议处理过程中存在对承载流（Stream）的连接本身的控制需求（应该难以避免），就会比较难办（实现上没问题），概念上会和方案 A 的分层抽象存在相抵的地方。 极致的理想态可能并不太适用于当下的真实环境。\n方案 B 平衡理想形态和事实现状，容易想到的一种解决方案：额外抽象一个连接层出来，这个连接能够拥有操作流（Stream）的语义。网络传输层和协议层的边界从流（Stream）移动到这个连接上面来：\n 网络传输层负责这个连接的准备工作，当连接建立完成后直接将连接交给协议层 协议层直接操作建连完成后的链接，不过和 Hertz 当前的网络传输层连接抽象不同，这个连接不具备直接（理论上）读/写数据的接口和能力，涉及到数据交互的操作需要通过连接提供的流（Stream）相关操作进行，比如要想读取数据，需要通过连接接口开启一个双/单向的流，之后的数据交换操作通过这个开启的流来完成  type ServeStream func(ctx context.Context, streamConn StreamConn) error 详细设计 明确新增接口的形态之后，StreamConn具体能够支持的语义就比较清晰了，具体来说，分为两部分：\n 支持连接级别控制能力 支持流（Stream）相关控制能力  // StreamConn is interface for stream-based connection abstraction. type StreamConn interface { GetRawConnection() interface{} // HandshakeComplete blocks until the handshake completes (or fails).  HandshakeComplete() context.Context // CloseWithError closes the connection with an error.  // The error string will be sent to the peer.  CloseWithError(err ApplicationError, errMsg string) error // LocalAddr returns the local address.  LocalAddr() net.Addr // RemoteAddr returns the address of the peer.  RemoteAddr() net.Addr // The context is cancelled when the connection is closed.  Context() context.Context // Streamer is the interface for stream operations.  Streamer } type Streamer interface { // AcceptStream returns the next stream opened by the peer, blocking until one is available.  // If the connection was closed due to a timeout, the error satisfies  // the net.Error interface, and Timeout() will be true.  AcceptStream(context.Context) (Stream, error) // AcceptUniStream returns the next unidirectional stream opened by the peer, blocking until one is available.  // If the connection was closed due to a timeout, the error satisfies  // the net.Error interface, and Timeout() will be true.  AcceptUniStream(context.Context) (ReceiveStream, error) // OpenStream opens a new bidirectional QUIC stream.  // There is no signaling to the peer about new streams:  // The peer can only accept the stream after data has been sent on the stream.  // If the error is non-nil, it satisfies the net.Error interface.  // When reaching the peer's stream limit, err.Temporary() will be true.  // If the connection was closed due to a timeout, Timeout() will be true.  OpenStream() (Stream, error) // OpenStreamSync opens a new bidirectional QUIC stream.  // It blocks until a new stream can be opened.  // If the error is non-nil, it satisfies the net.Error interface.  // If the connection was closed due to a timeout, Timeout() will be true.  OpenStreamSync(context.Context) (Stream, error) // OpenUniStream opens a new outgoing unidirectional QUIC stream.  // If the error is non-nil, it satisfies the net.Error interface.  // When reaching the peer's stream limit, Temporary() will be true.  // If the connection was closed due to a timeout, Timeout() will be true.  OpenUniStream() (SendStream, error) // OpenUniStreamSync opens a new outgoing unidirectional QUIC stream.  // It blocks until a new stream can be opened.  // If the error is non-nil, it satisfies the net.Error interface. // If the connection was closed due to a timeout, Timeout() will be true. OpenUniStreamSync(context.Context) (SendStream, error) } type Stream interface { ReceiveStream SendStream } type ReceiveStream interface { StreamID() int64 io.Reader // CancelRead aborts receiving on this stream.  // It will ask the peer to stop transmitting stream data.  // Read will unblock immediately, and future Read calls will fail.  // When called multiple times or after reading the io.EOF it is a no-op.  CancelRead(err ApplicationError) // SetReadDeadline sets the deadline for future Read calls and  // any currently-blocked Read call.  // A zero value for t means Read will not time out.  SetReadDeadline(t time.Time) error } type SendStream interface { StreamID() int64 // Writer writes data to the stream.  // Write can be made to time out and return a net.Error with Timeout() == true  // after a fixed time limit; see SetDeadline and SetWriteDeadline.  // If the stream was canceled by the peer, the error implements the StreamError  // interface, and Canceled() == true.  // If the connection was closed due to a timeout, the error satisfies  // the net.Error interface, and Timeout() will be true.  io.Writer // CancelWrite aborts sending on this stream.  // Data already written, but not yet delivered to the peer is not guaranteed to be delivered reliably.  // Write will unblock immediately, and future calls to Write will fail.  // When called multiple times or after closing the stream it is a no-op.  CancelWrite(err ApplicationError) // Closer closes the write-direction of the stream.  // Future calls to Write are not permitted after calling Close.  // It must not be called concurrently with Write.  // It must not be called after calling CancelWrite.  io.Closer // The Context is canceled as soon as the write-side of the stream is closed.  // This happens when Close() or CancelWrite() is called, or when the peer  // cancels the read-side of their stream.  Context() context.Context // SetWriteDeadline sets the deadline for future Write calls  // and any currently-blocked Write call.  // Even if write times out, it may return n \u003e 0, indicating that  // some data was successfully written.  // A zero value for t means Write will not time out.  SetWriteDeadline(t time.Time) error } type ApplicationError interface { ErrCode() uint64 fmt.Stringer } 优点 相较于方案 A，本方案最大的优势在于，能够在语义层面很好的自洽：协议层与网络传输层的职责节点清晰明确，无需为一些历史问题妥协设计语义，同时当下主流的开源实现（HTTP/2 及 HTTP/3 over QUIC）都能够比较容易得融合到这个架构中来。 对协议层直接暴露连接的接口，给协议层提供了极大的自由度和对连接的控制力，是一个更加符合实际的抽象方式。\n缺点 相比于 Hertz 当前存在的网络传输层抽象（主要是 HTTP/1.1 的实现），新增的这套抽象层级上并不完全对等（不过这个也是 HTTP 协议大版本之间的一个明显的 break change），目前看起来，要想完全在抽象层面填平这个 gap 困难相对较大。不过，新增的“基于流的连接”这个概念应该也不完全是一件坏事，针对拥有相似语义的协议簇具有统一语义的作用，不过也要求类似基于流来实现多路复用的协议最好能够按照抽象进行拆分（目前的Websocket、HTTP/2 还不是此形态）\n方案选型 方案 B 在综合考虑架构形态和事实的一些主流实现后方案 B 更加符合 Hertz 的分层演进路线\n协议层 基于网络传输层方案 B 进一步往前走，协议层的实现就相对灵活的多了：针对 StreamConn 提供的接口管理连接，同时负责流（Stream）的开启和关闭即可。 不过，由于引入的 StreamConn 和当前网络传输层的 Conn 接口定义不一致，因此协议层更多需要考虑的是基于 StreamConn 和Conn 的两套回调如何在协议层以及协议服务器（Protocol Server）注册阶段完成融合。基本的要求是对目前的现状不能有任何影响。\n现状 通过 Hertz 提供的接口就可以便捷的将实现了 Server 接口的自定义协议服务器（Protocol Server）添加到 Hertz 实例支持的协议 map 中来。详细方式参考这里。本质上其实还是要求扩展 Server 实现\nServe(c context.Context, conn network.Conn) error 这个接口，而目前的 HTTP/1.1、HTTP/2 的实现也都是按照这个方式来进行的。\n引入 StreamConn 接口设计 如网络传输层抽象方案 B 所述，新引入的 StreamConn 本身和当前的 network.Conn 在语义上存在很大的 diff，导致硬融合这两个接口为一个存在一定的困难。在“新增 QUIC \u0026 HTTP3 支持不能破坏存量抽象”的基本底线之上，更加合理的方式是显示增加一个独立且平行的基于流的 Server 接口： StreamServer：\ntype StreamServer interface { Serve(c context.Context, conn network.StreamConn) error } Protocol server factory：\ntype StreamServerFactory interface {New(core Core) (server protocol.StreamServer, err error)}// Core is the core interface that promises to be provided for the protocol layer extensions type Core interface {// IsRunning Check whether engine is running or not  IsRunning() bool// A RequestContext pool ready for protocol server impl  GetCtxPool() *sync.Pool// Business logic entrance  // After pre-read works, protocol server may call this method  // to introduce the middlewares and handlers  ServeHTTP(c context.Context, ctx *app.RequestContext)// GetTracer for tracing requirement  GetTracer() tracer.Controller } 按照这套新的抽象接口展开，对于存量架构的影响就非常小了，不过需要新增针对新增的网络抽象和协议抽象的映射。 当前网络传输层、协议层间不存在明显耦合：\n网络传输层原生提供：\n 基于netpoll的实现 基于标准库的实现  协议层提供：\n HTTP/1.1 HTTP/2  排除掉 Netpoll 不支持 TLS 这一点来看，其实网络传输层和协议层是能够自由组合，总共4（2*2）种不同的搭配。 但新引入的StreamConn（网络传输层） 、StreamServer（协议层）其实和上述实现完全平行，如果网络传输层采用 StreamConn 这套抽象接口，协议层也就只能是对接实现了 StreamServer 的 Server 了（目前的 HTTP/1.1、HTTP/2 都不是，不过 HTTP/2 是条流写回对存在改造/重写适配上 StreamConn \u0026 StreamServer 的可能性的）。\n实现 https://github.com/cloudwego/hertz/issues/458\n","categories":"","description":"","excerpt":"概述 根据 Hertz 的分层设计原则将 QUIC 和 HTTP3 的实现集成到框架中来，对外提供灵活的多协议支持，对内保持足够灵活的扩展性 …","ref":"/zh/docs/hertz/reference/stream_based_design/","tags":"","title":"Hertz 支持 QUIC \u0026 HTTP/3"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/reference/","tags":"","title":"Reference"},{"body":"Congratulations, you’ve read this far!\nAt this point, we’ve basically learned how to use Volo, and we’re ready to use Volo to kick off our Rust journey\nNext, you may need to select the right components, put them together, and interface with your system.\nThe related ecosystem maintained by Volo will be located in: https://github.com/volo-rs, we are working to build our ecosystem, and welcome everyone to join us ~\nIf there is a dire lack of components, you are welcomed to raise an issue in: https://github.com/cloudwego/volo, we will support it as soon as possible.\nIn the meantime, welcome to join our Lark user group and share your experience with us about Volo.\n  Looking forward to your unique work created with Volo.\n","categories":"","description":"","excerpt":"Congratulations, you’ve read this far!\nAt this point, we’ve basically …","ref":"/docs/volo/volo-grpc/getting-started/part_5/","tags":"","title":"Part 5. What's Next?"},{"body":"Congratulations, you’ve read this far!\nAt this point, we’ve basically learned how to use Volo, and we’re ready to use Volo to kick off our Rust journey\nNext, you may need to select the right components, put them together, and interface with your system.\nThe related ecosystem maintained by Volo will be located in: https://github.com/volo-rs, we are working to build our ecosystem, and welcome everyone to join us ~\nIf there is a dire lack of components, you are welcomed to raise an issue in: https://github.com/cloudwego/volo, we will support it as soon as possible.\nIn the meantime, welcome to join our Lark user group and share your experience with us about Volo.\n  Looking forward to your unique work created with Volo.\n","categories":"","description":"","excerpt":"Congratulations, you’ve read this far!\nAt this point, we’ve basically …","ref":"/docs/volo/volo-thrift/getting-started/part_5/","tags":"","title":"Part 5. What's Next?"},{"body":"恭喜你，阅读到了这里！\n至此，我们已经基本学会了 Volo 的大部分使用了，可以使用 Volo 来开启我们愉快的 Rust 之旅啦～\n接下来，你可能需要选择合适的组件，组装在一起，和你的系统进行对接。\nVolo 维护的相关生态会集中在：https://github.com/volo-rs 中，我们正在努力打造我们的生态，也非常欢迎大家一起参与～\n如果有比较急缺的组件，也欢迎在官方仓库：https://github.com/cloudwego/volo 的 issue 中提出，我们也会优先支持社区最急缺的组件。\n同时，欢迎加入我们的飞书用户群，交流 Volo 的使用心得～\n  期待你使用 Volo 创造出属于你的独一无二的作品～\n","categories":"","description":"","excerpt":"恭喜你，阅读到了这里！\n至此，我们已经基本学会了 Volo 的大部分使用了，可以使用 Volo 来开启我们愉快的 Rust 之旅啦～\n接下 …","ref":"/zh/docs/volo/volo-grpc/getting-started/part_5/","tags":"","title":"Part 5. What's Next?"},{"body":"恭喜你，阅读到了这里！\n至此，我们已经基本学会了 Volo 的大部分使用了，可以使用 Volo 来开启我们愉快的 Rust 之旅啦～\n接下来，你可能需要选择合适的组件，组装在一起，和你的系统进行对接。\nVolo 维护的相关生态会集中在：https://github.com/volo-rs 中，我们正在努力打造我们的生态，也非常欢迎大家一起参与～\n如果有比较急缺的组件，也欢迎在官方仓库：https://github.com/cloudwego/volo 的 issue 中提出，我们也会优先支持社区最急缺的组件。\n同时，欢迎加入我们的飞书用户群，交流 Volo 的使用心得～\n  期待你使用 Volo 创造出属于你的独一无二的作品～\n","categories":"","description":"","excerpt":"恭喜你，阅读到了这里！\n至此，我们已经基本学会了 Volo 的大部分使用了，可以使用 Volo 来开启我们愉快的 Rust 之旅啦～\n接下 …","ref":"/zh/docs/volo/volo-thrift/getting-started/part_5/","tags":"","title":"Part 5. What's Next?"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/reference/","tags":"","title":"参考"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/tutorials/framework-exten/","tags":"","title":"框架扩展"},{"body":"Supported api annotations\n Field annotation can be used forparameter binding and validation\nMethod annotation can be used to generate code that related to route registration\n Supported api annotations    Field annotation      annotation description   api.raw_body generate “raw_body” tag   api.query generate “query” tag   api.header generate “header” tag   api.cookie generate “cookie” tag   api.body generate “json” tag   api.path generate “path” tag   api.form generate “form” tag   api.go_tag (protobuf)\ngo.tag (thrift) passing go_tag through will generate the content defined in go_tag   api.vd generate “vd” tag       Method annotation      annotation description   api.get define GET methods and routes   api.post define POST methods and routes   api.put define PUT methods and routes   api.delete define DELETE methods and routes   api.patch define PATCH methods and routes   api.options define OPTIONS methods and routes   api.head define HEAD methods and routes   api.any define ANY methods and routes    Usage: Field annotation: Thrift:\nstructDemo{1:stringDemo (api.query=\"demo\",api.path=\"demo\");2:stringGoTag (go.tag=\"goTag:\"tag\"\");3:stringVd (api.vd=\"$!='your string'\");}Protobuf:\nmessage Demo { string Demo = 1[(api.query)=\"demo\",(api.path)=\"demo\"]; string GoTag = 2[(api.go_tag)=\"goTag:\"tag\"\"]; string Vd = 3[(api.vd)=\"$!='your string'\"];}Method annotation: Thrift:\nserviceDemo{RespMethod(1:Reqrequest)(api.get=\"/route\");}Protobuf:\nservice Demo { rpc Method(Req) returns(Resp) { option (api.get) = \"/route\"; }}","categories":"","description":"","excerpt":"Supported api annotations\n Field annotation can be used forparameter …","ref":"/docs/hertz/tutorials/toolkit/usage/annotation/","tags":"","title":"hz annotation"},{"body":"支持的 api 注解\n Field 注解可用于参数绑定及校验\nMethod 注解可用于生成路由注册相关代码\n 支持的 api 注解：    Field 注解      注解 说明   api.raw_body 生成 “raw_body” tag   api.query 生成 “query” tag   api.header 生成 “header” tag   api.cookie 生成 “cookie” tag   api.body 生成 “json” tag   api.path 生成 “path” tag   api.form 生成 “form” tag   api.go_tag (protobuf)\ngo.tag (thrift) 透传 go_tag，会生成 go_tag 里定义的内容   api.vd 生成 “vd” tag       Method 注解      注解 说明   api.get 定义 GET 方法及路由   api.post 定义 POST 方法及路由   api.put 定义 PUT 方法及路由   api.delete 定义 DELETE 方法及路由   api.patch 定义 PATCH 方法及路由   api.options 定义 OPTIONS 方法及路由   api.head 定义 HEAD 方法及路由   api.any 定义 ANY 方法及路由    使用方法： Field 注解： Thrift：\nstructDemo{1:stringDemo (api.query=\"demo\",api.path=\"demo\");2:stringGoTag (go.tag=\"goTag:\"tag\"\");3:stringVd (api.vd=\"$!='your string'\");}Protobuf:\nmessage Demo { string Demo = 1[(api.query)=\"demo\",(api.path)=\"demo\"]; string GoTag = 2[(api.go_tag)=\"goTag:\"tag\"\"]; string Vd = 3[(api.vd)=\"$!='your string'\"];}Method 注解： Thrift：\nserviceDemo{RespMethod(1:Reqrequest)(api.get=\"/route\");}Protobuf:\nservice Demo { rpc Method(Req) returns(Resp) { option (api.get) = \"/route\"; }}","categories":"","description":"","excerpt":"支持的 api 注解\n Field 注解可用于参数绑定及校验\nMethod 注解可用于生成路由注册相关代码\n 支持的 api 注解： …","ref":"/zh/docs/hertz/tutorials/toolkit/usage/annotation/","tags":"","title":"IDL 注解说明"},{"body":"Usage Scenarios For kitex_gen structs generated by the same IDL, if they are placed in different git repo, the type will be inconsistent. Some business teams will have an independent structs git repo for the public IDL to store these generated codes. The kitex tool can directly generate references to the remote repo for a specific IDL without actually generating a struct in the code generation stage, thereby solving the situation of type inconsistency.\nPractice First make sure:\n The kitex tool version is not lower than v0.4.4 thriftgo version not lower than v0.2.4  Create a file called idl-ref.yml to configure the remote references you want to use for a particular IDL:\nref:idl/base.thrift:\"github.com/xxxx/public_repo/base\"idl/public/item.thrift:\"github.com/xxxx/public_repo/item\"After the kitex command is normally executed in the directory with idl-ref.yml, the specified IDL will not generate a complete serialization and deserialization code after execution, but will generate a remote reference to the structs, thereby solving the common Library structure conflict problem. An example of the generated codes is as follows:\n// Code generated by thriftgo (0.2.4). DO NOT EDIT.  package base import ( base \"github.com/xxxx/public_repo/base\" ) type Base = base.Base var NewBase = base. NewBase type BaseResp = base. BaseResp var NewBaseResp = base. NewBaseResp const MY_CONST = base.MY_CONST var MAP_CONST = base.MAP_CONST ","categories":"","description":"Use Kitex tool to generate structs reference to solve public structs problem.","excerpt":"Use Kitex tool to generate structs reference to solve public structs …","ref":"/docs/kitex/tutorials/code-gen/struct_reference_generator/","tags":"","title":"Generate Structs Reference "},{"body":"使用场景 对于同一份 IDL 生成的 kitex_gen 结构体，如果分别放到不同的仓库后，会出现类型不一致的情况。 有的业务团队会对公共的 IDL 有独立的结构体仓库来存放这些生成产物。kitex 命令行可以在生成代码阶段直接对特定的 IDL 不进行实际的结构体生成，而是向远端做引用，从而解决类型不一致的情况。\n使用方式 首先确保：\n kitex 命令行版本不低于 v0.4.4 thriftgo 版本不低于 v0.2.4  创建一个名为 idl-ref.yml 的文件，对特定的 IDL 配置你想使用的远端引用：\nref:idl/base.thrift:\"github.com/xxxx/public_repo/base\"idl/public/item.thrift:\"github.com/xxxx/public_repo/item\"在有 idl-ref.yml 的目录下正常执行 kitex 命令后，这部分指定的 IDL 在执行后不会生成完整的序列化反序列化代码，而是对结构体生成一个远端引用，从而解决公共库结构体冲突问题。 生成产物的一个例子如下：\n// Code generated by thriftgo (0.2.4). DO NOT EDIT.  package base import ( base \"github.com/xxxx/public_repo/base\" ) type Base = base.Base var NewBase = base.NewBase type BaseResp = base.BaseResp var NewBaseResp = base.NewBaseResp const MY_CONST = base.MY_CONST var MAP_CONST = base.MAP_CONST ","categories":"","description":"使用 Kitex 命令行生成结构体引用，解决公共结构体问题","excerpt":"使用 Kitex 命令行生成结构体引用，解决公共结构体问题","ref":"/zh/docs/kitex/tutorials/code-gen/struct_reference_generator/","tags":"","title":"生成引用结构体"},{"body":"Session is a special object created by the server to hold user’s state.\nHertz also provides an implementation of Session, which references Gin’s implementation.\nInstall Download and install\ngo get github.com/hertz-contrib/sessions Import into your code\nimport \"github.com/hertz-contrib/sessions\" Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/incr\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) var count int v := session.Get(\"count\") if v != nil { count = v.(int) count++ } session.Set(\"count\", count) _ = session.Save() c.JSON(200, utils.H{\"count\": count}) }) h.Spin() } Config Hertz can configure the Session for a series of operations by using middleware. The Session interface defines the main methods to configure the Session operation. The introduction of the interface methods is as follows:\nNote: Session Wraps thinly gorilla-session methods.\n   Method Function Signatures Description     ID ID() string Used to fetch the Session ID generated by stores, it should not be used for user data.   Get Get(key interface{}) interface{} Used to get the session value associated to the given key.   Set Set(key, val interface{}) Used to set the session value associated to the given key.   Delete Delete(key interface{}) Used to remove the session value associated to the given key.   Clear Clear() Used to delete all values in the session.   AddFlash AddFlash(value interface{}, vars ...string) Used to add a flash message to the session.   Flashes Flashes(vars ...string) []interface{} Used to get a slice of flash messages from the session.   Options Options(Options) Used to set configuration for a session.   Save Save() error Used to save all sessions used during the current request.    NewStore The sessions middleware provides NewStore to store sessions in Cookie or Redis.\nCookie Function signatures of cookie.NewStore:\nfunc NewStore(keyPairs ...[]byte) Store Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/incr\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) var count int v := session.Get(\"count\") if v == nil { count = 0 } else { count = v.(int) count++ } session.Set(\"count\", count) _ = session.Save() c.JSON(200, utils.H{\"count\": count}) }) h.Spin() } Redis Function signatures of redis.NewStore:\nfunc NewStore(size int, network, addr, passwd string, keyPairs ...[]byte) (Store, error) Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/redis\" ) func main() { h := server.Default(server.WithHostPorts(\":8000\")) store, _ := redis.NewStore(10, \"tcp\", \"localhost:6379\", \"\", []byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/incr\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) var count int v := session.Get(\"count\") if v == nil { count = 0 } else { count = v.(int) count++ } session.Set(\"count\", count) session.Save() c.JSON(200, utils.H{\"count\": count}) }) h.Spin() } New The sessions middleware provides New to create a single Session.\nFunction signatures:\nfunc New(name string, store Store) app.HandlerFunc Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) if session.Get(\"hello\") != \"world\" { session.Set(\"hello\", \"world\") _ = session.Save() } c.JSON(200, utils.H{\"hello\": session.Get(\"hello\")}) }) h.Spin() } Many The sessions middleware provides Many to create multiple sessions.\nFunction signatures:\nfunc Many(names []string, store Store) app.HandlerFunc Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) sessionNames := []string{\"a\", \"b\"} h.Use(sessions.Many(sessionNames, store)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { sessionA := sessions.DefaultMany(c, \"a\") sessionB := sessions.DefaultMany(c, \"b\") if sessionA.Get(\"hello\") != \"world!\" { sessionA.Set(\"hello\", \"world!\") _ = sessionA.Save() } if sessionB.Get(\"hello\") != \"world?\" { sessionB.Set(\"hello\", \"world?\") _ = sessionB.Save() } c.JSON(200, utils.H{ \"a\": sessionA.Get(\"hello\"), \"b\": sessionB.Get(\"hello\"), }) }) h.Spin() } Default The sessions middleware provides Default to fetch a single Session.\nFunction signatures:\nfunc Default(c *app.RequestContext) Session Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) if session.Get(\"hello\") != \"world\" { session.Set(\"hello\", \"world\") _ = session.Save() } c.JSON(200, utils.H{\"hello\": session.Get(\"hello\")}) }) h.Spin() } DefaultMany The sessions middleware provides DefaultMany to get the Session based on its name.\nFunction signatures:\nfunc DefaultMany(c *app.RequestContext, name string) Session Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) sessionNames := []string{\"a\", \"b\"} h.Use(sessions.Many(sessionNames, store)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { sessionA := sessions.DefaultMany(c, \"a\") sessionB := sessions.DefaultMany(c, \"b\") if sessionA.Get(\"hello\") != \"world!\" { sessionA.Set(\"hello\", \"world!\") _ = sessionA.Save() } if sessionB.Get(\"hello\") != \"world?\" { sessionB.Set(\"hello\", \"world?\") _ = sessionB.Save() } c.JSON(200, utils.H{ \"a\": sessionA.Get(\"hello\"), \"b\": sessionB.Get(\"hello\"), }) }) h.Spin() } Distributed Session Hertz also provides a bizdemo for distributed session solution based on Redis.\nNote: This demo is only a simple demonstration of the distributed session, the specific business code needs to be modified by the user combined with the corresponding business logic\n The distributed session solution based on redis is to store the sessions of different servers in redis or redis cluster, which aims to solve the problem that the sessions of multiple servers are not synchronized in the case of distributed system.\n Display of core code\n Initialize session middleware:  // biz/mw/session.go func InitSession(h *server.Hertz) { store, err := redis.NewStore(consts.MaxIdleNum, consts.TCP, consts.RedisAddr, consts.RedisPasswd, []byte(consts.SessionSecretKey)) if err != nil { panic(err) } h.Use(sessions.New(consts.HertzSession, store)) } Store the session after user sign in:  // biz/handler/user/user_service.go/Login // ... session := sessions.Default(c) session.Set(consts.Username, req.Username) _ = session.Save() // ... When the user visits the home page directly, determine whether the corresponding Session exists, and if not, then redirect to the login page (in this example) or restricts the resources that can be browsed or used after login:  // pkg/render/render.go // ... session := sessions.Default(c) username := session.Get(consts.Username) if username == nil { // ...  c.Redirect(http.StatusMovedPermanently, []byte(\"/login.html\")) return } // ... Clear the session after user sign out:  // biz/handler/user/user_service.go/Logout // ... session := sessions.Default(c) session.Delete(consts.Username) _ = session.Save() // ... Session middleware encapsulates most of the complex logic, users only need to call the simple interfaces to complete the corresponding business process.\nFull Example As for usage, you may refer to example and hertz_session\n","categories":"","description":"","excerpt":"Session is a special object created by the server to hold user’s …","ref":"/docs/hertz/tutorials/basic-feature/middleware/session/","tags":"","title":"Session Extension"},{"body":"Session 是服务器为了保存用户状态而创建的一种特殊的对象。\nHertz 也提供了 Session 的 实现，它参考了 Gin 的 实现。\n安装 下载并安装\ngo get github.com/hertz-contrib/sessions 导入\nimport \"github.com/hertz-contrib/sessions\" 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/incr\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) var count int v := session.Get(\"count\") if v != nil { count = v.(int) count++ } session.Set(\"count\", count) _ = session.Save() c.JSON(200, utils.H{\"count\": count}) }) h.Spin() } 配置 Hertz 通过使用中间件，可以对 Session 进行一系列的操作配置。其中 Session 接口定义了对 Session 操作配置的主要方法，接口方法的介绍如下：\n注意： Session 接口对 gorilla-session 的方法进行了简单封装。\n   方法 函数签名 介绍     ID ID() string 用于获取存储时生成的Session ID，它不应该作为用户信息的一部分去使用   Get Get(key interface{}) interface{} 用于根据给定的键值参数获取Session值   Set Set(key, val interface{}) 用于设置与给定键值相关联的Session值   Delete Delete(key interface{}) 用于根据给定的键值删除相关联的Session值   Clear Clear() 用于删除Session中存储的所有值   AddFlash AddFlash(value interface{}, vars ...string) 用于向Session添加一条flash message   Flashes Flashes(vars ...string) []interface{} 用于获取Session中的flash message   Options Options(Options) 用于设置Session的配置   Save Save() error 用于保存当前请求期间使用的所有会话    NewStore sessions 中间件提供了 NewStore 用于将 Session 存储在 Cookie 或者 Redis 中。\nCookie 函数签名：\nfunc NewStore(keyPairs ...[]byte) Store 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/incr\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) var count int v := session.Get(\"count\") if v == nil { count = 0 } else { count = v.(int) count++ } session.Set(\"count\", count) _ = session.Save() c.JSON(200, utils.H{\"count\": count}) }) h.Spin() } Redis 函数签名：\nfunc NewStore(size int, network, addr, passwd string, keyPairs ...[]byte) (Store, error) 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/redis\" ) func main() { h := server.Default(server.WithHostPorts(\":8000\")) store, _ := redis.NewStore(10, \"tcp\", \"localhost:6379\", \"\", []byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/incr\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) var count int v := session.Get(\"count\") if v == nil { count = 0 } else { count = v.(int) count++ } session.Set(\"count\", count) session.Save() c.JSON(200, utils.H{\"count\": count}) }) h.Spin() } New sessions 中间件提供了 New 用于创建单个 Session。\n函数签名：\nfunc New(name string, store Store) app.HandlerFunc 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) if session.Get(\"hello\") != \"world\" { session.Set(\"hello\", \"world\") _ = session.Save() } c.JSON(200, utils.H{\"hello\": session.Get(\"hello\")}) }) h.Spin() } Many sessions 中间件提供了 Many 用于创建多个 Session。\n函数签名：\nfunc Many(names []string, store Store) app.HandlerFunc 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) sessionNames := []string{\"a\", \"b\"} h.Use(sessions.Many(sessionNames, store)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { sessionA := sessions.DefaultMany(c, \"a\") sessionB := sessions.DefaultMany(c, \"b\") if sessionA.Get(\"hello\") != \"world!\" { sessionA.Set(\"hello\", \"world!\") _ = sessionA.Save() } if sessionB.Get(\"hello\") != \"world?\" { sessionB.Set(\"hello\", \"world?\") _ = sessionB.Save() } c.JSON(200, utils.H{ \"a\": sessionA.Get(\"hello\"), \"b\": sessionB.Get(\"hello\"), }) }) h.Spin() } Default sessions 中间件提供了 Default 用于获取单个 Session 对象。\n函数签名：\nfunc Default(c *app.RequestContext) Session 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"mysession\", store)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { session := sessions.Default(c) if session.Get(\"hello\") != \"world\" { session.Set(\"hello\", \"world\") _ = session.Save() } c.JSON(200, utils.H{\"hello\": session.Get(\"hello\")}) }) h.Spin() } DefaultMany sessions 中间件提供了 DefaultMany 用于根据 Session 名获取对应的 Session 对象。\n函数签名：\nfunc DefaultMany(c *app.RequestContext, name string) Session 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.New(server.WithHostPorts(\":8000\")) store := cookie.NewStore([]byte(\"secret\")) sessionNames := []string{\"a\", \"b\"} h.Use(sessions.Many(sessionNames, store)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { sessionA := sessions.DefaultMany(c, \"a\") sessionB := sessions.DefaultMany(c, \"b\") if sessionA.Get(\"hello\") != \"world!\" { sessionA.Set(\"hello\", \"world!\") _ = sessionA.Save() } if sessionB.Get(\"hello\") != \"world?\" { sessionB.Set(\"hello\", \"world?\") _ = sessionB.Save() } c.JSON(200, utils.H{ \"a\": sessionA.Get(\"hello\"), \"b\": sessionB.Get(\"hello\"), }) }) h.Spin() } 分布式 Session Hertz 也提供了基于 Redis 的分布式 Session 解决方案的 bizdemo。\n注意：这只是对分布式 Session 功能的简单演示，具体业务代码需用户结合对应的业务逻辑做出相应修改\n 基于 Redis 的分布式 Session 解决方案是指将不同服务器的 Session 统一存储在 Redis 或 Redis 集群中，旨在解决分布式系统下多个服务器的 Session 不同步的问题。\n 核心代码展示\n Session 中间件初始化：  // biz/mw/session.go func InitSession(h *server.Hertz) { store, err := redis.NewStore(consts.MaxIdleNum, consts.TCP, consts.RedisAddr, consts.RedisPasswd, []byte(consts.SessionSecretKey)) if err != nil { panic(err) } h.Use(sessions.New(consts.HertzSession, store)) } 用户登录后存储 Session：  // biz/handler/user/user_service.go/Login // ... session := sessions.Default(c) session.Set(consts.Username, req.Username) _ = session.Save() // ... 用户直接访问主页时判断是否存在对应 Session，不存在则重定向到登录页面（本例）或者限制登录后才可以进行浏览或使用的资源：  // pkg/render/render.go // ... session := sessions.Default(c) username := session.Get(consts.Username) if username == nil { // ...  c.Redirect(http.StatusMovedPermanently, []byte(\"/login.html\")) return } // ... 用户登出后清理 Session：  // biz/handler/user/user_service.go/Logout // ... session := sessions.Default(c) session.Delete(consts.Username) _ = session.Save() // ... Session 中间件对大多数复杂的逻辑进行了封装，用户只需要调用简单的接口即可完成对应的业务流程。\n完整示例 完整用法示例详见 example 以及 hertz_session\n","categories":"","description":"","excerpt":"Session 是服务器为了保存用户状态而创建的一种特殊的对象。\nHertz 也提供了 Session 的 实现，它参考了 Gin 的 实 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/session/","tags":"","title":"Session扩展"},{"body":"Kitex provides the WithGRPCUnknownServiceHandler function when transport is using gRPC. When the server receives a request from an unknown gRPC method, it will execute the unknown service handler:\nfunc handler(ctx context.Context, methodName string, stream streaming.Stream) error { // .... handle unknown service  } func RunServer(){ // ...  svr := service.NewServer(server.WithGRPCUnknownServiceHandler(handler),xxx,xxx) // ...  } A gRPC Proxy Server can be implemented through the gRPCUnknownServiceHandler provided by Kitex. In the grpc proxy Kitex Example, the gRPC Proxy implementations of two scenarios are shown respectively, namely:\n Read gRPC Frame and forward it directly Read gRPC and decode it into a structure, and then forward it after checking or customizing the structure  The following two proxy implementation ideas in Kitex Example are explained, so that users can refer to them and implement them according to their own needs.\nRedirecting gRPC Frame When the gRPC Proxy we want to implement does not care about the specific content of RPC, it does not need to encode and decode, and directly forwards the obtained gRPC Frame message to the target end, without introducing other codes such as stub modules. An example is as follows:\nfunc GRPCFrameProxyHandler(ctx context.Context, methodName string, stream streaming.Stream) error { // find target address by methodName \tnetwork, address := proxy.Resolve(methodName) // create a new RPC Info and modify some infos if you want. \tsri := rpcinfo.GetRPCInfo(ctx) ri := rpcinfo.NewRPCInfo(sri.From(), sri.To(), sri.Invocation(), sri.Config(), sri.Stats()) clientCtx := rpcinfo.NewCtxWithRPCInfo(context.Background(), ri) conn, err := connPool.Get(clientCtx, network, address, remote.ConnOption{ Dialer: netpoll.NewDialer(), ConnectTimeout: 0, }) if err != nil { return err } clientConn := conn.(nphttp2.GRPCConn) defer func() { clientConn.Close() connPool.Put(clientConn) }() serverConn, err := nphttp2.GetServerConn(stream) if err != nil { return err } s2c := redirectFrame(serverConn, clientConn) c2s := redirectFrame(clientConn, serverConn) // ... } First, get IP Address and other information of the target terminal, and then directly obtain a peer connection from the connection pool, encapsulate it as a GRPCConn structure, and use its ReadFrame and WriteFrame to send data.\nIt should be noted that the user needs to create a new connection pool, set the corresponding parameters, and perform the corresponding connection release and other operations after using the connection in the Unknown Service Handler. For the relevant writing method, please refer to the code in this example.\nThe code for reading and forwarding gRPC Frame is implemented as follows:\nfunc redirectFrame(from, to nphttp2.GRPCConn) chan error { ret := make(chan error) go func() { for { hdr, data, err := from.ReadFrame() if err != nil { // write last empty data frame with END_STREAM flag \tto.WriteFrame(hdr, data) ret \u003c- err break } _, err = to.WriteFrame(hdr, data) if err != nil { ret \u003c- err break } } }() return ret } ReadFrame is used to continuously read gRPC Frame and write to the forwarding destination. When the last read ReadFrame receives a Data Frame with an EndStream identifier, ReadFrame will receive io.EOF, which means the connection is in a half-closed state. At this time, the values of hdr and data are both nil, so using WriteFrame is also far away. The end sends an empty packet with EndStream, indicating that the sending content is over, otherwise the proxy server may be blocked.\nDecoding and Redrecting In some proxy server scenarios, we need to decode and obtain the structure object, perform some custom processing (such as reading the request for judgment, or modify some fields of the request), and then resend the structure to the remote end. In this scenario, it may be necessary to introduce the corresponding client stub module code in the proxy server code. An example is as follows:\nfunc GRPCStructProxyHandler(ctx context.Context, methodName string, serverStream streaming.Stream) error { // find target address by methodName \t_, address := proxy.Resolve(methodName) // \tclient, _ := servicea.NewClient(\"destService\", client.WithHostPorts(address), client.WithTransportProtocol(transport.GRPC)) clientStream, err := client.Chat(context.Background()) if err != nil { return err } s2c := redirectStruct(serverStream, clientStream) c2s := redirectStruct(clientStream, serverStream) // ... } First, get IP Address and other information of the target, and then create a client to connect with the target. Next, the decoding and forwarding processing of the data is performed. This example is a bidirectional streaming scenario, so the client also performs multiple structure sending and receiving operations through clientStream. Write the following code to make serverStream read and decode the structure, and then forward it to clientStream:\nfunc redirectStruct(from, to streaming.Stream) chan error { ret := make(chan error) go func() { for { req := \u0026grpcproxy.Request{} err := from.RecvMsg(req) if err != nil { from.Close() ret \u003c- err break } // do your own filter logic here  //if req.Name==xxx{  // continue  //}  err = to.SendMsg(req) if err != nil { ret \u003c- err break } } }() return ret } In this part, the data read through RecvMsg is serialized and written into the structure, and the judgment and modification operations on the structure fields can be added, and then forwarded.\n","categories":"","description":"Kitex supports custom Proxy routing for unregistered gRPC method calls.","excerpt":"Kitex supports custom Proxy routing for unregistered gRPC method …","ref":"/docs/kitex/tutorials/advanced-feature/grpcproxy/","tags":"","title":"gRPC Proxy"},{"body":"Kitex 对 gRPC 场景提供了 WithGRPCUnknownServiceHandler 功能，当服务器接收到未注册的 gRPC 方法调用的请求时，将执行自定义的 Unknown Service Handler 函数进行处理：\nfunc handler(ctx context.Context, methodName string, stream streaming.Stream) error { // .... handle unknown service  } func RunServer(){ // ...  svr := service.NewServer(server.WithGRPCUnknownServiceHandler(handler),xxx,xxx) // ...  } 通过 Kitex 提供的 gRPCUnknownServiceHandler，可以实现 gRPC Proxy 代理服务器。在 Kitex Example 中的grpc proxy 示例中，分别展示了两种场景的 gRPC Proxy 实现，分别是：\n 读取 gRPC Frame 并直接转发 读取 gRPC 并解码为结构体，在对结构体进行检查或自定义操作后再进行转发  下文对 Kitex Example 中的两种 Proxy 实现思路进行讲解，以便使用者参考，并按照自己的需求进行实现。\ngRPC Frame 直接转发 当我们要实现的 gRPC Proxy 并不关心 RPC 的具体内容时，无需编解码，直接将拿到的 gRPC Frame 报文转发至目标端，不需要引入桩模块等其他代码。示例如下：\nfunc GRPCFrameProxyHandler(ctx context.Context, methodName string, stream streaming.Stream) error { // find target address by methodName \tnetwork, address := proxy.Resolve(methodName) // create a new RPC Info and modify some infos if you want. \tsri := rpcinfo.GetRPCInfo(ctx) ri := rpcinfo.NewRPCInfo(sri.From(), sri.To(), sri.Invocation(), sri.Config(), sri.Stats()) clientCtx := rpcinfo.NewCtxWithRPCInfo(context.Background(), ri) conn, err := connPool.Get(clientCtx, network, address, remote.ConnOption{ Dialer: netpoll.NewDialer(), ConnectTimeout: 0, }) if err != nil { return err } clientConn := conn.(nphttp2.GRPCConn) defer func() { clientConn.Close() connPool.Put(clientConn) }() serverConn, err := nphttp2.GetServerConn(stream) if err != nil { return err } s2c := redirectFrame(serverConn, clientConn) c2s := redirectFrame(clientConn, serverConn) // ... } 首先获取目标端的 IP Address 等信息，然后从连接池中直接获取到一条对端连接，封装为 GRPCConn 结构体，利用其 ReadFrame 与 WriteFrame 进行数据发送。\n需要注意的是，这里需要用户自己创建新的连接池，设置相应的参数，并在 Unknown Service Handler 中使用完连接后进行相应的连接释放等操作，相关写法可以参考本示例中的代码。\n读取并转发 gRPC Frame 的代码实现如下：\nfunc redirectFrame(from, to nphttp2.GRPCConn) chan error { ret := make(chan error) go func() { for { hdr, data, err := from.ReadFrame() if err != nil { // write last empty data frame with END_STREAM flag \tto.WriteFrame(hdr, data) ret \u003c- err break } _, err = to.WriteFrame(hdr, data) if err != nil { ret \u003c- err break } } }() return ret } 这里使用 ReadFrame 不断读取 gRPC Frame 并写入转发目标端。当最后一次读取 ReadFrame 收到带有 EndStream 标识符的 Data Frame 后，ReadFrame 会收到 io.EOF，代表连接处于半关闭状态，此时 hdr 和 data 的值都为 nil，所以使用 WriteFrame 也向远端发送一个带有 EndStream 的空包，表示发送内容结束，否则可能会出现 proxy server 阻塞的场景。\n解码处理后转发 在有些 proxy server 的场景中，我们需要解码获取到结构体对象，并进行一些自定义的处理（例如读取请求做判断，或者修改请求的某些字段），再将结构体重新发送到远端。这种场景下，可能需要在 proxy server 的代码中引入对应的 client 桩模块代码。示例如下：\nfunc GRPCStructProxyHandler(ctx context.Context, methodName string, serverStream streaming.Stream) error { // find target address by methodName \t_, address := proxy.Resolve(methodName) // \tclient, _ := servicea.NewClient(\"destService\", client.WithHostPorts(address), client.WithTransportProtocol(transport.GRPC)) clientStream, err := client.Chat(context.Background()) if err != nil { return err } s2c := redirectStruct(serverStream, clientStream) c2s := redirectStruct(clientStream, serverStream) // ... } 首先获取到目标端的 IP Address 等信息，然后创建客户端，和目标端进行连接。接下来进行数据的解码和转发处理。本示例为双向流的场景，所以客户端也通过 clientStream 进行多次的结构体收发操作，编写如下代码，使 serverStream 读取并解码结构体，然后转发到 clientStream 中：\nfunc redirectStruct(from, to streaming.Stream) chan error { ret := make(chan error) go func() { for { req := \u0026grpcproxy.Request{} err := from.RecvMsg(req) if err != nil { from.Close() ret \u003c- err break } // do your own filter logic here  //if req.Name==xxx{  // continue  //}  err = to.SendMsg(req) if err != nil { ret \u003c- err break } } }() return ret } 在这部分中，通过 RecvMsg 读取到的数据经过序列化，会写入结构体中，可以加入对结构体字段的判断和修改操作，然后再进行转发。\n","categories":"","description":"Kitex 支持对未注册的 gRPC 方法调用进行自定义 Proxy 路由处理。","excerpt":"Kitex 支持对未注册的 gRPC 方法调用进行自定义 Proxy 路由处理。","ref":"/zh/docs/kitex/tutorials/advanced-feature/grpcproxy/","tags":"","title":"gRPC Proxy"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/kitex/tutorials/options/","tags":"","title":"Option"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/kitex/tutorials/options/","tags":"","title":"Option"},{"body":"Error type In order to handle errors more efficiently, Hertz has predefined the following error types:\n// Error in binding process ErrorTypeBind ErrorType = 1 \u003c\u003c iota // Error in rendering process ErrorTypeRender // Hertz private errors that business need not be aware ErrorTypePrivate // Hertz public errors that require external perception as opposed to Private ErrorTypePublic // Other Error ErrorTypeAny It is recommended to define the corresponding errors according to the error type.\nRelevant interfaces // shortcut for creating a public *Error from string func NewPublic(err string) *Error { return New(errors.New(err), ErrorTypePublic, nil) } // shortcut for creating a private *Error from string func NewPrivate(err string) *Error { return New(errors.New(err), ErrorTypePrivate, nil) } func New(err error, t ErrorType, meta interface{}) *Error { return \u0026Error{ Err: err, Type: t, Meta: meta, } } ErrorChain In addition to the conventions for error definition, the framework also provides ErrorChain capability. As the name implies, it is easy for the business to bind all errors encountered on a request processing to the error chain, which can facilitate the subsequent (usually in the middleware) unified processing of all errors. The corresponding API is: RequestContext.Error(err), and calling this API will tie the err to the corresponding request context.\nMethod to get all the errors that have been bound by the request context: RequestContext.Errors (ErrorChain). ErrorChain currently provides the following API:\nByType：Return the corresponding sub-error chain by error type Errors：Converting error chains to standard error arrays JSON：Convert all errors to json objects Last： Return the last or latest error String：Show all errors in readable text ","categories":"","description":"","excerpt":"Error type In order to handle errors more efficiently, Hertz has …","ref":"/docs/hertz/tutorials/basic-feature/error-handle/","tags":"","title":"Error Handle"},{"body":"错误类型 为了更高效的处理错误，Hertz 针对错误类型做了如下预定义：\n// binding 过程的错误 ErrorTypeBind ErrorType = 1 \u003c\u003c iota // rendering 过程的错误 ErrorTypeRender // Hertz内部错误，业务无需感知 ErrorTypePrivate // 相对于Private来说，需要外部感知的错误 ErrorTypePublic // 其他错误 ErrorTypeAny 建议按照错误类别定义相应的错误。\n相关接口 // shortcut for creating a public *Error from string func NewPublic(err string) *Error { return New(errors.New(err), ErrorTypePublic, nil) } // shortcut for creating a private *Error from string func NewPrivate(err string) *Error { return New(errors.New(err), ErrorTypePrivate, nil) } func New(err error, t ErrorType, meta interface{}) *Error { return \u0026Error{ Err: err, Type: t, Meta: meta, } } ErrorChain 除了针对错误定义的约定以外，框架同时提供 ErrorChain（错误链）能力。顾名思义，能够方便业务将一次请求处理上所遇到的所有错误绑定到错误链上，可以方便后续（一般是在中间件中）对所有错误进行统一处理。 对应的 API 为：RequestContext.Error(err)，调用该 API 会将 err 绑到对应的请求上下文上之上。\n获取请求上下文已绑定的所有错误的方式：RequestContext.Errors（ErrorChain）。ErrorChain 目前提供的 API：\nByType：按错误类型返回对应的子错误链 Errors：将错误链转换为标准错误数组 JSON：将所有错误转换为json对象 Last： 返回最后（最新）的一个错误 String：可读性强的文本展示所有错误 ","categories":"","description":"","excerpt":"错误类型 为了更高效的处理错误，Hertz 针对错误类型做了如下预定义：\n// binding 过程的错误 ErrorTypeBind …","ref":"/zh/docs/hertz/tutorials/basic-feature/error-handle/","tags":"","title":"错误处理"},{"body":"会议主题：CloudWeGo 社区会议 5.19\n参会人： YangruiEmma, ag9920, Jiang Xuewu, liu-song, Joway, yccpt, Huang Yuting, CoderPoet, li-jin-gou, GuangmingLuo, simon0-o, scotty, yiyun, Authorixy, JZK-Keven, bodhisatan, ppzqh, Jacob953, Ivnszn, cyyolo, debug-LiXiwen, baize\n会前必读： http://www.cloudwego.io/ https://github.com/cloudwego\n录屏链接： https://bytedance.feishu.cn/minutes/obcn3zdn1g46avv887i11ms9?from=from_copylink\n议程 1 ：社区近期项目开源规划介绍 @GuangmingLuo  介绍新的开源项目 Frugal，欢迎感兴趣的同学熟悉并参与此项目。Kitex 下一个版本正式支持 Frugal，Kitex 新版本发布之后正式对外发文分享与宣传 Frugal。 Hertz 预计会在 5 月底或者 6 月初正式对外开源。正式开源后会发布会发布新手任务（代码层面 + 文档翻译），欢迎大家踊跃参与。   议程 2 ：Kitex 单测任务进展梳理 @GuangmingLuo   完成进度：7/14\n  提交 PR 注意事项：\n 一定注意 CI 报错，及时修复错误； 遵守 Issue Description 提到的要求； 提交 PR 的同学加快进度，团队内部负责 Review 的同学加紧跟进。争取在 5 月份的下一个版本发布之前，可以合入这些 PR。 需要 Rebase 的 Develop 代码单测错误已得到修复，Rebase 一下 Develop 分支代码即可解决。    因疫情影响，目前居家办公，给所有贡献者邮寄礼物进程会推迟，复工后统一邮寄。请同学们不用过于担心，承诺的礼物一定送到。\n   议程 3：Kitex 对接 xDS 方案介绍 @ppzqh @CoderPoet  相关文档：Kitex 对接 xDS 总体技术方案设计 提炼功能，在 Kitex 上面提一个 Issue，对要做的 Feature 做背景和方案概述，拆分开发工作量，方便社区里面感兴趣的同学参加。 会议后已建好 Issue：https://github.com/cloudwego/kitex/issues/461   议程 4：Kitex mall demo 介绍 @bodhisatan  很多 RPC 框架都有一个偏官方的电商 Demo，如 Kratos 和 Go-zero。 相关文档：KiteX mall demo 拆分细化任务之后，号召社区交流群及社区用户群的同学来参与，同时对外宣传。 目前社区任务分工：@daidai21(付韦虎) @@clark(王伟超)   议程 5：Kitex 源码分析活动介绍 @yiyun  背景： a. 从 Java 转到 Golang 或者 Go 语言的同学对 Kitex 有学习需求； b. 高校同学参加开源夏令营和培训活动，关注到 Kitex。 活动地址：https://github.com/cloudwego/community/issues/24 产出： a. 导师：整体梳理 Kitex 模块，把各个技术点的学习资料做成一套从 0 到 1 的学习笔记。（第一期导师@clark(王伟超) ） b. 学生：学习笔记、源码解读文章。   议程 6：CloudWeGo 公众号官宣 @yiyun  公众号定位：发布包括但不限于社区运行状态、社区新闻、项目版本发布、重要节点活动宣传、Committer 专访。 官宣：https://mp.weixin.qq.com/s/nSybru-NMdZmdaaQgLM2bQ   议程7：新成员自我介绍  新成员名单：ag9920 baize Jacob953 社区新成员分别进行自我介绍，主要包含个人基本情况、开源贡献经历和后续参与社区工作内容。   相关资讯： 新的开源项目 Frugal 已经 Public，欢迎大家熟悉了解并积极参与。 地址：https://github.com/cloudwego/frugal。\n","categories":"","description":"","excerpt":"会议主题：CloudWeGo 社区会议 5.19\n参会人： YangruiEmma, ag9920, Jiang Xuewu, …","ref":"/zh/community/meeting_notes/2022-05-19/","tags":"","title":"CloudWeGo 社区会议 5.19"},{"body":"kitex-contrib has provided the prometheus monitoring extensions.\nIf you want to get the more detailed monitoring, such as message packet size, or want to adopt other data source, such as InfluxDB, you can implement the Trace interface according to your requirements and inject by WithTracer Option.\n// Tracer is executed at the start and finish of an RPC. type Tracer interface { Start(ctx context.Context) context.Context Finish(ctx context.Context) } RPCInfo can be obtained from ctx, and further request time cost, package size, and error information returned by the request can be obtained from RPCInfo, for example:\ntype clientTracer struct { // contain entities which recording metric } // Start record the beginning of an RPC invocation. func (c *clientTracer) Start(ctx context.Context) context.Context { // do nothing  return ctx } // Finish record after receiving the response of server. func (c *clientTracer) Finish(ctx context.Context) { ri := rpcinfo.GetRPCInfo(ctx) rpcStart := ri.Stats().GetEvent(stats.RPCStart) rpcFinish := ri.Stats().GetEvent(stats.RPCFinish) cost := rpcFinish.Time().Sub(rpcStart.Time()) // TODO: record the cost of request } ","categories":"","description":"","excerpt":"kitex-contrib has provided the prometheus monitoring extensions.\nIf …","ref":"/docs/kitex/tutorials/framework-exten/monitoring/","tags":"","title":"Monitoring Extension"},{"body":"RPC Timeout  You can specify RPC timeout in client initialization, it will works for all RPC started by this client by default.  import \"github.com/cloudwego/kitex/client\" ... rpcTimeout := client.WithRPCTimeout(3*time.Second) client, err := echo.NewClient(\"echo\", rpcTimeout) if err != nil { log.Fatal(err) }  And you can also specify timeout for a specific RPC call.  import \"github.com/cloudwego/kitex/client/callopt\" ... rpcTimeout := callopt.WithRPCTimeout(3*time.Second) resp, err := client.Echo(context.Background(), req, rpcTimeout) if err != nil { log.Fatal(err) } Connection Timeout  You can specify connection timeout in client initialization, it will works for all RPC started by this client by default.  import \"github.com/cloudwego/kitex/client\" ... connTimeout := client.WithConnectTimeout(50*time.Millisecond) client, err := echo.NewClient(\"echo\", connTimeout) if err != nil { log.Fatal(err) } And you can also specify timeout for a specific RPC call.  import \"github.com/cloudwego/kitex/client/callopt\" ... connTimeout := callopt.WithConnectTimeout(50*time.Millisecond) resp, err := client.Echo(context.Background(), req, connTimeout) if err != nil { log.Fatal(err) } ","categories":"","description":"Kitex supports RPC timeout and connection timeout, both of which support client-level and invocation-level configurations.","excerpt":"Kitex supports RPC timeout and connection timeout, both of which …","ref":"/docs/kitex/tutorials/basic-feature/timeout/","tags":"","title":"Timeouts"},{"body":"用户如果需要更详细的打点，例如包大小，或者想要更换其他数据源，例如 influxDB，用户可以根据自己的需求实现 Trace 接口，并通过 WithTracer Option来注入。\n// Tracer is executed at the start and finish of an RPC. type Tracer interface { Start(ctx context.Context) context.Context Finish(ctx context.Context) } 从 ctx 中可以获得 RPCInfo，进一步的从 RPCInfo 中获取请求耗时、包大小和请求返回的错误信息等，举例：\ntype clientTracer struct { // contain entities which recording metric } // Start record the beginning of an RPC invocation. func (c *clientTracer) Start(ctx context.Context) context.Context { // do nothing \treturn ctx } // Finish record after receiving the response of server. func (c *clientTracer) Finish(ctx context.Context) { ri := rpcinfo.GetRPCInfo(ctx) rpcStart := ri.Stats().GetEvent(stats.RPCStart) rpcFinish := ri.Stats().GetEvent(stats.RPCFinish) cost := rpcFinish.Time().Sub(rpcStart.Time()) // TODO: record the cost of request } ","categories":"","description":"","excerpt":"用户如果需要更详细的打点，例如包大小，或者想要更换其他数据源，例如 influxDB，用户可以根据自己的需求实现 Trace 接口， …","ref":"/zh/docs/kitex/tutorials/framework-exten/monitoring/","tags":"","title":"监控扩展"},{"body":"RPC 超时  在 client 初始化时配置，配置的 RPC 超时将对此 client 的所有调用生效  import \"github.com/cloudwego/kitex/client\" ... rpcTimeout := client.WithRPCTimeout(3*time.Second) client, err := echo.NewClient(\"echo\", rpcTimeout) if err != nil { log.Fatal(err) } 在发起调用时配置，配置的 RPC 超时仅对此次调用生效  import \"github.com/cloudwego/kitex/client/callopt\" ... rpcTimeout := callopt.WithRPCTimeout(3*time.Second) resp, err := client.Echo(context.Background(), req, rpcTimeout) if err != nil { log.Fatal(err) } 连接超时  在 client 初始化时配置，配置的连接超时将对此 client 的所有调用生效  import \"github.com/cloudwego/kitex/client\" ... connTimeout := client.WithConnectTimeout(50*time.Millisecond) client, err := echo.NewClient(\"echo\", connTimeout) if err != nil { log.Fatal(err) } 在发起调用时配置，配置的连接超时仅对此次调用生效  import \"github.com/cloudwego/kitex/client/callopt\" ... connTimeout := callopt.WithConnectTimeout(50*time.Millisecond) resp, err := client.Echo(context.Background(), req, connTimeout) if err != nil { log.Fatal(err) } ","categories":"","description":"Kitex 支持 RPC 超时和连接超时，两种超时均支持 client 级别和调用级别的配置。","excerpt":"Kitex 支持 RPC 超时和连接超时，两种超时均支持 client 级别和调用级别的配置。","ref":"/zh/docs/kitex/tutorials/basic-feature/timeout/","tags":"","title":"超时控制"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/hertz/tutorials/toolkit/","tags":"","title":"Code Generation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/motore/","tags":"","title":"Motore"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/motore/","tags":"","title":"Motore"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/hertz/tutorials/toolkit/","tags":"","title":"代码生成"},{"body":"Kitex provides the ability to customize templates, if the default templates can not meet your needs, you can use the function of this custom template provided by Kitex. Now, it supports rendering single file and circular rendering according to methodInfo.\nHow to Use   The data used by the template is PackageInfo and we assume that this section contains all the metadata(e.g. methodInfo …). You only need to pass the template file, and the data in the template is PackageInfo data.\n  Template rendering can only render a single file at a time. If there is a situation of sorting the file by methods and rendering it, you need to control them in your code.\n  Templates are passed via the YAML folder and specified with the --template-dir command-line parameter. To avoid large files, templates are now organized into a dedicated directory.\n  extensions.yaml in the YAML folder is a specific file. The content of this configuration file is extending the service code. If it exists, there is no need to pass the ‘template-extension’ parameter.\n  There are currently four update options available: overwrite, skip, append or add files based on specified methods (loop_method is true). The behavior is determined by the key field in update_behavior, which can be skip, cover or append. When loop_method is enabled, append adds new files; otherwise, it appends to the end of the file, and the specified key during the update determines the behavior.\n  The code generated by Kitex is divided into two parts, ‘kitex_gen’ and ‘mainPkg’ (including ‘main.go’, ‘handler.go’ …). ‘kitex_gen’ is immutable. Choosing between ‘mainPkg’ and ‘custom layout’ is a binary decision; specifying a ‘custom layout’ will prevent the generation of ‘mainPkg’.\n  Usage Scenarios The default templates can not meet your needs. (e.g. want to generate ‘MVC Layout’,uniform error handling …)\nPractice kitex -module ${module_name} -template-dir ${template dir_path} idl/hello.thrift YAML File path:/a/main.go# specifies the path and name to the file. It will create the 'a' folder and 'main.go' file in the 'a' folderupdate_behavior:type:skip / cover / append# specifies the update behavior, if 'loop_methor' is true, append is not supported.the default value is skipkey:Test{{.Name}}# function nameappend_tpl:# the new tplimport_tpl:# the new import, it is a list and it can be renderedbody:template content# tql content--------------------------------path:/handler/{{ .Name }}.go update_is_skip:true# specifies whether the file is skipped, if it is true,not skip.Because the Loopfield is specified, the file is added when updatedloop_method:truebody:...# tql contente.g. tql\nhttps://github.com/cloudwego/cwgo/tree/main/tpl/kitex\nAppendix PackageInfo struct and some commonly used contents type PackageInfo struct { Namespace string // idl namespace, It is recommended not to use under pb  Dependencies map[string]string // package name =\u003e import path, used for searching imports  *ServiceInfo // the target service  Codec string NoFastAPI bool Version string RealServiceName string Imports map[string]map[string]bool ExternalKitexGen string Features []feature FrugalPretouch bool Module string // go module name } type ServiceInfo struct { PkgInfo ServiceName string RawServiceName string ServiceTypeName func() string Base *ServiceInfo Methods []*MethodInfo CombineServices []*ServiceInfo HasStreaming bool } type PkgInfo struct { PkgName string // the last paragraph of of namespace  PkgRefName string ImportPath string // this method's req and resp's import path } type MethodInfo struct { PkgInfo ServiceName string // this service's name  Name string // this method's name  RawName string // ditto  Oneway bool Void bool Args []*Parameter // params' info, including name, import path, and type  Resp *Parameter // response, including name, import path, and type  Exceptions []*Parameter ArgStructName string ResStructName string IsResponseNeedRedirect bool // int -\u003e int*  GenArgResultStruct bool ClientStreaming bool ServerStreaming bool } // Parameter type Parameter struct { Deps []PkgInfo Name string RawName string // StructB  Type string // *PkgA.StructB } ","categories":"","description":"","excerpt":"Kitex provides the ability to customize templates, if the default …","ref":"/docs/kitex/tutorials/code-gen/custom_tpl/","tags":"","title":"Custom Scaffold Template"},{"body":"Kitex 支持了自定义模板功能，如果默认的模板不能够满足大家的需求，大家可以使用 Kitex 的自定义模板功能。目前支持了单文件渲染和根据 methodInfo 循环渲染。\n如何使用  模板使用的数据为 PackageInfo，认为这部分内包含所有的元数据，如 methodInfo 等，用户只需要传递模板文件即可，模板内的数据为 PackageInfo 数据。 模板渲染只能渲染单个文件内容，如果涉及到按照 methods 分文件渲染的话，需要在代码中控制。 模板文件通过 yaml 文件夹传递，通过 --template-dir 命令行参数指定。因为所有模板写到一个文件中会导致该文件巨大，所以改为指定文件夹。 文件夹内的 extensions.yaml 为特定文件，该文件的内容为扩展 Service 代码的配置文件。如果该文件存在的话，则不用再传递 template-extension 参数。 更新时，目前支持覆盖、跳过、根据 methods 增加文件(loop_method 为 true)、在文件末尾追加四种方式(loop_method 为 false)，通过 loop_method 和 update_behavior 中的 key 字段共同确定。update_behavior 中的 key 字段值有三种：skip / cover / append。其中append 在开启了loop_method后为新增加文件；在不开启loop_method时为追加到文件末尾，通过指定更新时的key判断是否需要追加。 Kitex 代码生成分成两部分，kitex_gen 和 mainPkg(剩下的 main.go、handler.go )等等，kitex_gen 无论采用何种生成都不会改变；mainPkg 和 custom layout 只能二选一，如果制定了 custom layout 就不会再生成 mainPkg。  使用场景 当默认的脚手架模板不能够满足用户的需求，比如想要生成 MVC Layout、统一进行错误处理等。\n使用方式 kitex -module ${module_name} -template-dir ${template dir_path} idl/hello.thrift Yaml 文件配置 path:/a/main.go# 生成文件的路径及文件名，这会在项目根目录下创建 a 文件夹，并在文件夹内生成 main.go 文件update_behavior:type:skip / cover / append# 指定更新行为，如果 loop_method 为true，则不支持 append。默认是 skipkey:Test{{.Name}}# 函数名append_tpl:# 更新的内容模板import_tpl:# 新增的 import 内容，是一个 list，可以通过模版渲染body:template content# 模板内容--------------------------------path:/handler/{{ .Name }}.go update_is_skip:true# 更新时不跳过该文件，由于指定了 loopfield，所以更新时会增加文件loop_method:truebody:...# 模板内容示例 tpl：\nhttps://github.com/cloudwego/cwgo/tree/main/tpl/kitex\n附录 PackageInfo 结构体常用内容 type PackageInfo struct { Namespace string // idl namespace，pb 下建议不要使用  Dependencies map[string]string // package name =\u003e import path, used for searching imports  *ServiceInfo // the target service  Codec string NoFastAPI bool Version string RealServiceName string Imports map[string]map[string]bool ExternalKitexGen string Features []feature FrugalPretouch bool Module string // go module 名称 } type ServiceInfo struct { PkgInfo ServiceName string RawServiceName string ServiceTypeName func() string Base *ServiceInfo Methods []*MethodInfo CombineServices []*ServiceInfo HasStreaming bool } type PkgInfo struct { PkgName string // namespace 最后一段  PkgRefName string ImportPath string // 这个方法的 req 和 resp 的 import path } type MethodInfo struct { PkgInfo ServiceName string // 这个 service 的 name  Name string // 这个 method 的 name  RawName string // 同上  Oneway bool Void bool Args []*Parameter // 入参信息，包括入参名称、import 路径、类型  Resp *Parameter // 出参，包括入参名称、import 路径、类型  Exceptions []*Parameter ArgStructName string ResStructName string IsResponseNeedRedirect bool // int -\u003e int*  GenArgResultStruct bool ClientStreaming bool ServerStreaming bool } // Parameter . type Parameter struct { Deps []PkgInfo Name string RawName string // StructB  Type string // *PkgA.StructB } ","categories":"","description":"","excerpt":"Kitex 支持了自定义模板功能，如果默认的模板不能够满足大家的需求，大家可以使用 Kitex 的自定义模板功能。 …","ref":"/zh/docs/kitex/tutorials/code-gen/custom_tpl/","tags":"","title":"自定义脚手架模板"},{"body":"Command line parameter description Global: $ hz --help NAME: hz - A idl parser and code generator for Hertz projects USAGE: hz [global options] command [command options] [arguments...] VERSION: 0.0.1 COMMANDS: new Generate a new Hertz project update Update an existing Hertz project help, h Shows a list of commands or help for one command GLOBAL OPTIONS: --help, -h show help (default: false) --verbose turn on verbose mode (default: false) --version, -v print the version (default: false)  new: Create a new Hertz project    update: Updating an existing Hertz project  New $ hz help new NAME: hz new - Generate a new Hertz project USAGE: hz new [command options] [arguments...] OPTIONS: --client_dir value Specify the client path. If not specified, no client code is generated. --customize_layout value Specify the layout template. ({{Template Profile}}:{{Rendering Data}}) --customize_package value Specify the package template. ({{Template Profile}}:) --exclude_file value, -E value Specify the files that do not need to be updated. (accepts multiple inputs) --handler_dir value Specify the handler path. --idl value Specify the IDL file path. (.thrift or .proto) (accepts multiple inputs) --json_enumstr Use string instead of num for json enums when idl is thrift. (default: false) --model_dir value Specify the model path. --module value, --mod value Specify the Go module name to generate go.mod. --no_recurse Generate master model only. (default: false) --option_package value, -P value Specify the package path. ({include_path}={import_path}) (accepts multiple inputs) --out_dir value Specify the project path. --proto_path value, -I value Add an IDL search path for includes. (Valid only if idl is protobuf) (accepts multiple inputs) --protoc value, -p value Specify arguments for the protoc. ({flag}={value}) (accepts multiple inputs) --service value Specify the service name. --snake_tag Use snake_case style naming for tags. (Only works for 'form', 'query', 'json') (default: false) --thriftgo value, -t value Specify arguments for the thriftgo. ({flag}={value}) (accepts mul  client_dir: Specify the path to generate client-side code, if not specified, it will not be generated; currently generates a global client for each service, and will provide rich client code capabilities later    customize_layout: Customize the layout template of the project. For details, see: hz custom template use    customize_package: Customize the project package related templates, mainly for the handler template. For details, see: hz custom template use    exclude_file: Files that do not need to be updated(relative to the project path, multiple supported)    handler_dir: Specify the handler generation path, the default is “biz/handler”    idl: IDL file path (.thrift or .proto)    json_enumstr: When IDL is thrift, json enums uses string instead of num (option passed through to thriftgo)    model_dir: Specify the model generation path, the default is “biz/model”    module/mod: Specify the name of go mod, which must be specified under non-GOPATH, and default to a path relative to GOPATH under GOPATH.    no_recurse: Generate only the model code for main IDL    option_package/P: Specify the path to the package, ({include_path}={import_path})    out_dir: Specify the project build path    proto_path/I: When IDL is protobuf, specify the search path for IDL, equivalent to the option “-I” for protoc    protoc/p: Option passed through to protoc ({flag}={value})    service: Service name, reserved for later service discovery and other functions    snake_tag: The tag is named in snake_case style(only works for form、query、json )    thriftgo/t: Option passwd through to thrift ({flag}={value})    unset_omitempty: When IDL is protobuf, the model field is generated and the omitempty tag is removed; when IDL is thrift, whether to add omitempty is determined by whether the field is “optional” or “required”  Update $ hz help update NAME: hz update - Update an existing Hertz project USAGE: hz update [command options] [arguments...] OPTIONS: --client_dir value Specify the client path. If not specified, no client code is generated. --customize_package value Specify the package template. ({{Template Profile}}:) --exclude_file value, -E value Specify the files that do not need to be updated. (accepts multiple inputs) --handler_dir value Specify the handler path. --idl value Specify the IDL file path. (.thrift or .proto) (accepts multiple inputs) --json_enumstr Use string instead of num for json enums when idl is thrift. (default: false) --model_dir value Specify the model path. --no_recurse Generate master model only. (default: false) --option_package value, -P value Specify the package path. ({include_path}={import_path}) (accepts multiple inputs) --out_dir value Specify the project path. --proto_path value, -I value Add an IDL search path for includes. (Valid only if idl is protobuf) (accepts multiple inputs) --protoc value, -p value Specify arguments for the protoc. ({flag}={value}) (accepts multiple inputs) --snake_tag Use snake_case style naming for tags. (Only works for 'form', 'query', 'json') (default: false) --thriftgo value, -t value Specify arguments for the thriftgo. ({flag}={value}) (accepts multiple inputs) --unset_omitempty Remove 'omitempty' tag for generated struct. (default: false)  client_dir: Specify the path to generate client-side code, if not specified, it will not be generated; currently generates a global client for each service, and will provide rich client code capabilities later. Note: If you update the same set of IDL, the value of client_dir needs to be the same as when using new, otherwise it will generate redundant code that needs to be removed by the user.    customize_package: Customize the project package related templates, mainly for the handler template. For details, see:hz custom template use. Note: For an existing handler file, a handler function will be added according to the default template, and for handler files that do not exist yet, a handler will be generated according to a custom template.    exclude_file: Files that do not need to be updated(relative to the project path, multiple supported)    handler_dir: Specify the handler generation path, the default is “biz/handler”; Note: If you update the same set of IDL, the value of handler_dir needs to be the same as when using new, otherwise it will generate redundant code that needs to be removed by the user.    idl: IDL file path (.thrift or .proto)    json_enumstr: When IDL is thrift, json enums uses string instead of num (option passed through to thriftgo)    model_dir: Specify the model generation path, the default is “biz/model”; Note: If you update the same set of IDL, the value of model_dir needs to be the same as when using new, otherwise it will generate redundant code that needs to be removed by the user.    no_recurse: Generate only the model code for main IDL    option_package/P: Specify the path to the package, ({include_path}={import_path})    out_dir: Specify the project build path    proto_path/I: When IDL is protobuf, specify the search path for IDL, same as protoc’s -I command    protoc/p: Option passed through to protoc ({flag}={value})    snake_tag: The tag is named in snake_case style(only works for form、query、json )    thriftgo/t: Option passwd through to thrift ({flag}={value})    unset_omitempty: When IDL is protobuf, the model field is generated and the omitempty tag is removed; when IDL is thrift, whether to add omitempty is determined by whether the field is “optional” or “required”  ","categories":"","description":"","excerpt":"Command line parameter description Global: $ hz --help NAME: hz - A …","ref":"/docs/hertz/tutorials/toolkit/usage/command/","tags":"","title":"hz commands"},{"body":"命令行参数说明 Global: $ hz --help NAME: hz - A idl parser and code generator for Hertz projects USAGE: hz [global options] command [command options] [arguments...] VERSION: 0.0.1 COMMANDS: new Generate a new Hertz project update Update an existing Hertz project help, h Shows a list of commands or help for one command GLOBAL OPTIONS: --help, -h show help (default: false) --verbose turn on verbose mode (default: false) --version, -v print the version (default: false)  New: 创建一个新的 Hertz 项目    update: 更新一个已存在的 Hertz 项目  New $ hz help new NAME: hz new - Generate a new Hertz project USAGE: hz new [command options] [arguments...] OPTIONS: --client_dir value Specify the client path. If not specified, no client code is generated. --customize_layout value Specify the layout template. ({{Template Profile}}:{{Rendering Data}}) --customize_package value Specify the package template. ({{Template Profile}}:) --exclude_file value, -E value Specify the files that do not need to be updated. (accepts multiple inputs) --handler_dir value Specify the handler path. --idl value Specify the IDL file path. (.thrift or .proto) (accepts multiple inputs) --json_enumstr Use string instead of num for json enums when idl is thrift. (default: false) --model_dir value Specify the model path. --module value, --mod value Specify the Go module name to generate go.mod. --no_recurse Generate master model only. (default: false) --option_package value, -P value Specify the package path. ({include_path}={import_path}) (accepts multiple inputs) --out_dir value Specify the project path. --proto_path value, -I value Add an IDL search path for includes. (Valid only if idl is protobuf) (accepts multiple inputs) --protoc value, -p value Specify arguments for the protoc. ({flag}={value}) (accepts multiple inputs) --service value Specify the service name. --snake_tag Use snake_case style naming for tags. (Only works for 'form', 'query', 'json') (default: false) --thriftgo value, -t value Specify arguments for the thriftgo. ({flag}={value}) (accepts mul  client_dir: 指定 client 侧代码的生成路径，如果不指定则不生成；当前为每个 service 生成一个全局的 client，后续会提供更丰富的 client 代码能力    customize_layout: 自定义项目 layout 模板，具体详见：自定义模板使用    customize_package: 自定义项目 package 相关模板，主要可针对 handler 模板进行定制化，具体详见：自定义模板使用    exclude_file: 不需要更新的文件(相对项目路径，支持多个)    handler_dir: 指定 handler 的生成路径，默认为 “biz/handler”    idl: idl 文件路径(.thrift 或者.proto)    json_enumstr: 当 idl 为 thrift 时，json enums 使用 string 代替 num(透传给 thriftgo 的选项)    model_dir: 指定 model 的生成路径，默认为\"biz/model\"    module/mod: 指定 go mod 的名字，非 GOPATH 下必须指定，GOPATH 下默认以相对于 GOPATH 的路径作为名字    no_recurse: 只生成主 idl 的 model 代码    option_package/P: 指定包的路径，({include_path}={import_path})    out_dir: 指定项目生成路径    proto_path/I: 当 idl 为 protobuf 时，指定 idl 的搜索路径，同 protoc 的 -I 指令    protoc/p: 透传给 protoc 的选项({flag}={value})    service: 服务名，为之后做服务发现等功能预留    snake_tag: tag 使用 snake_case 风格命名(仅对 form、query、json 生效)    thriftgo/t: 透传给 thriftgo 的选项({flag}={value})    unset_omitempty: 当 idl 为 protobuf 时，生成 model field，去掉 omitempty tag；当 idl 为 thrift 时，是否添加 omitempty 根据 field 是 “optional\"还是\"required\"决定  Update $ hz help update NAME: hz update - Update an existing Hertz project USAGE: hz update [command options] [arguments...] OPTIONS: --client_dir value Specify the client path. If not specified, no client code is generated. --customize_package value Specify the package template. ({{Template Profile}}:) --exclude_file value, -E value Specify the files that do not need to be updated. (accepts multiple inputs) --handler_dir value Specify the handler path. --idl value Specify the IDL file path. (.thrift or .proto) (accepts multiple inputs) --json_enumstr Use string instead of num for json enums when idl is thrift. (default: false) --model_dir value Specify the model path. --no_recurse Generate master model only. (default: false) --option_package value, -P value Specify the package path. ({include_path}={import_path}) (accepts multiple inputs) --out_dir value Specify the project path. --proto_path value, -I value Add an IDL search path for includes. (Valid only if idl is protobuf) (accepts multiple inputs) --protoc value, -p value Specify arguments for the protoc. ({flag}={value}) (accepts multiple inputs) --snake_tag Use snake_case style naming for tags. (Only works for 'form', 'query', 'json') (default: false) --thriftgo value, -t value Specify arguments for the thriftgo. ({flag}={value}) (accepts multiple inputs) --unset_omitempty Remove 'omitempty' tag for generated struct. (default: false)  client_dir: 指定 client 侧代码的生成路径，如果不指定则不生成；当前为每个 service 生成一个全局的 client，后续会提供更丰富的 client 代码能力。注意：如果对同一套 idl 进行 update，需要 client_dir 的值与使用 new 的时候相同，否则会生成冗余的代码，需要用户自行删除。    customize_package: 自定义项目 package 相关模板，主要可针对 handler 模板进行定制化，具体详见：自定义模板使用 。注意：对于已经存在的 handler 文件会按照默认模板新增 handler 函数，对于还未存在的 handler 文件，则会按照自定义模板来生成 handler。    exclude_file: 不需要更新的文件(相对项目路径，支持多个)    handler_dir: 指定 handler 的生成路径，默认为\"biz/handler”；注意：如果对同一套 idl 进行 update，需要 handler_dir 的值与使用 new 的时候相同，否则会生成冗余的代码，需要用户自行删除。    idl: idl 文件路径(.thrift 或者.proto)    json_enumstr: 当 idl 为 thrift 时，json enums 使用 string 代替 num(透传给 thriftgo 的选项)    model_dir: 指定 model 的生成路径，默认为\"biz/model\"；注意：如果对同一套 idl 进行 update，需要 model_dir 的值与使用 new 的时候相同，否则会生成重复的 model 代码且导致 handler 引用不一致。    no_recurse: 只生成主 idl 的 model 代码    option_package/P: 指定包的路径，({include_path}={import_path})    out_dir: 指定项目生成路径    proto_path/I: 当 idl 为 protobuf 时，指定 idl 的搜索路径，同 protoc 的 -I 指令    protoc/p: 透传给 protoc 的选项({flag}={value})    snake_tag: tag 使用 snake_case 风格命名(仅对 form、query、json 生效)    thriftgo/t: 透传给 thriftgo 的选项({flag}={value})    unset_omitempty: 当 idl 为 protobuf 时，生成 model field，去掉 mitempty tag；当 idl 为 thrift 时，是否添加 omitempty 根据 field 是 “optional\"还是\"required\"决定  ","categories":"","description":"","excerpt":"命令行参数说明 Global: $ hz --help NAME: hz - A idl parser and code generator …","ref":"/zh/docs/hertz/tutorials/toolkit/usage/command/","tags":"","title":"hz 命令梳理"},{"body":"Hertz provides the pprof extension to help users perform performance analysis on Hertz projects. The implementation of the pprof extension refers to the implementation of Gin.\nInstall go get github.com/hertz-contrib/pprof Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/pprof\" ) func main() { h := server.Default() pprof.Register(h) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } Config PrefixOptions The default prefix of pprof is debug/pprof, that is, after the user registers and uses pprof extension in the Hertz project, the user can view the sampling information of the current project by visiting localhost:8888/debug/pprof. Additionally, pprof supports user-defined prefixes.\nThe function signature is as follows:\nRegister(r *server.Hertz, prefixOptions ...string) Sample code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/pprof\" ) func main() { h := server.Default() // default is \"debug/pprof\" \tpprof.Register(h, \"dev/pprof\") h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } RouteRegister pprof can be registered not only on the Hertz object, but also on the router group (RouterGroup).\nThe function signature is as follows:\nRouteRegister(rg *route.RouterGroup, prefixOptions ...string) The pprof prefix registered in this way is the result of splicing the prefix of the routing group and the custom prefix.\n If the user does not specify a prefix, the prefix of the registered pprof is the result of concatenating the prefix of the routing group and the default prefix /debug/pprof, that is, /xxx/debug/pprof (xxx is the prefix of the routing group); If the user specifies a prefix, the prefix of the registered pprof is the result of concatenating the prefix of the routing group and the custom prefix. For example, in the following example, the registered pprof prefix is /admin/pprof.  Sample code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/pprof\" ) func main() { h := server.Default() pprof.Register(h) adminGroup := h.Group(\"/admin\") adminGroup.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) pprof.RouteRegister(adminGroup, \"pprof\") h.Spin() } View pprof sampling information Via browser Access localhost:8888/debug/pprof via browser\n Hertz port number defaults to 8888 pprof default address prefix is debug/pprof The port number and access route are the same as the user’s actual port number and pprof prefix  Via go tool pprof Use the go tool pprof tool to view stack sampling information:\ngo tool pprof http://localhost:8888/debug/pprof/heap Use the go tool pprof tool to view the CPU sampling information:\ngo tool pprof http://localhost:8888/debug/pprof/profile  The default sampling time is 30s , and the sampling time can be customized by query string:\n go tool pprof http://localhost:8888/debug/pprof/profile?seconds=10 Use the go tool pprof tool to view the blocking information of the go coroutine:\ngo tool pprof http://localhost:8888/debug/pprof/block Get the execution trace information:\nwget http://localhost:8888/debug/pprof/trace?seconds=5 View flame graphs with go tool pprof Install graphviz\ngo tool pprof -http :8080 localhost:8888/debug/pprof/profile?seconds=10 See the full usage example\n","categories":"","description":"","excerpt":"Hertz provides the pprof extension to help users perform performance …","ref":"/docs/hertz/tutorials/basic-feature/middleware/pprof/","tags":"","title":"Pprof"},{"body":"Hertz 提供了 pprof 扩展，帮助用户对 Hertz 项目进行性能分析，pprof 扩展的实现参考了 Gin 的实现。\n安装 go get github.com/hertz-contrib/pprof 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/pprof\" ) func main() { h := server.Default() pprof.Register(h) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 配置 PrefixOptions pprof 的默认前缀为 debug/pprof，即用户在 Hertz 项目中注册并使用 pprof 后，用户可以通过访问 localhost:8888/debug/pprof 来查看当前项目的采样信息。 此外，用户可以在注册 pprof 时指定自定义前缀。\n函数签名如下：\nRegister(r *server.Hertz, prefixOptions ...string) 示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/pprof\" ) func main() { h := server.Default() // default is \"debug/pprof\" \tpprof.Register(h, \"dev/pprof\") h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } RouteRegister pprof 不仅可以注册到 Hertz 对象上，还可以注册到路由组（RouterGroup）上。\n函数签名如下：\nRouteRegister(rg *route.RouterGroup, prefixOptions ...string) 本方式注册后的 pprof 前缀为路由组的前缀与自定义前缀拼接后的结果。\n 用户不指定前缀，注册后的 pprof 的前缀为路由组的前缀与默认前缀 /debug/pprof 拼接后的结果，即为 /xxx/debug/pprof （xxx 为路由组前缀）； 用户指定前缀，注册后的 pprof 的前缀为路由组的的前缀与自定义前缀拼接后的结果，比如下文示例中注册后的 pprof 前缀为 /admin/pprof。  示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/pprof\" ) func main() { h := server.Default() pprof.Register(h) adminGroup := h.Group(\"/admin\") adminGroup.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) pprof.RouteRegister(adminGroup, \"pprof\") h.Spin() } 查看 pprof 采样信息 通过浏览器查看 通过浏览器访问 localhost:8888/debug/pprof\n Hertz 端口号默认为 8888 pprof 默认地址前缀为 debug/pprof 端口号和访问路由与用户实际端口号和 pprof 前缀一致  通过 go tool pprof 查看 使用 go tool pprof 工具查看堆栈采样信息：\ngo tool pprof http://localhost:8888/debug/pprof/heap 使用 go tool pprof 工具查看 CPU 采样信息：\ngo tool pprof http://localhost:8888/debug/pprof/profile  默认采样时间为 30s ，可通过查询字符串来自定义采样时间：\n go tool pprof http://localhost:8888/debug/pprof/profile?seconds=10 使用 go tool pprof 工具查看 go 协程阻塞信息：\ngo tool pprof http://localhost:8888/debug/pprof/block 获取执行 trace 信息：\nwget http://localhost:8888/debug/pprof/trace?seconds=5 通过 go tool pprof 查看火焰图 安装 graphviz\ngo tool pprof -http :8080 localhost:8888/debug/pprof/profile?seconds=10 完整用法示例详见 example\n","categories":"","description":"","excerpt":"Hertz 提供了 pprof 扩展，帮助用户对 Hertz 项目进行性能分析，pprof 扩展的实现参考了 Gin 的实现。\n安装 go …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/pprof/","tags":"","title":"Pprof"},{"body":"Hertz provides the keyauth extension to help users achieve token authentication. The implementation of the keyauth extension references the Fiber and Echo implementation.\nInstall go get github.com/hertz-contrib/keyauth Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithContextKey(\"token\"), keyauth.WithKeyLookUp(\"query:token\", \"\"), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } Config WithFilter The keyauth extension provides WithFilter to help users set custom filtering logic for skipping the keyauth extension, which defaults to nil and is not skipped.\nFunction signatures:\ntype KeyAuthFilterHandler func(c context.Context, ctx *app.RequestContext) bool Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithFilter(func(c context.Context, ctx *app.RequestContext) bool { return string(ctx.GetHeader(\"admin\")) == \"test\" }), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } WithValidator The keyauth extension provides WithValidator to help users set custom validation logic for token validation, which returns true and nil by default.\nFunction signatures:\ntype KeyAuthValidatorHandler func(context.Context, *app.RequestContext, string) (bool, error) Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithValidator(func(ctx context.Context, requestContext *app.RequestContext, s string) (bool, error) { if s == \"test_admin\" { return true, nil } return false, nil }), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } WithSuccessHandler The keyauth extension provides WithSuccessHandler to help users set up custom processing logic for verifying that the token has passed.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithSuccessHandler(func(c context.Context, ctx *app.RequestContext) { ctx.Next(c) }), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } WithErrorHandler The keyauth extension provides WithErrorHandler to help users set up custom handling logic for verifying token failures.\nFunction signatures:\ntype KeyAuthErrorHandler func(context.Context, *app.RequestContext, error) Default logic:\nfunc errHandler(c context.Context, ctx *app.RequestContext, err error) { if err == ErrMissingOrMalformedAPIKey { ctx.AbortWithMsg(err.Error(), http.StatusBadRequest) return } ctx.AbortWithMsg(err.Error(), http.StatusUnauthorized) } WithKeyLookUp The keyauth extension provides WithKeyLookUp to help users set keyLookup.\nkeyLookup is used to extract token from source (supported sources include cookie, header, param, query, form).\nThe format is \u003csource\u003e:\u003ctoken_name\u003e and default value isheader:Authorization.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithKeyLookUp(\"header:token\", \"Bearer\"), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } WithContextKey The keyauth extension provides WithContextKey to help users set the key corresponding to the token in the request context.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithContextKey(\"token\"), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } ","categories":"","description":"","excerpt":"Hertz provides the keyauth extension to help users achieve token …","ref":"/docs/hertz/tutorials/basic-feature/middleware/keyauth/","tags":"","title":"KeyAuth"},{"body":"Hertz 提供了 keyauth 扩展用于帮助用户实现 token 鉴权。 keyauth 扩展的实现参考了 Fiber 和 Echo 的实现。\n安装 go get github.com/hertz-contrib/keyauth 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithContextKey(\"token\"), keyauth.WithKeyLookUp(\"query:token\", \"\"), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } 配置 WithFilter keyauth 扩展提供了 WithFilter 用于帮助用户设置自定义过滤逻辑用于跳过 keyauth扩展，默认为 nil，不跳过。\nFilter 函数签名如下:\ntype KeyAuthFilterHandler func(c context.Context, ctx *app.RequestContext) bool 示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithFilter(func(c context.Context, ctx *app.RequestContext) bool { return string(ctx.GetHeader(\"admin\")) == \"test\" }), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } WithValidator keyauth 扩展提供了 WithValidator 用于帮助用户设置自定义的校验逻辑用于 token 校验，默认返回 true 和 nil。\nValidator 函数签名如下:\ntype KeyAuthValidatorHandler func(context.Context, *app.RequestContext, string) (bool, error) 示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithValidator(func(ctx context.Context, requestContext *app.RequestContext, s string) (bool, error) { if s == \"test_admin\" { return true, nil } return false, nil }), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } WithSuccessHandler keyauth 扩展提供了 WithSuccessHandler 用于帮助用户设置校验 token 通过的自定义处理逻辑。\n示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithSuccessHandler(func(c context.Context, ctx *app.RequestContext) { ctx.Next(c) }), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } WithErrorHandler keyauth 扩展提供了 WithErrorHandler 用于帮助用户设置校验 token 失败的自定义处理逻辑。\nErrorHandler 函数签名如下:\ntype KeyAuthErrorHandler func(context.Context, *app.RequestContext, error) 默认处理逻辑如下:\nfunc errHandler(c context.Context, ctx *app.RequestContext, err error) { if err == ErrMissingOrMalformedAPIKey { ctx.AbortWithMsg(err.Error(), http.StatusBadRequest) return } ctx.AbortWithMsg(err.Error(), http.StatusUnauthorized) } WithKeyLookUp keyauth 扩展提供了 WithKeyLookUp 帮助用户设置 keyLookup。\nkeyLookup 用于从 source(支持的 source 包括 cookie、header 、param、query、form) 中提取 token。\n格式为 \u003csource\u003e:\u003ctoken_name\u003e，默认值为:header:Authorization。\n示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithKeyLookUp(\"header:token\", \"Bearer\"), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } WithContextKey keyauth 扩展提供了 WithContextKey 用于帮助用户设置存储在请求上下文的 token 对应的 key。\n示例代码:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/keyauth\" ) func main() { h := server.Default() h.Use(keyauth.New( keyauth.WithContextKey(\"token\"), )) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { value, _ := ctx.Get(\"token\") ctx.JSON(consts.StatusOK, utils.H{\"ping\": value}) }) h.Spin() } ","categories":"","description":"","excerpt":"Hertz 提供了 keyauth 扩展用于帮助用户实现 token 鉴权。 keyauth 扩展的实现参考了 Fiber 和 Echo 的 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/keyauth/","tags":"","title":"KeyAuth"},{"body":"Frugal is a very fast dynamic Thrift serializer \u0026 deserializer based on just-in-time compilation.\nFeatures Code Generation Free Traditional Thrift serializer and deserializer are based on generated code which is no longer needed since we can use JIT compilation to dynamically generate machine code.\nHigh Performance Thanks to JIT compilation, Frugal can generate better machine code than Go language compiler. In multi-core scenarios, Frugal’s performance is about 5 times higher than that of traditional serializer and deserializer.\nname old time/op new time/op delta MarshalAllSize_Parallel/small-16 78.8ns ± 0% 14.9ns ± 0% -81.10% MarshalAllSize_Parallel/medium-16 1.34µs ± 0% 0.32µs ± 0% -76.32% MarshalAllSize_Parallel/large-16 37.7µs ± 0% 9.4µs ± 0% -75.02% UnmarshalAllSize_Parallel/small-16 368ns ± 0% 30ns ± 0% -91.90% UnmarshalAllSize_Parallel/medium-16 11.9µs ± 0% 0.8µs ± 0% -92.98% UnmarshalAllSize_Parallel/large-16 233µs ± 0% 21µs ± 0% -90.99% name old speed new speed delta MarshalAllSize_Parallel/small-16 7.31GB/s ± 0% 38.65GB/s ± 0% +428.84% MarshalAllSize_Parallel/medium-16 12.9GB/s ± 0% 54.7GB/s ± 0% +322.10% MarshalAllSize_Parallel/large-16 11.7GB/s ± 0% 46.8GB/s ± 0% +300.26% UnmarshalAllSize_Parallel/small-16 1.56GB/s ± 0% 19.31GB/s ± 0% +1134.41% UnmarshalAllSize_Parallel/medium-16 1.46GB/s ± 0% 20.80GB/s ± 0% +1324.55% UnmarshalAllSize_Parallel/large-16 1.89GB/s ± 0% 20.98GB/s ± 0% +1009.73% name old alloc/op new alloc/op delta MarshalAllSize_Parallel/small-16 112B ± 0% 0B -100.00% MarshalAllSize_Parallel/medium-16 112B ± 0% 0B -100.00% MarshalAllSize_Parallel/large-16 779B ± 0% 57B ± 0% -92.68% UnmarshalAllSize_Parallel/small-16 1.31kB ± 0% 0.10kB ± 0% -92.76% UnmarshalAllSize_Parallel/medium-16 448B ± 0% 3022B ± 0% +574.55% UnmarshalAllSize_Parallel/large-16 1.13MB ± 0% 0.07MB ± 0% -93.54% name old allocs/op new allocs/op delta MarshalAllSize_Parallel/small-16 1.00 ± 0% 0.00 -100.00% MarshalAllSize_Parallel/medium-16 1.00 ± 0% 0.00 -100.00% MarshalAllSize_Parallel/large-16 1.00 ± 0% 0.00 -100.00% UnmarshalAllSize_Parallel/small-16 6.00 ± 0% 1.00 ± 0% -83.33% UnmarshalAllSize_Parallel/medium-16 6.00 ± 0% 30.00 ± 0% +400.00% UnmarshalAllSize_Parallel/large-16 4.80k ± 0% 0.76k ± 0% -84.10% What can you do with Frugal ? Use Frugal as Kitex serializer and deserializer No more massive serialization and deserialization code, leads to a more tidy project. No more meaningless diff of generated code in code review.\nSerialized and Deserialize struct generated by Thriftgo If you have a Thrift file, and all you need is using Frugal to do serialization and deserialization. You can use Thriftgo to generate Go struct, then you can use Frugal.\nSerialization and deserialization on a customized Go struct If you don’t want any Thrift files, and you want serialize or deserialize a customized Go struct. You can add some struct field tag to the Go struct, then you can use Frugal.\nUsage Using with Kitex 1. Update Kitex to v0.4.2 or higher version go get github.com/cloudwego/kitex@latest 2. Generate code with -thrift frugal_tag option Example:\nkitex -thrift frugal_tag -service a.b.c my.thrift If you don’t need codec code, you can use -thrift template=slim option.\nkitex -thrift frugal_tag,template=slim -service a.b.c my.thrift 3. Init clients and servers with WithPayloadCodec(thrift.NewThriftFrugalCodec()) option Client example:\npackage client import ( \"context\" \"github.com/cloudwego/kitex-examples/kitex_gen/api/echo\" \"github.com/cloudwego/kitex/client\" \"github.com/cloudwego/kitex/pkg/remote/codec/thrift\" ) func Echo() { codec := thrift.NewThriftCodecWithConfig(thrift.FastRead | thrift.FastWrite | thrift.FrugalRead | thrift.FrugalWrite) cli := echo.MustNewClient(\"a.b.c\", client.WithPayloadCodec(codec)) ... } Server example:\npackage main import ( \"log\" \"github.com/cloudwego/kitex-examples/kitex_gen/api/echo\" \"github.com/cloudwego/kitex/pkg/remote/codec/thrift\" \"github.com/cloudwego/kitex/server\" ) func main() { codec := thrift.NewThriftCodecWithConfig(thrift.FastRead | thrift.FastWrite | thrift.FrugalRead | thrift.FrugalWrite) svr := echo.NewServer(new(EchoImpl), server.WithPayloadCodec(codec)) err := svr.Run() if err != nil { log.Println(err.Error()) } } Using with Thrift IDL Prepare Thrift file We can define a struct in Thrift file like below:\nmy.thrift:\nstructMyStruct{1:stringmsg2:i64code}Use Thriftgo to generate code Now we have thrift file, we can use Thriftgo with frugal_tag option to generate Go code.\nExample:\nthriftgo -r -o thrift -g go:frugal_tag,package_prefix=example.com/kitex_test/thrift my.thrift If you don’t need codec code, you can use template=slim option\nthriftgo -r -o thrift -g go:frugal_tag,template=slim,package_prefix=example.com/kitex_test/thrift my.thrift Use Frugal to serialize or deserialize Now we can use Frugal to serialize or deserialize the struct defined in thrift file.\nExample:\npackage main import ( \"github.com/cloudwego/frugal\" ) func main() { ms := \u0026thrift.MyStruct{ Msg: \"my message\", Code: 1024, } ... buf := make([]byte, frugal.EncodedSize(ms)) frugal.EncodeObject(buf, nil, ms) ... got := \u0026thrift.MyStruct{} frugal.DecodeObject(buf, got) ... } Serialization and deserialization on a customized Go struct Define a Go struct We can define a struct like this:\ntype MyStruct struct { Msg string Code int64 Numbers []int64 } Add Frugal tag to struct fields Frugal tag is like frugal:\"1,default,string\", 1 is field ID, default is field requiredness, string is field type. Field ID and requiredness is always required, but field type is only required for list, set and enum.\nYou can add Frugal tag to MyStruct like below:\ntype MyStruct struct { Msg string `frugal:\"1,default\"` Code int64 `frugal:\"2,default\"` Numbers []int64 `frugal:\"3,default,list\u003ci64\u003e\"` } All types example:\ntype MyEnum int64 type Example struct { MyOptBool *bool `frugal:\"1,optional\"` MyReqBool bool `frugal:\"2,required\"` MyOptByte *int8 `frugal:\"3,optional\"` MyReqByte int8 `frugal:\"4,required\"` MyOptI16 *int16 `frugal:\"5,optional\"` MyReqI16 int16 `frugal:\"6,required\"` MyOptI32 *int32 `frugal:\"7,optional\"` MyReqI32 int32 `frugal:\"8,required\"` MyOptI64 *int64 `frugal:\"9,optional\"` MyReqI64 int64 `frugal:\"10,required\"` MyOptString *string `frugal:\"11,optional\"` MyReqString string `frugal:\"12,required\"` MyOptBinary []byte `frugal:\"13,optional\"` MyReqBinary []byte `frugal:\"14,required\"` MyOptI64Set []int64 `frugal:\"15,optional,set\u003ci64\u003e\"` MyReqI64Set []int64 `frugal:\"16,required,set\u003ci64\u003e\"` MyOptI64List []int64 `frugal:\"17,optional,list\u003ci64\u003e\"` MyReqI64List []int64 `frugal:\"18,required,list\u003ci64\u003e\"` MyOptI64StringMap map[int64]string `frugal:\"19,optional\"` MyReqI64StringMap map[int64]string `frugal:\"20,required\"` MyOptEnum *MyEnum `frugal:\"21,optional,i64\"` MyReqEnum *MyEnum `frugal:\"22,optional,i64\"` } Use Frugal to serialize or deserialize Example:\npackage main import ( \"github.com/cloudwego/frugal\" ) func main() { ms := \u0026thrift.MyStruct{ Msg: \"my message\", Code: 1024, Numbers: []int64{0, 1, 2, 3, 4}, } ... buf := make([]byte, frugal.EncodedSize(ms)) frugal.EncodeObject(buf, nil, ms) ... got := \u0026thrift.MyStruct{} frugal.DecodeObject(buf, got) ... } ","categories":"","description":"By integrating Frugal, Kitex's performance can reach about 5 times that of traditional codec methods, and there is no need to generate codec codes in advance.","excerpt":"By integrating Frugal, Kitex's performance can reach about 5 times …","ref":"/docs/kitex/tutorials/advanced-feature/codec_frugal/","tags":"","title":"Frugal"},{"body":"Frugal 是一款基于 JIT 编译的高性能动态 Thrift 编解码器。\n特点 无需生成代码 传统的 Thrift 编解码方式，要求用户必须要先生成编解码代码，Frugal 通过 JIT 编译技术在运行时动态生成编解码机器代码，避免了这一过程。\n高性能 基于 JIT 技术 Frugal 可以生成比 Go 语言编译器性能更好的机器代码，在多核场景下，Frugal 的性能可以达到传统编解码方式的 5 倍左右。\nname old time/op new time/op delta MarshalAllSize_Parallel/small-16 78.8ns ± 0% 14.9ns ± 0% -81.10% MarshalAllSize_Parallel/medium-16 1.34µs ± 0% 0.32µs ± 0% -76.32% MarshalAllSize_Parallel/large-16 37.7µs ± 0% 9.4µs ± 0% -75.02% UnmarshalAllSize_Parallel/small-16 368ns ± 0% 30ns ± 0% -91.90% UnmarshalAllSize_Parallel/medium-16 11.9µs ± 0% 0.8µs ± 0% -92.98% UnmarshalAllSize_Parallel/large-16 233µs ± 0% 21µs ± 0% -90.99% name old speed new speed delta MarshalAllSize_Parallel/small-16 7.31GB/s ± 0% 38.65GB/s ± 0% +428.84% MarshalAllSize_Parallel/medium-16 12.9GB/s ± 0% 54.7GB/s ± 0% +322.10% MarshalAllSize_Parallel/large-16 11.7GB/s ± 0% 46.8GB/s ± 0% +300.26% UnmarshalAllSize_Parallel/small-16 1.56GB/s ± 0% 19.31GB/s ± 0% +1134.41% UnmarshalAllSize_Parallel/medium-16 1.46GB/s ± 0% 20.80GB/s ± 0% +1324.55% UnmarshalAllSize_Parallel/large-16 1.89GB/s ± 0% 20.98GB/s ± 0% +1009.73% name old alloc/op new alloc/op delta MarshalAllSize_Parallel/small-16 112B ± 0% 0B -100.00% MarshalAllSize_Parallel/medium-16 112B ± 0% 0B -100.00% MarshalAllSize_Parallel/large-16 779B ± 0% 57B ± 0% -92.68% UnmarshalAllSize_Parallel/small-16 1.31kB ± 0% 0.10kB ± 0% -92.76% UnmarshalAllSize_Parallel/medium-16 448B ± 0% 3022B ± 0% +574.55% UnmarshalAllSize_Parallel/large-16 1.13MB ± 0% 0.07MB ± 0% -93.54% name old allocs/op new allocs/op delta MarshalAllSize_Parallel/small-16 1.00 ± 0% 0.00 -100.00% MarshalAllSize_Parallel/medium-16 1.00 ± 0% 0.00 -100.00% MarshalAllSize_Parallel/large-16 1.00 ± 0% 0.00 -100.00% UnmarshalAllSize_Parallel/small-16 6.00 ± 0% 1.00 ± 0% -83.33% UnmarshalAllSize_Parallel/medium-16 6.00 ± 0% 30.00 ± 0% +400.00% UnmarshalAllSize_Parallel/large-16 4.80k ± 0% 0.76k ± 0% -84.10% 用 Frugal 可以做什么？ 使用 Frugal 作为 Kitex 的编解码 可以不用再生成大量的编解码代码，使仓库变得干净整洁，review 时也不用再带上一堆无意义的 diff。然后相比于生成的编解码代码，Frugal 的性能更高。\n在 Thriftgo 生成的 struct 上进行编解码 如果你只需要使用 Thrift 的编解码能力，同时也定义好了 IDL，那么只需要用 Thriftgo 生成 IDL 对应的 Go 语言 struct，就可以使用 Frugal 的编解码能力了。\n直接定义 struct 进行编解码 如果你们连 IDL 都不想有，没问题，直径定义好 Go 语言 struct 后，给每个 Field 带上 Frugal 所需的 tag，就可以直接使用 Frugal 进行编解码了。\n使用手册 配合 Kitex 使用 1. 更新 Kitex 到 v0.4.2 以上版本 go get github.com/cloudwego/kitex@latest 2. 带上 -thrift frugal_tag 参数重新生成一次代码 示例：\nkitex -thrift frugal_tag -service a.b.c my.thrift 如果不需要编解码代码，可以带上 -thrift template=slim 参数\nkitex -thrift frugal_tag,template=slim -service a.b.c my.thrift 3. 初始化 client 和 server 时使用 WithPayloadCodec(thrift.NewThriftFrugalCodec()) option client 示例：\npackage client import ( \"context\" \"github.com/cloudwego/kitex-examples/kitex_gen/api/echo\" \"github.com/cloudwego/kitex/client\" \"github.com/cloudwego/kitex/pkg/remote/codec/thrift\" ) func Echo() { codec := thrift.NewThriftCodecWithConfig(thrift.FastRead | thrift.FastWrite | thrift.FrugalRead | thrift.FrugalWrite) cli := echo.MustNewClient(\"a.b.c\", client.WithPayloadCodec(codec)) ... } server 示例：\npackage main import ( \"log\" \"github.com/cloudwego/kitex-examples/kitex_gen/api/echo\" \"github.com/cloudwego/kitex/pkg/remote/codec/thrift\" \"github.com/cloudwego/kitex/server\" ) func main() { codec := thrift.NewThriftCodecWithConfig(thrift.FastRead | thrift.FastWrite | thrift.FrugalRead | thrift.FrugalWrite) svr := server.NewServer(new(EchoImpl), server.WithPayloadCodec(codec)) err := svr.Run() if err != nil { log.Println(err.Error()) } } 配合 Thriftgo 做 Thrift IDL 的编解码 编写 Thrift 文件 现在假设我们有如下 Thrift 文件： my.thrift:\nstructMyStruct{1:stringmsg2:i64code}使用 Thriftgo 生成代码 定义好需要的 Thrift 文件后，在使用 Thriftgo 生成 Go 语言代码时使用 frugal_tag 参数。 示例：\nthriftgo -r -o thrift -g go:frugal_tag,package_prefix=example.com/kitex_test/thrift my.thrift 如果不需要编解码代码，可以带上 template=slim 参数\nthriftgo -r -o thrift -g go:frugal_tag,template=slim,package_prefix=example.com/kitex_test/thrift my.thrift 使用 Frugal 进行编解码 生成所需要的结构体后，直接使用 Frugal 进行编解码即可。 示例：\npackage main import ( \"github.com/cloudwego/frugal\" ) func main() { ms := \u0026thrift.MyStruct{ Msg: \"my message\", Code: 1024, } ... buf := make([]byte, frugal.EncodedSize(ms)) frugal.EncodeObject(buf, nil, ms) ... got := \u0026thrift.MyStruct{} frugal.DecodeObject(buf, got) ... } 直接定义 struct 进行编解码 定义 struct 现在假设我们需要如下 struct：\ntype MyStruct struct { Msg string Code int64 Numbers []int64 } 给结构体字段添加 tag Frugal 所需的 tag 形如 frugal:\"1,default,string\"，其中 1 为字段 ID， default 为字段的 requiredness， string 表示字段的类型。字段 ID 和 字段 requiredness 是必须的，但是字段类型只有当字段为 list 、set 和 enum 时是必须的。\n上述的 MyStruct 可以添加如下 tag：\ntype MyStruct struct { Msg string `frugal:\"1,default\"` Code int64 `frugal:\"2,default\"` Numbers []int64 `frugal:\"3,default,list\u003ci64\u003e\"` } 下面是完整的类型示例：\ntype MyEnum int64 type Example struct { MyOptBool *bool `frugal:\"1,optional\"` MyReqBool bool `frugal:\"2,required\"` MyOptByte *int8 `frugal:\"3,optional\"` MyReqByte int8 `frugal:\"4,required\"` MyOptI16 *int16 `frugal:\"5,optional\"` MyReqI16 int16 `frugal:\"6,required\"` MyOptI32 *int32 `frugal:\"7,optional\"` MyReqI32 int32 `frugal:\"8,required\"` MyOptI64 *int64 `frugal:\"9,optional\"` MyReqI64 int64 `frugal:\"10,required\"` MyOptString *string `frugal:\"11,optional\"` MyReqString string `frugal:\"12,required\"` MyOptBinary []byte `frugal:\"13,optional\"` MyReqBinary []byte `frugal:\"14,required\"` MyOptI64Set []int64 `frugal:\"15,optional,set\u003ci64\u003e\"` MyReqI64Set []int64 `frugal:\"16,required,set\u003ci64\u003e\"` MyOptI64List []int64 `frugal:\"17,optional,list\u003ci64\u003e\"` MyReqI64List []int64 `frugal:\"18,required,list\u003ci64\u003e\"` MyOptI64StringMap map[int64]string `frugal:\"19,optional\"` MyReqI64StringMap map[int64]string `frugal:\"20,required\"` MyOptEnum *MyEnum `frugal:\"21,optional,i64\"` MyReqEnum *MyEnum `frugal:\"22,optional,i64\"` } 使用 Frugal 进行编解码 直接使用 Frugal 进行编解码即可。 示例：\npackage main import ( \"github.com/cloudwego/frugal\" ) func main() { ms := \u0026thrift.MyStruct{ Msg: \"my message\", Code: 1024, Numbers: []int64{0, 1, 2, 3, 4}, } ... buf := make([]byte, frugal.EncodedSize(ms)) frugal.EncodeObject(buf, nil, ms) ... got := \u0026thrift.MyStruct{} frugal.DecodeObject(buf, got) ... } ","categories":"","description":"Kitex 通过集成 Frugal，性能可以达到传统编解码方式的 5 倍左右，且无需提前生成编解码代码。","excerpt":"Kitex 通过集成 Frugal，性能可以达到传统编解码方式的 5 倍左右，且无需提前生成编解码代码。","ref":"/zh/docs/kitex/tutorials/advanced-feature/codec_frugal/","tags":"","title":"Frugal"},{"body":"Introduction There are currently three types of retries: Exception Retry, Backup Request and Connection Failed Retry. Among them, Connection Failed Retry is a network-level problem, since the request is not sent, the framework will retry by default. Here we only present the use of the first two types of retries:\n Exception Retry: Improve the overall success rate of the service. Backup Request: Reduce delay jitter of request.  Because many requests are not idempotent, these two types of retries are not used as the default policy.\nAttention  Confirm that your service is idempotent before enable retry. Exception Retry will increase overall latency.  Retry Policy Only one of the Exception Retry and Backup Request policies can be configured at method granularity.\n Exception Retry  The default is for timeout retry only, and it can be configured to support specific exception or Resp retry.\n   Configuration Item Default value Description Limit     MaxRetryTimes 2 The first request is not included. If it is configured as 0, it means to stop retrying. Value: [0-5]   MaxDurationMS 0 Including the time-consuming of the first failed request and the retry request. If the limit is reached, the subsequent retry will be stopped. 0 means unlimited. Note: if configured, the configuration item must be greater than the request timeout.    EERThreshold 10% If the method-level request error rate exceeds the threshold, retry stops. Value: (0-30%]   ChainStop - Chain Stop is enabled by default. If the upstream request is a retry request, it will not be retried. \u003e= v0.0.5 as the default policy.   DDLStop false If the timeout period of overall request chain is reached, the retry request won’t be sent with this policy. Notice, Kitex doesn’t provide build-in implementation, use retry.RegisterDDLStop(ddlStopFunc) to register is needed.    BackOff None Retry waiting strategy, NoneBackOff by default. Optional: FixedBackOff, RandomBackOff.    RetrySameNode false By default, Kitex selects another node to retry. If you want to retry on the same node, set this parameter to true.      Backup Request     Configuration Item Default value Description Limit     RetryDelayMS - Duration of waiting for initiating a Backup Requset when the first request is not returned. This parameter must be set manually. It is suggested to set as TP99.    MaxRetryTimes 1 The first request is not included. If it is configured as 0, it means to stop retrying. Value: [0-2]   EERThreshold 10% If the method-level request error rate exceeds the threshold, retry stops. Value: (0-30%]   ChainStop false Chain Stop is enabled by default. If the upstream request is a retry request, it will not be retried after timeout. \u003e= v0.0.5 as the default policy.   RetrySameNode false By default, Kitex selects another node to retry. If you want to retry on the same node, set this parameter to true.     How to use Enable by Code Configuration Note: Dynamic configuration (see 3.3) cannot take effect if retry is enabled by code configuration.\nException Retry Configuration  Configuration e.g.  // import \"github.com/cloudwego/kitex/pkg/retry\" fp := retry.NewFailurePolicy() fp.WithMaxRetryTimes(3) // set the maximum number of retries to 3 xxxCli := xxxservice.NewClient(\"destServiceName\", client.WithFailureRetry(fp))  Strategy selection:  fp := retry.NewFailurePolicy() // Number of retries. The default value is 2, excluding the first request. fp.WithMaxRetryTimes(xxx) // Total time consuming. Including the time-consuming for the first failed request and retry request. If the duration limit is reached, the subsequent retries are stopped. fp.WithMaxDurationMS(xxx) // Disable `Chain Stop` fp.DisableChainRetryStop() // Enable DDL abort fp.WithDDLStop() // Backoff policy. No backoff strategy by default. fp.WithFixedBackOff(fixMS int) // Fixed backoff fp.WithRandomBackOff(minMS int, maxMS int) // Random backoff  // Set errRate for retry circuit breaker fp.WithRetryBreaker(errRate float64) // Retry on the same node fp.WithRetrySameNode() Retry with Specific Result（Exception/Resp） v0.4.0 is supported.\nIt can be configured to support specific result to retry, and the result can be request failure or Resp. Because the business may set status information in Resp, and return retry for a certain type. This is collectively referred to as exception retry.\n Configuration e.g.  // import \"github.com/cloudwego/kitex/pkg/retry\"  var opts []client.Option opts = append(opts, client.WithSpecifiedResultRetry(yourResultRetry)) xxxCli := xxxservice.NewClient(targetService, opts...)  retry.ShouldResultRetry Definition  In order to judge error and resp at specific method granularity, rpcinfo is provided as an input argument. The method can be obtained through ri.To().Method().\n// ShouldResultRetryit is used for specifying which error or resp need to be retried type ShouldResultRetry struct { ErrorRetry func(err error, ri rpcinfo.RPCInfo) bool RespRetry func(resp interface{}, ri rpcinfo.RPCInfo) bool }   Specific Exception/Resp Implementation e.g.\n  Resp:\nResp of Thrift and KitexProtobuf protocol correspond to *XXXResult in the generated code, not the real business Resp. To get the real Resp, you need to assert interface{ GetResult() interface{} }.\n  Error:\nThe error returned by the peer, kitex will be uniformly encapsulated as kerrors.ErrRemoteOrNetwork. For Thrift and KitexProtobuf, the following examples can get the Error Msg returned by the peer. For gRPC, if the peer returns an error constructed by status.Error, and the local can use status.FromError(err) to get *status.Status. Pay attention to Status needs to be provided by Kitex, and the package path is github.com/cloudwego/kitex/pkg/remote/trans/nphttp2/status.\n    // retry with specify Resp for one method respRetry := func(resp interface{}, ri rpcinfo.RPCInfo) bool { if ri.To().Method() == \"mock\" { // Notice: you should test with your code, this is only a demo, thrift gen-code of Kitex has GetResult() interface{}  if respI, ok1 := resp.(interface{ GetResult() interface{} }); ok1 { if r, ok2 := respI.GetResult().(*xxx.YourResp); ok2 \u0026\u0026 r.Msg == retryMsg { return true } } } return false } // retry with specify Error for one method errorRetry := func(err error, ri rpcinfo.RPCInfo) bool { if ri.To().Method() == \"mock\" { if te, ok := errors.Unwrap(err).(*remote.TransError); ok \u0026\u0026 te.TypeID() == -100 { return true } } return false } // client option yourResultRetry := \u0026retry.ShouldResultRetry{ErrorRetry:errorRetry , RespRetry: respRetry} opts = append(opts, client.WithSpecifiedResultRetry(yourResultRetry)) In particular, for Thrift’s Exception, although the rpc call layer returns an error, the internal processing of the framework is actually regarded as a one-time cost RPC request (because there is an actual return). If you want to judge it, you need to pay attention to two points:\n Judge by resp instead of error. If the method retry is successful, namely, GetSuccess() != nil, you need to reset Exception to nil. Because the retry uses the XXXResult, and the Resp and Exception correspond to the two fields of XXXResult. Exception has been set for the first, and the second successfully set to Resp. However, the framework layer will not reset Exception, and the user needs to reset it by himself.  e.g.\nrespRetry := func(resp interface{}, ri rpcinfo.RPCInfo) bool { if ri.To().Method() == \"testException\" { teResult := resp.(*stability.TestExceptionResult) if teResult.GetSuccess() != nil { teResult.SetStException(nil) } else if teResult.IsSetXXException() \u0026\u0026 teResult.XxException.Message == xxx { return true } } return false } Backup Request Configuration  Retry Delay recommendations  It is recommended to configure as TP99, then 1% request will trigger Backup Request.\n Configuration e.g.  // If the first request is not returned after XXX ms, the backup request will be initiated and the `Chain Retry Stop` is enabled bp := retry.NewBackupPolicy(xxx) xxxCli := xxxservice.NewClient(\"targetService\", client.WithBackupRequest(bp))  Strategy selection:  bp := retry.NewBackupPolicy(xxx) // Number of retries. The default value is 1, excluding the first request. bp.WithMaxRetryTimes(xxx) // Disable `Chain Stop` bp.DisableChainRetryStop() // Set errRate for retry circuit breaker bp.WithRetryBreaker(errRate float64) // Retry on the same node bp.WithRetrySameNode() Method Granularity Configuration Retry v0.4.0 is supported.\nThe sample configuration of 3.1.1, 3.1.2 will take effect for all methods. If you want to configure retry only for some methods, or configure on Failure Retry or BackupRequest for different methods respectively, configure as follows:\n Configuration e.g.  // import \"github.com/cloudwego/kitex/pkg/retry\" methodPolicies := client.WithRetryMethodPolicies(map[string]retry.Policy{ \"method1\": retry.BuildFailurePolicy(retry.NewFailurePolicy()), \"method2\": retry.BuildFailurePolicy(retry.NewFailurePolicyWithResultRetry(yourResultRetry))}) // other methods do backup request except above methods otherMethodPolicy := client.WithBackupRequest(retry.NewBackupPolicy(10)) var opts []client.Option opts = append(opts, methodPolicies, otherMethodPolicy) xxxCli := xxxservice.NewClient(targetService, opts...)  If both WithFailureRetry or WithBackupRequest are configured, methods not configured in WithRetryMethodPolicies will be executed according to the WithFailureRetry or WithBackupRequest policy. But WithFailureRetry and WithBackupRequest cannot be configured at the same time because they will take effect on all client methods.\n Request Level Configuration Retry（callopt） v0.4.0 is supported.\n Configuration e.g.  import ( \"github.com/cloudwego/kitex/pkg/retry\" ) // demo1: call with failure retry policy, default retry error is Timeout resp, err := cli.Mock(ctx, req, callopt.WithRetryPolicy(retry.BuildFailurePolicy(retry.NewFailurePolicy()))) // demo2: call with customized failure retry policy resp, err := cli.Mock(ctx, req, callopt.WithRetryPolicy(retry.BuildFailurePolicy(retry. NewFailurePolicyWithResultRetry(retry.AllErrorRetry())))) // demo3: call with backup request policy bp := retry.NewBackupPolicy(10) bp.WithMaxRetryTimes(1) resp, err := cli.Mock(ctx, req, callopt.WithRetryPolicy(retry.BuildBackupRequest(bp))) Circuit Breaker Reuse When circuit breaker is enabled for a service, you can reuse the breaker’s statistics to reduce additional CPU consumption. Note that the error rate threshold for retries must be lower than the threshold for a service.\n Configuration e.g.  // 1. Initialize kitex's built-in cbsuite cbs := circuitbreak.NewCBSuite(circuitbreak.RPCInfo2Key)// 2. Initialize retryContainer, passing in ServiceControl and ServicePanel retryC := retry.NewRetryContainerWithCB(cs.cbs.ServiceControl(), cs.cbs.ServicePanel()) var opts []client.Option // 3. Set retryContainer opts = append(opts, client.WithRetryContainer(retryC)) // 4. Set Service circuit breaker opts = append(opts, client.WithMiddleware(cbs.ServiceCBMW())) // 5. Initialize Client and pass in the configuration option cli, err := xxxservice.NewClient(targetService, opts...) Dynamic open or adjust strategy If you want to adjust the policy in combination with remote configuration, dynamic open retry, or runtime, you can take effect through the NotifyPolicyChange method of retryContainer. Currently, the open source version of Kitex does not provide a remote configuration module, and users can integrate their own configuration center. Note: If it is turned on through code configuration, dynamic configuration cannot take effect.\n Configuration e.g.  retryC := retry.NewRetryContainer() // demo // 1. define your change func // 2. exec yourChangeFunc in your config module yourChangeFunc := func(key string, oldData, newData interface{}) { newConf := newData.(*retry.Policy) method := parseMethod(key) retryC.NotifyPolicyChange(method, policy) } // configure retryContainer cli, err := xxxservice.NewClient(targetService, client.WithRetryContainer(retryC)) Tracking Kitex records the retry times and previous request time in rpcInfo. You can report or output a retry request based on the retry Tag in Client’s metric or log through:\nvar retryCount string var lastCosts string toInfo := rpcinfo.GetRPCInfo(ctx).To() if retryTag, ok := toInfo.Tag(rpcinfo.RetryTag); ok { retryCount = retryTag if lastCostTag, ok := toInfo.Tag(rpcinfo.RetryLastCostTag); ok { lastCosts = lastCostTag } } Downstream identification If using TTHeader as the transport protocol, you can determine if the downstream handler is currently a retry request and decide whether to continue processing.\nretryReqCount, exist := metainfo.GetPersistentValue(ctx,retry.TransitKey) For example, retryReqCount = 2, which means the second retry request (excluding the first request), then the business degradation strategy can be adopted(non-retry requests do not have this information).\n Question: Chain Stop is enabled by default, is it necessary for services to identify retry requests?\n  Answer：Chain Stop means that the retry request on the chain will not be retried. Assuming that there is a request chain A-\u003eB-\u003eC, A sends a retry request to B, while during B-\u003eC, if a timeout occurs or Backup is configured, B will not send a retry request to C. If the service can identify the retry request, it can directly decide whether to continue the request to C. In short, Chain Stop avoids retry amplification caused by B sending a retry request to C. The service’s own control can completely avoid requests from B to C.\n ","categories":"","description":"Kitex Exception retry and Backup Request policy Introduction and Usage Guide.","excerpt":"Kitex Exception retry and Backup Request policy Introduction and Usage …","ref":"/docs/kitex/tutorials/basic-feature/retry/","tags":"","title":"Retry"},{"body":"重试功能说明 目前有三类重试：异常重试、Backup Request，建连失败重试（默认）。其中建连失败是网络层面问题，由于请求未发出，框架会默认重试。 本文档介绍前两类重试的使用：\n 异常重试：提高服务整体的成功率 Backup Request：减少服务的延迟波动  因为很多的业务请求不具有幂等性，这两类重试不会作为默认策略。\n注意：  确认你的服务具有幂等性，再开启重试 异常重试会增加延迟  重试策略 异常重试和 Backup Request 策略方法粒度上只能配置其中之一。\n  异常重试\n默认只对超时重试，可配置支持指定异常或 Resp 重试。\n     配置项 默认值 说明 限制     MaxRetryTimes 2 最大重试次数，不包含首次请求。如果配置为 0 表示停止重试。 合法值：[0-5]   MaxDurationMS 0 累计最大耗时，包括首次失败请求和重试请求耗时，如果耗时达到了限制的时间则停止后续的重试。0 表示无限制。注意：如果配置，该配置项必须大于请求超时时间。    EERThreshold 10% 重试熔断错误率阈值, 方法级别请求错误率超过阈值则停止重试。 合法值：(0-30%]   ChainStop - 链路中止, 默认启用。如果上游请求是重试请求，不会重试。 \u003e= v0.0.5 后作为默认策略   DDLStop false 链路超时中止，该策略是从链路的超时时间判断是否需要重试。注意，Kitex 未内置该实现，需通过 retry.RegisterDDLStop(ddlStopFunc) 注册 DDL func，结合链路超时判断，实现上建议基于上游的发起调用的时间戳和超时时间判断。​​    BackOff None 重试等待策略，默认立即重试（NoneBackOff）。可选：固定时长退避 (FixedBackOff)、随机时长退避 (RandomBackOff)。    RetrySameNode false 框架默认选择其他节点重试，若需要同节点重试，可配置为 true。      Backup Request     配置项 默认值 说明 限制     RetryDelayMS - Backup Request 的等待时间，若该时间内若请求未返回，会发送新的请求。必须手动配置，建议参考 TP99。    MaxRetryTimes 1 最大重试次数，不包含首次请求。 如果配置为 0 表示停止重试。 合法值：[0-2]   EERThreshold 10% 重试熔断错误率阈值，方法级别请求错误率超过阈值则停止重试。 合法值：(0-30%]   ChainStop - 链路中止, 默认启用。如果上游请求是重试请求，不会发送 Backup Request。 \u003e= v0.0.5 后作为默认策略   RetrySameNode false 框架默认选择其他节点重试，若需要同节点重试，可配置为 true     使用方式 代码配置开启 注意：若通过代码配置开启重试，动态配置 (见 3.3) 则无法生效。\n异常重试配置  配置示例：  // import \"github.com/cloudwego/kitex/pkg/retry\" fp := retry.NewFailurePolicy() fp.WithMaxRetryTimes(3) // 配置最多重试3次 xxxCli := xxxservice.NewClient(\"destServiceName\", client.WithFailureRetry(fp))  策略选择：  fp := retry.NewFailurePolicy() // 重试次数, 默认2，不包含首次请求 fp.WithMaxRetryTimes(xxx) // 总耗时，包括首次失败请求和重试请求耗时达到了限制的duration，则停止后续的重试。 fp.WithMaxDurationMS(xxx) // 关闭链路中止 fp.DisableChainRetryStop() // 开启DDL中止 fp.WithDDLStop() // 退避策略，默认无退避策略 fp.WithFixedBackOff(fixMS int) // 固定时长退避 fp.WithRandomBackOff(minMS int, maxMS int) // 随机时长退避  // 开启重试熔断 fp.WithRetryBreaker(errRate float64) // 同一节点重试 fp.WithRetrySameNode() 指定结果重试（异常/Resp） 支持版本 v0.4.0。\n可配置支持指定结果重试，结果可以是请求失败，也可以指定 Resp。因为业务可能在 Resp 设置状态信息，针对某类返回重试，所以支持指定 Resp 重试，这里统称为异常重试。\n 配置示例：  // import \"github.com/cloudwego/kitex/pkg/retry\"  var opts []client.Option opts = append(opts, client.WithSpecifiedResultRetry(yourResultRetry)) xxxCli := xxxservice.NewClient(targetService, opts...)  retry.ShouldResultRetry 定义  为了能具体到方法粒度对 error 和 resp 做判断，提供 rpcinfo 作为入参，可以通过 ri.To().Method() 获取方法。\n// ShouldResultRetryit is used for specifying which error or resp need to be retried type ShouldResultRetry struct { ErrorRetry func(err error, ri rpcinfo.RPCInfo) bool RespRetry func(resp interface{}, ri rpcinfo.RPCInfo) bool }   指定 异常/Resp 实现示例：\n  关于 Resp：\nThrift 和 KitexProtobuf 协议 Resp 对应的是生成代码中的 *XXXResult，不是真实的业务 Resp，获取真实的 Resp 需要断言 interface{ GetResult() interface{} }；\n  关于 Error：\n对端返回的 error，kitex 都会统一封装为 kerrors.ErrRemoteOrNetwork，对于 Thrift 和 KitexProtobuf 以下示例可以获取对端返回 Error Msg；对于 gRPC 如果对端通过 status.Error 构造的错误返回，本端使用 status.FromError(err) 可以获取 *status.Status，注意 Status 需使用 Kitex 提供的，包路径是 github.com/cloudwego/kitex/pkg/remote/trans/nphttp2/status。\n    // retry with specify Resp for one method respRetry := func(resp interface{}, ri rpcinfo.RPCInfo) bool { if ri.To().Method() == \"mock\" { // Notice: you should test with your code, this is only a demo, thrift gen-code of Kitex has GetResult() interface{}  if respI, ok1 := resp.(interface{ GetResult() interface{} }); ok1 { if r, ok2 := respI.GetResult().(*xxx.YourResp); ok2 \u0026\u0026 r.Msg == retryMsg { return true } } } return false } // retry with specify Error for one method errorRetry := func(err error, ri rpcinfo.RPCInfo) bool { if ri.To().Method() == \"mock\" { if te, ok := errors.Unwrap(err).(*remote.TransError); ok \u0026\u0026 te.TypeID() == -100 { return true } } return false } // client option yourResultRetry := \u0026retry.ShouldResultRetry{ErrorRetry:errorRetry , RespRetry: respRetry} opts = append(opts, client.WithSpecifiedResultRetry(yourResultRetry)) 特别地，对于 Thrift 的 Exception，rpc 调用层面虽然返回了 error，但对框架内部处理其实视为一次成本的 RPC 请求（因为有实际的返回），如果要对其做判断需注意两点：\n 通过 resp 做判断而不是 error 若该方法重试成功即 GetSuccess() != nil，需重置 Exception 为 nil，因为重试使用的是一个 XXXResult，且 Resp 和 Exception 对应的是 XXXResult 的两个字段，第一次返回 Exception 已经做了赋值，第二次成功对 Resp 赋值但框架层面不会重置 Exception，需要用户自行重置。  示例如下：\nrespRetry := func(resp interface{}, ri rpcinfo.RPCInfo) bool { if ri.To().Method() == \"testException\" { teResult := resp.(*stability.TestExceptionResult) if teResult.GetSuccess() != nil { teResult.SetStException(nil) } else if teResult.IsSetXXException() \u0026\u0026 teResult.XxException.Message == xxx { return true } } return false } Backup Request 配置  Retry Delay 建议  建议配置为 TP99，则 1% 请求会触发 Backup Request。\n 配置示例：  // 首次请求 xxx ms未返回，发起 backup 请求，并开启链路中止 bp := retry.NewBackupPolicy(xxx) xxxCli := xxxservice.NewClient(targetService, client.WithBackupRequest(bp))  策略选择：  bp := retry.NewBackupPolicy(xxx) // 重试次数, 默认1，不包含首次请求 bp.WithMaxRetryTimes(xxx) // 关闭链路中止 bp.DisableChainRetryStop() // 开启重试熔断 bp.WithRetryBreaker(errRate float64) // 同一节点重试 bp.WithRetrySameNode() 方法粒度配置重试 支持版本 v0.4.0。\n3.1.1,3.1.2 的示例配置会对所有方法生效，如果希望只对部分方法配置重试，或对不同方法分别配置 失败重试 或 BackupRequest，配置如下：\n 配置示例：  // import \"github.com/cloudwego/kitex/pkg/retry\" methodPolicies := client.WithRetryMethodPolicies(map[string]retry.Policy{ \"method1\": retry.BuildFailurePolicy(retry.NewFailurePolicy()), \"method2\": retry.BuildFailurePolicy(retry.NewFailurePolicyWithResultRetry(yourResultRetry))}) // other methods do backup request except above methods otherMethodPolicy := client.WithBackupRequest(retry.NewBackupPolicy(10)) var opts []client.Option opts = append(opts, methodPolicies, otherMethodPolicy) xxxCli := xxxservice.NewClient(targetService, opts...)  如果同时配置了 WithFailureRetry 或 WithBackupRequest，则 WithRetryMethodPolicies 未配置的方法会按照 WithFailureRetry 或 WithBackupRequest 策略执行。但 WithFailureRetry 和 WithBackupRequest 因为会对 client 所有方法生效，不能同时配置。\n 请求级别配置重试（callopt） 支持版本 v0.4.0。\n 配置示例：  import ( \"github.com/cloudwego/kitex/pkg/retry\" ) // demo1: call with failure retry policy, default retry error is Timeout resp, err := cli.Mock(ctx, req, callopt.WithRetryPolicy(retry.BuildFailurePolicy(retry.NewFailurePolicy()))) // demo2: call with customized failure retry policy resp, err := cli.Mock(ctx, req, callopt.WithRetryPolicy(retry.BuildFailurePolicy(retry. NewFailurePolicyWithResultRetry(retry.AllErrorRetry())))) // demo3: call with backup request policy bp := retry.NewBackupPolicy(10) bp.WithMaxRetryTimes(1) resp, err := cli.Mock(ctx, req, callopt.WithRetryPolicy(retry.BuildBackupRequest(bp))) 复用熔断器 当开启了服务的熔断配置可以复用熔断的统计减少额外的 CPU 消耗，注意重试的熔断阈值须低于服务的熔断阈值。\n 配置示例：  // 1. 初始化 kitex 内置的 cbsuite cbs := circuitbreak.NewCBSuite(circuitbreak.RPCInfo2Key) // 2. 初始化 retryContainer，传入ServiceControl和ServicePanel retryC := retry.NewRetryContainerWithCB(cs.cbs.ServiceControl(), cs.cbs.ServicePanel()) var opts []client.Option // 3. 配置 retryContainer opts = append(opts, client.WithRetryContainer(retryC)) // 4. 配置 Service circuit breaker opts = append(opts, client.WithMiddleware(cbs.ServiceCBMW())) // 5. 初始化 Client, 传入配置 option cli, err := xxxservice.NewClient(targetService, opts...) 动态开启或调整策略 若需要结合远程配置，动态开启重试或运行时调整策略，可以通过 retryContainer 的 NotifyPolicyChange 方法生效，目前 Kitex 开源版本暂未提供远程配置模块，使用者可集成自己的配置中心。注意：若已通过代码配置开启，动态配置则无法生效。\n 配置示例：  retryC := retry.NewRetryContainer() // demo // 1. define your change func // 2. exec yourChangeFunc in your config module yourChangeFunc := func(key string, oldData, newData interface{}) { newConf := newData.(*retry.Policy) method := parseMethod(key) retryC.NotifyPolicyChange(method, policy) } // configure retryContainer cli, err := xxxservice.NewClient(targetService, client.WithRetryContainer(retryC)) 监控埋点 Kitex 对重试的请求在 rpcinfo 中记录了重试次数和之前请求的耗时，可以在Client侧的 metric 或日志中根据 retry tag 区分上报或输出。获取方式：\nvar retryCount string var lastCosts string toInfo := rpcinfo.GetRPCInfo(ctx).To() if retryTag, ok := toInfo.Tag(rpcinfo.RetryTag); ok { retryCount = retryTag if lastCostTag, ok := toInfo.Tag(rpcinfo.RetryLastCostTag); ok { lastCosts = lastCostTag } } 下游识别重试请求 如果使用 TTHeader 作为传输协议，下游 handler 可以通过如下方式判断当前是否是重试请求，自行决定是否继续处理。\nretryReqCount, exist := metainfo.GetPersistentValue(ctx,retry.TransitKey) 比如 retryReqCount = 2，表示第二次重试请求（不包括首次请求），则采取业务降级策略返回部分或 mock 数据返回（非重试请求没有该信息）。\n Q: 框架默认开启链路中止，业务是否还有必要识别重试请求？\n链路中止是指链路上的重试请求不会重试，比如 A-\u003eB-\u003eC，A 向 B 发送的是重试请求，如果 B-\u003eC 超时了或者配置了 Backup，则 B 不会再发送重试请求到 C。如果业务自行识别重试请求，可以直接决定是否继续请求到 C。简言之链路中止避免了 B 向 C 发送重试请求导致重试放大，业务自己控制可以完全避免 B 到 C 的请求。\n ","categories":"","description":"Kitex 异常重试与 Backup Request 策略介绍与使用指南。","excerpt":"Kitex 异常重试与 Backup Request 策略介绍与使用指南。","ref":"/zh/docs/kitex/tutorials/basic-feature/retry/","tags":"","title":"请求重试"},{"body":"会议主题 ：CloudWeGo 社区会议 6.2\n参会人 ：YangruiEmma, baiyutang, joway, yccpt, Huang Yuting, CoderPoet, li-jin-gou, GuangmingLuo, simon0-o, yiyun, JZK-Keven, bodhisatan, Jacob953, cyyolo, debug-LiXiwen, baize, zstone12, You Gaoming, HeyJavaBean, jayantxie, Skyenought\n会前必读 ：http://www.cloudwego.io/；https://github.com/cloudwego\n议程 1 ：新人介绍  新成员名单：Skyenought, zstone12, You Gaoming 社区新成员分别进行自我介绍，主要包含个人基本情况、开源贡献经历和后续参与社区工作内容。   议程 2 ：Frugal 项目介绍 @simon0-o  相关文档：https://mp.weixin.qq.com/s/b17bSqx9y5AIH3WEx1haog   议程 3：Integrate Polaris Go SDK to Support Their Service Governance Ability 任务介绍 @jayantxie  地址：https://github.com/cloudwego/kitex/issues/421 已认领 Issue @debug-LiXiwen 继注册发现能力之后，再以 Polaris 为服务治理中心，集成服务治理能力。熔断部分会在 Kitex 中注入 Middleware，通过 Middleware 上报每次请求结果。上报时需要 Polaris 实例，所以需要转换一下，这个转换可以通过缓存用 Key 去做查找。 此 PR 已经支持外部限流器的实现。可以通过扩展接口传入外部实现的限流器，对接 Polaris 的限流功能。 关于动态路由和负载均衡，通过扩展 Kitex LoadBalancer 实现。在 Polaris LoadBalancer 里，通过服务发现的实例去构造 Kitex 的实例，在LoadBalancer 接口里把这个实例转换成 Polaris 的实例，再把它写到缓存里。每一次 Pick 时，从 Pick 里找到调用 Polaris 动态路由的 API 对应的子集，再从这些子集里调用负载均衡的 API ，拿到对应实例。这个实例需要转成 Kitex 的 Instance， 所以也需要通过 Key 做查找操作。扩展 Next Picker 只会在第一次选择时执行这个逻辑。 新建 Polaris 仓库，把原有 Registry-Polaris 仓库代码复制过去，后续只维持新仓库。   议程 4：Kitex 源码分析活动进展介绍 @yiyun  第一期 5.19 — 6.30 进程近半，现有参与人数 93 人，开始撰写及提交笔记 10 人左右。6.1 晚第一次活动会议，讨论过后开了“百人共享”，共同整理 Kitex 基础教程。 相关文档：Kitex前传：RPC框架那些你不得不知的故事 。后续对这些感兴趣同学，可以直接联系逸云，加到 CloudWeGo study group 完成这个教程。   议程 5：社区开放性讨论 \u0026 QA @GuangmingLuo  希望有更多感兴趣的同学帮助官网做一些优化，尤其是 Community 内容展示和主页。有前端背景或者对开源项目的前端技术、网站建设感兴趣同学可以联系广明。   相关资讯： Kitex v0.3.2 已发布！\nhttps://github.com/cloudwego/kitex/releases/tag/v0.3.2\n","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 6.2\n参会人 ：YangruiEmma, baiyutang, joway, yccpt, …","ref":"/zh/community/meeting_notes/2022-06-02/","tags":"","title":"CloudWeGo 社区会议 6.2"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/pilota/","tags":"","title":"Pilota"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/pilota/","tags":"","title":"Pilota"},{"body":"Notes on using protobuf IDL hz currently supports the syntax of proto2 / proto3\nWe hope that users specify go_package when defining the protobuf IDL, so that one is consistent with the semantics of protobuf and the location of the generated model can be determined by go_package. If the user does not specify go_package, hz will default the package of the proto file to go_package, which may have some unintended naming conflicts.\nFor example, go_package can be defined like this\noption go_package = \"hello.world\"; // or hello/world The generated path of model will be:\n${project path}/${model_dir}/hello/world\nThe handler file will take the last level of go_package as the generation path, and its generation path will be:\n${project path}/${handler_dir}/world\nThe router registration file will also take the last level of the go_package as the generation path, and the generation path will be:\n${project path}/biz/router/world\nNotes on using thrift IDL hz has no special requirements for the definition of thrift IDL, it only needs to comply with the grammar specification. The code generation path will be related to the thrift namespace\nFor example, a namespace can be defined like this\nnamespacegohello.worldThe generated path of model will be:\n${project path}/${model_dir}/hello/world\nThe handler file will take namespace as the generation path, and its generation path will be:\n${project path}/${handler_dir}/hello/world\nThe router registration file will also take namespace as the generation path, and its generation path will be:\n${project path}/biz/router/hello/world\nDescription of the behavior when using the update command  Notes on using custom path  For the convenience of user, hz provides custom handler paths, model paths, templates, etc. However, hz does not save the current project information when creating a new project, so it can be considered as a stateless update when using the update command. Therefore, for the same set of IDL in new and update, using different custom information may result in duplicate code, for example, as follows:\nCreate a new project:\nhz new -idl demo.thrift // In this case, hz will generate the model under \"biz/model\" Update an existing project:\nhz update -idl demo.thrift --model_dir=my_model // In this case, hz will not update the model code under \"biz/model\", but under \"my_model\"; then the code under \"biz/model\" and \"my_model\" will be duplicated, and the new handler will depend on \"my_model\",while the previous handler will depend on \"biz/model\". In this case, you need to delete \u0026 change some code manually. Therefore, we hope that user use the update command with custom paths “client_dir”, “model_dir”, “handler_dir”, preferably same as new.\nBehavior of update handler  hz will generate handlers based on default/custom template when creating a new project, where each service generates a file that contains all the handler code defined by the service; if IDL defines multiple services, each service will generate a file, and these files are in the same path; for example:\n// demo.thrift namespacegohello.exampleserviceService1{HelloRespMethod1(1:HelloReqrequest)(api.get=\"/hello\");}serviceService2{HelloRespMethod2(1:HelloReqrequest)(api.get=\"/new\");}// Then the handler file generated by the IDL is as follows: ${handler_dir}/${namespace}/service1.go-\u003emethod1${handler_dir}/${namespace}/service2.go-\u003emethod2When a new method is added to the IDL, the handler template will be added at the end of the corresponding service file; note that the handler added here will use the default template, and the new service file will use a custom template if appropriate.\nBehavior of update router  The router code generated by hz in new mainly includes the following three:\n biz/router/${namespace}/${idlName}.go: Each primary IDL generates a corresponding routing registration code file, which registers all the routes defined in the IDL in a routing group, and sets the default middleware.    biz/router/${namespace}/middleware.go: The default middleware function corresponding to each primary IDL, which can be modified by the user to add specific middleware logic to a particular route.    biz/router/register.go: This file is responsible for calling the route registration generated by different IDL; for example, if i define service in both IDL “demo1.thrift” and “demo2.thrift”, then both files will generate the corresponding route registration code. register.go is responsible for calling the route registration functions of these two parts.  Based on the above description, a description of the router’s behavior during update is given:\n biz/${namespace}/${idlName}.go: Regenerate based on IDL every time, users should not change the code of this file, otherwise the code will be lost.    biz/${namespace}/middleware.go: Appends a currently unavailable middleware to the end each time.    biz/router/register.go: If there is a new IDL, the route registration method of the new IDL will be inserted.  Notes on using Windows Operating System Hz uses symlink when creating \u0026 updating projects. For Windows, you may need to enable your device’s development mode to get permission for your Windows user.\nWhen creating projects based on protobuf IDL, you need to manually download \u0026 install the protoc command from https://github.com/protocolbuffers/protobuf/releases. If your protobuf IDL contains a dependency on the google/protobuf package, you need to unzip protoc-win64.zip and put everything under the include directory in the same directory as your protoc binary file.\n","categories":"","description":"","excerpt":"Notes on using protobuf IDL hz currently supports the syntax of proto2 …","ref":"/docs/hertz/tutorials/toolkit/usage/cautions/","tags":"","title":"note"},{"body":"使用 protobuf IDL 的注意事项 hz 目前支持 proto2 / proto3 的语法\n我们希望用户在定义 protobuf idl 的时候指定 go_package，这样一来符合 protobuf 的语义，二来生成的 model 位置可以通过 go_package 来决定。如果用户不指定 go_package，hz 会默认将 proto 文件的 package 做为 go_package，可能会有一些预期外的命名冲突。\n例如，可以这样定义 go_package\noption go_package = \"hello.world\"; // or hello/world model 生成的路径会是：\n${项目路径}/${model_dir}/hello/world\nhandler 文件会取 go_package 最后一级作为生成路径，其生成路径会是：\n${项目路径}/${handler_dir}/world\nrouter 注册文件同样会取 go_package 最后一级作为生成路径，其生成路径会是：\n${项目路径}/biz/router/world\n使用 thrift IDL 的注意事项 hz 对于 thrift idl 的定义无特殊要求，符合语法规范即可。代码的生成路径会和 thrift 的 namespace 相关。\n例如，可以这样定义 namespace\nnamespacegohello.worldmodel 生成的路径会是：\n${项目路径}/${model_dir}/hello/world\nhandler 文件会取 namespace 作为生成路径，其生成路径会是：\n${项目路径}/${handler_dir}/hello/world\nrouter 注册文件同样会取 namespace 作为生成路径，其生成路径会是：\n${项目路径}/biz/router/hello/world\n使用 update 命令时的行为说明  使用自定义路径的注意事项  hz 为了用户使用方便，提供了自定义 handler 路径、model 路径、模板等功能。但是 hz 在创建一个新项目的时候并没有保存当前项目的信息，所以在使用 update 命令时可以认为是一种无状态的更新。因此对于同一套 idl 在 new 和 update 的时候，使用了不同的自定义信息，可能会产生重复的代码，举个例子，如下：\n创建新项目：\nhz new -idl demo.thrift // 此时，hz 会把 model 生成在 \"biz/model\"下 更新项目：\nhz update -idl demo.thrift --model_dir=my_model // 此时，hz 不会更新\"biz/model\"下的 model 代码，而是会在\"my_model\"下；这时\"biz/model\"和\"my_model\"下的代码就会重复，且新生成的handler会依赖\"my_model\"，之前的handler会依赖\"biz/model\"，这时就需要用户手动删除\u0026改动一些代码了。 因此，我们希望用户使用 update 命令的时候，自定义的路径 “client_dir”、“model_dir”、“handler_dir”，最好和 new 相同。\nupdate handler 的行为  hz 在 new 项目的时候会根据默认模板/自定义模板来生成 handler，其中每个 service 生成一个文件，该文件包含了该 service 定义的所有 handler 代码；如果 idl 定义了多个 service，则每个 service 都会生成一个文件，这些文件都在同一路径下；举个例子：\n// demo.thrift namespacegohello.exampleserviceService1{HelloRespMethod1(1:HelloReqrequest)(api.get=\"/hello\");}serviceService2{HelloRespMethod2(1:HelloReqrequest)(api.get=\"/new\");}// 那么该 idl 生成的 handler 文件如下： ${handler_dir}/${namespace}/service1.go-\u003emethod1${handler_dir}/${namespace}/service2.go-\u003emethod2当该 idl 增加了新的 method 后，就会在对应 service 的文件的末尾追加 handler 模板；注意这里追加的 handler 会使用默认的模板，新生成 service 文件会根据情况使用自定义模板。\nupdate router 的行为  hz 在 new 的时候生成的 router 代码主要有如下三个：\n biz/router/${namespace}/${idlName}.go: 每个主 idl 都会生成对应的路由注册代码文件，该文件以路由组的方式注册 idl 中定义的所有路由，并设置默认的中间件。    biz/router/${namespace}/middleware.go: 每个主 idl 对应的默认中间件函数，用户可修改中间件函数，以此为特定的路由增加特定的中间件逻辑。    biz/router/register.go：该文件负责调用不同 idl 生成的路由注册；比如我在两个 idl “demo1.thrift”、“demo2.thrift\"中都定义了 service ，那么这两个文件都会生成对应的路由注册代码。register.go 负责调用这两部分的路由注册函数。  基于上述描述，给出 router 在 update 时的行为描述：\n biz/${namespace}/${idlName}.go: 每次都基于 idl 重新生成，用户不要改该文件代码，否则会丢失代码。    biz/${namespace}/middleware.go: 每次都会在尾部追加目前没有的 middleware。    biz/router/register.go: 如果有新增的 idl 会插入新的 idl 的路由注册方式。  使用 Windows 操作系统时的注意事项 使用 hz 命令创建项目时将用到 symlink ，在 Windows 操作系统下你可能需要开启开发者模式来启用用户权限的 symlink\n在基于 protobuf IDL 创建项目时，你需要手动安装 protoc 命令行工具至 PATH 环境变量，另外如果你使用 google/protobuf 包下的文件，你需要将protoc-win64.zip 中 include目录下的所有文件放在 protoc 同一目录。\n","categories":"","description":"","excerpt":"使用 protobuf IDL 的注意事项 hz 目前支持 proto2 / proto3 的语法\n我们希望用户在定义 protobuf …","ref":"/zh/docs/hertz/tutorials/toolkit/usage/cautions/","tags":"","title":"注意事项"},{"body":"Hertz middleware to automatically generate RESTful API documentation with Swagger 2.0.\nThe implementation of the swagger extension refers to the implementation of Gin.\nUsage   Add comments to your API source code, See Declarative Comments Format.\n  Download Swag for Go by using:\n  go get install executables needs to work with GOPATH mode.\ngo get github.com/swaggo/swag/cmd/swag Starting in Go 1.17,installing executables with go get is deprecated. go install may be used instead:\ngo install github.com/swaggo/swag/cmd/swag@latest Run the Swag at your Go project root path(for instance ~/root/go-project-name), Swag will parse comments and generate required files(docs folder and docs/doc.go) at ~/root/go-project-name/docs.  swag init swag init with options(All options can be viewed via swag init -h).\nswag init --parseDependency --parseInternal --parseDepth 5 --instanceName \"swagger\"    Options Default Description     parseInternal false Parse go files in internal packages.   parseDependency false Parse go files inside dependency folder.   parseDepth 100 Dependency parse depth.If you know the depth of the data structure to be parsed, it is recommended to use parseDepth, the swag command execution time will be greatly reduced.   instanceName “swagger” The instance name of the swagger document. If multiple different swagger instances should be deployed on one hertz router, ensure that each instance has a unique name.    Download hertz-swagger by using:  go get github.com/hertz-contrib/swagger go get github.com/swaggo/files Import following in your code:\nimport \"github.com/hertz-contrib/swagger\" // hertz-swagger middleware import \"github.com/swaggo/files\" // swagger embed files Example Now assume you have implemented a simple api as following:\nfunc PingHandler(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]string{ \"ping\": \"pong\", }) } So how to use hertz-swagger on api above? Just follow the following guide.\n Add Comments for apis and main function with hertz-swagger rules like following:  // PingHandler TestHandler // @Summary TestSummary // @Description TestDescription // @Accept application/json // @Produce application/json // @Router /ping [get] func PingHandler(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]string{ \"ping\": \"pong\", }) } Use swag init command to generate a docs, docs generated will be stored at docs/. Import the generated docs package into the current project: I assume your project named github.com/go-project-name/docs.  import ( docs \"github.com/go-project-name/docs\" )  Build your application and after that, go to http://localhost:8888/swagger/index.html ,you to see your Swagger UI.\n  The full code and folder relatives here:\n  package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/swagger\" _ \"github.com/hertz-contrib/swagger/example/basic/docs\" swaggerFiles \"github.com/swaggo/files\" ) // PingHandler Testhandler // @Summary TestSummary // @Description TestDescription // @Accept application/json // @Produce application/json // @Router /ping [get] func PingHandler(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]string{ \"ping\": \"pong\", }) } // @title HertzTest // @version 1.0 // @description This is a demo using Hertz.  // @contact.name hertz-contrib // @contact.url https://github.com/hertz-contrib  // @license.name Apache 2.0 // @license.url http://www.apache.org/licenses/LICENSE-2.0.html  // @host localhost:8888 // @BasePath / // @schemes http func main() { h := server.Default() h.GET(\"/ping\", PingHandler) url := swagger.URL(\"http://localhost:8888/swagger/doc.json\") // The url pointing to API definition \th.GET(\"/swagger/*any\", swagger.WrapHandler(swaggerFiles.Handler, url)) h.Spin() } Demo project tree, swag init is run at relative ..\n. ├── docs │ ├── docs.go │ ├── swagger.json │ └── swagger.yaml ├── go.mod ├── go.sum └── main.go Multiple APIs This feature was introduced in swag v1.7.9.\nConfiguration You can configure Swagger using different configuration options.\nfunc main() { h := server.Default() h.GET(\"/ping\", PingHandler) url := swagger.URL(\"http://localhost:8888/swagger/doc.json\") // The url pointing to API definition \th.GET(\"/swagger/*any\", swagger.WrapHandler(swaggerFiles.Handler, url, swagger.DefaultModelsExpandDepth(-1))) h.Spin() }    Option Type Default Description     URL string “doc.json” URL pointing to API definition   DocExpansion string “list” Controls the default expansion setting for the operations and tags. It can be ‘list’ (expands only the tags), ‘full’ (expands the tags and operations) or ‘none’ (expands nothing).   DeepLinking bool true If set to true, enables deep linking for tags and operations. See the Deep Linking documentation for more information.   DefaultModelsExpandDepth int 1 Default expansion depth for models (set to -1 completely hide the models).   PersistAuthorization bool false If set to true, it persists authorization data and it would not be lost on browser close/refresh.   Oauth2DefaultClientID string \"\" If set, it’s used to prepopulate the client_id field of the OAuth2 Authorization dialog.     ","categories":"","description":"","excerpt":"Hertz middleware to automatically generate RESTful API documentation …","ref":"/docs/hertz/tutorials/basic-feature/middleware/swagger/","tags":"","title":"Swagger"},{"body":"这是一个用 Swagger 2.0 来自动生成 RESTful API 文档的 Hertz 中间件。\n参考了 gin 的实现，对 Hertz 进行了适配。\n使用用法   在你的 API 源代码中添加注释， 参考 Declarative Comments Format。\n  可以通过运行以下命令下载 Go 对应的 Swag 可执行文件:\n  但是需要注意的是， go get 安装可执行文件需要配合 GOPATH 模式工作。\ngo get github.com/swaggo/swag/cmd/swag 因为从 Go 1.17 开始，在 go mod 模式下通过 go get 下载对应库文件将无法自动编译并安装到 $GOPATH/bin 的路径， 所以不再推荐用 go get 来安装可执行文件的方式。可以使用 go install来代替。\ngo install github.com/swaggo/swag/cmd/swag@latest 在你的 Go 项目的根目录下运行 Swag (例如 ~/root/go-project-name)，Swag 会解析注释并在 ~/root/go-project-name/docs 目录下生成必要的文件(docs 文件夹和 docs/doc.go)。  swag init 使用参数运行 Swag (全部参数可以通过运行 swag init -h 查看)。\nswag init --parseDependency --parseInternal --parseDepth 5 --instanceName \"swagger\"    选项 默认值 描述     parseInternal false 解析内部依赖包。   parseDependency false 解析外部依赖包。   parseDepth 100 解析依赖包深度，如果你知道解析结构的深度，推荐使用这个参数，swag命令的执行时间会显著减少。   instanceName “swagger” swagger 文档的实例名称。如果要在一个 Hertz 路由上部署多个不同的 swagger 实例，请确保每个实例有一个唯一的名字。    通过运行以下命令在工程中下载 hertz-swagger :  go get github.com/hertz-contrib/swagger go get github.com/swaggo/files 并在你的代码中引用如下代码:\nimport \"github.com/hertz-contrib/swagger\" // hertz-swagger middleware import \"github.com/swaggo/files\" // swagger embed files 示例代码 现在假设你已经实现了一个简单的 api，如下所示：\nfunc PingHandler(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]string{ \"ping\": \"pong\", }) } 那么如何在 api 上面使用 hertz-swagger？只要按照下面的步骤即可。\n 使用 hertz-swagger 规则为 api 和主函数添加注释，如下所示：  // PingHandler 测试handler // @Summary 测试Summary // @Description 测试Description // @Accept application/json // @Produce application/json // @Router /ping [get] func PingHandler(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]string{ \"ping\": \"pong\", }) }  使用 swag init 命令来生成文档，生成的文档将被存储在docs/目录下。\n  将生成的 docs 包导入当前项目中:\n假设你的项目名为 github.com/go-project-name/docs。\n  import ( docs \"github.com/go-project-name/docs\" )  编译运行你的应用程序，之后在 http://localhost:8888/swagger/index.html，可以看到 Swagger UI 界面。\n  完整的代码和文件依赖关系，如下所示:\n  package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/swagger\" _ \"github.com/hertz-contrib/swagger/example/basic/docs\" swaggerFiles \"github.com/swaggo/files\" ) // PingHandler 测试handler // @Summary 测试Summary // @Description 测试Description // @Accept application/json // @Produce application/json // @Router /ping [get] func PingHandler(c context.Context, ctx *app.RequestContext) { ctx.JSON(200, map[string]string{ \"ping\": \"pong\", }) } // @title HertzTest // @version 1.0 // @description This is a demo using Hertz.  // @contact.name hertz-contrib // @contact.url https://github.com/hertz-contrib  // @license.name Apache 2.0 // @license.url http://www.apache.org/licenses/LICENSE-2.0.html  // @host localhost:8888 // @BasePath / // @schemes http func main() { h := server.Default() h.GET(\"/ping\", PingHandler) url := swagger.URL(\"http://localhost:8888/swagger/doc.json\") // The url pointing to API definition \th.GET(\"/swagger/*any\", swagger.WrapHandler(swaggerFiles.Handler, url)) h.Spin() } 样例的项目目录结构树如下， swag init 运行在相对的目录 . 下。\n. ├── docs │ ├── docs.go │ ├── swagger.json │ └── swagger.yaml ├── go.mod ├── go.sum └── main.go 支持多个API 这个功能是在 swag v1.7.9 中引入的。\n配置 你可以使用不同的配置选项来配置 Swagger。\nfunc main() { h := server.Default() h.GET(\"/ping\", PingHandler) url := swagger.URL(\"http://localhost:8888/swagger/doc.json\") // The url pointing to API definition \th.GET(\"/swagger/*any\", swagger.WrapHandler(swaggerFiles.Handler, url, swagger.DefaultModelsExpandDepth(-1))) h.Spin() }    选项 类型 默认值 描述     URL string “doc.json” 指向 API 定义的 URL   DocExpansion string “list” 控制操作和标签的默认扩展设置。它可以是 list（只展开标签）、full（展开标签和操作）或 none（不展开）。   DeepLinking bool true 如果设置为 true，可以启用标签和操作的深度链接。更多信息请参见深度链接文档。   DefaultModelsExpandDepth int 1 模型的默认扩展深度（设置为-1完全隐藏模型）。   PersistAuthorization bool false 如果设置为 true，则会持久化保存授权数据，在浏览器关闭/刷新时不会丢失。   Oauth2DefaultClientID string \"\" 如果设置了这个字段，它将用于预填 OAuth2 授权对话框的 client_id 字段。    ","categories":"","description":"","excerpt":"这是一个用 Swagger 2.0 来自动生成 RESTful API 文档的 Hertz 中间件。\n参考了 gin 的实现，对 Hertz …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/swagger/","tags":"","title":"Swagger"},{"body":"xDS is a set of discovery services, with the full name of “X Discovery Service”, in which “X” refers to different type of discovery services, including LDS (Listener), RDS (RouteConfiguration), CDS (Cluster), and EDS (Endpoint/ClusterLoadAssignment), etc. xDS API enables the date-plane to communicate with the control plane (i.e. Istio) and perform discovery of dynamic service configuration resource.\nKitex supports xDS API via the extension of kitex-contrib/xds, which enables Kitex to perform in Proxyless mode. For more details of the design, please refer to the proposal.\nFeature  Service Discovery Traffic Route: only support exact match for header and method  HTTP route configuration: configure via VirtualService. ThriftProxy: configure via patching EnvoyFilter.   Timeout:  Configuration inside HTTP route configuration: configure via VirtualService.    Usage There are two steps for enabling xDS for Kitex applications: 1. xDS module initialization and 2. Kitex Client/Server Option configuration.\nxDS module To enable xDS mode in Kitex, we should invoke xds.Init() to initialize the xds module, including the xdsResourceManager and xdsClient.\nBootstrap The xdsClient is responsible for the interaction with the xDS Server (i.e. Istio). It needs some environment variables for initialization, which need to be set inside the spec.containers.env of the Kubernetes Manifest file in YAML format.\n POD_NAMESPACE: the namespace of the current service. POD_NAME: the name of this pod. INSTANCE_IP: the ip of this pod.  Add the following part to the definition of your container that uses xDS-enabled Kitex client.\n- name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: INSTANCE_IP valueFrom: fieldRef: fieldPath: status.podIP Client-side For now, we only provide the support on the client-side. To use a xds-enabled Kitex client, you should specify destService using the URL of your target service and add one option WithXDSSuite.\n Construct a xds.ClientSuite that includes RouteMiddleware and Resolver, and then pass it into the WithXDSSuite option.  // import \"github.com/cloudwego/kitex/pkg/xds\" client.WithXDSSuite(xds.ClientSuite{ RouterMiddleware: xdssuite.NewXDSRouterMiddleware(), Resolver: xdssuite.NewXDSResolver(), }),  The URL of the target service should be in the format, which follows the format in Kubernetes:  \u003cservice-name\u003e.\u003cnamespace\u003e.svc.cluster.local:\u003cservice-port\u003e Traffic route based on Tag Match We can define traffic route configuration via VirtualService in Istio.\nThe following example indicates that when the tag contains {\"stage\":\"canary\"} in the header, the request will be routed to the v1 subcluster of kitex-server.\napiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: kitex-server spec: hosts: - kitex-server http: - name: \"route-based-on-tags\" match: - headers: stage: exact: \"canary\" route: - destination: host: kitex-server subset: v1 weight: 100 timeout: 0.5s To match the rule defined in VirtualService, we can use client.WithTag(key, val string) or callopt.WithTag(key, val string)to specify the tags, which will be used to match the rules.\n Set key and value to be “stage” and “canary” to match the above rule defined in VirtualService.  client.WithTag(\"stage\", \"canary\") callopt.WithTag(\"stage\", \"canary\") Traffic route based on Method Match Same as above, using VirtualService in Istio to define traffic routing configuration.\nThe example below shows that requests with method equal to SayHello are routed to the v1 subcluster of kitex-server. It should be noted that when defining rules, you need to include package name and service name, corresponding to namespace and service in thrift idl.\n uri: /${PackageName}.${ServiceName}/${MethodName}  apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: kitex-server spec: hosts: - kitex-server http: - name: \"route-based-on-path\" match: - uri: # /${PackageName}.${ServiceName}/${MethodName} exact: /proxyless.GreetService/SayHello route: - destination: host: kitex-server subset: v2 weight: 100 timeout: 0.5s Example The usage is as follows:\nimport ( \"github.com/cloudwego/kitex/client\" xds2 \"github.com/cloudwego/kitex/pkg/xds\" \"github.com/kitex-contrib/xds\" \"github.com/kitex-contrib/xds/xdssuite\" \"github.com/cloudwego/kitex-proxyless-test/service/codec/thrift/kitex_gen/proxyless/greetservice\" ) func main() { // initialize xds module err := xds.Init() if err != nil { return } // initialize the client cli, err := greetservice.NewClient( destService, client.WithXDSSuite(xds2.ClientSuite{ RouterMiddleware: xdssuite.NewXDSRouterMiddleware(), Resolver: xdssuite.NewXDSResolver(), }), ) req := \u0026proxyless.HelloRequest{Message: \"Hello!\"} resp, err := c.cli.SayHello1( ctx, req, ) } Detailed examples can be found here kitex-proxyless-example.\nLimitation mTLS mTLS is not supported for now. Please disable mTLS via configuring PeerAuthentication.\napiVersion: \"security.istio.io/v1beta1\" kind: \"PeerAuthentication\" metadata: name: \"default\" namespace: {your_namespace} spec: mtls: mode: DISABLE Limited support for Service Governance Current version only support Service Discovery, Traffic route and Timeout Configuration via xDS on the client-side.\nOther features supported via xDS, including Load Balancing, Rate Limit and Retry etc., will be added in the future.\nDependencies Kitex \u003e= v0.4.0\n","categories":"","description":"Kitex supports the xDS protocol and runs in Proxyless mode, managed by the service mesh in unify.","excerpt":"Kitex supports the xDS protocol and runs in Proxyless mode, managed by …","ref":"/docs/kitex/tutorials/advanced-feature/xds/","tags":"","title":"xDS Support"},{"body":"xDS 是一组发现服务的总称，全称为 “X Discovery Service”，其中的 “X” 代指多种发现服务，包含 LDS (Listener), RDS (RouteConfiguration), CDS (Cluster), 和 EDS (Endpoint/ClusterLoadAssignment) 等。 数据面可以利用 xDS API 与控制平面（如 Istio）通信，完成配置信息的动态发现。\nKitex 通过外部扩展 kitex-contrib/xds 的形式对 xDS API 进行了支持，可通过代码配置开启 xDS 模块，让 Kitex 服务以 Proxyless 的模式运行，被服务网格统一纳管。具体的设计方案参见 proposal。\n已支持的功能  服务发现 服务路由：当前仅支持 header 与 method 的精确匹配。  HTTP route configuration: 通过 VirtualService 进行配置 ThriftProxy: 通过 EnvoyFilter 进行配置。   超时:  HTTP route configuration 内包含的配置，同样通过 VirtualService 来配置。    开启方式 开启的步骤分为两个部分：1. xDS 模块的初始化和 2. Kitex Client/Server 的 Option 配置。\nxDS 模块 调用 xds.Init() 便可开启对 xDS 模块的初始化，其中包括 xdsResourceManager - 负责 xDS 资源的管理，xdsClient - 负责与控制面进行交互。\nBootstrap xdsClient 负责与控制面（例如 Istio）交互，以获得所需的 xDS 资源。在初始化时，需要读取环境变量用于构建 node 标识。所以，需要在 K8S 的容器配置文件 spec.containers.env 部分加入以下几个环境变量。\n POD_NAMESPACE: 当前 pod 所在的 namespace。 POD_NAME: pod 名。 INSTANCE_IP: pod 的 ip。  在需要使用 xDS 功能的容器配置中加入以下定义即可：\n- name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: INSTANCE_IP valueFrom: fieldRef: fieldPath: status.podIP Kitex 客户端 目前，我们仅在 Kitex 客户端提供 xDS 的支持。 想要使用支持 xds 的 Kitex 客户端，请在构造 Kitex Client 时将 destService 指定为目标服务的 URL，并添加一个选项 WithXDSSuite。\n 构造一个 xds.ClientSuite，需要包含用于服务路由的RouteMiddleware中间件和用于服务发现的 Resolver。将该 ClientSuite 传入WithXDSSuite option 中.  // import \"github.com/cloudwego/kitex/pkg/xds\" client.WithXDSSuite(xds.ClientSuite{ RouterMiddleware: xdssuite.NewXDSRouterMiddleware(), Resolver: xdssuite.NewXDSResolver(), }),  目标服务的 URL 格式应遵循 Kubernetes 中的格式：  \u003cservice-name\u003e.\u003cnamespace\u003e.svc.cluster.local:\u003cservice-port\u003e 基于 tag 匹配的路由匹配 我们可以通过 Istio 中的 VirtualService 来定义流量路由配置。\n下面的例子表示 header 内包含 {\"stage\":\"canary\"} 的 tag 时，则将请求路由到 kitex-server 的 v1 子集群。\napiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: kitex-server spec: hosts: - kitex-server http: - name: \"route-based-on-tags\" match: - headers: stage: exact: \"canary\" route: - destination: host: kitex-server subset: v1 weight: 100 timeout: 0.5s 为了匹配 VirtualService 中定义的规则，我们可以使用client.WithTag(key, val string)或者callopt.WithTag(key, val string)来指定标签，这些标签将用于匹配规则。\n 比如：将 key 和 value 设置为“stage”和“canary”，以匹配 VirtualService 中定义的上述规则。  client.WithTag(\"stage\", \"canary\") callopt.WithTag(\"stage\", \"canary\") 基于 method 的路由匹配 同上，利用 Istio 中的 VirtualService 来定义流量路由配置。\n下面的例子表示，对于 method 等于 SayHello 的请求，路由到 kitex-server 的 v1 子集群。 需要注意的是，在定义规则时需要包含 package name 和 service name，对应 thrift idl 内的 namespace 和 service。\n uri: /${PackageName}.${ServiceName}/${MethodName}  apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: kitex-server spec: hosts: - kitex-server http: - name: \"route-based-on-path\" match: - uri: # /${PackageName}.${ServiceName}/${MethodName} exact: /proxyless.GreetService/SayHello route: - destination: host: kitex-server subset: v2 weight: 100 timeout: 0.5s 示例 完整的客户端用法如下:\nimport ( \"github.com/cloudwego/kitex/client\" xds2 \"github.com/cloudwego/kitex/pkg/xds\" \"github.com/kitex-contrib/xds\" \"github.com/kitex-contrib/xds/xdssuite\" \"github.com/cloudwego/kitex-proxyless-test/service/codec/thrift/kitex_gen/proxyless/greetservice\" ) func main() { // initialize xds module err := xds.Init() if err != nil { return } // initialize the client cli, err := greetservice.NewClient( destService, client.WithXDSSuite(xds2.ClientSuite{ RouterMiddleware: xdssuite.NewXDSRouterMiddleware(), Resolver: xdssuite.NewXDSResolver(), }), ) req := \u0026proxyless.HelloRequest{Message: \"Hello!\"} resp, err := c.cli.SayHello1( ctx, req, ) } 更详细的例子可以参考该仓库：kitex-proxyless-example.\n当前版本的不足 mTLS 目前不支持 mTLS。 请通过配置 PeerAuthentication 以禁用 mTLS。\napiVersion: \"security.istio.io/v1beta1\" kind: \"PeerAuthentication\" metadata: name: \"default\" namespace: {your_namespace} spec: mtls: mode: DISABLE 有限的服务治理功能 当前版本仅支持客户端通过 xDS 进行服务发现、流量路由和超时配置。\nxDS 所支持的其他服务治理功能，包括负载均衡、限流和重试等，将在未来补齐。\n依赖 Kitex \u003e= v0.4.0\n","categories":"","description":"Kitex 支持 xDS 协议进而以 Proxyless 模式运行，被服务网格统一纳管。","excerpt":"Kitex 支持 xDS 协议进而以 Proxyless 模式运行，被服务网格统一纳管。","ref":"/zh/docs/kitex/tutorials/advanced-feature/xds/","tags":"","title":"xDS 支持"},{"body":"会议主题 ：CloudWeGo 社区会议 6.16\n参会人 ：YangruiEmma, joway, yccpt, CoderPoet, GuangmingLuo, simon0-o, yiyun, bodhisatan, Jacob953, cyyolo, HeyJavaBean, Skyenought, Quan Hu, ppzqh, ZhangHanAA, Suo Dianjun, Yin Xuran\n会前必读 ：http://www.cloudwego.io/；https://github.com/cloudwego\n议程 1 ：Hertz 项目介绍 @Yin Xuran  项目地址： https://github.com/cloudwego/hertz/blob/develop/README_cn.md 项目背景： Hertz 之前，字节跳动内部使用的 HTTP 框架是基于 Gin 进行了一层封装。存在的问题：Gin 出现 Bug 无法修复；难以迭代支持一些 Feature；随着业务发展性能不足逐渐显现，且难以改变。 Hertz 定位 ：   超大规模企业级实现，拥有极强的稳定性。 微服务框架。完善 CloudWeGo 的生态矩阵，让 CloudWeGo 成为云原生最佳的解决方案之一，从而向客户推广。 开箱即用的框架。包括比如搭积木的能力，用户可以按需组装模块；可能会生成一些 Client 代码，可以方便用户 Benchmark 或者帮助用户去调试，甚至生成一些生产上的代码。 “三高”的框架。高扩展性、高易用性和高性能。  内部使用情况： 是内部最大的 HTTP 框架，在内部线上有 1w+ 的服务峰值，QPS 4000w+。某些典型服务迁移 Hertz 后，相比 Gin 框架，CPU 使用率降低 30%—60%。 Roadmap：   无缝接入微服务体系。支持 xDS API，从 Istio 动态获取服务配置。 有更完善的生态。如 CORS、Trace、Metrics 、反向代理、Session 等。 支持多协议。Hertz 目前只开源了 HTTP1 的部分，未来还会开源其他协议，如：HTTP2、Websocket、ALPN 等。 更高的性能。结合用户需求，持续迭代。  6.21 官宣后会开放新手任务，以及社区参与指南，欢迎大家参与 Hertz 社区贡献。   议程 2 ：Hertz Swagger \u0026 JWT Middleware @bodhisatan  项目地址：https://github.com/hertz-contrib/swagger；https://github.com/hertz-contrib/jwt 贡献了 Hertz 的两个插件，Swagger 和 JWT。Fork 了 Gin 排名比较高的对应的仓库，然后对赫兹做适配，争取让开发者比较方便的从 Gin 切换到 Hertz。过程中需要看一些赫兹的接口源码，保证 Hertz 和 Gin 的表现相同。 对 Hertz 源码感兴趣的初学者可以从这里入手，建议社区也可以考虑把一些 Gin 里面常见的中间件以 First-good-issue 的形式开放。   议程 3：CloudWeGo “全新”社区页面介绍 @Skyenought @yiyun  地址：https://www.cloudwego.io/zh/community/ 参考 Google Kubernetes 社区实现，从社区获得相应的图片和文字描述，进行组合。目前上线了中文页面，后续根据社区要求进行改动，比如不定时更新的近期活动可以拆成模板，方便更新。   议程 4：CCF 活动进展同步 \u0026 CloudWeGo Meetup 预告 @yiyun  目前已经有 126 个同学加入社区，竞争 5 个 Issue。同学反馈问题是给到高校群体的开发任务量比较少，因此 Hertz 开源建设中，后续会开放出大量的新手任务，如小型的开发任务、文档类的整理任务、活动类任务等。 已有近 26 位同学参与 Issue 选拔。后续也会有社区的导师持续地跟进开发，11 月底活动结束。   议程 5：Q \u0026 A Q：社区 Committer 的申请要求是什么？\nA：相关链接：https://github.com/cloudwego/community/blob/main/COMMUNITY_MEMBERSHIP.md\n对社区有贡献的同学可以在 Issue 上面提出申请，相关人员会确认是否同意这个同学成为 Committer。一般来讲贡献比较多的同学会被提名，然后让这个同学自己在 Issue 上面申请。当然，如果同学个人觉得自己贡献比较多，也可以自己提名。如果大家同意会在下面回复，同意的人数足够多就可以加入。\n 相关资讯： 6 月 21 日，Hertz 正式官宣开源！ 官宣链接：https://mp.weixin.qq.com/s/D1Pol8L9F_5-Yte_k4DH8A\n技术解读：https://mp.weixin.qq.com/s/RC-BJOTEO7WaEemG96yR6w\n5 月 26 日 — 6 月 24 日，CloudWeGo - GLCC 开源编程夏令营开始报名，活动报名链接：https://mp.weixin.qq.com/s/owd13tN5XfKPQs7DeONWng\n6 月 25 日，CloudWeGo \u0026 稀土掘金 Meetup 活动直播，邀请到来自字节跳动、森马电商和华兴证券的资深开发者，向社区分享 CloudWeGo 的最新企业落地实践。 活动链接：https://mp.weixin.qq.com/s/D93dk-9dw2pQocI4anBXfg\n","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 6.16\n参会人 ：YangruiEmma, joway, yccpt, CoderPoet, …","ref":"/zh/community/meeting_notes/2022-06-16/","tags":"","title":"CloudWeGo 社区会议 6.16"},{"body":"Hertz supports graceful shutdown, which is executed as follows：\n Set the state of engine to closed Sequential non-blocking trigger callback function []OnShutDown (consistent with standard library net/http), Select waits them until wait timeout or finish Select waits for the business coroutine to exit：  For netpoll network library, turn on ticker with default 1s (set in netpoll, not changeable at the moment) and check if active conn (business handle exits and connection is not in blocking read state) is 0 at regular intervals; for go net network library, turn off listening and do not process the connection. Triggered by the context of ExitWaitTime, default 5s   Uniformly add Connection:Close header to request packets in the process of closing Registration Center deregisters this service. Shut down the signal listening of the network library  If you want to modify the wait timeout, you can configure it with server.WithExitWaitTime().\nIf you want to register the hook function, you can do so by getting the Engine and registering it:\nh.Engine.OnShutdown = append(h.Engine.OnShutdown, shutDownFunc) waitSignal is default implementation for signal waiter,which is executed as follows:\n SIGTERM triggers immediately close. SIGHUP|SIGINT triggers graceful shutdown.  If Default one is not met the requirement, SetCustomSignalWaiter set this function to customize.\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" ) func main() { h := server.New() h.SetCustomSignalWaiter(func(err chan error) error { return nil }) ... } Hertz will exit immediately if f returns an error,otherwise it will exit gracefully.\n","categories":"","description":"","excerpt":"Hertz supports graceful shutdown, which is executed as follows：\n Set …","ref":"/docs/hertz/tutorials/basic-feature/graceful-shutdown/","tags":"","title":"Graceful Shutdown"},{"body":"Hertz 支持优雅退出，优雅退出过程如下：\n 设置 engine 状态为 closed 顺序非阻塞触发回调函数 []OnShutDown（与标准包 net/http 一致），Select 等待回调函数执行完成或者超时返回 Select 等待业务协程退出：  对于 netpoll 网络库，开启默认1s（netpoll 中设置，暂时不可更改）的 ticker，定时查看 active conn（业务 handle 退出且连接不处于阻塞读状态）是否为0；对于 go net 网络库，则关闭监听，不对连接做处理。 等待超时时间为 ExitWaitTime 的 context 触发，默认 5s   注册中心注销对应服务 关闭网络库的信号监听 对处于关闭过程中的请求回包统一带上 Connection:Close header  如需修改等待超时时间，可通过 server.WithExitWaitTime() 进行配置。\n如需注册退出 hook 函数，可通过获取到 Engine 后进行注册:\nh.Engine.OnShutdown = append(h.Engine.OnShutdown, shutDownFunc) Hertz 使用 waitSignal 函数作为信号处理的默认实现方式，处理如下:\n 当接收到 SIGTERM 系统信号时触发立即退出。 当接收到 SIGHUP|SIGINT 系统信号时触发优雅退出。  当信号处理的默认实现方式无法满足需求时，可通过 SetCustomSignalWaiter 来自定义信号处理方式。\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/server\" ) func main() { h := server.New() h.SetCustomSignalWaiter(func(err chan error) error { return nil }) ... } 当自定义信号处理函数返回 error 时 Hertz 会立即退出，其他情况下则会优雅退出。\n","categories":"","description":"","excerpt":"Hertz 支持优雅退出，优雅退出过程如下：\n 设置 engine 状态为 closed 顺序非阻塞触发回调函数 []OnShutDown（ …","ref":"/zh/docs/hertz/tutorials/basic-feature/graceful-shutdown/","tags":"","title":"优雅退出"},{"body":"Kitex supports extending protocols, including overall Codec and Payloadcodec. Generally, RPC protocol includes application layer transport protocol and payload protocol. For example, HTTP/HTTP2 belong to application layer transport protocol, payloads with different formats and protocols can be carried over HTTP/HTTP2.\nKitex supports built-in TTHeader as transport protocol, and supports Thrift, Kitex Protobuf, gRPC protocol as payload. In addition, Kitex integrates netpoll-http2 to support HTTP2. At present, it is mainly used for gRPC, Thrift over HTTP2 is considered to support in the future.\nThe definition of TTHeader transport protocol as follows, service information can be transparently transmitted through the TTHeader to do service governance.\n* TTHeader Protocol * +-------------2Byte--------------|-------------2Byte-------------+ * +----------------------------------------------------------------+ * | 0| LENGTH | * +----------------------------------------------------------------+ * | 0| HEADER MAGIC | FLAGS | * +----------------------------------------------------------------+ * | SEQUENCE NUMBER | * +----------------------------------------------------------------+ * | 0| Header Size(/32) | ... * +--------------------------------- * * Header is of variable size: * (and starts at offset 14) * * +----------------------------------------------------------------+ * | PROTOCOL ID |NUM TRANSFORMS . |TRANSFORM 0 ID (uint8)| * +----------------------------------------------------------------+ * | TRANSFORM 0 DATA ... * +----------------------------------------------------------------+ * | ... ... | * +----------------------------------------------------------------+ * | INFO 0 ID (uint8) | INFO 0 DATA ... * +----------------------------------------------------------------+ * | ... ... | * +----------------------------------------------------------------+ * | | * | PAYLOAD | * | | * +----------------------------------------------------------------+ Extension API of Codec Codec API is defined as follows:\n// Codec is the abstraction of the codec layer of Kitex. type Codec interface { Encode(ctx context.Context, msg Message, out ByteBuffer) error Decode(ctx context.Context, msg Message, in ByteBuffer) error Name() string } Codec is the overall codec interface, which is extended in combination with the transmission protocol and payload to be supported. The PayloadCodec interface is called according to the protocol type. Decode needs to detect the protocol to judge the transmission protocol and payload. Kitex provides defaultCodec extension implementation by default.\nExtension API of PayloadCodec PayloadCodec API is defined as follows:\n// PayloadCodec is used to marshal and unmarshal payload. type PayloadCodec interface { Marshal(ctx context.Context, message Message, out ByteBuffer) error Unmarshal(ctx context.Context, message Message, in ByteBuffer) error Name() string } By default, the payload supported by Kitex includes Thrift, Kitex Protobuf and gRPC protocols. Kitex Protobuf is the message protocol based Protobuf, the protocol definition is similar to Thrift message.\nIn particular, generic call of Kitex is also implemented by extending payloadcodec:\nDefault Codec Usage Kitex will use the built-in Codec if no customized codec provider set.\n Set default codec size limit, no limit by default option: codec.NewDefaultCodecWithSizeLimit  maxSizeBytes = 1024 * 1024 * 10 // 10 MB  // server side svr := xxxservice.NewServer(handler, server.WithCodec(codec.NewDefaultCodecWithSizeLimit(maxSizeBytes))) // client side cli, err := xxxservice.NewClient(targetService, client.WithCodec(codec.NewDefaultCodecWithSizeLimit(maxSizeBytes))) Customized Codec or PayloadCodec Usage Specify customized Codec and PayloadCodec through option.\n Specify Codec option: WithCodec  // server side svr := xxxservice.NewServer(handler, server.WithCodec(yourCodec)) // client side cli, err := xxxservice.NewClient(targetService, client.WithCodec(yourCodec))  Specify PayloadCodec option: WithPayloadCodec  // server side svr := xxxservice.NewServer(handler, server.WitWithPayloadCodechCodec(yourPayloadCodec)) // client side cli, err := xxxservice.NewClient(targetService, client.WithPayloadCodec(yourPayloadCodec)) ","categories":"","description":"","excerpt":"Kitex supports extending protocols, including overall Codec and …","ref":"/docs/kitex/tutorials/framework-exten/codec/","tags":"","title":"Extension of Codec"},{"body":"Kitex provides 3 LoadBalancers officially:\n WeightedRoundRobin WeightedRandom ConsistentHash  Kitex uses WeightedRoundRobin by default.\nWeightedRoundRobin WeightedRoundRobin uses a round-robin strategy based on weights, which is also Kitex’s default strategy.\nThis LoadBalancer will make all instances have the min inflight requests to reduce the overload of instance.\nIf all instances have the same weights, it will use a pure round-robin implementation to avoid extra overhead of weighting calculations.\nWeightedRandom WeightedRandom uses a random strategy.\nThis LoadBalancer will be weighted randomly according to the weight of the instance, and ensure that the load assigned to each instance is proportional to its own weight.\nIf all instances have the same weights, it uses a purely random implementation to avoid extra overhead of weighting calculations.\nConsistentHash Introduction Consistent hashing is mainly suitable for scenarios with high dependence on context (such as instance local cache). If you want the same type of request to hit the same endpoint, you can use this load balancing method.\nIf you don’t know what a consistent hash is, or don’t know the side effects, DO NOT use a consistent hash.\nUsage If you want to use a consistent hash, you can pass the parameter with client.WithLoadBalancer(loadbalance.NewConsistBalancer(loadbalance.NewConsistentHashOption(keyFunc))) when initializing the client.\nConsistentHashOption is defined as follows:\ntype ConsistentHashOption struct { GetKey KeyFunc // Whether or not to use Replica  // If replica is set, it would be tried in turn when the request fails (connection failure)  // Replica brings additional memory and computational overhead  // If replica is not set, then the request returns directly after failure (connection failure)  Replica uint32 // Number of virtual nodes  // The number of virtual nodes corresponding to each real node  // The higher the value, the higher the memory and computational cost, and the more balanced the load  // When the number of nodes is large, it can be set smaller; conversely, it can be set larger  // It is recommended that the median VirtualFactor * Weight (if Weighted is true) is around 1000, and the load should be well balanced  // Recommended total number of virtual nodes within 2000W (it takes 250ms to build once under 1000W, but it is theoretically fine to build in the background within 3s)  VirtualFactor uint32 // Whether to follow Weight for load balancing  // If false, Weight is ignored for each instance, and VirtualFactor virtual nodes are generated for indiscriminate load balancing  // Weight() * VirtualFactor virtual nodes for each instance  // Note that for instance with weight 0, no virtual nodes will be generated regardless of the VirtualFactor number  // It is recommended to set it to true, but be careful to reduce the VirtualFactor appropriately  Weighted bool // Whether or not to perform expiration processing  // Implementation will cache all keys  // Never expiring will cause memory to keep growing  // Setting expiration will result in additional performance overhead  // Current implementations scan for deletions every minute and delete once when the instance changes rebuild  // It is recommended to always set the value not less than one minute  ExpireDuration time.Duration } Note that if GetKey is nil or VirtualFactor is 0, panic will occur.\nPerformance After testing, with a weight of 10 and a VirtualFactor of 100, the build performance of different instances is as follows:\nBenchmarkNewConsistPicker_NoCache/10ins-16 6565 160670 ns/op 164750 B/op 5 allocs/op BenchmarkNewConsistPicker_NoCache/100ins-16 571 1914666 ns/op 1611803 B/op 6 allocs/op BenchmarkNewConsistPicker_NoCache/1000ins-16 45 23485916 ns/op 16067720 B/op 10 allocs/op BenchmarkNewConsistPicker_NoCache/10000ins-16 4 251160920 ns/op 160405632 B/op 41 allocs/op Therefore, when there are 10,000 instances, each instance weight is 10, and the VirtualFactor is 100 (the total number of virtual nodes is 10,000,000), it takes 251 ms to build once.\nBoth build and request information are cached, so the latency of a normal request (no build is required) has nothing to do with the number of nodes:\nBenchmarkNewConsistPicker/10ins-16 12557137 81.1 ns/op 0 B/op 0 allocs/op BenchmarkNewConsistPicker/100ins-16 13704381 82.3 ns/op 0 B/op 0 allocs/op BenchmarkNewConsistPicker/1000ins-16 14418103 81.3 ns/op 0 B/op 0 allocs/op BenchmarkNewConsistPicker/10000ins-16 13942186 81.0 ns/op 0 B/op 0 allocs/op Note  When the target node changes, the consistent hash result may change, and some keys may change; If there are too many target nodes, the build time may be longer during the first cold start, and if the rpc timeout is short, it could cause a timeout; If the first request fails and Replica is larger than 0, the try will hit the Replica, so the second and subsequent requests will still be sent to the first instance.  The degree of load balance As tested, when the number of target instances is 10, if the VirtualFactor is set to 1 and Weighted is not turned on, the load is very uneven, as follows:\naddr2: 28629 addr7: 13489 addr3: 10469 addr9: 4554 addr0: 21550 addr6: 6516 addr8: 2354 addr4: 9413 addr5: 1793 addr1: 1233 When VirtualFactor is set to 10, the load is as follows:\naddr7: 14426 addr8: 12469 addr3: 8115 addr4: 8165 addr0: 8587 addr1: 7193 addr6: 10512 addr9: 14054 addr2: 9307 addr5: 7172 It can be seen that it is much better than when the VirtualFactor is 1.\nWhen the VirtualFactor is 1000, the load is as follows:\naddr7: 9697 addr5: 9933 addr6: 9955 addr4: 10361 addr8: 9828 addr0: 9729 addr9: 10528 addr2: 10121 addr3: 9888 addr1: 9960 Load is basically balanced at this time.\nLet’s take the situation with Weight. We set the weight of addr0 to 0, the weight of addr1 to 1, the weight of addr2 to 2… and so on.\nSet VirtualFactor to 1000 and get the load result as follows:\naddr4: 8839 addr3: 6624 addr6: 13250 addr1: 2318 addr8: 17769 addr2: 4321 addr5: 11099 addr9: 20065 addr7: 15715 You could see that it is basically consistent with the distribution of weight. There is no addr0 here because weight is 0 and will not be scheduled.\nIn summary, increase VirtualFactor can make the load more balanced, but it will also increase the performance overhead, so you need to make trade-offs.\n","categories":"","description":"This doc covers LoadBalancer implementation principles and usage guidelines provided by Kitex.","excerpt":"This doc covers LoadBalancer implementation principles and usage …","ref":"/docs/kitex/tutorials/basic-feature/loadbalance/","tags":"","title":"LoadBalancer"},{"body":"Kitex 支持扩展协议，包括整体的 Codec 和 PayloadCodec。通常 RPC 协议中包含应用层传输协议和 Payload 协议，如 HTTP/HTTP2 属于应用层传输协议，基于 HTTP/HTTP2 可以承载不同格式和不同协议的 Payload。\nKitex 默认支持内置的 TTHeader 传输协议，Payload 支持 Thrift、KitexProtobuf、gRPC。另外，Kitex 集成 netpoll-http2 支持 HTTP2，目前主要用于 gRPC，后续会考虑基于 HTTP2 支持 Thrift。\nTTHeader 协议定义如下，通过 TTHeader 可以透传服务信息，便于服务治理。\n* TTHeader Protocol * +-------------2Byte--------------|-------------2Byte-------------+ * +----------------------------------------------------------------+ * | 0| LENGTH | * +----------------------------------------------------------------+ * | 0| HEADER MAGIC | FLAGS | * +----------------------------------------------------------------+ * | SEQUENCE NUMBER | * +----------------------------------------------------------------+ * | 0| Header Size(/32) | ... * +--------------------------------- * * Header is of variable size: * (and starts at offset 14) * * +----------------------------------------------------------------+ * | PROTOCOL ID |NUM TRANSFORMS . |TRANSFORM 0 ID (uint8)| * +----------------------------------------------------------------+ * | TRANSFORM 0 DATA ... * +----------------------------------------------------------------+ * | ... ... | * +----------------------------------------------------------------+ * | INFO 0 ID (uint8) | INFO 0 DATA ... * +----------------------------------------------------------------+ * | ... ... | * +----------------------------------------------------------------+ * | | * | PAYLOAD | * | | * +----------------------------------------------------------------+ Codec 定义 Codec 接口定义如下：\n// Codec is the abstraction of the codec layer of Kitex. type Codec interface { Encode(ctx context.Context, msg Message, out ByteBuffer) error Decode(ctx context.Context, msg Message, in ByteBuffer) error Name() string } Codec 是整体的编解码接口，结合需要支持的传输协议和 Payload 进行扩展，根据协议类型调用 PayloadCodec 接口，其中 Decode 需要进行协议探测判断传输协议和 Payload。Kitex 默认提供 defaultCodec 扩展实现。\nPayloadCodec 定义 PayloadCodec 接口定义如下：\n// PayloadCodec is used to marshal and unmarshal payload. type PayloadCodec interface { Marshal(ctx context.Context, message Message, out ByteBuffer) error Unmarshal(ctx context.Context, message Message, in ByteBuffer) error Name() string } Kitex 默认支持的 Payload 有 Thrift、Kitex Protobuf 以及 gRPC 协议。其中 Kitex Protobuf 是 Kitex 基于 Protobuf 定义的消息协议，协议定义与 Thrift Message 类似。\n特别地，Kitex 的泛化调用也是通过扩展 PayloadCodec 实现：\n默认的 Codec 如果用户不指定 Codec，则使用默认的内置 Codec。\n 指定默认 Codec 的包大小限制，默认无限制 option: codec.NewDefaultCodecWithSizeLimit  maxSizeBytes = 1024 * 1024 * 10 // 10 MB  // server side svr := xxxservice.NewServer(handler, server.WithCodec(codec.NewDefaultCodecWithSizeLimit(maxSizeBytes))) // client side cli, err := xxxservice.NewClient(targetService, client.WithCodec(codec.NewDefaultCodecWithSizeLimit(maxSizeBytes))) 指定自定义 Codec 和 PayloadCodec 通过 option 指定 Codec 和 PayloadCodec。\n 指定 Codec option: WithCodec  // server side svr := xxxservice.NewServer(handler, server.WithCodec(yourCodec)) // client side cli, err := xxxservice.NewClient(targetService, client.WithCodec(yourCodec))  指定 PayloadCodec option: WithPayloadCodec  // server side svr := xxxservice.NewServer(handler, server.WitWithPayloadCodechCodec(yourPayloadCodec)) // client side cli, err := xxxservice.NewClient(targetService, client.WithPayloadCodec(yourPayloadCodec)) ","categories":"","description":"","excerpt":"Kitex 支持扩展协议，包括整体的 Codec 和 PayloadCodec。通常 RPC 协议中包含应用层传输协议和 Payload 协 …","ref":"/zh/docs/kitex/tutorials/framework-exten/codec/","tags":"","title":"编解码 (协议) 扩展"},{"body":"Kitex 默认提供了 3 种 LoadBalancer：\n WeightedRoundRobin WeightedRandom ConsistentHash  Kitex 默认使用的是 WeightedRoundRobin。\nWeightedRoundRobin 该 LoadBalancer 使用的是基于权重的轮询策略，也是 Kitex 的默认策略。\n该 LoadBalancer 能让所有下游实例拥有最小的同时 inflight 请求数，以减少下游过载情况的发生。\n如果所有的实例的权重都一样，会使用一个纯轮询的实现，来避免加权计算的一些额外开销。\nWeightedRandom 顾名思义，这个 LoadBalancer 使用的是基于权重的随机策略。\n这个 LoadBalancer 会依据实例的权重进行加权随机，并保证每个实例分配到的负载和自己的权重成比例。\n如果所有的实例的权重都一样，会使用一个纯随机的实现，来避免加权计算的一些额外开销。\nConsistentHash 简介 一致性哈希主要适用于对上下文（如实例本地缓存）依赖程度高的场景，如希望同一个类型的请求打到同一台机器，则可使用该负载均衡方法。\n如果你不了解什么是一致性哈希，或者不知道带来的副作用，请勿使用一致性哈希。\n使用 如果要使用一致性哈希，可以在初始化 client 的时候传入 client.WithLoadBalancer(loadbalance.NewConsistBalancer(loadbalance.NewConsistentHashOption(keyFunc)))。\nConsistentHashOption 定义如下：\ntype ConsistentHashOption struct { GetKey KeyFunc // 是否使用 replica  // 如果使用，当请求失败（连接失败）后会依次尝试 replica  // 会带来额外内存和计算开销  // 如果不设置，那么请求失败（连接失败）后直接返回  Replica uint32 // 虚拟节点数  // 每个真实节点对应的虚拟节点的数量  // 这个数值越大，内存和计算代价越大，负载越均衡  // 当节点数多时，可以适当设小一些；反之可以适当设大一些  // 推荐 VirtualFactor * Weight（如果 Weighted 为 true）的中位数在 1000 左右，负载应当已经很均衡了  // 推荐 总虚拟节点数 在 2000W 以内（1000W 情况之下 build 一次需要 250ms，不过为后台 build 理论上 3s 内均无问题）  VirtualFactor uint32 // 是否要遵循 Weight 进行负载均衡  // 如果为 false，对于每个 instance 都会忽略 Weight，均生成 VirtualFactor 个虚拟节点，进行无差别负载均衡  // 如果为 true，对于每个 instance 会生成 instance.Weight() * VirtualFactor 个虚拟节点  // 需要注意，对于 weight 为 0 的 instance，无论 VirtualFactor 为多少，均不会生成虚拟节点  // 建议设为 true，不过要注意适当调小 VirtualFactor  Weighted bool // 是否进行过期处理  // 实现会缓存所有的 Key  // 如果永不过期会导致内存一直增长  // 设置过期会导致额外性能开销  // 目前的实现是每分钟扫描删除一次，以及实例发生变动 rebuild 时删除一次  // 建议一定要设置，值不要小于一分钟  ExpireDuration time.Duration } 要注意，如果 GetKey 是 nil 或者 VirtualFactor 是 0，会 panic。\n性能 经过测试，在 weight 为 10、VirtualFactor 为 100 的情况之下，不同 instance 数量的 build 性能如下：\nBenchmarkNewConsistPicker_NoCache/10ins-16 6565 160670 ns/op 164750 B/op 5 allocs/op BenchmarkNewConsistPicker_NoCache/100ins-16 571 1914666 ns/op 1611803 B/op 6 allocs/op BenchmarkNewConsistPicker_NoCache/1000ins-16 45 23485916 ns/op 16067720 B/op 10 allocs/op BenchmarkNewConsistPicker_NoCache/10000ins-16 4 251160920 ns/op 160405632 B/op 41 allocs/op 所以当有 10000 个 instance，每个 instance weight 为 10，VirtualFactor 为 100 的情况之下（总虚拟节点数 1000W），build 一次需要 251 ms。\nbuild 和 请求 信息都会被缓存，所以一次正常请求（不需要 build）的时延和节点多少无关，如下：\nBenchmarkNewConsistPicker/10ins-16 12557137 81.1 ns/op 0 B/op 0 allocs/op BenchmarkNewConsistPicker/100ins-16 13704381 82.3 ns/op 0 B/op 0 allocs/op BenchmarkNewConsistPicker/1000ins-16 14418103 81.3 ns/op 0 B/op 0 allocs/op BenchmarkNewConsistPicker/10000ins-16 13942186 81.0 ns/op 0 B/op 0 allocs/op 注意事项  下游节点发生变动时，一致性哈希结果可能会改变，某些 key 可能会发生变化； 如果下游节点非常多，第一次冷启动时 build 时间可能会较长，如果 rpc 超时短的话可能会导致超时； 如果第一次请求失败，并且 Replica 不为 0，那么会请求到 Replica 上；而第二次及以后仍然会请求 第一个 实例。  负载的均衡度 经过测试，当下游实例为 10 个时，如果 VirtualFactor 设置为 1 并且不开启 Weighted 时，负载非常不均衡，如下：\naddr2: 28629 addr7: 13489 addr3: 10469 addr9: 4554 addr0: 21550 addr6: 6516 addr8: 2354 addr4: 9413 addr5: 1793 addr1: 1233 当 VirtualFactor 设置为 10 时，负载如下：\naddr7: 14426 addr8: 12469 addr3: 8115 addr4: 8165 addr0: 8587 addr1: 7193 addr6: 10512 addr9: 14054 addr2: 9307 addr5: 7172 可以看出比 VirtualFactor 为 1 时要好很多。\n当 VirtualFactor 为 1000 时，负载如下：\naddr7: 9697 addr5: 9933 addr6: 9955 addr4: 10361 addr8: 9828 addr0: 9729 addr9: 10528 addr2: 10121 addr3: 9888 addr1: 9960 可以看出此时负载基本均衡。\n再来看看带 Weight 的情况，我们设置 addr0 的 weight 为 0，addr1 的 weight 为 1，addr2 的 weight 为 2……以此类推。\n设置 VirtualFactor 为 1000，得到负载结果如下：\naddr4: 8839 addr3: 6624 addr6: 13250 addr1: 2318 addr8: 17769 addr2: 4321 addr5: 11099 addr9: 20065 addr7: 15715 可以看到基本是和 weight 的分布一致。在这里没有 addr0 是因为 weight 为 0 是不会被调度到的。\n综上，提高 VirtualFactor，可以使得负载更加均衡，但是也要注意会增加性能开销，需要找个平衡点。\n","categories":"","description":"Kitex 提供的负载均衡器实现原理和使用指南。","excerpt":"Kitex 提供的负载均衡器实现原理和使用指南。","ref":"/zh/docs/kitex/tutorials/basic-feature/loadbalance/","tags":"","title":"负载均衡"},{"body":"Note: There is additional performance overhead when enable profiler module, overhead cause by: background continuous pprof, and the processing functions written by users.\nHow it works Go provides the SetGoroutineLabels API that can set labels for a Goroutine, and all other Goroutines started in this Goroutine will inherit the labels.\nThe Go Pprof sampler will sample and count the currently running function stack every 10ms, and summarize the cost times of Goroutine Labels including each stack. We can analyze this result, group by labels and finally get the runtime cost of different request tags.\nKitex will create or reuse a Goroutine for each request, so as long as the labels are set for Goroutine at the beginning of the request process, the costs of business logic can be calculated on the labels.\nUsage Write Tagging functions We need to “color” the Goroutine and subsequent Goroutines according to Kitex request parameters.\nThe process of a request has two stages:\n Transport Stage: The stage where Kitex receives a complete binary packet. If it is the TTHeader protocol, we can quickly parse metadata information from the header without deserialization. Message Stage: The stage where Kitex deserializes the binary packet into a Request struct. The deserialization part tends to account for a large part of the overall overhead if the structure of the request is complex.  In our microservice governance practice, we recommend putting general information such as the source service name in the TTHeader, so that the Goroutine labels can be marked in advance without fully deserializing the request.\n If you need to collect tags from the transport layer, use: server.WithProfilerTransInfoTagging. If you need to collect tags from the message layer, use: server.WithProfilerMessageTagging.  Example:\n// example kitex_gen type Request struct { Message string `thrift:\"Message,1,required\" json:\"Message\"` Type int32 `thrift:\"Type,2,required\" json:\"Type\"` } // tagging logic var msgTagging remote.MessageTagging = func(ctx context.Context, msg remote.Message) (context.Context, []string) { if data := msg.Data(); data == nil { return ctx, nil } var tags = make([]string, 0, 2) var reqType int32 if args, ok := msg.Data().(ArgsGetter); ok { if req := args.GetReq(); req != nil { reqType = req.Type tags = append(tags, \"req_type\", strconv.Itoa(reqType)) } } // if you don't need to get the tags in other middlewares, no need to change ctx \treturn context.WithValue(ctx, \"ctxKeyReqType\", reqType), []string{\"req_type\", strconv.Itoa(reqType)} } // register tagging function svr := xxxserver.NewServer(server.WithProfilerMessageTagging(msgTagging)) Write Processor functions Kitex will periodically run callback functions with statistical results. If we have a metric system, we can upload results in the processor function.\nFor example, if we want to log the results:\nfunc LogProcessor(profiles []*profiler.TagsProfile) error { if len(profiles) == 0 { return nil } klog.Infof(\"KITEX: profiler collect %d records\", len(profiles)) for _, p := range profiles { klog.Infof(\"KITEX: profiler - %s %.2f%% %d\", p.Key, p.Percent*100, p.Value) } klog.Info(\"---------------------------------\") return nil } Setup profiler We can configure two settings for the profiler:\n interval: how many times should wait for a sample. If it is 0, it means cyclic sampling. If sampling takes up too much CPU, you can increase this setting to reduce sampling accuracy and costs. window: how long a sample should last. The longer the time, the more statistical data in a window, and the larger paused time when results aggregation calculation is performed. It is generally recommended that 10s-60s is the best.  interval, window := time.Duration(0), 30*time.Second pc := profiler.NewProfiler(LogProcessor, interval, window) svr := xxxserver.NewServer( new(ServerImpl), server.WithProfilerMessageTagging(msgTagging), server.WithProfiler(pc), ) ","categories":"","description":"Kitex Profiler provides request-level runtime cost statistic capability.","excerpt":"Kitex Profiler provides request-level runtime cost statistic …","ref":"/docs/kitex/tutorials/advanced-feature/profiler/","tags":"","title":"Request Profiler"},{"body":"注意：该模块的开启会产生额外的性能开销，包括：常驻后台 pprof 程序的运行开销，用户编写的处理函数开销。\n工作原理 Go 提供了 SetGoroutineLabels API 可以做到给一个 Goroutine 设置好 labels，这个 Goroutine 内启动的所有其他 Goroutine 都会继承这个 labels。\nGo Pprof 采样程序会每 10ms 进行一次当前正在运行的函数 Stack 采样计数，最后汇总出包含了每个 Stack 的 Goroutine Labels 的统计结果。我们可以分析这份结果，将之前设置的 labels 作为 tags 再进行聚合统计，最后得出不同 tags 组合分别占用的程序运行时开销。\nKitex 会对每一个请求都开启或重用一个 Goroutine，所以只要在请求开始的时候为 Goroutine 设置好 labels，后续业务逻辑同步异步的开销都能够被计算在该 labels 上。\n使用方法 编写请求 Tags 抽取函数 我们需要根据 Kitex Server 接受到的请求参数，对当前 Goroutine 以及后续的 Goroutine 进行“染色”。\nKitex 处理请求分为两个阶段：\n 传输层：Kitex 收到了一个完整的二进制数据包的阶段。如果是 TTHeader 协议，在二进制包中，我们就能快速解析出一些 metadata 信息，而无需反序列化。 消息层：Kitex 将二进制反序列化为一个 Request 结构体的阶段。当结构体比较复杂时，反序列化部分对服务总体开销占比往往会比较大。  在我们的微服务治理实践里，我们推荐把来源服务名这类通用信息放在 TTHeader 中，这样不需要完全反序列化请求便可以提前进行 Goroutine 的 labels 打点。\n 如果需要从传输层采集 tags，则使用：server.WithProfilerTransInfoTagging。 如果需要从消息层采集 tags，则使用：server.WithProfilerMessageTagging。  使用示例：\n// example kitex_gen type Request struct { Message string `thrift:\"Message,1,required\" json:\"Message\"` Type int32 `thrift:\"Type,2,required\" json:\"Type\"` } // tagging logic var msgTagging remote.MessageTagging = func(ctx context.Context, msg remote.Message) (context.Context, []string) { if data := msg.Data(); data == nil { return ctx, nil } var tags = make([]string, 0, 2) var reqType int32 if args, ok := msg.Data().(ArgsGetter); ok { if req := args.GetReq(); req != nil { reqType = req.Type tags = append(tags, \"req_type\", strconv.Itoa(reqType)) } } // if you don't need to get the tags after middleware, not need to change ctx \treturn context.WithValue(ctx, \"ctxKeyReqType\", reqType), []string{\"req_type\", strconv.Itoa(reqType)} } // register tagging function svr := xxxserver.NewServer(server.WithProfilerMessageTagging(msgTagging)) 编写数据处理回调函数 Kitex 会定期将聚合后的统计结果传入到提前设置好的回调函数内执行，我们可以在这个回调函数中实现统计上报功能。这里以简单的日志打印作为示范：\nfunc LogProcessor(profiles []*profiler.TagsProfile) error { if len(profiles) == 0 { return nil } klog.Infof(\"KITEX: profiler collect %d records\", len(profiles)) for _, p := range profiles { klog.Infof(\"KITEX: profiler - %s %.2f%% %d\", p.Key, p.Percent*100, p.Value) } klog.Info(\"---------------------------------\") return nil } 设置 Profiler 我们可以为 profiler 配置两个参数：\n interval: 多少时间采一次样，为 0 则表示循环采样。如果采样占用 CPU 过高，可以增大该参数以降低采样精度，提高性能。 window: 一次采样持续多少时间，时间越长，一个窗口内统计数据会越多，进行数据聚合计算时，采样停顿也会更大。一般建议 10s-60s 最佳。  interval, window := time.Duration(0), 30*time.Second pc := profiler.NewProfiler(LogProcessor, interval, window) svr := xxxserver.NewServer( new(ServerImpl), server.WithProfilerMessageTagging(msgTagging), server.WithProfiler(pc), ) ","categories":"","description":"Kitex Profiler 模块提供了请求级别的运行时开销统计能力。","excerpt":"Kitex Profiler 模块提供了请求级别的运行时开销统计能力。","ref":"/zh/docs/kitex/tutorials/advanced-feature/profiler/","tags":"","title":"请求成本度量"},{"body":"X-Request-ID is a common non-standard response fields in HTTP Headers, used to correlate HTTP requests between a client and server. Hertz also provides Request ID middleware that can operate on X-Request-ID, inspired by gin’s implementation.\nInstall Download and install\ngo get github.com/hertz-contrib/requestid Import into your code\nimport \"github.com/hertz-contrib/requestid\" Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() h.Use( // provide your own request id generator here  requestid.New( requestid.WithGenerator(func(ctx context.Context, c *app.RequestContext) string { return \"cloudwego.io\" }), // set custom header for request id  requestid.WithCustomHeaderStrKey(\"Your-Customised-Key\"), ), ) // Example ping request.  h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { hlog.Info(string(c.Response.Header.Header())) c.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } Config Hertz is able to add an identifier to the response using the X-Request-ID header, and passes the X-Request-ID value back to the caller if it’s sent in the request headers by using middleware. The Request ID middleware provides the default configuration, you can also customize the following configuration using WithGenerator, WithCustomHeaderStrKey, WithHandler functions according to different scenarios.\n   configuration Description     WithGenerator Define a function that generates a Request ID. By default, a UUID identifier is generated.   WithCustomHeaderStrKey Define the key value of the Request ID. By default, the key value is X-Request-ID.   WithHandler Define the handler function of the Request ID.    New The requestid middleware provides New to add the Request ID field to the response header.\nFunction signatures:\nfunc New(opts ...Option) app.HandlerFunc Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() h.Use( requestid.New(), ) // Example ping request.  h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } WithCustomHeaderStrKey The requestid middleware provides WithCustomHeaderStrKey to customize the Request ID key value.\nNote: If you want to set up the request id in the request header, you need to keep consistent with the custom request id keys.\nFunction signatures:\nfunc WithCustomHeaderStrKey(s HeaderStrKey) Option Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() // define your own header to save request id here  h.Use( requestid.New( requestid.WithCustomHeaderStrKey(\"Your-Header-StrKey\"), ), ) // Example ping request.  h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } WithGenerator The requestid middleware provides WithGenerator for custom Request ID value generation.\nFunction signatures:\nfunc WithGenerator(g Generator) Option Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() h.Use( // define your own request id generator here  requestid.New(requestid.WithGenerator(func(ctx context.Context, c *app.RequestContext) string { return \"cloudwego.io\" })), ) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } WithHandler The requestid middleware provides WithHandler for custom Request ID handlers.\nFunction signatures:\nfunc WithHandler(handler Handler) Option Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() var bar string h.Use( requestid.New( requestid.WithGenerator(func(ctx context.Context, c *app.RequestContext) string { return \"hello\" }), // define your request id handler here  requestid.WithHandler(func(ctx context.Context, c *app.RequestContext, requestID string) { bar = requestID + \" hertz\" }), ), ) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{ \"ping\": \"pong\", \"foo\": bar, // hello hertz  }) }) h.Spin() } Get requestid middleware provides Get which is a helper function to retrieve request id from request headers. It also works with customised header as defined with requestid.WithCustomHeaderStrKey.\nFunction signatures:\nfunc Get(c *app.RequestContext) string Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() h.Use( requestid.New(requestid.WithGenerator(func(ctx context.Context, c *app.RequestContext) string { return \"cloudwego.io\" })), ) // You may retrieve request id from header by calling requestid.Get  h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{ \"ping\": \"pong\", \"request-id\": requestid.Get(c), }) }) h.Spin() } Full Example As for usage, you may refer to hertz example\n","categories":"","description":"","excerpt":"X-Request-ID is a common non-standard response fields in HTTP Headers, …","ref":"/docs/hertz/tutorials/basic-feature/middleware/requestid/","tags":"","title":"Request ID"},{"body":"X-Request-ID 在 HTTP Headers 中是一种非标准响应字段，通常用于关联客户端和服务器之间的 HTTP 请求。 Hertz 也提供了可以对 X-Request-ID 进行操作的 Request ID 中间件，参考了 gin 的实现。\n安装 下载并安装\ngo get github.com/hertz-contrib/requestid 导入\nimport \"github.com/hertz-contrib/requestid\" 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() h.Use( // 自定义 request id 生成逻辑  requestid.New( requestid.WithGenerator(func(ctx context.Context, c *app.RequestContext) string { return \"cloudwego.io\" }), // 自定义 request id 响应头键值  requestid.WithCustomHeaderStrKey(\"Your-Customised-Key\"), ), ) // Example ping request.  h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { hlog.Info(string(c.Response.Header.Header())) c.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 配置 Hertz 通过使用中间件，可以在响应头中添加一个键为 X-Request-ID 的标识符，如果在请求头中设置了 X-Request-ID 字段，则会在响应头中将 X-Request-ID 原样返回。 Request ID 中间件提供了默认配置，用户也可以依据业务场景使用 WithGenerator，WithCustomHeaderStrKey，WithHandler 函数对以下配置项进行定制。\n   配置 介绍     WithGenerator 定义生成 Request ID 的函数，默认生成 UUID 标识符   WithCustomHeaderStrKey 定义 Request ID 的键值，默认为 X-Request-ID   WithHandler 定义 Request ID 的处理函数    初始化 Request ID requestid 中间件提供了 New 用于在响应头添加 Request ID 字段。\n函数签名：\nfunc New(opts ...Option) app.HandlerFunc 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() h.Use( requestid.New(), ) // Example ping request.  h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 自定义 Request ID 键值 requestid 中间件提供了 WithCustomHeaderStrKey 用于自定义 Request ID 键值。\n注意：如果需要在请求头中设置 X-Request-ID，则需要保持和自定义响应头键值一致。\n函数签名：\nfunc WithCustomHeaderStrKey(s HeaderStrKey) Option 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() // define your own header to save request id here  h.Use( requestid.New( requestid.WithCustomHeaderStrKey(\"Your-Header-StrKey\"), ), ) // Example ping request.  h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 自定义 Request ID 值 requestid 中间件提供了 WithGenerator 用于自定义 Request ID 值的生成。\n函数签名：\nfunc WithGenerator(g Generator) Option 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() h.Use( // define your own request id generator here  requestid.New(requestid.WithGenerator(func(ctx context.Context, c *app.RequestContext) string { return \"cloudwego.io\" })), ) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 自定义 Request ID Handler requestid 中间件提供了 WithHandler 用于自定义 Request ID 的处理函数。\n函数签名：\nfunc WithHandler(handler Handler) Option 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() var bar string h.Use( requestid.New( requestid.WithGenerator(func(ctx context.Context, c *app.RequestContext) string { return \"hello\" }), // define your request id handler here  requestid.WithHandler(func(ctx context.Context, c *app.RequestContext, requestID string) { bar = requestID + \" hertz\" }), ), ) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{ \"ping\": \"pong\", \"foo\": bar, // hello hertz  }) }) h.Spin() } 获取 Request ID requestid 中间件提供了 Get 用于从请求头中获取 Request ID，它也支持获取使用 requestid.WithCustomHeaderStrKey 自定义 Request ID 键值。\n函数签名：\nfunc Get(c *app.RequestContext) string 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"github.com/hertz-contrib/requestid\" ) func main() { h := server.Default() h.Use( requestid.New(requestid.WithGenerator(func(ctx context.Context, c *app.RequestContext) string { return \"cloudwego.io\" })), ) // You may retrieve request id from header by calling requestid.Get  h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(consts.StatusOK, utils.H{ \"ping\": \"pong\", \"request-id\": requestid.Get(c), }) }) h.Spin() } 完整示例 完整用法示例详见 example\n","categories":"","description":"","excerpt":"X-Request-ID 在 HTTP Headers 中是一种非标准响应字段，通常用于关联客户端和服务器之间的 HTTP 请求。 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/requestid/","tags":"","title":"Request ID"},{"body":"Forward proxy A forward proxy is a special network service that allows a network terminal (usually a client) to make a non-direct connection with another network terminal (usually a server) through this service. Some network devices such as gateways and routers have network proxy functions. Proxy services are generally considered to be beneficial to safeguard the privacy or security of network terminals and prevent attacks.\nA complete proxy request process is that the client first creates a connection to the proxy server, and then requests to create a connection to the target server, or to obtain the specified resources of the target server, according to the proxy protocol used by the proxy server.\nInstall Hertz has a built-in function for accessing a forward proxy.\nDefinition // Proxy struct, which selects the proxy uri to access based on the request type Proxy func(*protocol.Request) (*protocol.URI, error) // ProxyURI is used to generate a Proxy that only returns a fixed proxy uri func ProxyURI(fixedURI *protocol.URI) Proxy // SetProxy is used to set the proxy of the client, after setting, the client will build concatenated requests with the proxy func (c *Client) SetProxy(p protocol.Proxy) Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/protocol\" ) func main() { proxyURL := \"http://\u003c__user_name__\u003e:\u003c__password__\u003e@\u003c__proxy_addr__\u003e:\u003c__proxy_port__\u003e\" // Convert the proxy uri to *protocol.URI  parsedProxyURL := protocol.ParseURI(proxyURL) c, err := client.NewClient() if err != nil { return } // Set proxy  c.SetProxy(protocol.ProxyURI(parsedProxyURL)) upstreamURL := \"http://google.com\" _, body, _ := client.Get(context.Background(), nil, upstreamURL) }  The client does not support TLS by default, if you want to access https addresses, you should use the standard library.\n c, err := client.NewClient(client.WithDialer(standard.NewDialer()))  If a certificate error is reported, certificate verification needs to be skipped.\n clientCfg := \u0026tls.Config{ InsecureSkipVerify: true, } c, err := client.NewClient(client.WithTLSConfig(clientCfg), client.WithDialer(standard.NewDialer())) Reverse proxy In computer networks, a reverse proxy is an application that sits in front of back-end applications and forwards client (e.g. browser) requests to those applications.\nReverse proxies help increase scalability, performance, resilience and security. The resources returned to the client appear as if they originated from the web server itself.\nInstall go get github.com/hertz-contrib/reverseproxy Specific implementation type ReverseProxy struct { client *client.Client // target is set as a reverse proxy address  target string // director must be a function which modifies the request  // into a new request. Its response is then redirected  // back to the original client unmodified.  // director must not access the provided Request  // after returning.  director func (*protocol.Request) // modifyResponse is an optional function that modifies the  // Response from the backend. It is called if the backend  // returns a response at all, with any HTTP status code.  // If the backend is unreachable, the optional errorHandler is  // called without any call to modifyResponse.  //  // If modifyResponse returns an error, errorHandler is called  // with its error value. If errorHandler is nil, its default  // implementation is used.  modifyResponse func(*protocol.Response) error // errorHandler is an optional function that handles errors  // reaching the backend or errors from modifyResponse.  // If nil, the default is to log the provided error and return  // a 502 Status Bad Gateway response.  errorHandler func(*app.RequestContext, error) } // NewSingleHostReverseProxy returns a new ReverseProxy that routes // URLs to the scheme, host, and base path provided in target. If the // target's path is \"/base\" and the incoming request was for \"/dir\", // the target request will be for /base/dir. // NewSingleHostReverseProxy does not rewrite the Host header. // To rewrite Host headers, use ReverseProxy directly with a custom // director policy. func NewSingleHostReverseProxy(target string, opts ...config.Option) (*reverseProxy, error)   For NewSingleHostReverseProxy function, if no config.ClientOption is passed it will use the default global client.Client instance. When passing config.ClientOption it will initialize a local client.Client instance. Using ReverseProxy.SetClient if there is need for shared customized client.Client instance. The reverse proxy resets the header of the response, any such modifications before the request is made will be discarded.   We provide the SetXxx() method for setting private properties\n   Method Description     SetDirector use to customize protocol.Request   SetClient use to customize client   SetModifyResponse use to customize modify response function   SetErrorHandler use to customize error handler    Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/reverseproxy\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8000\")) // set target address  proxy, err := reverseproxy.NewSingleHostReverseProxy(\"http://127.0.0.1:8000/proxy\") if err != nil { panic(err) } h.GET(\"/proxy/backend\", func(cc context.Context, c *app.RequestContext) { c.JSON(200, utils.H{ \"msg\": \"proxy success!!\", }) }) h.GET(\"/backend\", proxy.ServeHTTP) h.Spin() } FAQ How to proxy HTTPS  Netpoll does not support TLS, Client needs to use standard network library.\n Proxying HTTPS requires some additional configuration.\n Use WithDialer in the NewSingleHostReverseProxy method to pass standard.NewDialer() to specify the standard network library. Use SetClient to set up a Hertz Client using the standard networking library.  How to use with middleware You can also use ReverseProxy.ServeHTTP in the hertz handler to implement complex requirements instead of registering ReverseProxy.ServeHTTP directly to the route.\nExample Code\npackage main import ( //... ) func main() { //...  r.Use(func(c context.Context, ctx *app.RequestContext) { if ctx.Query(\"country\") == \"cn\" { proxy.ServeHTTP(c, ctx) ctx.Response.Header.Set(\"key\", \"value\") ctx.Abort() } else { ctx.Next(c) } }) //... } More Examples    Purpose Sample Code     Proxy tls code   Using service discovery code   Use with middleware code    For more usages, please refer to the following examples.\n","categories":"","description":"","excerpt":"Forward proxy A forward proxy is a special network service that allows …","ref":"/docs/hertz/tutorials/basic-feature/proxy/","tags":"","title":"Forward Proxy and Reverse Proxy"},{"body":"正向代理 正向代理是一种特殊的网络服务，允许一个网络终端（一般为客户端）通过这个服务与另一个网络终端（一般为服务器）进行非直接的连接。一些网关、路由器等网络设备具备网络代理功能。一般认为代理服务有利于保障网络终端的隐私或安全，防止攻击。\n一个完整的代理请求过程为：客户端（Client）首先与代理服务器创建连接，接着根据代理服务器所使用的代理协议，请求对目标服务器创建连接、或者获得目标服务器的指定资源。\n安装 hertz内置了访问正向代理的功能\n定义 // Proxy 结构体，根据 request 来选定访问的代理 uri type Proxy func(*protocol.Request) (*protocol.URI, error) // ProxyURI 用来生成只会返回固定代理 uri 的 Proxy func ProxyURI(fixedURI *protocol.URI) Proxy // SetProxy 用来设置 client 的 proxy，设置后 client 会与 proxy 建连发请求 func (c *Client) SetProxy(p protocol.Proxy) 示例 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/protocol\" ) func main() { proxyURL := \"http://\u003c__user_name__\u003e:\u003c__password__\u003e@\u003c__proxy_addr__\u003e:\u003c__proxy_port__\u003e\" // 将代理的 uri 转成 *protocol.URI 的形式  parsedProxyURL := protocol.ParseURI(proxyURL) c, err := client.NewClient() if err != nil { return } // 设置代理  c.SetProxy(protocol.ProxyURI(parsedProxyURL)) upstreamURL := \"http://google.com\" _, body, _ := c.Get(context.Background(), nil, upstreamURL) }  客户端默认不支持 TLS，如果要访问 https 地址，应该使用标准库\n c, err := client.NewClient(client.WithDialer(standard.NewDialer()))  如果报证书错误还需要跳过证书验证\n clientCfg := \u0026tls.Config{ InsecureSkipVerify: true, } c, err := client.NewClient(client.WithTLSConfig(clientCfg), client.WithDialer(standard.NewDialer())) 反向代理 反向代理在计算机网络中是代理服务器的一种。\n服务器根据客户端的请求，从其关系的一组或多组后端服务器（如 Web 服务器）上获取资源，然后再将这些资源返回给客户端，客户端只会得知反向代理的 IP 地址，而不知道在代理服务器后面的服务器集群的存在。\n安装 go get github.com/hertz-contrib/reverseproxy 具体实现 type ReverseProxy struct { // 用于转发的客户端，可以通过 SetClient 方法对其进行配置  client *client.Client // 设置反向代理的目标地址  target string // 用于转换 request，可以通过 SetDirector 方法来自定义  // director 必须是将一个请求转换为一个新的请求的函数。  // 响应直接未经修改重定向返回给原始客户端  // 请求返回后 direcotr 不得访问  director func (*protocol.Request) // modifyResponse 这是一个可选的函数，用于修改来自后端的响应  // 可以通过 SetModifyResponse 方法进行修改  // 如果后端返回任意响应，不管状态码是什么，这个方法将会被调用。  // 如果后端不可访问，errorHandler 方法会使用错误信息做入参被调用。  // 如果 modifyResponse 方法返回一个错误，errorHandler 方法将会使用错误做入参被调用。  // 如果 errorHandler 未设置，将使用默认实现。  modifyResponse func(*protocol.Response) error // errorHandler 是一个可选的函数，用于处理到达后台的错误或来自 modifyResponse 的错误。  // 如果未进行设置，默认返回 StatusBadGateway (502)  errorHandler func(*app.RequestContext, error) } // NewSingleHostReverseProxy 返回一个新的反向代理来路由请求到指定后端。如果后端路径是 ”/base“ 请求路径是 ”/dir” ，目标路径将会是 “/base/dir” 。 // NewSingleHostReverseProxy 不会重写 Host 请求头。 // 要想覆盖 Host 请求头，可以选择自定义 director func NewSingleHostReverseProxy(target string, opts ...config.Option) (*reverseProxy, error)   NewSingleHostReverseProxy 方法如果没有设置 config.ClientOption 将会使用默认的全局 client.Client 实例， 如果设置了 config.ClientOption 将会初始化一个 client.Client 实例。 如果你需要共享一个 client.Client 实例，可以使用 ReverseProxy.SetClient 来设置。 反向代理会重置响应头，如果在请求之前修改了响应头将不会生效。   我们提供了 SetXxx() 函数用于设置私有属性\n   方法 描述     SetDirector 用于指定 protocol.Request   SetClient 用于指定转发的客户端   SetModifyResponse 用于指定响应修改方法   SetErrorHandler 用于指定处理到达后台的错误或来自 modifyResponse 的错误    示例 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/reverseproxy\" ) func main() { h := server.Default(server.WithHostPorts(\"127.0.0.1:8000\")) // 设置目标地址  proxy, err := reverseproxy.NewSingleHostReverseProxy(\"http://127.0.0.1:8000/proxy\") if err != nil { panic(err) } h.GET(\"/proxy/backend\", func(cc context.Context, c *app.RequestContext) { c.JSON(200, utils.H{ \"msg\": \"proxy success!!\", }) }) // 设置代理  h.GET(\"/backend\", proxy.ServeHTTP) h.Spin() } FAQ 如何代理 HTTPS  Netpoll 不支持 TLS，Client 需要使用标准网络库.\n 代理 HTTPS 需要在额外做一些配置.\n NewSingleHostReverseProxy 方法中使用 WithDialer 传递 standard.NewDialer() 指定标准网络库。 使用 SetClient 设置一个使用标准网络库的 Hertz Client。  如何配合中间件使用 可以在 hertz handler 中也使用 ReverseProxy.ServeHTTP 来实现复杂的需求而不是直接将 ReverseProxy.ServeHTTP 注册到路由。\n示例代码\npackage main import ( //... ) func main() { //...  r.Use(func(c context.Context, ctx *app.RequestContext) { if ctx.Query(\"country\") == \"cn\" { proxy.ServeHTTP(c, ctx) ctx.Response.Header.Set(\"key\", \"value\") ctx.Abort() } else { ctx.Next(c) } }) //... } 更多示例    用途 示例代码     代理 tls code   使用服务发现 code   配合中间件使用 code    更多使用方法可参考如下 examples。\n","categories":"","description":"","excerpt":"正向代理 正向代理是一种特殊的网络服务，允许一个网络终端（一般为客户端）通过这个服务与另一个网络终端（一般为服务器）进行非直接的连接。一些网 …","ref":"/zh/docs/hertz/tutorials/basic-feature/proxy/","tags":"","title":"正向代理和反向代理"},{"body":"会议主题 ：CloudWeGo 社区会议 6.30\n参会人 ：GuangmingLuo, welkeyever, YangruiEmma, liu-song, byene0923, Ivnszn, ylck, li-jin-gou, stephenzhang0713, Li Zheming, debug-LiXiwen, joway, yccpt, Yin Xuran, JZK-Keven, Li Weiting, Fan Guangyu, Jacob953, errocks, Huang Xiaolong, towelong, powerxu519, jayantxie, baiyutang, skyenought, yiyun, baize, yunwei37, 834810071, LhdDream\n会前必读 ：http://www.cloudwego.io/；https://github.com/cloudwego\n议程 1 ：新人自我介绍 @GuangmingLuo  新成员名单：stephenzhang0713, yunwei37, errocks, Li Weiting, Huang Xiaolong, towelong, powerxu519, LhdDream, ylck, byene0923 社区新成员分别进行自我介绍，主要包含个人基本情况、开源贡献经历和后续参与社区工作内容。   议程 2 ：Good-first-issue 复盘 @GuangmingLuo  Kitex 单测任务还有两个子任务待完成，希望加快进度。后续会持续放出其它新手任务，希望大家可以保持关注并积极参与。后续针对 PR 可能会有单测覆盖率限制，希望后面每一个提交贡献的同学都能补充相关的单测，提升相关模块的单测覆盖率，保证项目的代码质量。 Hertz 文档建设进展：   先前发布了文档翻译类型的新手任务，英文文档建设是项目非常重要的一部分，新手、字节内部同学、国内熟悉英文的用户都可查看。后续也会将项目进行国际化推广，因而英文文档建设也是很有价值的。 英文文档建设可以锻炼英文翻译能力、对项目技术的理解能力，在翻译时要考虑中英文表达方式的差异，不能只是文字对照翻译。也欢迎大家后续对文档翻译进行持续优化，这也是为社区作出重要贡献的方式之一。   议程 3 ：工程化模板或标准化的讨论 @baiyutang  Issue 地址：https://github.com/cloudwego/kitex/issues/500 背景：用户在做技术选型的时候，对工具化模板是有一定诉求的，比如说怎样快速便捷生成一些基础的业务代码。对比 Go-zero 框架的 API 生成、RPC 生成、Model 生成以及模版的管理四类命令工具，Kitex 有一些生成客户端代码的命令、生成基础 Handler 方法的服务端代码命令等，如果想满足更多用户的诉求，我们可以确定一个 Layout 或者丰富工具化、生成业务代码方面的命令。 相关讨论：   Kitex 和 Hertz 有两套单独的 RPC 命令生成工具，生成 Model 可能需要一个总的工具，因为有很多业务诉求是有共性的，这个问题正在考虑中。 Q：Kitex 和 Hertz 同属一个 Group，命令是否可以相似，如果不去自动指定 Model 的话，可以自动从执行命令最近的文件夹里面找到 Go mod 文件？ A：建议提出 PR，相关同学后续会跟进。  欢迎感兴趣的同学加入讨论！\n 议程 4：Hertz 近期 Roadmap 介绍、实战案例建设、新手任务介绍等等 @welkeyever  Hertz 上周已正式官宣，内部在逐步梳理开源侧的 Roadmap。主库拆成 Hertz 对外提供的各维度的能力：   HTTP2 在内部已经有一个工程实践，内部很多组件用户已经在使用，但是出于成熟度的考量，还没有正式开源。因此首先后期会补充 HTTP2 的能力，对此感兴趣的同学可以一起参与； HTTP3 的 RFC 文档在 6 月份正式发布，这部分也是即将举办的 Byte Camp 的议题，后续的开发工作也会以 Issue 和 PR 的形式直接在主库上展开。也欢迎大家加入到开发过程中； 关于协议，如 ALPN 已经开源，后续希望组织好这些协议，把 ALPN 的能力发挥到极致。协议间无感切换是说在用户在使用 Hertz 时，它能够做到一键切换协议版本； Automatic TLS 在内部不是刚需，主要面对开源用户。其余各维度的能力也在陆续梳理中。 对于 Hz，后续会提供多场景、高定制化、开箱即用等用户自定义能力，通过 Hz 能够直接一键创建出可以快速上线的一整个代码脚架。还会涉及 API 管理以及生成工具提供一些更高层面的抽象能力，包括屏蔽掉 HTTP 协议相关的 Request Response，给用户生成一些基于 IDL、类似于 RPC 方向的开发体验。欢迎感兴趣的同学一起进行 Hz 工具的打磨。  Contrib 仓库为 Hertz 提供全方位的组件能力：   Websocket 已经在内部使用一年多，本质上是基于 Gorilla Websocket 的库做适配，因此没有直接开源。后续可作为新手任务。 反向代理与 Websocket 类似，这个实现也是基于 Golang 原生的实现做的适配，没有直接开源。后续可作为新手任务。 常用中间件（Session/Compress/Cache），每个中间件相对独立，所以希望每个同学单独承接，做独立开发。 服务治理相关能力，与 Automatic TLS 类似，在内部会直接卸载到 Service Mesh 上。服务发现、负载均衡、限流、熔断、超时，都在 Service Mesh上有对应的实现。这一系列的服务治理的相关能力也在开源的 Roadmap 中，后续会逐步地将任务梳理出来。 可观测性（Log/Trace/Metrics），我们现在已经做了一些集成的，日志能够支持具体实现注入，Trace 也有相应的埋点，Example 库也提供了类似于使用 Tracing 能力的示例，这些也在规划中。 云原生（Proxyless/一键部署/CICD），Proxyless 在服务治理能力补齐之后会开始做，直接对接 Istio，Kitex 的这部分已经在进行中，Hertz 后续也会逐步补充。一键部署是指部署到第三方云环境的能力，包括集成 CICD 等等，都是 Contrib 仓库会涵盖的。  希望已经给 Hertz 提供 PR 或 Issue 的同学多使用，帮助框架进一步做性能提升。细节部分可以在 Hertz SIG 讨论，公共事务可以在开发者交流群进行沟通。\n 议程 5：社区 Mentor 机制介绍 @GuangmingLuo  上周社区开发者交流群里进行的问卷调查，是为了有针对性地给群里各位新加入的同学提供学习成长路径和帮助，后续会针对大家的意愿，给各位同学匹配对应的 Mentor，遇到问题可以及时跟 Mentor 交流沟通，方便大家快速地学习以及真正地深入到这个项目的开发中，也帮助大家快速成为社区 Committer。   议程 6：Issue 任务答疑 Q \u0026 A 环节 Q：Hertz 和 Kitex 都要做服务治理，在功能上是不是有些重复？\nA： 二者业务场景不同，整个框架的治理能力是可扩展性的，Kitex 目前在对接 OpenSergo 和 Polaris 等项目，针对服务治理能力做一些集成对接，分别把它们封装成两套不同的服务治理 Suite 进行接入。这部分 Kitex 已经在进行中了，如果后续 Hertz 对应接口扩展性这方面完成准备，也会启动类似这样的集成对接。字节的服务治理能力是由服务网格去实现的，目前 Hertz 框架的服务治理还比较薄弱，因此我们后面会统一对接第三方的服务治理能力，以 Suite 的方法一键集成进来，需要上云的用户就可以一键集成对应不同公务云的通用服务指引能力。有个性化需求的用户可以去做一些集成的对接，但不会对框架的 Core 有侵入。\nQ：Hertz 提供 IDL 生成是不是导致与 Kitex 有重叠？\nA：在 Hertz 中，IDL 主要是用在接口描述上面，在这个接口描述布局下面，生成对应的 HTTP 框架的代码。后续 Kitex 会基于 IDL 做一部分代码生成，但 Hertz 是没有的。本质上其实可以理解为还是 HTTP 协议，跟 RPC 没有任何关系。\nQ：既然支持 Thrift 和 PB 两种语言，那是否可能自己开发出一套语言来进行接口描述？\nA：Thrift 和 PB 都只是在 Hertz 中发挥接口描述的功能。除此之外，我们内部其实都是以 Thrift 的 IDL 做一些描述，包括 RPC 是直接基于 Thrift 生成代码的。其实在 Hertz 这边，我们仅仅只是用了接口描述的能力，如果你想换成自定义协议套都是可以的。后续我们其实也会考虑是否可以设计一套通用的接口描述，撑起整个 Hertz 代码生成逻辑。\nQ：因为 Hertz 和 Kitex 字节内部已经有一些应用实践经验，我们可以不仅仅从产品设计上去考虑，而且还要把它当做技术产品去看待，响应市场的需求。针对不同的人群来讲，第一类是不太了解微服务的概念或者实践的人群，第二类是更关注性能测试的中高级的用户，Hertz 和 Kitex 是否可以给出一些最佳实践文档？\nA： 我们最近也开展了类似的源码解读活动，是面向新手和年轻开发者的活动，之后也在陆续整理一些相关概念和知识介绍。至于偏具体业务场景的使用案例，后续我们希望能有更多同学参与进来。这个其实是一个社区攻坚的过程，我们也会尽可能把字节内部已有的比较好的实践进行输出。希望大家能够就是借着这个框架可以自己去做一些相关领域的实践，我们目前也正在搭一个电商的样例，这个项目会在近期完成，最后我们会把它发布出来放在官网。一些企业用户案例也比较有借鉴意义，我们也希望能够在不同行业，比如电商、证券、游戏和机器学习等做一些企业用户的行业标杆。后续我们也会收集和整理相关企业用户进行落地页实现的案例，放在官网统一的位置做展示，让用户和需要做技术选型的同学能够快速地看到，能够了解这个项目究竟能给业务带来什么价值，能在哪些场景上铺开使用。\n","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 6.30\n参会人 ：GuangmingLuo, welkeyever, YangruiEmma, …","ref":"/zh/community/meeting_notes/2022-06-30/","tags":"","title":"CloudWeGo 社区会议 6.30"},{"body":"Kitex provides a default implementation of Circuit Breaker, but it’s disabled by default.\nThe following document will introduce that how to enable circuit breaker and configure the policy.\nHow to use Example // build a new CBSuite cbs := circuitbreak.NewCBSuite(GenServiceCBKeyFunc) // add to the client options opts = append(opts, client.WithCircuitBreaker(cbs)) // init client cli, err := xxxservice.NewClient(targetService, opts) Introduction Kitex provides a set of CBSuite that encapsulates both service-level breaker and instance-level breaker, which are the implementations of Middleware.\n  Service-Level Breaker\nStatistics by service granularity, enabled via WithMiddleware.\nThe specific division of service granularity depends on the Circuit Breaker Key, which is the key for breaker statistics. When initializing the CBSuite, you need to pass it in GenServiceCBKeyFunc. The default key is circuitbreak.RPCInfo2Key, and the format of RPCInfo2Key is  fromServiceName/toServiceName/method.\n  Instance-Level Breaker\nStatistics by instance granularity, enabled via WithInstanceMW.\nInstance-Level Breaker is used to solve the single-instance exception problem. If it’s triggered, the framework will automatically retry the request.\nNote that the premise of retry is that you need to enable breaker with WithInstanceMW, which will be executed after load balancing.\n  Threshold and Threshold Change\n  The default breaker threshold is ErrRate: 0.5, MinSample: 200, which means it’s triggered by an error rate of 50% and requires the count of requests \u003e 200.\nIf you want to change the threshold, you can modify the UpdateServiceCBConfig and UpdateInstanceCBConfig in CBSuite.\nThe Role of Circuit Breaker When making RPC calls, errors are inevitable for downstream services.\nWhen a downstream has a problem, if the upstream continues to make calls to it, it both prevents the downstream from recovering and wastes the upstream’s resources.\nTo solve this problem, you can set up some dynamic switches that manually shut down calls to the downstream when it goes wrong.\nA better approach, however, is to use Circuit Breaker.\nHere is a more detailed document Circuit Breaker Pattern.\nOne of the famous circuit breakers is hystrix, and here is its design.\nBreaker Strategy The idea of a Circuit Breaker is simple: restrict access to downstream based on successful failures of RPC Calls.\nThe Circuit Breaker is usually divided into three periods: CLOSED, OPEN, and HALFOPEN.\n CLOSED when the RPC is normal. OPEN when RPC errors increase. HALFOPEN after a certain cooling time after OPEN.  HALFOPEN will make some strategic access to the downstream, and then decide whether to become CLOSED or OPEN according to the result.\nIn general, the transition of the three states is roughly as follows:\n [CLOSED] ---\u003e tripped ----\u003e [OPEN]\u003c-------+ ^ | ^ | v + | detect fail | | v | cooling timeout | The timeout for cooling | v +-- detect succeed --\u003c-[HALFOPEN]--\u003e--+ Trigger Strategies Kitex provides three basic fuse triggering strategies by default:\n  Number of consecutive errors reaches threshold (ConsecutiveTripFunc)\n  Error count reaches threshold (ThresholdTripFunc)\n  Error rate reaches the threshold (RateTripFunc)\n  Of course, you can write your own triggering strategy by implementing the TripFunc function.\nCircuitbreaker will call TripFunc when Fail or Timeout happen to decide whether to trigger breaker.\nCooling Strategy After entering the OPEN state, the breaker will cool down for a period of time, the default is 10 seconds which is also configurable (with CoolingTimeout).\nDuring this period, all IsAllowed() requests will be returned false.\nEntering HALFOPEN when cooling is complete.\nHalf-Open Strategy During HALFOPEN, the breaker will let a request go every “interval”, and after a “number” of consecutive successful requests, the breaker will become CLOSED; If any of them fail, it will become OPEN.\nThe process is a gradual-trial process.\nBoth the “interval” (DetectTimeout) and the “number” (DEFAULT_HALFOPEN_SUCCESSES) are configurable.\nStatistics Default Config The breaker counts successes, failures and timeouts within a period of time window(default window size is 10 seconds).\nThe time window can be set by two parameters, but usually you can leave it alone.\nStatistics Implementation The statistics will divide the time window into buckets, each bucket recording data for a fixed period of time.\nFor example, to count data within 10 seconds, you can spread the 10 second time period over 100 buckets, each bucket counting data within a 100ms time period.\nThe BucketTime and BucketNums in Options correspond to the time period of each bucket, and the number of buckets.\nIf BucketTime is set to 100ms, and BucketNums is set to 100, this corresponds to a 10 second time window.\nJitter As time moves, the oldest bucket in the window expires. The jitter occurs when the last bucket expires.\nAs an example:\n  You divide 10 seconds into 10 buckets, bucket 0 corresponds to a time of [0S, 1S), bucket 1 corresponds to [1S, 2S), … , and bucket 9 corresponds to [9S, 10S).\n  At 10.1S, a Succ is executed, and the following operations occur within the circuitbreaker.\n (1) detects that bucket 0 has expired and discards it; (2) creates a new bucket 10, corresponding to [10S, 11S); (3) puts that Succ into bucket 10.    At 10.2S, you execute Successes() to query the number of successes in the window, then you get the actual statistics for [1S, 10.2S), not [0.2S, 10.2S).\n  Such jitter cannot be avoided if you use time-window-bucket statistics. A compromise approach is to increase the number of buckets, which can reduce the impact of jitter.\nIf 2000 buckets are divided, the impact of jitter on the overall data is at most 1/2000. In this package, the default number of buckets is 2000, the bucket time is 5ms, and the time window is 10S.\nThere are various technical solutions to avoid this problem, but they all introduce other problems, so if you have good ideas, please create a issue or PR.\n","categories":"","description":"This doc covers Kitex Circuit Breaker use guide and principle introduction.","excerpt":"This doc covers Kitex Circuit Breaker use guide and principle …","ref":"/docs/kitex/tutorials/basic-feature/circuitbreaker/","tags":"","title":"Circuit Breaker"},{"body":"By default, Kitex integrates the self-developed high-performance network library Netpoll. But Kitex is not strongly bound with Netpoll, it also supports users to extend other network libraries and choose one on demand. In addition, Kitex provides ShmIPC to further improve IPC performance, this extension will be open source later.\nExtension APIs The main extension interfaces of transport module are as follows:\ntype TransServer interface {...} type ServerTransHandler interface {...} type ClientTransHandler interface {...} type ByteBuffer interface {...} type Extension interface {...} // ------------------------------------------------------------- // TransServerFactory is used to create TransServer instances. type TransServerFactory interface { NewTransServer(opt *ServerOption, transHdlr ServerTransHandler) TransServer } // ClientTransHandlerFactory to new TransHandler for client type ClientTransHandlerFactory interface { NewTransHandler(opt *ClientOption) (ClientTransHandler, error) } // ServerTransHandlerFactory to new TransHandler for server type ServerTransHandlerFactory interface { NewTransHandler(opt *ServerOption) (ServerTransHandler, error) } TransServer is the startup interface of the server, ServerTransHandler and ClientTransHandler are the message processing interfaces of the server and client respectively, ByteBuffer is the read-write interface. Under the same IO model, the code logic of the TransHandler is usually consistent, so Kitex provides the default implementation of TransHandler for synchronous IO and abstracts the extension interface for different parts. Therefore, in the scenario of synchronous IO, it is not necessary to implement the complete TransHandler interface, just implement the Extension API.\nNetpoll Extension Below figure is Kitex’s extension to netpoll synchronous IO, which implements Extension, ByteBuffer, TransServer interfaces.\nCustomized Transport Module Usage   Server Side\noption: WithTransServerFactory, WithTransHandlerFactory\nvar opts []server.Option opts = append(opts, server.WithTransServerFactory(yourTransServerFactory) opts = append(opts, server.WithTransHandlerFactory(yourTransHandlerFactory) svr := xxxservice.NewServer(handler, opts...)   Client Side\noption: WithTransHandlerFactory\ncli, err := xxxservice.NewClient(targetService, client.WithTransHandlerFactory(yourTransHandlerFactory)   ","categories":"","description":"","excerpt":"By default, Kitex integrates the self-developed high-performance …","ref":"/docs/kitex/tutorials/framework-exten/transport/","tags":"","title":"Extension of Transport Module"},{"body":"Kitex 默认集成了自研的高性能网络库 Netpoll，但没有与 Netpoll 强绑定，同时也支持使用者扩展其他网络库按需选择。Kitex 还提供了 ShmIPC 进一步提升 IPC 性能，该扩展会在后续开源。\n扩展接口 传输模块主要的扩展接口如下：\ntype TransServer interface {...} type ServerTransHandler interface {...} type ClientTransHandler interface {...} type ByteBuffer interface {...} type Extension interface {...} // ------------------------------------------------------------- // TransServerFactory is used to create TransServer instances. type TransServerFactory interface { NewTransServer(opt *ServerOption, transHdlr ServerTransHandler) TransServer } // ClientTransHandlerFactory to new TransHandler for client type ClientTransHandlerFactory interface { NewTransHandler(opt *ClientOption) (ClientTransHandler, error) } // ServerTransHandlerFactory to new TransHandler for server type ServerTransHandlerFactory interface { NewTransHandler(opt *ServerOption) (ServerTransHandler, error) } TransServer 是服务端的启动接口，ServerTransHandler 和 ClientTransHandler 分别是服务端和调用端对消息的处理接口，ByteBuffer 是读写接口。相同的 IO 模型下 TransHandler 的逻辑通常是一致的，Kitex 对同步 IO 提供了默认实现的 TransHandler，针对不一样的地方抽象出了 Extension 接口，所以在同步 IO 的场景下不需要实现完整的 TransHandler 接口，只需实现 Extension 即可。\nNetpoll 的扩展 如下是 Kitex 对 Netpoll 同步 IO 的扩展，分别实现了Extension、ByteBuffer、TransServer 接口。\n指定自定义的传输模块   服务端\noption: WithTransServerFactory, WithTransHandlerFactory\nvar opts []server.Option opts = append(opts, server.WithTransServerFactory(yourTransServerFactory) opts = append(opts, server.WithTransHandlerFactory(yourTransHandlerFactory) svr := xxxservice.NewServer(handler, opts...)   调用端\noption: WithTransHandlerFactory\ncli, err := xxxservice.NewClient(targetService, client.WithTransHandlerFactory(yourTransHandlerFactory)   ","categories":"","description":"","excerpt":"Kitex 默认集成了自研的高性能网络库 Netpoll，但没有与 Netpoll 强绑定，同时也支持使用者扩展其他网络库按需选 …","ref":"/zh/docs/kitex/tutorials/framework-exten/transport/","tags":"","title":"传输模块扩展"},{"body":"Kitex 提供了熔断器的实现，但是没有默认开启，需要用户主动使用。 下面简单介绍一下如何使用以及 Kitex 熔断器的策略。\n如何使用 使用示例： // build a new CBSuite cbs := circuitbreak.NewCBSuite(GenServiceCBKeyFunc) // add to the client options opts = append(opts, client.WithCircuitBreaker(cbs)) // init client cli, err := xxxservice.NewClient(targetService, opts) 使用说明 Kitex 大部分服务治理模块都是通过 middleware 集成，熔断也是一样。Kitex 提供了一套 CBSuite，封装了服务粒度的熔断器和实例粒度的熔断器。\n  服务粒度熔断\n按照服务粒度进行熔断统计，通过 WithMiddleware 添加。服务粒度的具体划分取决于 Circuit Breaker Key，既熔断统计的 key，初始化 CBSuite 时需要传入 GenServiceCBKeyFunc，默认提供的是 circuitbreak.RPCInfo2Key ，该 key 的格式是 fromServiceName/toServiceName/method，即按照方法级别的异常做熔断统计。\n  实例粒度熔断\n按照实例粒度进行熔断统计，主要用于解决单实例异常问题，如果触发了实例级别熔断，框架会自动重试。\n注意，框架自动重试的前提是需要通过 WithInstanceMW 添加，WithInstanceMW 添加的 middleware 会在负载均衡后执行。\n  熔断阈值及阈值变更\n默认的熔断阈值是 ErrRate: 0.5, MinSample: 200，错误率达到 50% 触发熔断，同时要求统计量 \u003e200。若要调整阈值，调用 CBSuite 的 UpdateServiceCBConfig 和 UpdateInstanceCBConfig 来更新 Key 的阈值。\n   熔断器作用 在进行 RPC 调用时，下游服务难免会出错；\n当下游出现问题时，如果上游继续对其进行调用，既妨碍了下游的恢复，也浪费了上游的资源；\n为了解决这个问题，你可以设置一些动态开关，当下游出错时，手动的关闭对下游的调用；\n然而更好的办法是使用熔断器，自动化的解决这个问题。\n这里是一篇更详细的熔断器介绍。\n比较出名的熔断器当属 hystrix 了，这里是它的设计文档。\n熔断策略 熔断器的思路很简单：根据 RPC 的成功失败情况，限制对下游的访问；\n通常熔断器分为三个时期： CLOSED、OPEN、HALFOPEN；\nRPC 正常时，为 CLOSED；\n当 RPC 错误增多时，熔断器会被触发，进入 OPEN；\nOPEN 后经过一定的冷却时间，熔断器变为 HALFOPEN；\nHALFOPEN 时会对下游进行一些有策略的访问，然后根据结果决定是变为 CLOSED，还是 OPEN；\n总的来说三个状态的转换大致如下图：\n [CLOSED] ---\u003e tripped ----\u003e [OPEN]\u003c-------+ ^ | ^ | v | + | detect fail | | | | cooling timeout | ^ | ^ | v | +--- detect succeed --\u003c-[HALFOPEN]--\u003e--+ 触发策略 Kitex 默认提供了三个基本的熔断触发策略：\n  连续错误数达到阈值 (ConsecutiveTripFunc)\n  错误数达到阈值 (ThresholdTripFunc)\n  错误率达到阈值 (RateTripFunc)\n  当然，你可以通过实现 TripFunc 函数来写自己的熔断触发策略；\nCircuitbreaker 会在每次 Fail 或者 Timeout 时，去调用 TripFunc，来决定是否触发熔断；\n冷却策略 进入 OPEN 状态后，熔断器会冷却一段时间，默认是 10 秒，当然该参数可配置 (CoolingTimeout)；\n在这段时期内，所有的 IsAllowed() 请求将会被返回 false；\n冷却完毕后进入 HALFOPEN；\n半打开时策略 在 HALFOPEN 时，熔断器每隔 \" 一段时间 \" 便会放过一个请求，当连续成功 \" 若干数目 \" 的请求后，熔断器将变为 CLOSED； 如果其中有任意一个失败，则将变为 OPEN；\n该过程是一个逐渐试探下游，并打开的过程；\n上述的 \" 一段时间 “(DetectTimeout) 和 \" 若干数目 “(DEFAULT_HALFOPEN_SUCCESSES) 都是可以配置的；\n统计 默认参数 熔断器会统计一段时间窗口内的成功，失败和超时，默认窗口大小是 10S；\n时间窗口可以通过两个参数设置，不过通常情况下你可以不用关心 .\n统计方法 统计方法是将该段时间窗口分为若干个桶，每个桶记录一定固定时长内的数据；\n比如统计 10 秒内的数据，于是可以将 10 秒的时间段分散到 100 个桶，每个桶统计 100ms 时间段内的数据；\nOptions 中的 BucketTime 和 BucketNums，就分别对应了每个桶维护的时间段，和桶的个数；\n如将 BucketTime 设置为 100ms，将 BucketNums 设置为 100，则对应了 10 秒的时间窗口；\n抖动 随着时间的移动，窗口内最老的那个桶会过期，当最后那个桶过期时，则会出现了抖动；\n举个例子：\n  你将 10 秒分为了 10 个桶，0 号桶对应了 [0S，1S) 的时间，1 号桶对应 [1S，2S)，…，9 号桶对应 [9S，10S)；\n  在 10.1S 时，执行一次 Succ，则 circuitbreaker 内会发生下述的操作；\n (1) 检测到 0 号桶已经过期，将其丢弃； (2) 创建新的 10 号桶，对应 [10S，11S)； (3) 将该次 Succ 放入 10 号桶内；    在 10.2S 时，你执行 Successes() 查询窗口内成功数，则你得到的实际统计值是 [1S，10.2S) 的数据，而不是 [0.2S，10.2S)；\n  如果使用分桶计数的办法，这样的抖动是无法避免的，比较折中的一个办法是将桶的个数增多，可以降低抖动的影响；\n如划分 2000 个桶，则抖动对整体的数据的影响最多也就 1/2000； 在该包中，默认的桶个数也是 2000，桶时间为 5ms，总体窗口为 10S；\n当时曾想过多种技术办法来避免这种问题，但是都会引入更多其他的问题，如果你有好的思路，请 issue 或者 PR.\n","categories":"","description":"Kitex 熔断使用指南、原理介绍。","excerpt":"Kitex 熔断使用指南、原理介绍。","ref":"/zh/docs/kitex/tutorials/basic-feature/circuitbreaker/","tags":"","title":"熔断器"},{"body":"This middleware is used to hertz that logs HTTP request/response details and inspired by logger.\nInstall go get github.com/hertz-contrib/logger/accesslog Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New()) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } Config Hertz provides the accesslog.Option function to custom the log format and content.\nWithFormat The accesslog provides WithFormat to help users set the format of the log, default is [${time}] ${status} - ${latency} ${method} ${path}. The format parameter consists of ${tag}, The tag details are as follows Supported tags.\nFunction signatures:\nfunc WithFormat(s string) Option Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New(accesslog.WithFormat(\"[${time}] ${status} - ${latency} ${method} ${path} ${queryParams}\"))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } WithTimeFormat The accesslog provides WithTimeFormat to help users set the format of the time, default is 15:04:05. For specific information, please refer to the time package of go.\nFunction signatures:\nfunc WithTimeFormat(s string) Option Sample Code:\npackage main import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New( accesslog.WithTimeFormat(time.RFC822), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } WithTimeInterval The accesslog provides WithTimeInterval to help the user set the update interval of the timestamp, default is 500ms.\nFunction signatures:\nfunc WithTimeInterval(t time.Duration) Option Sample Code:\npackage main import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New( accesslog.WithTimeInterval(time.Second), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } WithAccessLogFunc The accesslog provides WithAccessLogFunc to help users set the log printing functions.\nFunction signatures:\nfunc WithAccessLogFunc(f func(ctx context.Context, format string, v ...interface{})) Option Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New( accesslog.WithAccessLogFunc(hlog.CtxInfof), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } WithTimeZoneLocation The accesslog provides WithTimeZoneLocation to help users set the log printing location.\nFunction signatures:\nfunc WithTimeZoneLocation(loc *time.Location) Option Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) location, err := time.LoadLocation(\"Asia/Shanghai\") if err != nil { return } h.Use(accesslog.New( accesslog.WithTimeZoneLocation(location), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } Log Format Default Log Format [${time}] ${status} - ${latency} ${method} ${path} example:\n[21:54:36] 200 - 2.906859ms GET /ping Supported tags    tag Introduction     pid pid   time time   referer the referer HTTP request header contains the absolute or partial address from which a resource has been requested   protocol protocol   port port   ip the ip info in Host   ips X-Forwarded-For   host host   method method   path path   url url   ua User-Agent   latency latency   status the status code of response   resBody response body   reqHeaders request headers   resHeaders response headers   queryParams request parameters   body request body   bytesSent the length of response body   bytesReceived the length of request body   route the path of route    Custom Tag We can add custom tags to the accesslog.Tags, but please note that it is not thread-safe.\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/bytebufferpool\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { accesslog.Tags[\"test_tag\"] = func(ctx context.Context, c *app.RequestContext, buf *bytebufferpool.ByteBuffer) (int, error) { return buf.WriteString(\"test\") } h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New(accesslog.WithFormat(\"${test_tag}\"))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } ","categories":"","description":"","excerpt":"This middleware is used to hertz that logs HTTP request/response …","ref":"/docs/hertz/tutorials/basic-feature/middleware/access-log/","tags":"","title":"access log"},{"body":"访问日志可以收集所有 HTTP 请求的详细信息，包括时间、端口、请求方法等。Hertz 也提供了 access log 的实现，这里的实现参考了 fiber。\n安装 go get github.com/hertz-contrib/logger/accesslog 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New()) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } 配置 用户可以通过自定义初始化配置来设置访问日志的格式以及内容。\nWithFormat 使用 WithFormat 自定义日志格式，默认的日志格式为 [${time}] ${status} - ${latency} ${method} ${path}。传入的格式方式为 ${tag}，具体 tag 参数可以参考下面的支持的标签。\n函数签名：\nfunc WithFormat(s string) Option 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New(accesslog.WithFormat(\"[${time}] ${status} - ${latency} ${method} ${path} ${queryParams}\"))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } WithTimeFormat 使用 WithTimeFormat 自定义时间格式，默认时间格式为 15:04:05， 具体格式可以参考该链接或者 go 的 time 包。\n函数签名：\nfunc WithTimeFormat(s string) Option 示例代码：\npackage main import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New( accesslog.WithTimeFormat(time.RFC822), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } WithTimeInterval 使用 WithTimeInterval 配置时间戳的刷新间隔，默认值为 500ms。\n函数签名：\nfunc WithTimeInterval(t time.Duration) Option 示例代码：\npackage main import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New( accesslog.WithTimeInterval(time.Second), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } WithAccessLogFunc 使用 WithAccessLogFunc 自定义日志打印函数。\n函数签名：\nfunc WithAccessLogFunc(f func(ctx context.Context, format string, v ...interface{})) Option 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New( accesslog.WithAccessLogFunc(hlog.CtxInfof), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } WithTimeZoneLocation 使用 WithTimeZoneLocation 自定义时区，默认使用当地时区。\n函数签名：\nfunc WithTimeZoneLocation(loc *time.Location) Option 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { h := server.Default( server.WithHostPorts(\":8080\"), ) location, err := time.LoadLocation(\"Asia/Shanghai\") if err != nil { return } h.Use(accesslog.New( accesslog.WithTimeZoneLocation(location), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } 日志格式 默认日志格式 [${time}] ${status} - ${latency} ${method} ${path} 例子:\n[21:54:36] 200 - 2.906859ms GET /ping 支持的标签    标签 介绍     pid 进程 ID   time 时间   referer 当前请求的来源页面地址   protocol 协议类型   port 端口   ip Host 中的 ip 地址   ips Header 中的 X-Forwarded-For   host HTTP 中的 Host   method 请求方法   path 请求路径   url 请求 url   ua User-Agent 的缩写   latency 处理消息的延迟   status HTTP 返回的状态码   resBody 返回内容   reqHeaders 请求的 Header 内容   resHeaders 返回的 Header 内容   queryParams 请求的 query 参数   body 请求的消息体内容   bytesSent 返回的消息体长度   bytesReceived 请求的消息体长度   route 请求路由的路径    标签扩展 支持自定义标签，前提要保证是线程安全的。\n代码示例:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/bytebufferpool\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/logger/accesslog\" ) func main() { accesslog.Tags[\"test_tag\"] = func(ctx context.Context, c *app.RequestContext, buf *bytebufferpool.ByteBuffer) (int, error) { return buf.WriteString(\"test\") } h := server.Default( server.WithHostPorts(\":8080\"), ) h.Use(accesslog.New(accesslog.WithFormat(\"${test_tag}\"))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{\"msg\": \"pong\"}) }) h.Spin() } ","categories":"","description":"","excerpt":"访问日志可以收集所有 HTTP 请求的详细信息，包括时间、端口、请求方法等。Hertz 也提供了 access log 的实现，这里的实现参 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/access-log/","tags":"","title":"访问日志"},{"body":"Secure is an HTTP middleware from Hertz that checks HTTP requests to quickly secure access requests. Secure middleware provides not only a default base configuration, but also a wide range of custom configuration options.\nThe implementation of the secure extension refers to the implementation of gin-contrib/secure.\nInstall Download and install\ngo get github.com/hertz-contrib/secure Import in your code\nimport \"github.com/hertz-contrib/secure\" Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/secure\" ) func main() { h := server.Default() // use default config  h.Use(secure.New()) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(200, \"pong\") }) h.Spin() } Config Instructions Most of the Secure configuration items are designed to simplify the user’s configuration of HTTP response headers, if you are confused about how to use HTTP headers, you can check it yourself in MDN Docs\nNew Secure provides the New() function for integrating Secure into Hertz, which is configured by default as follows\n   Configuration Description Default Value     WithSSLRedirect If WithSSLRedirect is set to true, only https requests will be allowed true   WithIsDevelopment If WithIsDevelopment is set to true, the entire security policy of the middleware application will be completely disabled false   WithSTSSecond WithSTSSecond is used to set the number of seconds for the max-age of Strict-Transport-Security 315360000   WithFrameDeny WithFrameDeny is used to set the value in X-Frame-Options, true sets the value to DENY true   WithContentTypeNosniff If WithContentTypeNosniff is set to true,  then add the nosniff value to the X-Content-Type-Options true   WithBrowserXssFilter If WithBrowserXssFilter is set to true,  then add the value 1; mode=block to the X-XSS-Protection header true   WithContentSecurityPolicy WithContentSecurityPolicy is used to configure policies in Content-Security-Policy “default-src ‘self’”   WithIENoOpen WithIENoOpen is used to prevent Internet Explorer from executing download tasks in the website, the default setting is true, that is, to prevent downloading true   WIthSSLProxyHeaders WIthSSLProxyHeaders is used to set the request headers map. If the request is insecure, the information in the request header is matched against the information in the request headers map. If it matches the corresponding value, the request is considered secure map[string]string{“X-Forwarded-Proto”: “https”}    Of course, in addition to these default configuration items, we have other configuration items that will be introduced later\nWithAllowHosts WithAllowHosts is used to set a whitelist of fully qualified domains that are allowed to be accessed, which defaults to an empty list by default, allowing any and all host names\nFunction signature:\nfunc WithAllowedHosts(ss []string) Option WithSSLTemporaryRedirect When WithSSLTemporaryRedirect is set to true, a 302 status code (StatusFound) will be used on redirects. Otherwise, 301 (StatusMovedPermanently) is used\nFunction signature:\nfunc WithSSLTemporaryRedirect(b bool) Option WithSSLHost WithSSLHost is used to set the host name to redirect http requests to https, default is \"\" which means use the same host name\nFunction signature:\nfunc WithSSLHost(s string) Option WithSTSIncludeSubdomains WhenWithSTSIncludeSubdomains is set to true, will be appended to the Strict-Transport-Security header. Default is false.\nFunction signature:\nfunc WithSTSIncludeSubdomains(b bool) Option WithCustomFrameOptionsValue Use WithCustomFrame-OptionsValue to fill in custom values in X-Frame-Options\nNote: This setting will override the WithFrameDeny  setting mentioned above\nFunction signature:\nfunc WithCustomFrame-OptionsValue(s string) Option WithReferrerPolicy WithReferrerPolicy is used to set the policy in the Referrer-Policy, which regulates the access source information that should be included in the generated request\nFunction signature:\nfunc WithReferrerPolicy(s string) Option WithBadHostHandler WithBadHostHandler is used to set the logic to handle the request when an error occurs, default return 403 (StatusForbidden) status code\nFunction signature:\nfunc WithBadHostHandler(handler app.HandlerFunc) Option Example:\npackage main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/secure\" ) func main() { h := server.New(server.WithHostPorts(\"127.0.0.1:8080\")) h.Use(secure.New( secure.WithAllowedHosts([]string{\"example.com\"}), secure.WithSSLHost(\"example.com\"), secure.WithBadHostHandler(func(ctx context.Context, c *app.RequestContext) { c.AbortWithStatusJSON(http.StatusForbidden, utils.H{ \"message\": \"this is a custom Bad Host Handler!\", }) }), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(200, \"pong\") }) h.Spin() } WithFeaturePolicy WithFeaturePolicy is used to set the policy of Feature-Policy\nFunction signature:\nfunc WithFeaturePolicy(s string) Option WithDontRedirectIPV4Hostnames When WithDontRedirectIPV4Hostnames is set to true, then requests for hostnames with IPV4 addresses will not be redirected. This is configured so that a health check like Loadbalancer’s setup succeeds.\nFunction signature:\nfunc WithDontRedirectIPV4Hostnames(b bool) Option ","categories":"","description":"","excerpt":"Secure is an HTTP middleware from Hertz that checks HTTP requests to …","ref":"/docs/hertz/tutorials/basic-feature/middleware/secure/","tags":"","title":"Secure"},{"body":"Secure 是 Hertz 的一个 HTTP 中间件 , 它可以通过检查 HTTP 请求以达到快速的保证访问请求安全(secure), 并且 Secure 中间件不仅提供了默认的基础配置, 还提供了大量的自定义配置选项可供选择。\n本中间件参考了 gin-contrib/secure 的实现\n安装 安装\ngo get github.com/hertz-contrib/secure 在工程中引入\nimport \"github.com/hertz-contrib/secure\" 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/secure\" ) func main() { h := server.Default() // use default config \th.Use(secure.New()) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(200, \"pong\") }) h.Spin() } 配置 使用须知 Secure 所提供的配置项是为了简化一些常见的 HTTP headers 的配置, 如对配置项配置 HTTP headers 的作用感到困惑, 可以自行在 MDN Docs 中进行查询它们的作用\nNew Secure 提供 New() 函数用于将 Secure 集成进入 Hertz。默认配置如下所示\n   配置函数 描述 默认值     WithSSLRedirect WithSSLRedirect 设置为 true, 则将只允许 https 请求访问 true   WithIsDevelopment 如果 WithIsDevelopment 设置为 true, 则中间件应用的整个安全策略将被完全禁用 false   WithSTSSecond WithSTSSecond 用于设置 Strict-Transport-Security 的 max-age 的秒数(second) 315360000   WithFrameDeny WithFrameDeny 用于设置 X-Frame-Options 中的值, 为 true 则设置值为 DENY true   WithContentTypeNosniff 如果 WithContentTypeNosniff 设置为 true,  则在 X-Content-Type-Options 中 添加 nosniff 值 true   WithBrowserXssFilter 如果 WithBrowserXssFilter 设置为 true,  则添加在 X-XSS-Protection头中添加 1; mode=block 的值 true   WithContentSecurityPolicy WithContentSecurityPolicy  用于配置 Content-Security-Policy 中的策略 “default-src ‘self’”   WithIENoOpen WithIENoOpen 用于防止 Internet Explorer 在网站的中执行下载任务, 默认设置为 true, 即阻止下载 true   WIthSSLProxyHeaders WIthSSLProxyHeaders 用于设置 request headers map。若请求是不安全的，就将请求头的信息和 request headers map 中的信息进行匹配。如果匹配到了相应的值，就把该请求视为安全的请求 map[string]string{“X-Forwarded-Proto”: “https”}    当然，除了这些默认的配置项，我们还有其他的配置项在后续介绍\nWithAllowHosts WithAllowHosts 用于设置一个允许访问的完全合格域名的白名单，该名单默认为默认为空列表，允许任何和所有的主机名称\n函数签名:\nfunc WithAllowedHosts(ss []string) Option WithSSLTemporaryRedirect WithSSLTemporaryRedirect 在设置为 true 时, 在重定向时将使用 302 状态码(StatusFound)。否则使用 301 (StatusMovedPermanently)\n函数签名:\nfunc WithSSLTemporaryRedirect(b bool) Option WithSSLHost WithSSLHost 用于设置将 http 请求重定向到 https 的主机名, 默认为 \"\" 表示使用同一个主机名\n函数签名:\nfunc WithSSLHost(s string) Option WithSTSIncludeSubdomains WithSTSIncludeSubdomains 设置为 true 时, 将会在 Strict-Transport-Security 中填入 includeSubdomains 的值, 默认值为 false\n函数签名:\nfunc WithSTSIncludeSubdomains(b bool) Option WithCustomFrameOptionsValue 使用 WithCustomFrameOptionsValue 可以在 X-Frame-Options 中填入自定义的值\n注意: 这一设置将会覆盖上文提到的 WithFrameDeny 的设置\n函数签名:\nfunc WithCustomFrameOptionsValue(s string) Option WithReferrerPolicy WithReferrerPolicy 用于设置 Referrer-Policy 中的策略, Referrer-Policy 监管的访问来源信息应当包含在生成的请求之中\n函数签名:\nfunc WithReferrerPolicy(s string) Option WithBadHostHandler WithBadHostHandler 用于设置在请求发生错误时的处理逻辑, 默认返回 403 (StatusForbidden) 状态码\n函数签名:\nfunc WithBadHostHandler(handler app.HandlerFunc) Option 示例:\npackage main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/hertz-contrib/secure\" ) func main() { h := server.New(server.WithHostPorts(\"127.0.0.1:8080\")) h.Use(secure.New( secure.WithAllowedHosts([]string{\"example.com\"}), secure.WithSSLHost(\"example.com\"), // 如果在启动服务器后访问 http://127.0.0.1:8080/ping, 就可以看到效果 \tsecure.WithBadHostHandler(func(ctx context.Context, c *app.RequestContext) { c.AbortWithStatusJSON(http.StatusForbidden, utils.H{ \"message\": \"this is a custom Bad Host Handler!\", }) }), )) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(200, \"pong\") }) h.Spin() } WithFeaturePolicy WithFeaturePolicy 用于设置 Feature-Policy 的策略\n函数签名:\nfunc WithFeaturePolicy(s string) Option WithDontRedirectIPV4Hostnames WithDontRedirectIPV4Hostnames 设置为 true 时, 那么对 IPV4 地址的主机名的请求就不会被重定向。这项配置为了让类似 Loadbalancer 的设置健康检查成功。\n函数签名:\nfunc WithDontRedirectIPV4Hostnames(b bool) Option ","categories":"","description":"","excerpt":"Secure 是 Hertz 的一个 HTTP 中间件 , 它可以通过检查 HTTP 请求以达到快速的保证访问请求安全(secure), 并 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/secure/","tags":"","title":"Secure"},{"body":"Rate limiting is an imperative technique to protect server, which prevents server from overloaded by sudden traffic increase from a client.\nKitex supports the user-defined QPS limiter and connections limiter, and provides default implementation.\nNote  When server.WithLimit and server.WithQPSLimiter or server.WithLimit and server.WithConnectionLimiter are used at the same time, only the latter will take effect. To save request deserialization overhead and improve performance, in non-multiplexing scenarios, Kitex’s default QPS limiter takes effect at the OnRead hook, while in multiplexing or user-defined QPS limiter scenarios, the current limiter takes effect at the OnMessage hook. This is to ensure that the user-defined QPS limiter can obtain the basic information of the request such as rpc method. Rate limiting only works on Thrift or Kitexpb protocols, but not for gRPC protocols. gRPC can use flow control to limit traffic at transport layer. Kitex provides WithGRPCInitialWindowSize and WithGRPCInitialConnWindowSize to set the flow control window size of stream and connection respectively. For details, see gRPC official documentation  Use default rate limiter code example import \"github.com/cloudwego/kitex/pkg/limit\" func main() { svr := xxxservice.NewServer(handler, server.WithLimit(\u0026limit.Option{MaxConnections: 10000, MaxQPS: 1000})) svr.Run() } Parameter description：\n  MaxConnections: max connections\n  MaxQPS: max QPS (Queries Per Second)\n  UpdateControl: provide the ability to modify the rate limit threshold dynamically, for example:\n  import \"github.com/cloudwego/kitex/pkg/limit\" // define your limiter updater to update limit threshold type MyLimiterUpdater struct { updater limit.Updater } func (lu *MyLimiterUpdater) YourChange() { // your logic: set new option as needed \tnewOpt := \u0026limit.Option{ MaxConnections: 20000, MaxQPS: 2000, } // update limit config \tisUpdated := lu.updater.UpdateLimit(newOpt) // your logic } func (lu *MyLimiterUpdater) UpdateControl(u limit.Updater) { lu.updater = u } //--- init server --- var lu = MyLimiterUpdater{} svr := xxxservice.NewServer(handler, server.WithLimit(\u0026limit.Option{MaxConnections: 10000, MaxQPS: 1000, UpdateControl: lu.UpdateControl})) Implementation The default ConcurrencyLimiter and RateLimiter are used respectively to limit max connection and max QPS.\n ConcurrencyLimiter：a simple counter； RateLimiter：token bucket algorithm is used here.  Monitoring The default limiters define the LimitReporter interface, which is used by rate limiting status monitoring, e.g. connection overloaded, QPS overloaded, etc.\nUsers may implement this interface and inject this implementation by WithLimitReporter if required.\n// LimitReporter is the interface define to report(metric or print log) when limit happen type LimitReporter interface { ConnOverloadReport() QPSOverloadReport() } Use user-defined rate limiter import ( \"context\" \"time\" \"github.com/cloudwego/kitex/pkg/limiter\" \"github.com/cloudwego/kitex/pkg/rpcinfo\" \"github.com/cloudwego/kitex/server\" ) type qpsLimiter struct{} func (l *qpsLimiter) Acquire(ctx context.Context) bool { ri := rpcinfo.GetRPCInfo(ctx) md := ri.From().Method() return acquire(md) // return true to allow this request } func (l *qpsLimiter) Status(ctx context.Context) (max, current int, interval time.Duration) { // max: the maximum number of requests allowed in the interval;  // current: the remaining number of requests allowed in the interval;  return } type connectionLimiter struct{} func (l *connectionLimiter) Acquire(ctx context.Context) bool { ri := rpcinfo.GetRPCInfo(ctx) addr := ri.From().Address() return acquire(addr) // return true to allow this connection } func (l *connectionLimiter) Release(ctx context.Context) { ri := rpcinfo.GetRPCInfo(ctx) addr := ri.From().Address() return release(addr) // release occupied resource by the connection, only called after the release is successful. } func (l *connectionLimiter) Status(ctx context.Context) (limit, occupied int) { // limit: the maximum number of connections allowed.  // occupied: the number of existing connections.  return } func main() { myQPSLimiter := \u0026qpsLimiter{} myConnectionLimiter := \u0026connectionLimiter{} svr := xxxservice.NewServer(handler, server.WithQPSLimiter(myQPSLimiter), server.WithConnectionLimiter(myConnectionLimiter)) svr.Run() } ","categories":"","description":"Usage guide for Kitex Default and Custom rate limiting.","excerpt":"Usage guide for Kitex Default and Custom rate limiting.","ref":"/docs/kitex/tutorials/basic-feature/limiting/","tags":"","title":"Rate Limiting"},{"body":"限流是一种保护 server 的措施，防止上游某个 client 流量突增导致 server 端过载。\n目前 Kitex 支持用户自定义的 QPS 限流器和连接数限流器，同时提供了默认的实现。\n注意事项  同时定义 server.WithLimit 和 server.WithQPSLimiter 或同时定义 server.WithLimit 和 server.WithConnectionLimiter 时，只有后者会生效。 为节省请求反序列化开销提高性能，在非多路复用场景下，Kitex 默认的 QPS 限流器是在 OnRead hook 处生效的，而在多路复用或使用自定义 QPS 限流器场景下，限流器在 OnMessage hook 处生效。这是为了保证自定义限流器能获取到请求的基本信息，避免在例如按 method 限流等场景下无法生效的问题。 目前的限流功能只对 Thrift、Kitexpb 协议生效，对 gRPC 协议暂不生效。gRPC 可采用流控在传输层面做流量限制，Kitex 提供了 WithGRPCInitialWindowSize 和 WithGRPCInitialConnWindowSize 分别用于设置 stream 和连接的流控窗口大小，详见gRPC官方文档  使用默认的限流器 代码示例 import \"github.com/cloudwego/kitex/pkg/limit\" func main() { svr := xxxservice.NewServer(handler, server.WithLimit(\u0026limit.Option{MaxConnections: 10000, MaxQPS: 1000})) svr.Run() } 参数说明：\n  MaxConnections 表示最大连接数\n  MaxQPS 表示最大 QPS\n  UpdateControl 提供动态修改限流阈值的能力，举例：\n  import \"github.com/cloudwego/kitex/pkg/limit\" // define your limiter updater to update limit threshold type MyLimiterUpdater struct { updater limit.Updater } func (lu *MyLimiterUpdater) YourChange() { // your logic: set new option as needed \tnewOpt := \u0026limit.Option{ MaxConnections: 20000, MaxQPS: 2000, } // update limit config \tisUpdated := lu.updater.UpdateLimit(newOpt) // your logic } func (lu *MyLimiterUpdater) UpdateControl(u limit.Updater) { lu.updater = u } //--- init server --- var lu = MyLimiterUpdater{} svr := xxxservice.NewServer(handler, server.WithLimit(\u0026limit.Option{MaxConnections: 10000, MaxQPS: 1000, UpdateControl: lu.UpdateControl})) 实现 默认限流器分别使用 ConcurrencyLimiter 和 RateLimiter 对最大连接数和最大 QPS 进行限流。\n ConcurrencyLimiter：简单的计数器； RateLimiter：这里的限流算法采用了 \" 令牌桶算法 “。  监控 默认限流器定义了 LimitReporter 接口，用于限流状态监控，例如当前连接数过多、QPS 过大等。\n如有需求，用户需要自行实现该接口，并通过 WithLimitReporter 注入。\n// LimitReporter is the interface define to report(metric or print log) when limit happen type LimitReporter interface { ConnOverloadReport() QPSOverloadReport() } 使用自定义的限流器 import ( \"context\" \"time\" \"github.com/cloudwego/kitex/pkg/limiter\" \"github.com/cloudwego/kitex/pkg/rpcinfo\" \"github.com/cloudwego/kitex/server\" ) type qpsLimiter struct{} func (l *qpsLimiter) Acquire(ctx context.Context) bool { ri := rpcinfo.GetRPCInfo(ctx) md := ri.From().Method() return acquire(md) // return true to allow this request } func (l *qpsLimiter) Status(ctx context.Context) (max, current int, interval time.Duration) { // max: the maximum number of requests allowed in the interval;  // current: the remaining number of requests allowed in the interval;  return } type connectionLimiter struct{} func (l *connectionLimiter) Acquire(ctx context.Context) bool { ri := rpcinfo.GetRPCInfo(ctx) addr := ri.From().Address() return acquire(addr) // return true to allow this connection } func (l *connectionLimiter) Release(ctx context.Context) { ri := rpcinfo.GetRPCInfo(ctx) addr := ri.From().Address() return release(addr) // release occupied resource by the connection, only called after the release is successful. } func (l *connectionLimiter) Status(ctx context.Context) (limit, occupied int) { // limit: the maximum number of connections allowed.  // occupied: the number of existing connections.  return } func main() { myQPSLimiter := \u0026qpsLimiter{} myConnectionLimiter := \u0026connectionLimiter{} svr := xxxservice.NewServer(handler, server.WithQPSLimiter(myQPSLimiter), server.WithConnectionLimiter(myConnectionLimiter)) svr.Run() } ","categories":"","description":"Kitex 默认限流和自定义限流使用指南。","excerpt":"Kitex 默认限流和自定义限流使用指南。","ref":"/zh/docs/kitex/tutorials/basic-feature/limiting/","tags":"","title":"限流"},{"body":"Hertz provides users with customized retry logic,Let’s take a look at how to use Client Retry. Note: Hertz version \u003e= v0.4.0\nRetry times and delay policy configuration First create a Client, and use the configuration item WithRetryConfig() to configure the Retry related logic. (This section mainly configures the times of retry and the delay policy)\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/client/retry\" ) func main() { cli, err := client.NewClient( client.WithRetryConfig( retry.WithXxx(), // the method of setting retry config \t), ) }    Configuration Name Type Description     WithMaxAttemptTimes uint Set the maximum attempts times. Default：1 times (That is, only request once without retry)   WithInitDelay time.Duration Set initial delay time. Default: 1ms   WithMaxDelay time.Duration Set the maximum delay time. Default: 100ms   WithMaxJitter time.Duration Set the maximum jitter time, which needs to be used in conjunction with RandomDelayPolicy, and will generate a random time not exceeding the maximum jitter time. Default: 20ms   WithDelayPolicy type DelayPolicyFunc func(attempts uint, err error, retryConfig *Config) time.Duration Set the delay policy, you can use any combination of the following four policies, FixedDelayPolicy, BackOffDelayPolicy, RandomDelayPolicy, DefaultDelayPolicy ( See the next section Delay Policy for details ) . Default: DefaultDelayPolicy (That is, the retry delay is 0)    Delay Policy retry.WithDelayPolicy() usage\ncli, err := client.NewClient( client.WithRetryConfig( ... retry.WithDelayPolicy(retry.CombineDelay(retry.FixedDelayPolicy, retry.BackOffDelayPolicy, retry.RandomDelayPolicy)), ... ), )    Function Name Description     CombineDelay It is used to combine any of the following four policies and sum the values calculated by the selected policy. When you only need one of the following four policies, you can choose to use CombineDelay or directly pass any policy into WithDelayPolicy as a parameter   FixedDelayPolicy Set the fixed delay time and use the value set by WithInitDelay to generate an equivalent delay time   BackOffDelayPolicy Set the exponential delay time. Use the value set by WithInitDelay. The exponential delay time is generated according to the number of retries currently   RandomDelayPolicy Set the random delay time. Use the value set by WithMaxJitter to generate a random delay time that does not exceed this value   DefaultDelayPolicy Set the default delay time (That is, 0) . Generally, it is used alone and has no effect when combined with other policies    Complete example package main import ( \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/client/retry\" ) func main() { cli, err := client.NewClient( client.WithRetryConfig( retry.WithMaxAttemptTimes(3), // Maximum number of attempts, including initial calls \tretry.WithInitDelay(1*time.Millisecond), // Initial delay \tretry.WithMaxDelay(6*time.Millisecond), // Maximum delay.No matter how many retries and what the policy is, the delay will not exceed this delay \tretry.WithMaxJitter(2*time.Millisecond), // Maximum jitter delay, which will have effect only when combined with RandomDelayPolicy \t/* To configure the delay policy, you can select any combination of the following four, and the final result is the sum of each delay policy. FixedDelayPolicy uses the value set by retry.WithInitDelay, BackOffDelayPolicy increases exponentially with the number of retries based on the value set by retry.WithInitDelay, RandomDelayPolicy generates a random value of [0, 2*time.Millisecond). 2*time.Millisecond is the value set by retry.WithMaxJitter, DefaultDelayPolicy generates a value of 0. If it is used alone, retry again immediately, retry.CombineDelay() sums the values generated by the set delay policy, and the final result is the delay time of the current retry, The first call failed -\u003e Retry delay：1 + 1\u003c\u003c1 + rand[0,2)ms -\u003e The second call failed -\u003e Retry delay：min(1 + 1\u003c\u003c2 + rand[0,2) , 6)ms -\u003e The third call succeeded/failed */ retry.WithDelayPolicy(retry.CombineDelay(retry.FixedDelayPolicy, retry.BackOffDelayPolicy, retry.RandomDelayPolicy)), ), ) } Retry condition configuration If you want to customize the conditions under which retries occur, you can use client SetRetryIfFunc() configuration. The parameter of this function is a function, and the signature is:\nfunc(req *protocol.Request, resp *protocol.Response, err error) bool Relevant parameters include the req, resp and err fields in the Hertz request. You can use these parameters to determine whether the request should be retried. In the following example, when the status code returned by the request is not 200 or err!=nil during the call, we return true, that is, we retry.\ncli.SetRetryIfFunc(func(req *protocol.Request, resp *protocol.Response, err error) bool { return resp.StatusCode() != 200 || err != nil }) Note that if you do not set client SetRetryIfFunc() . We will judge according to Hertz’s default retry conditions, that is, whether the request meets the following DefaultRetryIf() function and whether the call is idempotent. ( Idempotent call: when canIdempotentRetry is true in pkg/protocol/http1/client.go::Do() and pkg/protocol/http1/client.go::doNonNilReqResp() )\n// DefaultRetryIf Default retry condition, mainly used for idempotent requests. // If this cannot be satisfied, you can implement your own retry condition. func DefaultRetryIf(req *protocol.Request, resp *protocol.Response, err error) bool { // cannot retry if the request body is not rewindable  if req.IsBodyStream() { return false } if isIdempotent(req, resp, err) { return true } // Retry non-idempotent requests if the server closes  // the connection before sending the response.  //  // This case is possible if the server closes the idle  // keep-alive connection on timeout.  //  // Apache and nginx usually do this.  if err == io.EOF { return true } return false } func isIdempotent(req *protocol.Request, resp *protocol.Response, err error) bool { return req.Header.IsGet() || req.Header.IsHead() || req.Header.IsPut() || req.Header.IsDelete() || req.Header.IsOptions() || req.Header.IsTrace() } Table - 1 When canIdempotentRetry in Hertz source code doNonNilReqResp() is true.\n   doNonNilReqResp() return true     err = conn.SetWriteDeadline(currentTime.Add(c.WriteTimeout))   err = reqI.Write(req, zw)   err = reqI.ProxyWrite(req, zw)   err = zw.Flush()   err = conn.SetReadTimeout(c.ReadTimeout)   ( err = respI.ReadHeaderAndLimitBody() || err = respI.ReadBodyStream() ) \u0026\u0026 (err != errs.ErrBodyTooLarge)    ","categories":"","description":"","excerpt":"Hertz provides users with customized retry logic,Let’s take a look at …","ref":"/docs/hertz/tutorials/basic-feature/retry/","tags":"","title":"Retry"},{"body":"Hertz 为用户提供了自定义的重试逻辑，下面来看一下 Client 的 Retry 使用方法。注意：Hertz 版本 \u003e= v0.4.0\nRetry 次数及延迟策略配置 首先创建 Client ，使用配置项 WithRetryConfig() 来配置 Retry 相关逻辑（这一部分主要配置 Retry 的次数和延时部分）\npackage main import ( \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/client/retry\" ) func main() { cli, err := client.NewClient( client.WithRetryConfig( retry.WithXxx(), // 设置 Retry 配置的方式 \t), ) }    配置名称 类型 介绍     WithMaxAttemptTimes uint 用于设置最大尝试次数，默认1次（即只请求1次不重试）   WithInitDelay time.Duration 用于设置初始延迟时间，默认 1ms   WithMaxDelay time.Duration 用于设置最大延迟时间，默认100ms   WithMaxJitter time.Duration 用于设置最大扰动时间，需要配合 RandomDelayPolicy 使用，会生成不超过最大扰动时间的随机时间，默认20ms   WithDelayPolicy type DelayPolicyFunc func(attempts uint, err error, retryConfig *Config) time.Duration 用于设置延迟策略，可以使用以下四种的任意结合， FixedDelayPolicy, BackOffDelayPolicy, RandomDelayPolicy, DefaultDelayPolicy（详情见下一小节: 延迟策略）默认使用 DefaultDelayPolicy （即重试延迟为0）    延迟策略 retry.WithDelayPolicy() 使用方法\ncli, err := client.NewClient( client.WithRetryConfig( ... retry.WithDelayPolicy(retry.CombineDelay(retry.FixedDelayPolicy, retry.BackOffDelayPolicy, retry.RandomDelayPolicy)), ... ), )    函数名称 说明     CombineDelay 用于将下面四种策略进行任意组合，将所选策略计算出的值进行加和。当你只需要下面四种策略中的一种时，你可以选择使用 CombineDelay 或选择直接将任意一种策略传入 WithDelayPolicy 作为参数   FixedDelayPolicy 用于设置固定延迟时间，使用 WithInitDelay 设置的值，来生成等值的延迟时间   BackOffDelayPolicy 用于设置指数级延迟时间，使用 WithInitDelay 设置的值，根据当前是第几次重试，指数级生成延迟时间   RandomDelayPolicy 用于设置随机延迟时间，使用 WithMaxJitter 设置的值，生成不超过该值的随机延迟时间   DefaultDelayPolicy 用于设置默认延迟时间，返回 0 ，一般单独使用，和其他策略结合没有效果    完整示例 package main import ( \"github.com/cloudwego/hertz/pkg/app/client\" \"github.com/cloudwego/hertz/pkg/app/client/retry\" ) func main() { cli, err := client.NewClient( client.WithRetryConfig( retry.WithMaxAttemptTimes(3), // 最大的尝试次数，包括初始调用 \tretry.WithInitDelay(1*time.Millisecond), // 初始延迟 \tretry.WithMaxDelay(6*time.Millisecond), // 最大延迟，不管重试多少次，策略如何，都不会超过这个延迟 \tretry.WithMaxJitter(2*time.Millisecond), // 延时的最大扰动，结合 RandomDelayPolicy 才会有效果 \t/* 配置延迟策略，你可以选择下面四种中的任意组合，最后的结果为每种延迟策略的加和 FixedDelayPolicy 使用 retry.WithInitDelay 所设置的值 ， BackOffDelayPolicy 在 retry.WithInitDelay 所设置的值的基础上随着重试次数的增加，指数倍数增长， RandomDelayPolicy 生成 [0，2*time.Millisecond）的随机数值 ，2*time.Millisecond 为 retry.WithMaxJitter 所设置的值， DefaultDelayPolicy 生成 0 值，如果单独使用则立刻重试， retry.CombineDelay() 将所设置的延迟策略所生成的值加和，最后结果即为当前次重试的延迟时间， 第一次调用失败 -\u003e 重试延迟：1 + 1\u003c\u003c1 + rand[0,2)ms -\u003e 第二次调用失败 -\u003e 重试延迟：min(1 + 1\u003c\u003c2 + rand[0,2) , 6)ms -\u003e 第三次调用成功/失败 */ retry.WithDelayPolicy(retry.CombineDelay(retry.FixedDelayPolicy, retry.BackOffDelayPolicy, retry.RandomDelayPolicy)), ), ) } Retry 条件配置 如果你想要自定义配置重试发生的条件，你可以使用 client.SetRetryIfFunc() 配置，该函数的参数是一个函数，签名为:\nfunc(req *protocol.Request, resp *protocol.Response, err error) bool 相关参数包括 Hertz 请求中的 req、resp 和 err 字段，你可以通过这些参数，判断这个请求该不该重试。在如下例子中，当请求返回的状态码不是 200 或者调用过程中 err != nil 时我们返回 true，即进行重试。\ncli.SetRetryIfFunc(func(req *protocol.Request, resp *protocol.Response, err error) bool { return resp.StatusCode() != 200 || err != nil }) 需要注意的是，如果你没有设置 client.SetRetryIfFunc() 。我们将会按照 Hertz 默认的重试发生条件进行判断，即判断请求是否满足下面的 DefaultRetryIf() 函数并且判断该调用是否是幂等调用（幂等调用：即 pkg/protocol/http1/client.go::Do() 和 pkg/protocol/http1/client.go::doNonNilReqResp() 中 canIdempotentRetry 为 true 的情况）\n// DefaultRetryIf Default retry condition, mainly used for idempotent requests. // If this cannot be satisfied, you can implement your own retry condition. func DefaultRetryIf(req *protocol.Request, resp *protocol.Response, err error) bool { // cannot retry if the request body is not rewindable  if req.IsBodyStream() { return false } if isIdempotent(req, resp, err) { return true } // Retry non-idempotent requests if the server closes  // the connection before sending the response.  //  // This case is possible if the server closes the idle  // keep-alive connection on timeout.  //  // Apache and nginx usually do this.  if err == io.EOF { return true } return false } func isIdempotent(req *protocol.Request, resp *protocol.Response, err error) bool { return req.Header.IsGet() || req.Header.IsHead() || req.Header.IsPut() || req.Header.IsDelete() || req.Header.IsOptions() || req.Header.IsTrace() } Table - 1 Hertz 源码 doNonNilReqResp() 中 canIdempotentRetry 为 true 的情况\n   doNonNilReqResp() 返回 true 的情况     err = conn.SetWriteDeadline(currentTime.Add(c.WriteTimeout))   err = reqI.Write(req, zw)   err = reqI.ProxyWrite(req, zw)   err = zw.Flush()   err = conn.SetReadTimeout(c.ReadTimeout)   ( err = respI.ReadHeaderAndLimitBody() || err = respI.ReadBodyStream() ) \u0026\u0026 (err != errs.ErrBodyTooLarge)    ","categories":"","description":"","excerpt":"Hertz 为用户提供了自定义的重试逻辑，下面来看一下 Client 的 Retry 使用方法。注意：Hertz 版本 \u003e= v0.4.0 …","ref":"/zh/docs/hertz/tutorials/basic-feature/retry/","tags":"","title":"重试"},{"body":"会议主题 ：CloudWeGo 社区会议 7.14\n参会人 ：GuangmingLuo, Cheng Guozhu, simon0-o, welkeyever, YangruiEmma, liu-song, Ivnszn, CoderPoet, li-jin-gou, joway, bodhisatan, Fan Guangyu, Jacob953, Wang Yafeng, gova, Huang Xiaolong, Zhang Guiyuan, chenzBin, yccpt, jayantxie, baiyutang, skyenought, yiyun, rogerogers, Zhou Xinyi, baize, LhdDream, Li Congyan, Liu Jia\n会前必读 ：http://www.cloudwego.io/；https://github.com/cloudwego\n议程 1 ：新人自我介绍  新成员名单：@王亚峰 @张桂元 @周鑫宜 @rogerogers 社区新成员分别进行自我介绍，主要包含个人基本情况、开源贡献经历和后续参与社区工作内容。   议程 2 ：Hertz-Contrib/Limiter 组件分享 @LhdDream  介绍PPT：过载保护-限流算法.pptx 相关讨论：   Q： 造成 CPU 负载的因素很多，如何判断这是通过访问量或者高并发请求产生的负载？有时用户的加码程序或者某些在系统上跑的程序也会导致 CPU 负载很高，会不会有限流失误的问题？ A： 如果一个程序出现了问题，CPU 已经负载很高的时候，也没有必要再承担一个请求，因为这个机器的性能已经达到了负荷。  后续补充限流算法相关案例和使用算法的趋势图，方便直观感受使用这个组件带来的收益。   议程 3 ：Hertz-Contrib/Obs-Opentelemetry 设计与应用场景介绍 @CoderPoet  地址：github.com/hertz-contrib/obs-opentelemetry    默认提供开箱即用 OpenTelemetry Provider；\n  对 Hertz 做了一些 Instrumentation，主要有三点：\n Tracing  Support server and client Hertz http tracing Support automatic transparent transmission of peer service through http headers // 基于对端服务信息透传，实现服务拓扑能力   Metrics  Support Hertz http metrics [R.E.D] // 做 http metrics 的埋点，实现一些服务的黄金指标 Support service topology map metrics [Service Topology Map] // 基于 http headers 透传对端服务信息，生成 Service Topology Map Support go runtime metrics   Logging  Extend Hertz logger based on logrus Implement tracing auto associated logs // 拓展 Hertz logger 接口，基于 logrus hook 机制，从 Context 里面提取相应的 trace context 放到日志里，通过这样的模式实现 trace context 和日志的串联      OpenTelemetry 目标是实现 Tracing/Metrics/Logging 三个数据的互联互通，但三者本身的成熟度上不同步，在社区状态中，Tracing 基本都是 Stable，Metrics 只有 API 和协议是 Stable 状态，Logging 是 Draft 状态。相关链接：https://opentelemetry.io/status/ Hertz 并不是把 Logging 的 API 集成起来，而只是把协议里面提到的比如 Log Model、Trace ID 如何定义等规范集成，所以即使 Logging 没有达到一定成熟度，也可以使用。关于使用场景：   如果想要实现全链路观测，可以直接集成该。比如访问 Hertz Server 和 Kitex Server 会有一个简单的链路串联，可以输入一些自定义的属性，并且默认也会帮你输入根据 OpenTelemetry 语法规范做的、协议相关的属性； 如果想自动做请求维度的一些 RED 指标，比如计算 QPS，只要去把数据源导入就可以做相应的面板绘制； Runtime Metrics 也做了自动集成，可以在 Dashboard 里面绘制相应状态； 最新的 Jaeger 已经原生支持 OTLP Protocol 获取协议，相当于我们的库可以直接跟 Jaeger Collector 做集成，不需要用 OpenTelemetry Collector 做数据中转。  使用场景：github.com/cloudwego/hertz-examples/tree/main/opentelemetry\n相关讨论：   Q： 如果在 Hertz 使用 Obs 扩展，比如有一个 Trace ID，想快速找到有问题的请求，有没有可能就是把这个 Trace ID 或者是能够唯一标识这一次链路追踪的 ID 返回到 Response 里面去呢？ A： 目前对于这种错误链路，可以在尾采样中做异常全采，不用借助 Response，可以直接在链路搜索里面找到相应的错误那条 Trace，然后看它上游或者下游哪些地方发生了异常。   议程 4：关于 Hertz-Template 的优化建议与讨论 @skyenought  相关文档：关于 Hertz template 的新 feat  原本如果要定义 Template，所有内容都写在 YAML 文件里，需要转移符号判断文本，这样看起来可读性比较差、耦合度高。解决方案是不使用 Body 关键字，添加 TemplatePath，只描述Template 文件在这个项目中的位置，这样分散开来比较方便修改和浏览。经过逻辑判断，要保证 Body 和 TemplatePath 不能同时使用，这样可能会造成混乱。如果是 Body 就直接读 Body 的值，如果是 TemplatePath 就通过 IO 把内容读进来以后再进行模版分析。优化实现有待进一步讨论。\n相关文档：Hertz 和 Kitex 对于 IDL 的不同处理  Q： CloudWeGo 一个组织中，代码风格却大不相同。Kitex 因为有 Netpoll 存在，只针对 Linux 环境，所以对后缀不做限定。Hertz 在 Go net, windows 和 Linux 环境都可进行开发，它拥有强规定。它们为什么不能统一风格呢？\nA： Apache Thrift 的官方并没有对 Thrift 文件后缀有明确规定，从长期大量的实践来看，有很多用户不会把 Thrift 文件的后缀给改为 .Thrift。在内部，以 HTTP 的 IDL 举例，基本都是以 Thrift 或者 PB 的形式存在，所以说我们没有考虑制定拓展名。\n 议程 5： 关于新增的 Biz-Demo 的后续规划 @GuangmingLuo  地址：https://github.com/cloudwego/biz-demo 新增 Biz-Demo 仓库。第一，存放同时集成 Hertz example 和 Kitex example 的案例；第二，存放各行各业最佳企业落地实践 Examples。正式呼吁感兴趣的同学提交有价值的业务案例！ 提交案例可以帮助同学从新手期向成熟期过渡，同时可以更深入地了解各个技术栈，得到较大的自我提升。后续会将好的 Business Demo 做一些推广，在官网上和公众号上都会有展示。参考案例：https://github.com/cloudwego/kitex-examples/pull/28   议程 6：Hertz 源码解读活动介绍 @yiyun  源码解读活动一期结束，对于 RPC 相关基础知识整理了 1.6 万字，可以在 Community 仓库查看。 源码解读活动二期已经开始，期间有四期直播分享：   了解 HTTP 框架的设计； 上手企业级 HTTP 框架 Hertz 的操作实践； CSG 一期源码解读优秀成员分享如何进行源码解读； 社区 Committer 和 Go 夜读作者分享，如何规划自己的代码学习和提升路径。  欢迎大家关注 CloudWeGo 公众号获取相关信息。\n活动相关资料 Issue 地址：https://github.com/cloudwego/community/issues/33\n第一期直播回顾：https://meetings.feishu.cn/s/1i38ftnck0f18?src_type=3\u0026disable_cross_redirect=true\n第二期直播回顾：https://meetings.feishu.cn/s/1i3fsqit6jchu?src_type=3\n","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 7.14\n参会人 ：GuangmingLuo, Cheng Guozhu, simon0-o, …","ref":"/zh/community/meeting_notes/2022-07-14/","tags":"","title":"CloudWeGo 社区会议 7.14"},{"body":"Metadata transparently transmission transmits some additional RPC information to the downstream based on the transport protocol, and reads the upstream transparently transmitted information carried by transport protocol. The transparently transmitted field needs to be combined with the internal governance capability. It is recommended that users extend and implement it by themselves.\nExtension API // MetaHandler reads or writes metadata through certain protocol. // The protocol will be a thrift.TProtocol usually. type MetaHandler interface { WriteMeta(ctx context.Context, msg Message) (context.Context, error) ReadMeta(ctx context.Context, msg Message) (context.Context, error) } Extension Example  ClientMetaHandler  package transmeta var\tClientTTHeaderHandler remote.MetaHandler = \u0026clientTTHeaderHandler{} // clientTTHeaderHandler implement remote.MetaHandler type clientTTHeaderHandler struct{} // WriteMeta of clientTTHeaderHandler writes headers of TTHeader protocol to transport func (ch *clientTTHeaderHandler) WriteMeta(ctx context.Context, msg remote.Message) (context.Context, error) { ri := msg.RPCInfo() transInfo := msg.TransInfo() hd := map[uint16]string{ transmeta.FromService: ri.From().ServiceName(), transmeta.FromIDC: ri.From().DefaultTag(consts.IDC, \"\"), transmeta.FromMethod: ri.From().Method(), transmeta.ToService: ri.To().ServiceName(), transmeta.ToMethod: ri.To().Method(), transmeta.MsgType: strconv.Itoa(int(msg.MessageType())), } transInfo.PutTransIntInfo(hd) if metainfo.HasMetaInfo(ctx) { hd := make(map[string]string) metainfo.SaveMetaInfoToMap(ctx, hd) transInfo.PutTransStrInfo(hd) } return ctx, nil } // ReadMeta of clientTTHeaderHandler reads headers of TTHeader protocol from transport func (ch *clientTTHeaderHandler) ReadMeta(ctx context.Context, msg remote.Message) (context.Context, error) { ri := msg.RPCInfo() remote := remoteinfo.AsRemoteInfo(ri.To()) if remote == nil { return ctx, nil } transInfo := msg.TransInfo() strInfo := transInfo.TransStrInfo() ad := strInfo[transmeta.HeaderTransRemoteAddr] if len(ad) \u003e 0 { // when proxy case to get the actual remote address \t_ = remote.SetRemoteAddr(utils.NewNetAddr(\"tcp\", ad)) } return ctx, nil }   Customized ClientMetaHandler Usage\ncli, err := xxxservice.NewClient(targetService, client.WithMetaHandler(transmeta.ClientTTHeaderHandler))   ","categories":"","description":"","excerpt":"Metadata transparently transmission transmits some additional RPC …","ref":"/docs/kitex/tutorials/framework-exten/transmeta/","tags":"","title":"Extension of Metadata Transparent Transmission"},{"body":"Transport Pipeline refers to Netty ChannelPipeline and provides Inbound and Outbound interfaces to support message or I/O event extensions. TLS, Traffic Limit, Transparent Transmission Processing can be extended based on In/OutboundHandler. As shown in the figure below, each BoundHandler is executed in series.\nExtension API // OutboundHandler is used to process write event. type OutboundHandler interface { Write(ctx context.Context, conn net.Conn, send Message) (context.Context, error) } // InboundHandler is used to process read event. type InboundHandler interface { OnActive(ctx context.Context, conn net.Conn) (context.Context, error) OnInactive(ctx context.Context, conn net.Conn) context.Context OnRead(ctx context.Context, conn net.Conn) (context.Context, error) OnMessage(ctx context.Context, args, result Message) (context.Context, error) } Default Extensions   Traffic Limit Handler of Server Side\nKitex supports connection level and request level limiting. The purpose of limiting is to ensure service availability. When the threshold is reached, the request should be limited in time. And the purpose of implementing limit in transport layer is to limit traffic in a timely manner. The implementation is in limiter_inbound.go.\n Limiting of Connection level implements OnActive(), OnInactive() Limiting of Request level implements OnRead()    Metadata Transparent Transmission Handler\nMeta information transparent transmission is to transmit some RPC additional information to the downstream based on the transport protocol, and read the upstream transparent transmission information carried by transport protocol. The implementation is in transmeta_bound.go.\n Write metainfo implements Write() Read metainfo implements OnMessage()  In order to make it more convenient to extend Metadata Transparent Transmission for users, Kitex defines the separately extension API MetaHandler.\n// MetaHandler reads or writes metadata through certain protocol. type MetaHandler interface { WriteMeta(ctx context.Context, msg Message) (context.Context, error) ReadMeta(ctx context.Context, msg Message) (context.Context, error) }   Customized BoundHandler Usage   Server Side\noption: WithBoundHandler\nsvr := xxxservice.NewServer(handler, server.WithBoundHandler(yourBoundHandler))   Client Side\noption: WithBoundHandler\ncli, err := xxxservice.NewClient(targetService, client.WithBoundHandler(yourBoundHandler))   ","categories":"","description":"","excerpt":"Transport Pipeline refers to Netty ChannelPipeline and provides …","ref":"/docs/kitex/tutorials/framework-exten/trans_pipeline/","tags":"","title":"Extension of Transport Pipeline-Bound"},{"body":"Transport Pipeline 参考 Netty ChannelPipeline，提供 Inbound 和 Outbound 接口，支持对消息或 I/O 事件扩展。基于 In/OutboundHandler 可以扩展实现 TLS、限流、透传信息处理等。如下图所示，各个 BoundHandler 会串行依次执行。\n接口定义 // OutboundHandler is used to process write event. type OutboundHandler interface { Write(ctx context.Context, conn net.Conn, send Message) (context.Context, error) } // InboundHandler is used to process read event. type InboundHandler interface { OnActive(ctx context.Context, conn net.Conn) (context.Context, error) OnInactive(ctx context.Context, conn net.Conn) context.Context OnRead(ctx context.Context, conn net.Conn) (context.Context, error) OnMessage(ctx context.Context, args, result Message) (context.Context, error) } 默认扩展   服务端限流 Handler\nKitex 支持连接级别和请求级别限流，限流是为了保障服务的可用性，当达到阈值应当及时限流，放到 Transport 层可以达到及时限流的目的，实现见 limiter_inbound.go。\n 连接级别限流 OnActive(), OnInactive() 请求级别限流 OnRead()    元信息透传 Handler\n元信息透传是基于传输协议透传一些 RPC 额外的信息给下游，同时读取传输协议中上游透传的信息，实现见 transmeta_bound.go。\n 写入透传信息 Write() 读取透传信息 OnMessage()  为更明确的为使用者元信息透传的扩展能力，Kitex 单独定义了信息透传的处理接口 MetaHandler，这里会执行 MetaHandler 进行透传信息的处理。\n// MetaHandler reads or writes metadata through certain protocol. type MetaHandler interface { WriteMeta(ctx context.Context, msg Message) (context.Context, error) ReadMeta(ctx context.Context, msg Message) (context.Context, error) }   指定自定义的 BoundHandler   服务端\noption: WithBoundHandler\nsvr := xxxservice.NewServer(handler, server.WithBoundHandler(yourBoundHandler))   调用端\noption: WithBoundHandler\ncli, err := xxxservice.NewClient(targetService, client.WithBoundHandler(yourBoundHandler))   ","categories":"","description":"","excerpt":"Transport Pipeline 参考 Netty ChannelPipeline，提供 Inbound 和 Outbound 接口，支 …","ref":"/zh/docs/kitex/tutorials/framework-exten/trans_pipeline/","tags":"","title":"Transport Pipeline-Bound 扩展"},{"body":"元信息透传是基于传输协议透传一些额外的 RPC 信息给下游，同时读取传输协议中上游透传的信息，透传字段需结合内部的治理能力，建议使用者自行扩展实现。\n接口定义 // MetaHandler reads or writes metadata through certain protocol. // The protocol will be a thrift.TProtocol usually. type MetaHandler interface { WriteMeta(ctx context.Context, msg Message) (context.Context, error) ReadMeta(ctx context.Context, msg Message) (context.Context, error) } 扩展示例  ClientMetaHandler  package transmeta var\tClientTTHeaderHandler remote.MetaHandler = \u0026clientTTHeaderHandler{} // clientTTHeaderHandler implement remote.MetaHandler type clientTTHeaderHandler struct{} // WriteMeta of clientTTHeaderHandler writes headers of TTHeader protocol to transport func (ch *clientTTHeaderHandler) WriteMeta(ctx context.Context, msg remote.Message) (context.Context, error) { ri := msg.RPCInfo() transInfo := msg.TransInfo() hd := map[uint16]string{ transmeta.FromService: ri.From().ServiceName(), transmeta.FromIDC: ri.From().DefaultTag(consts.IDC, \"\"), transmeta.FromMethod: ri.From().Method(), transmeta.ToService: ri.To().ServiceName(), transmeta.ToMethod: ri.To().Method(), transmeta.MsgType: strconv.Itoa(int(msg.MessageType())), } transInfo.PutTransIntInfo(hd) if metainfo.HasMetaInfo(ctx) { hd := make(map[string]string) metainfo.SaveMetaInfoToMap(ctx, hd) transInfo.PutTransStrInfo(hd) } return ctx, nil } // ReadMeta of clientTTHeaderHandler reads headers of TTHeader protocol from transport func (ch *clientTTHeaderHandler) ReadMeta(ctx context.Context, msg remote.Message) (context.Context, error) { ri := msg.RPCInfo() remote := remoteinfo.AsRemoteInfo(ri.To()) if remote == nil { return ctx, nil } transInfo := msg.TransInfo() strInfo := transInfo.TransStrInfo() ad := strInfo[transmeta.HeaderTransRemoteAddr] if len(ad) \u003e 0 { // when proxy case to get the actual remote address \t_ = remote.SetRemoteAddr(utils.NewNetAddr(\"tcp\", ad)) } return ctx, nil }   添加该 ClientMetaHandler\ncli, err := xxxservice.NewClient(targetService, client.WithMetaHandler(transmeta.ClientTTHeaderHandler))   ","categories":"","description":"","excerpt":"元信息透传是基于传输协议透传一些额外的 RPC 信息给下游，同时读取传输协议中上游透传的信息，透传字段需结合内部的治理能力，建议使用者自行扩 …","ref":"/zh/docs/kitex/tutorials/framework-exten/transmeta/","tags":"","title":"元信息传递扩展"},{"body":"   一个由开发者来定义的开源社区 这里有一群致力于打造「 高性能、可拓展、高可靠 」框架项目的开发者们，我们有着不同的身份、来自不同的企业、承担着不同的角色， 却在社区内，通过社区活动和开源协作，推进项目功能演进，拓展着 CloudWeGo 的开源生态。 开源开放，多元包容！共同定义着什么才是「CloudWeGo 社区」。 在这里，我们有关注开发者从0到1成长的 CSG 小组（CloudWeGo Study Group），CloudWeGo 社区文化乐于分享和帮助开发者共同成长。在这里，我们有社区例会和社区 Meetup 活动， 让成员更加方便的参与社区日常运营和开发任务，共同推进项目演进。 在这里，我们有真正志同道合的开源伙伴：有为了帮助项目技术分享和获得更多开发者反馈的布道师、有热衷技术并不断挑战优化的开发者、 有持续关注技术进展和开源发展的高校群体、有帮助项目上下游生态落地的合作伙伴、有持续不断为项目提供真实需求反馈的企业用户。 我们欢迎更多希望打造一个 真正优质、体检更佳、业界顶尖 的开源项目 的同学加入我们！共同建设，享受开源的魅力与乐趣！  贡献者名单  社区周报  讨论  会议记录  发行版本    贡献者名单 如何成为社区 Committer ? 其中展示了从成立至今经过 CloudWeGo 社区认证的 Committer 们 (排名不分先后) CoderPoet baiyutang horizonzy li-jin-gou liu-song skyenought  查看全部    社区周报 CloudWeGo 社区例会和双周进展动态，将会更新在社区周报中\n继续阅读    讨论 社区开发者们都在关注那些技术热点？日常会如何进行技术讨论和答疑解惑？ 欢迎加入社区讨论组，和社区开发者们共同交流。我们有以下方式可参与到社区讨论中   微信群  ▶ 更便捷的交流方式：日常开发者交流、活动分享、技术答疑\n  飞书群  ▶ 更快速的企业支持：企业使用场景、技术问题可被快速跟进\n  GitHub ▶ 关于项目的 issue 和pr 请在这里提交\n  Slack  ▶ 更适合海外同学参与社区\n   会议记录 这里记录了 CloudWeGo 双周例会会议纪要和例会分享材料\n继续阅读     未来活动    演讲主题  字节跳动微服务体系下接口测试平台实践\n陈佳庆 字节跳动-开发者服务-研发工程师\nKitex 在数美科技可用性治理的落地实践\n代俊凯 数美科技-架构师\nCloudWeGo在贪玩游戏 SDK 接口上的应用实践\n李华松 贪玩游戏-技术经理\n客服平台-流程引擎 Java 转 Go 的实践分享\n王晨 字节跳动-客服平台-架构工程师\n查看往期活动    ","categories":"","description":"","excerpt":"   一个由开发者来定义的开源社区 这里有一群致力于打造「 高性能、可拓展、高可靠 」框架项目的开发者们，我们有着不同的身份、来自不同的企 …","ref":"/zh/community/overview/","tags":"","title":"概述"},{"body":" Support Version: \u003e= v0.5.0 （go.mod dependencies: github/cloudwego/kitex)\nProtobuf Generated code version: \u003e=v0.5.0（The version can be found in the header of the generated code file and in the version comments.）\nThrift : No specific requirement for the generated code version\n 1.Kitex Fallback Functional Description After an RPC request fails, businesses usually take some fallback measures to ensure a valid response (such as constructing a default response when encountering timeouts or circuit breakers). Kitex’s Fallback supports handling all exceptional requests. Additionally, as business exceptions maybe return through Resp (BaseResp), Fallback also supports handling Resp.\n1.1 Result types that support Fallback  RPC Error: RPC request exceptions such as timeout, circuit breaker, rate limiting, and protocol errors at the RPC level. Business Error: Business custom exception, which is distinct from RPC Exception, for the details please see Kitex - Business Exception Usage Guide Resp: In the absence of using business exceptions, users will define error returns in Resp (BaseResp). Therefore, fallback can also be done by judging Resp.  1.2 Monitoring reporting After fallback, a successful Resp may be directly returned, which appears as a successful request to the user, but is still considered a failed request at the RPC level. Therefore, the monitoring system defaults to reporting the original result, but can be configured to report based on the fallback result.\n2.Usage approach Due to the involvement of business logic, Fallback is only supported through code configuration.\n2.1 Client-level configuration var opts []client.Option opts = append(opts, client.WithFallback(yourFallbackPolicy)) xxxCli := xxxservice.NewClient(\"target_service\", opts...) Call-level configuration import ( \"github.com/cloudwego/kitex/pkg/retry\" bretry \"code.byted.org/kite/kitex/pkg/retry\" ) xxxCli.XXXMethod(ctx, req, callopt.WithFallback(yourFallbackPolicy)) 2.3 How to configure Fallback Policy 2.3.1 Define your Fallback Func Kitex provides two ways to define Fallback Func:\n  Use XXXArgs/XXXResult as req/resp parameters, similar to Middleware.\n  Use actual RPC Req/Resp as parameters, similar to Handler’s parameter types.\n  The latter is more intuitive and user-friendly, but it is not compatible with APIs that have multiple request parameters. Therefore, the framework defaults to using the former method.\nUse XXXArgs/XXXResult as req/resp parameters\nNote: You must replace the original return value using result.SetSuccess(yourFallbackResult).\n// Func is the definition for fallback func, which can do fallback both for error and resp. // Notice !! The args and result are not the real rpc req and resp, are respectively XXArgs and XXXResult of generated code. // setup eg: client.WithFallback(fallback.NewFallbackPolicy(yourFunc)) type Func func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) // use demo client.WithFallback( fallback.NewFallbackPolicy( func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { // your fallback logic...  result.SetSuccess(yourFallbackResult) return } ) ) Use actual RPC Req/Resp as parameters\nBy using the fallback.UnwrapHelper provided by Kitex, you can define a Fallback Func with the signature of RealReqRespFunc, whose parameter types are consistent with Handler’s req and resp.\nNote: If you need to return resp, you need to construct the actual RPC resp as the return value here, and the Helper will call the SetSuccess method to replace the original return value.\n// RealReqRespFunc is the definition for fallback func with real rpc req as param, and must return the real rpc resp. // setup eg: client.WithFallback(fallback.NewFallbackPolicy(fallback.UnwrapHelper(yourRealReqRespFunc))) type RealReqRespFunc func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) // use demo client.WithFallback( fallback.NewFallbackPolicy( fallback.UnwrapHelper( func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { // your fallback logic...  return fbResp, fbErr } ) ) ) 2.3.2 Construct your Fallback Policy The default constructor method for creating a Fallback Policy is NewFallbackPolicy, the framework will trigger fallback execution for both errors and responses to make it easier for businesses to use.Also,the framework provides encapsulation for users who want to execute fallbacks for errors or timeouts/circuit breakers.\n Execute fallback based on judgment of both errors and responses  // Method 1: XXXArgs/XXXResult as params fallback.NewFallbackPolicy( func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { // your fallback logic...  result.SetSuccess(yourFallbackResult) return } ) // Method 2: real rpc req/resp as params fallback.NewFallbackPolicy( fallback.UnwrapHelper( func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { // your fallback logic...  return } ) )  Execute fallback only on Errors (including business errors)\nThe Fallback will not be executed for non-Errors.\n  // 1: XXXArgs/XXXResult as params fallback.ErrorFallback( func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { // your fallback logic...  result.SetSuccess(yourFallbackResult) return } ) // 2: real rpc req/resp as params fallback.ErrorFallback( fallback.UnwrapHelper( func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { // your fallback logic...  return } ) )  Execute fallback only on timeout and circuit-breaker errors\nThe Fallback will not be executed for non-timeout and circuit-breaker error.\n  // 1: XXXArgs/XXXResult as params fallback.TimeoutAndCBFallback(func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { // your fallback logic...  result.SetSuccess(yourFallbackResult) return }) // 2: real rpc req/resp as params fallback.TimeoutAndCBFallback(fallback.UnwrapHelper(func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { // your fallback logic...  return })) 2.3.3 How to report monitoring data based on Fallback result The framework defaults to reporting monitoring data based on the original RPC results.The fallback.Policy provides the EnableReportAsFallback() method to choose to report the fallback results.\nNote: If the original result was not an RPC failure (business error), but if an error is returned in the Fallback, even if EnableReportAsFallback is set, the framework will not report the Fallback result.\n   Original Result Whether to use EnableReportAsFallback() Reported Result     RPC Fail YES fallback result   RPC Fail NO is_error=1 (rpcinfo.GetRPCInfo(ctx).Stats().Error() is not nil)   Business Error(Biz Err or BaseResp Non-successful state) YES/NO is_error=0 (rpcinfo.GetRPCInfo(ctx).Stats().Error() is nil)    2.4 Configuration example Example 1: Only execute fallback for timeout and circuit-breaker errors, and reporting monitoring data based on the fallback result. yourFallbackPolicy := fallback.TimeoutAndCBFallback(func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { methodName := rpcinfo.GetRPCInfo(ctx).To().Method() fbRPCResp := buildFallbackRPCResp(methodName, req) result.SetSuccess(fbRPCResp) return nil }).EnableReportAsFallback() var opts []client.Option opts = append(opts, client.WithFallback(yourFallbackPolicy)) xxxCli := xxxservice.NewClient(\"target_service\", opts...) Example 2: Fallback is needed for both Error and Resp, and the real RPC req/resp types are used as parameters yourFallbackPolicy := fallback.NewFallbackPolicy(fallback.UnwrapHelper(func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { methodName := rpcinfo.GetRPCInfo(ctx).To().Method() fbResp = buildFallbackRPCResp(methodName, req, resp) return fbResp, nil })).EnableReportAsFallback() xxxCli.XXXMethod(ctx, req, callopt.WithFallback(yourFallbackPolicy)) 3.Notes 3.1 Description of special return values  If both resp and err in the Fallback are nil, the framework will return the original resp and error. If both resp and err in the Fallback are not nil, the resp will not be returned to the user. It is allowed for the Fallback to return an error.  3.2 Usage of Kitex Protobuf / Kitex gRPC  Fallback is supported for Kitex Protobuf and Kitex gRPC unary requests, but requires generated code version \u003e=v0.5.0 (The version can be found in the header of the generated code file and in the version comments.) Kitex gRPC streaming requests do not support fallback.  ","categories":"","description":"Kitex Fallback Introduction and Usage Guide.","excerpt":"Kitex Fallback Introduction and Usage Guide.","ref":"/docs/kitex/tutorials/basic-feature/fallback/","tags":"","title":"Fallback"},{"body":" 支持版本：\u003e= v0.5.0 （go.mod依赖 github/cloudwego/kitex)\nProtobuf 生成代码版本：\u003e=v0.5.0（版本见生成代码文件头部与版本注释）\nThrift 对生成代码版本无要求\n 1. Kitex Fallback 功能说明 业务在 RPC 请求失败后通常会有一些降级措施保证有效返回（比如请求超时、熔断后，构造默认返回），Kitex 的 Fallback 支持对所有异常请求进行处理。同时，因为业务异常通常会通过 Resp（BaseResp） 返回，所以也支持对 Resp 进行处理。\n1.1 支持 Fallback 的结果类型  RPC Error：RPC 请求异常，如超时、熔断、限流、协议等 RPC 层面的异常 业务 Error：业务自定义的异常，区别于 RPC 异常，具体是 Kitex - 业务异常处理使用文档 Resp：在没有使用业务异常的情况下，用户会在 Resp（BaseResp） 中定义错误返回，所以也支持对 Resp 判断做 fallback  1.2 监控上报 Fallback 后可能直接返回成功的 Resp，对用户而言是一次成功请求，但 RPC 层面还是失败请求，所以监控默认以原来的结果上报，但支持配置化调整为以 Fallback 结果上报。\n2. 使用方式 因为 Fallback 涉及业务逻辑，只支持代码配置。\n2.1 Client 维度配置 var opts []client.Option opts = append(opts, client.WithFallback(yourFallbackPolicy)) xxxCli := xxxservice.NewClient(\"target_service\", opts...) 2.2 Call 维度配置 import ( \"github.com/cloudwego/kitex/pkg/retry\" bretry \"code.byted.org/kite/kitex/pkg/retry\" ) xxxCli.XXXMethod(ctx, req, callopt.WithFallback(yourFallbackPolicy)) 2.3 如何配置 Fallback Policy 2.3.1 Fallback Func 定义 Kitex 提供两种 Fallback Func 定义：\n  以 XXXArgs/XXXResult 作为 req/resp 参数，与 Middleware 相同\n  以真实的 RPC Req/Resp 作为参数，与 Handler 的参数类型相同\n  后者符合使用直觉，对用户更加友好，但不兼容有多个请求参数的 API，因此框架默认使用前一种方法。\nXXXArgs/XXXResult 作为 req/resp 参数\n注意：必须通过 result.SetSuccess(yourFallbackResult) 替换原返回值。\n// Func is the definition for fallback func, which can do fallback both for error and resp. // Notice !! The args and result are not the real rpc req and resp, are respectively XXArgs and XXXResult of generated code. // setup eg: client.WithFallback(fallback.NewFallbackPolicy(yourFunc)) type Func func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) // use demo client.WithFallback( fallback.NewFallbackPolicy( func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { // your fallback logic... result.SetSuccess(yourFallbackResult) return })) 真实的 RPC Req/Resp 作为参数\n通过使用 Kitex 提供的 fallback.UnwrapHelper，可以定义签名为 RealReqRespFunc 的 Fallback Func，参数类型和 Handler 的 req、resp 一致。\n注意：如果需要返回 resp，这里需要构造真实的 RPC resp 作为返回值，Helper 会调用 SetSuccess 方法 替换原返回值。\n// RealReqRespFunc is the definition for fallback func with real rpc req as param, and must return the real rpc resp. // setup eg: client.WithFallback(fallback.NewFallbackPolicy(fallback.UnwrapHelper(yourRealReqRespFunc))) type RealReqRespFunc func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) // use demo client.WithFallback(fallback.NewFallbackPolicy(fallback.UnwrapHelper(func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { // your fallback logic... return fbResp, fbErr })) 2.3.2 构造 Fallback Policy 默认的构造方法 NewFallbackPolicy，框架会对 Error 和 Resp 均触发 Fallback 执行，为了方便业务使用，如果用户是希望对 Error 或者 超时/熔断 做 fallback，框架也提供了封装。\n 对 Error 和 Resp 均做判断执行 Fallback  // 方法1：XXXArgs/XXXResult as params fallback.NewFallbackPolicy(func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { // your fallback logic...  result.SetSuccess(yourFallbackResult) return }) // 方法2：real rpc req/resp as params fallback.NewFallbackPolicy(fallback.UnwrapHelper(func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { // your fallback logic...  return })  只对 Error（包括业务 Error） 进行 Fallback\n非 Error 不会执行 Fallback\n  // 1: XXXArgs/XXXResult as params fallback.ErrorFallback(func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { // your fallback logic...  result.SetSuccess(yourFallbackResult) return }) // 2: real rpc req/resp as params fallback.ErrorFallback(fallback.UnwrapHelper(func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { // your fallback logic...  return })  只对超时和熔断 Error 进行 Fallback\n非 超时 和 熔断 Error 不会执行 Fallback\n  // 1: XXXArgs/XXXResult as params fallback.TimeoutAndCBFallback(func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { // your fallback logic...  result.SetSuccess(yourFallbackResult) return }) // 2: real rpc req/resp as params fallback.TimeoutAndCBFallback(fallback.UnwrapHelper(func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { // your fallback logic...  return }) 2.3.3 如何以 Fallback 结果进行监控上报 框架默认以原来的 RPC 结果进行监控上报，fallback.Policy 提供了 EnableReportAsFallback() 方法可以选择以 Fallback 结果上报。\n注意：如果原结果本来就不是 RPC 失败（业务 Error），但如果在 Fallback 里返回了 error，即使 设置了 EnableReportAsFallback，框架也不会以 Fallback 结果上报。\n   原结果 是否使用 EnableReportAsFallback() 上报结果     RPC 失败 是 fallback 结果   RPC 失败 否 is_error=1 (rpcinfo.GetRPCInfo(ctx).Stats().Error() is not nil)   业务错误 （Biz Err 或 BaseResp 非成功状态） 是/否 is_error=0 (rpcinfo.GetRPCInfo(ctx).Stats().Error() is nil)    2.4 配置示例 示例1：只对 超时和熔断 error 做 fallback，且以 fallback 结果进行监控上报 yourFallbackPolicy := fallback.TimeoutAndCBFallback(func(ctx context.Context, args utils.KitexArgs, result utils.KitexResult, err error) (fbErr error) { methodName := rpcinfo.GetRPCInfo(ctx).To().Method() fbRPCResp := buildFallbackRPCResp(methodName, req) result.SetSuccess(fbRPCResp) return nil }).EnableReportAsFallback() var opts []client.Option opts = append(opts, client.WithFallback(yourFallbackPolicy)) xxxCli := xxxservice.NewClient(\"target_service\", opts...) 示例2：对 Error 和 Resp 都需要 fallback，使用真实的 RPC req/resp 类型作为参数 yourFallbackPolicy := fallback.NewFallbackPolicy(fallback.UnwrapHelper(func(ctx context.Context, req, resp interface{}, err error) (fbResp interface{}, fbErr error) { methodName := rpcinfo.GetRPCInfo(ctx).To().Method() fbResp = buildFallbackRPCResp(methodName, req, resp) return fbResp, nil })).EnableReportAsFallback() xxxCli.XXXMethod(ctx, req, callopt.WithFallback(yourFallbackPolicy)) 3.注意事项 3.1 特殊返回值说明  若 Fallback 的 resp, err 均为 nil，框架将返回原来的 resp 和 error 若 Fallback 的 resp, err 均不为 nil，不会返回 resp 给用户 允许 fallback 返回 error  3.2 Kitex Protobuf / Kitex gRPC 使用  Kitex Protobuf 和 Kitex gRPC 的 Unary 请求均支持 fallback ，但需要用 \u003e=v0.5.0 工具版本生成的代码（版本见生成代码文件头部与版本注释） Kitex gRPC streaming 请求不支持 fallback  ","categories":"","description":"Kitex 自定义 Fallback 使用指南。","excerpt":"Kitex 自定义 Fallback 使用指南。","ref":"/zh/docs/kitex/tutorials/basic-feature/fallback/","tags":"","title":"Fallback"},{"body":"Sentry is an open-source real-time error monitoring project that supports many platforms, including web front-end, server-side, mobile, and game-side. Hertz integrates with the Sentry-Go SDK by using the middleware hertzsentry. It provides several unified interfaces to help users get access to the sentry hub and report error messages.\nNote: Information reporting is still implemented using Sentry’s Go SDK.\nThis project refers to fibersentry.\nInstall go get github.com/hertz-contrib/hertzsentry Example package main import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/getsentry/sentry-go\" \"github.com/hertz-contrib/hertzsentry\" ) var yourDsn = \"\" func main() { // set interval to 0 means using fs-watching mechanism.  h := server.Default(server.WithAutoReloadRender(true, 0)) // init sentry  if err := sentry.Init(sentry.ClientOptions{ // The DSN to use. If the DSN is not set, the client is effectively disabled.  Dsn: yourDsn, // Before send callback.  BeforeSend: func(event *sentry.Event, hint *sentry.EventHint) *sentry.Event { return event }, // In debug mode, the debug information is printed to stdout to help you understand what  // sentry is doing.  Debug: true, // Configures whether SDK should generate and attach stacktraces to pure capture message calls.  AttachStacktrace: true, }); err != nil { log.Fatal(\"sentry init failed\") } // use sentry middleware and config with your requirements.  // attention! you should use sentry handler after recovery.Recovery()  h.Use(hertzsentry.NewSentry( hertzsentry.WithSendRequest(true), hertzsentry.WithRePanic(true), )) h.GET(\"/hello\", func(c context.Context, ctx *app.RequestContext) { // use GetHubFromContext to get the hub  if hub := hertzsentry.GetHubFromContext(ctx); hub != nil { hub.WithScope(func(scope *sentry.Scope) { scope.SetTag(\"hertz\", \"CloudWeGo Hertz\") scope.SetLevel(sentry.LevelDebug) hub.CaptureMessage(\"Just for debug\") }) } ctx.SetStatusCode(0) }) h.Spin() } Config Hertz integrates the functionality of Sentry-Go through the use of middleware. The hertzsentry.options structure defines the configuration information for hertzsentry and provides a default configuration that can be customized by the user according to the business scenario.\n   Parameter Introduction     rePanic Used to configure whether Sentry should panic again after recovery; set to true if the Recover middleware is used, the default is false.   waitForDelivery Used to configure whether the request should be blocked and the buffer emptied before continuing to process the response (only asynchronous transfers really have an operation to empty the buffer). If using Recover middleware, it is safe to skip this option or set it to false, the default is false.   sendRequest Used to configure whether the current request headers should be added when capturing sentry events, the default is false.   sendBody Used to configure whether to add the current request body information when capturing sentry events, the default is false.   timeout Used to configure the timeout for sentry event delivery requests, the default is 2 seconds.    Flush（Go-Sentry） Go-Sentry can choose to send the captured information asynchronously or synchronously, with Flush used to empty the cache when asynchronous is selected. No concept of cache when sending synchronously, returns true directly.\nWhen Flush is triggered it waits until the underlying transport has sent all events to the Sentry server, returning true, but waits up to a given timeout and returns false if the timeout is reached, in which case some events may not be sent. (The buffer will be emptied in both cases)\nFlush should be called before terminating the program to avoid inadvertently discarding events.\nDo not call Flush indiscriminately after each CaptureEvent, CaptureException or CaptureMessage call. Instead, to have the SDK send events synchronously over the network, configure it to use HTTPSyncTransport.\nFunction signatures:\nfunc (hub *Hub) Flush(timeout time.Duration) bool The internal call logic for Flush is as follows:\nfunc (hub *Hub) Flush(timeout time.Duration) bool { client := hub.Client() if client == nil { return false } // The client's transfer pattern is asynchronous or synchronous (Go-Sentry initialization parameters must be pre-configured)  return client.Flush(timeout) } ","categories":"","description":"","excerpt":"Sentry is an open-source real-time error monitoring project that …","ref":"/docs/hertz/tutorials/basic-feature/middleware/sentry/","tags":"","title":"Sentry"},{"body":"Sentry 是一个开源的实时错误监控项目，支持很多平台，包括 Web 前端、服务器端、移动端和游戏端等。Hertz 通过使用中间件 hertzsentry ，整合了 Sentry-Go 的 SDK。提供了一些统一的接口，帮助用户获得 sentry hub 和报告错误信息。\n注意：信息上报功能的实现，依旧是以 Sentry 的 Go SDK 为载体。\n这个项目参考了 fibersentry 的实现。\n安装 go get github.com/hertz-contrib/hertzsentry 示例代码 package main import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/getsentry/sentry-go\" \"github.com/hertz-contrib/hertzsentry\" ) var yourDsn = \"\" func main() { // set interval to 0 means using fs-watching mechanism.  h := server.Default(server.WithAutoReloadRender(true, 0)) // init sentry  if err := sentry.Init(sentry.ClientOptions{ // The DSN to use. If the DSN is not set, the client is effectively disabled.  Dsn: yourDsn, // Before send callback.  BeforeSend: func(event *sentry.Event, hint *sentry.EventHint) *sentry.Event { return event }, // In debug mode, the debug information is printed to stdout to help you understand what  // sentry is doing.  Debug: true, // Configures whether SDK should generate and attach stacktraces to pure capture message calls.  AttachStacktrace: true, }); err != nil { log.Fatal(\"sentry init failed\") } // use sentry middleware and config with your requirements.  // attention! you should use sentry handler after recovery.Recovery()  h.Use(hertzsentry.NewSentry( hertzsentry.WithSendRequest(true), hertzsentry.WithRePanic(true), )) h.GET(\"/hello\", func(c context.Context, ctx *app.RequestContext) { // use GetHubFromContext to get the hub  if hub := hertzsentry.GetHubFromContext(ctx); hub != nil { hub.WithScope(func(scope *sentry.Scope) { scope.SetTag(\"hertz\", \"CloudWeGo Hertz\") scope.SetLevel(sentry.LevelDebug) hub.CaptureMessage(\"Just for debug\") }) } ctx.SetStatusCode(0) }) h.Spin() } 配置 Hertz 通过使用中间件，整合了 Sentry-Go 的功能。其中 hertzsentry.options 结构定义了 hertzsentry 的配置信息，并提供了默认配置，用户也可以依据业务场景进行定制。\n   参数 介绍     rePanic 用于配置 Sentry 在恢复后是否要再次 panic。如果使用了 Recover 中间件，则设置为 true，默认为 false。   waitForDelivery 用于配置是否要在继续处理响应之前阻止请求并清空缓存区（只有异步传输时才真正意义上有清空缓存区的操作）。如果使用 Recover 中间件，跳过这个选项或将其设置为 false 是安全的，默认为 false。   sendRequest 用于配置在捕获 sentry 事件时是否要添加当前的请求头信息，默认为 false。   sendBody 用于配置在捕获 sentry 事件时是否要添加当前的请求正文信息，默认为 false。   timeout 用于配置 sentry 事件传递请求的超时时长，默认为2秒。    Flush（Go-Sentry） Go-Sentry 可以选择异步或者同步发送捕获的信息，选择异步发送时，Flush 用于清空缓存区，同步发送时没有缓存的概念，直接返回 true。\n触发 Flush 时等待，直到底层传输系统向 Sentry 服务器发送所有事件完毕，返回 true。但最多等待给定的超时时间，如果达到超时，则返回 false。在这种情况下，有些事件可能没有被发送。（这两种情况下缓存区都将被清空）\n应该在终止程序之前调用 Flush，以避免无意中丢弃事件。\n不要在每次调用 CaptureEvent、CaptureException 或 CaptureMessage 后不加区分地调用 Flush。相反，要想让 SDK 在网络上同步发送事件，请将其配置为使用 HTTPSyncTransport。\n函数签名：\nfunc (hub *Hub) Flush(timeout time.Duration) bool Flush 调用逻辑如下：\nfunc (hub *Hub) Flush(timeout time.Duration) bool { client := hub.Client() if client == nil { return false } // client 的传输方式为异步或同步（需提前配置 Go-Sentry 的初始化参数）  return client.Flush(timeout) } ","categories":"","description":"","excerpt":"Sentry 是一个开源的实时错误监控项目，支持很多平台，包括 Web 前端、服务器端、移动端和游戏端等。Hertz …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/sentry/","tags":"","title":"Sentry"},{"body":"Hook is a generic concept that indicates the action that accompanies an event when it is triggered.\nHertz provides a global Hook for injecting your processing logic on the server-side after triggering startup and before exiting.\nStartHook StartHook is a function to be called after the server-side has triggered a start, represented in Hertz by the type CtxErrCallback. Hertz uses the OnRun property to store the StartHook list.\n// CtxErrCallback refer to it's function signatures below OnRun []CtxErrCallback Hook functions get triggered sequentially after triggering the startup. Once the call is completed, Hertz will officially start listening on the port, or terminate the service immediately if any error occurs.\nFunction signatures:\ntype CtxErrCallback func(ctx context.Context) error Sample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.OnRun = append(h.OnRun, func(ctx context.Context) error { hlog.Info(\"run the first start hook\") return nil }) h.OnRun = append(h.OnRun, func(ctx context.Context) error { hlog.Info(\"run the second start hook\") return nil }) h.OnRun = append(h.OnRun, func(ctx context.Context) error { hlog.Info(\"run the third start hook\") return nil }) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } Note: After triggering startup, The logs of the three StartHook functions will be printed in the terminal in order.\nmain.go:17: [Info] run the first start hook main.go:21: [Info] run the second start hook main.go:25: [Info] run the third start hook ShutdownHook ShutdownHook is a function to be called before the server-side exiting, represented in Hertz by the type CtxCallback. Hertz uses the OnShutdown property to store the ShutdownHook list.\nHook functions get triggered simultaneously before the server-side exiting. The user can configure the max expiration time by server.WithExitWaitTime, the default is 5 seconds, and once timeout, the server is terminated.\nThe ShutdownHook call process is essentially a part of the Hertz Graceful Shutdown.\nFunction signatures:\ntype CtxCallback func(ctx context.Context) Sample Code1:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) { hlog.Info(\"run the first shutdown hook\") }) h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) { hlog.Info(\"run the second shutdown hook\") }) h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) { hlog.Info(\"run the third shutdown hook\") }) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } Note: Before exiting, the logs of the three ShutdownHook functions will be printed in the terminal disorderly.\nmain.go:17: [Info] run the first shutdown hook main.go:23: [Info] run the third shutdown hook main.go:20: [Info] run the second shutdown hook Sample Code2:\npackage main import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithExitWaitTime(time.Second * 2)) h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) { hlog.Info(\"run shutdown hook\") time.Sleep(time.Second * 5) }) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } Note: When terminating the service, the timeout log is printed because the hook function took more than 2 seconds to execute.\nhertz.go:77: [Info] HERTZ: Begin graceful shutdown, wait at most num=2 seconds... main.go:17: [Info] run shutdown hook engine.go:276: [Info] HERTZ: Execute OnShutdownHooks timeout: error=context deadline exceeded ","categories":"","description":"","excerpt":"Hook is a generic concept that indicates the action that accompanies …","ref":"/docs/hertz/tutorials/basic-feature/hooks/","tags":"","title":"Hooks"},{"body":"钩子函数（Hooks）是一个通用的概念，表示某事件触发时所伴随的操作。\nHertz 提供了全局的 Hook 注入能力，用于在服务触发启动后和退出前注入自己的处理逻辑。\nStartHook StartHook 在 Hertz 当中表示服务触发启动后需调用的函数，使用 CtxErrCallback 类型表示。Hertz 使用 OnRun 属性存储 StartHook 列表。\n// CtxErrCallback 参见下方其函数签名 OnRun []CtxErrCallback 触发 Server 启动后，框架会按函数声明顺序依次调用所有的 StartHook 函数，完成调用之后，才会正式开始端口监听，如果发生错误，则立刻终止服务。\n函数签名：\ntype CtxErrCallback func(ctx context.Context) error 示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.OnRun = append(h.OnRun, func(ctx context.Context) error { hlog.Info(\"run the first start hook\") return nil }) h.OnRun = append(h.OnRun, func(ctx context.Context) error { hlog.Info(\"run the second start hook\") return nil }) h.OnRun = append(h.OnRun, func(ctx context.Context) error { hlog.Info(\"run the third start hook\") return nil }) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 提示：启动服务，将在控制台顺序打印三个 StartHook 函数的日志。\nmain.go:17: [Info] run the first start hook main.go:21: [Info] run the second start hook main.go:25: [Info] run the third start hook ShutdownHook ShutdownHook 在 Hertz 当中表示服务退出前需调用的函数，使用 CtxCallback 类型表示。Hertz 使用 OnShutdown 属性存储 ShutdownHook 列表。\nServer 退出前，框架会并发地调用所有声明的 ShutdownHook 函数，并且可以通过 server.WithExitWaitTime配置最大等待时长，默认为5秒，如果超时，则立刻终止服务。\nShutdownHook 的调用本质上是 Hertz 优雅退出 的一环。\n函数签名：\ntype CtxCallback func(ctx context.Context) 示例代码1：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default() h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) { hlog.Info(\"run the first shutdown hook\") }) h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) { hlog.Info(\"run the second shutdown hook\") }) h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) { hlog.Info(\"run the third shutdown hook\") }) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 提示：终止服务，将在控制台乱序打印三个 ShutdownHook 函数的日志。\nhertz.go:77: [Info] HERTZ: Begin graceful shutdown, wait at most num=5 seconds... main.go:22: [Info] run the third shutdown hook main.go:16: [Info] run the first shutdown hook main.go:19: [Info] run the second shutdown hook engine.go:279: [Info] HERTZ: Execute OnShutdownHooks finish 示例代码2：\npackage main import ( \"context\" \"time\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/hlog\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" ) func main() { h := server.Default(server.WithExitWaitTime(time.Second * 2)) h.OnShutdown = append(h.OnShutdown, func(ctx context.Context) { hlog.Info(\"run shutdown hook\") time.Sleep(time.Second * 5) }) h.GET(\"/ping\", func(c context.Context, ctx *app.RequestContext) { ctx.JSON(consts.StatusOK, utils.H{\"ping\": \"pong\"}) }) h.Spin() } 提示：终止服务时，因为钩子函数执行时间超过2秒，打印超时日志。\nhertz.go:77: [Info] HERTZ: Begin graceful shutdown, wait at most num=2 seconds... main.go:17: [Info] run shutdown hook engine.go:276: [Info] HERTZ: Execute OnShutdownHooks timeout: error=context deadline exceeded ","categories":"","description":"","excerpt":"钩子函数（Hooks）是一个通用的概念，表示某事件触发时所伴随的操作。\nHertz 提供了全局的 Hook 注入能力，用于在服务触发启动后和 …","ref":"/zh/docs/hertz/tutorials/basic-feature/hooks/","tags":"","title":"Hooks"},{"body":"会议主题 ：CloudWeGo 社区会议 7.28\n参会人 ：li-jin-gou, liu-song, GuangmingLuo, pkumza, ag9920, lsjbd, sinnera, welkeyever, YangruiEmma, CoderPoet, stephenzhang0713, joway, Quan Hu, zstone12, Yin Xuran, bodhisatan, Suo Dianjun, Fan Guangyu, Jacob953, Zhang Guiyuan, ppzqh, HeyJavaBean, simon0-o, jayantxie, daidai21, baiyutang, rogerogers, Zhou Xinyi, skyenought, yiyun, cyyolo, baize, Sunxy88\n会前必读 ：http://www.cloudwego.io/；https://github.com/cloudwego\n议程 1：Kitex \u0026 Hertz 对接 sentinel-go 方案和实现介绍 @GuangmingLuo @skyenought  相关文档：ybwflbcn12.feishu.cn/docx/doxcnXcNmOMPaWasGNNQ1dib7xh 基于 CloudWeGo 和 OpenSergo 项目合作的背景下，我们会从开源方面做一些合作对接。Sentinel 会作为 OpenSergo 的具体实现，服务治理的相关标准会沉淀在 OpenSergo 里面，Kitex 与 Hertz 对接 sentinel-go 的 PR 均已经被合入。与 Gin 集成方式保持一致，通过 Middleware 的形式，集成 sentinel-go 的 Entry。 sentinel-go 只提供了一个高度封装的方法，对外只能通过中间件的方式进行。提交到 sentinel-go 仓库里的代码后续维护情况还需进一步讨论。   议程 2：Kitex 定制框架错误处理和规范介绍 @YangruiEmma  Issue 地址：https://github.com/cloudwego/kitex/issues/511 背景：对于用户而言，工程实践里面 RPC 异常分成两大类。   RPC 异常。即 RPC 请求失败，对应超时、协议错误、熔断或者限流等等情况； RPC 层面成功，用户层面异常。用户把请求发到下游，希望根据他的处理逻辑返回状态码给上游，上游可以通过这些状态码做一些额外处理。这种情况在 RPC 层面其实是请求成功，业务错误属于业务逻辑层面。因此服务监控建议对于 RPC 错误上报为请求失败，而业务层面错误，上报为请求成功，但上报 status_code 用于识别错误码。该能力对于工程实践具有一定的价值。  起初，内部要求用户在 Thrift IDL 定义中定义全公司统一的 Base Response 字段，用户通过 Base Response 用户设置业务层面的状态码，我们把这个状态码上报，用户就可以通过监控看到业务层面出现的异常。但是考虑到开源后这套规范并不是很优雅，所以我们想定制一个通用的规范，让用户定义自己的异常。Kitex 本身支持多协议，这一套异常又不能和协议做耦合，因此我们要定义一套通用的接口。\n接口定义：我们会定义一个 bizStatusError 接口。因为 gRPC 用户常用 Status 回传 Error，gRPC 无论是 RPC 真正的框架层面异常，还是用户自定义异常，都使用 Status，其实是没有办法区分的。我们给用户提供的是 gRPC 本身就提供给用户的，即通过 Status 构造 Error，因此我们也要对应地做支持。所以用户可以按照 gRPC 的 Status 实现接口，同时也可以实现 Kitex 定义的这套接口，Kitex 会根据接口判断是否有用户自定义异常，如果是 gRPC 的 Status，我们也会按照 gRPC 的规范通过 HTTPHeader 把错误写到 Header，通过 Header 回传。 用户使用：服务端可以直接通过 bizerror 包构造 bizStatusError。调用端可以通过 bizerror.FromError 方法判断对端返回的是不是 bizerror。 框架实现：Thrift 和 Kitex Protobuf 对于 RPC 层面的异常是放在 Payload 里面编码的，gRPC 是统一放在 HTTPHeader 里面做编码的。因为考虑用户层面的异常，Thrift 和 Kitex Protobuf 放在 Payload 里面编码不是特别合适，所以我们考虑统一在 Header 里面做返回，不再放在 Payload 里面，Payload 里面只写 RPC 层面的异常。 框架处理：具体参见 https://github.com/cloudwego/kitex/issues/511。   议程 3：关于 CloudWeGo 代码生成工具相关建议和方案的讨论 @lsjbd  Issue 地址：https://github.com/cloudwego/kitex/issues/531 李纪昀提了关于 Kitex Tool 的改进建议。解答如下：   问题一：第一，Kitex 默认使用 go path 模式，如果没有指定 -model 参数，会认为当前项目是在 go path 下，之后尝试搜索 go path source 的相对路径，决定代码输出的前缀。现在 gomodule 已经使用比较广泛，我们是否可以默认在 gomodule 文件承载情况下，直接使用当前已知的 gomodule 不要求参数指定？这里的问题是我们内部还有很多项目不使用 gomodule，所以默认行为一旦改变，可能会产生很多 breaking change；第二，gomodule 不一定在当前目录，所以如果实现必须逐层向上搜索，但这可能会达不到预期的效果。 问题二：我们内部可能会使用一些比较奇怪的 IDL 后缀。在它开发的早期，我们其实做了限制，入口的 IDL 必须是 .thrift 或者 .proto 。所以理论上这个是可以做支持的，根据 Thrift 还是 Proto 来确定当前的 Tag，只有在其他情况下才要求它必须指定一个 Tag，所以这是可以实现的。 问题三：我们内部已经在考虑，即使不能合并，是否在两者的页面或者参数做一些统一的功能，此外生成代码的结构体将来是否能够复用也在研究中。 问题四：起初设计 Kitex 也考虑过自定义模板，其实 Kitex 本身支持模版还是比较复杂的，因为 Kitex 并不主导生成代码的过程。它底层有 Protoc 和 Thriftgo 这样两个实际的编译器在做生成代码的工作。所以 Kitex 支持自定义模版还需要考虑两个底层的编译器是否能支持自定义模版的问题。而两个编译器都支持插件，所以自定义模版的功能完全可以用插件的功能实现。   议程 4：2021-2022 Awesome Contributor 评选事宜 @yiyun  Issue 地址：https://github.com/cloudwego/community/issues/36 背景：9 月份 CloudWeGo 开源一周年，一年内除了技术迭代，还收获了 100+ 社区贡献者，以及几百名活动布道者。希望通过 Awesome Contributor 评选，表彰和感谢他们对社区的贡献和支持，共有 100 个名额。活动奖励类型、奖励方式、具体范围、评选标准、评选时间和公示参见 Issue 地址。 8 月 1 日正式开启评选。可以自荐，直接在 Issue 下面评论名单和贡献内容即可。   议程 5： Go through good-first-issue \u0026 QA @GuangmingLuo  Kitex good-first-issue 地址：https://github.com/cloudwego/kitex/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22  一个文档翻译任务待领取，两个单测任务完成情况待审核。\nHertz good-first-issue 地址：https://github.com/cloudwego/hertz/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22  两个任务待认领：https://github.com/cloudwego/hertz/issues/61；https://github.com/cloudwego/hertz/issues/62\n（第二个任务可以考虑和 Kitex 对接远程配置中心设置一个通用方案。）\n业务场景 Business 仓库：https://github.com/cloudwego/biz-demo  欢迎大家提交业务案例！\n 相关资讯 Hertz v0.2.0 发布！\n相关链接：https://mp.weixin.qq.com/s/OOlO-ng4NVgnh32D2dj8Qw\n","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 7.28\n参会人 ：li-jin-gou, liu-song, GuangmingLuo, …","ref":"/zh/community/meeting_notes/2022-07-28/","tags":"","title":"CloudWeGo 社区会议 7.28"},{"body":"A good project can’t be built without unit tests. To help users build good projects, hertz of course provides unit testing tools.\nThe principle is similar to that of golang httptest, both of them just execute ServeHTTP without going through the network and return the response after execution.\nExample import ( \"bytes\" \"context\" \"testing\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/test/assert\" \"github.com/cloudwego/hertz/pkg/common/ut\" \"github.com/cloudwego/hertz/pkg/route\" ) func TestPerformRequest(t *testing.T) { router := route.NewEngine(config.NewOptions([]config.Option{})) router.GET(\"/hey/:user\", func(ctx context.Context, c *app.RequestContext) { user := c.Param(\"user\") assert.DeepEqual(t, \"close\", c.Request.Header.Get(\"Connection\")) c.Response.SetConnectionClose() c.JSON(201, map[string]string{\"hi\": user}) }) w := ut.PerformRequest(router, \"GET\", \"/hey/hertz\", \u0026ut.Body{bytes.NewBufferString(\"1\"), 1}, ut.Header{\"Connection\", \"close\"}) resp := w.Result() assert.DeepEqual(t, 201, resp.StatusCode()) assert.DeepEqual(t, \"{\\\"hi\\\":\\\"hertz\\\"}\", string(resp.Body())) } Work with biz handler Assume you have a handler go file and a function called Ping()\npackage handler import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/common/utils\" ) // Ping . func Ping(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{ \"message\": \"pong\", }) } Now you can do some unit test directly to the Ping() function.\npackage handler import ( \"bytes\" \"testing\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/test/assert\" \"github.com/cloudwego/hertz/pkg/common/ut\" ) func TestPerformRequest(t *testing.T) { h := server.Default() h.GET(\"/ping\", Ping) w := ut.PerformRequest(h.Engine, \"GET\", \"/ping\", \u0026ut.Body{bytes.NewBufferString(\"1\"), 1}, ut.Header{\"Connection\", \"close\"}) resp := w.Result() assert.DeepEqual(t, 201, resp.StatusCode()) assert.DeepEqual(t, \"{\\\"message\\\":\\\"pong\\\"}\", string(resp.Body())) } Every time you change the Ping() behavior, you don’t need to copy it to test file again and again.\nFor more examples, refer to the unit test file in pkg/common/ut.\n","categories":"","description":"","excerpt":"A good project can’t be built without unit tests. To help users build …","ref":"/docs/hertz/tutorials/basic-feature/unit-test/","tags":"","title":"Unit Test"},{"body":"一个好的项目的构建离不开单元测试。为了帮助使用者构建出好的项目，hertz 当然也提供了单元测试的工具。\n原理和 golang httptest 类似，都是不经过网络只执行 ServeHTTP 返回执行后的 response。\n例子 import ( \"bytes\" \"context\" \"testing\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/common/config\" \"github.com/cloudwego/hertz/pkg/common/test/assert\" \"github.com/cloudwego/hertz/pkg/common/ut\" \"github.com/cloudwego/hertz/pkg/route\" ) func TestPerformRequest(t *testing.T) { router := route.NewEngine(config.NewOptions([]config.Option{})) router.GET(\"/hey/:user\", func(ctx context.Context, c *app.RequestContext) { user := c.Param(\"user\") assert.DeepEqual(t, \"close\", c.Request.Header.Get(\"Connection\")) c.Response.SetConnectionClose() c.JSON(201, map[string]string{\"hi\": user}) }) w := ut.PerformRequest(router, \"GET\", \"/hey/hertz\", \u0026ut.Body{bytes.NewBufferString(\"1\"), 1}, ut.Header{\"Connection\", \"close\"}) resp := w.Result() assert.DeepEqual(t, 201, resp.StatusCode()) assert.DeepEqual(t, \"{\\\"hi\\\":\\\"hertz\\\"}\", string(resp.Body())) } 与业务handler配合使用 假如已经创建了handler以及一个函数Ping()\npackage handler import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/common/utils\" ) // Ping . func Ping(ctx context.Context, c *app.RequestContext) { c.JSON(200, utils.H{ \"message\": \"pong\", }) } 可以在单元测试中直接对ping()函数进行测试\npackage handler import ( \"bytes\" \"testing\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/test/assert\" \"github.com/cloudwego/hertz/pkg/common/ut\" ) func TestPerformRequest(t *testing.T) { h := server.Default() h.GET(\"/ping\", Ping) w := ut.PerformRequest(h.Engine, \"GET\", \"/ping\", \u0026ut.Body{bytes.NewBufferString(\"1\"), 1}, ut.Header{\"Connection\", \"close\"}) resp := w.Result() assert.DeepEqual(t, 201, resp.StatusCode()) assert.DeepEqual(t, \"{\\\"message\\\":\\\"pong\\\"}\", string(resp.Body())) } 之后对Ping()函数进行修改，单元测试文件不需要复制相同的业务逻辑。\n更多 examples 参考 pkg/common/ut 中的单测文件。\n","categories":"","description":"","excerpt":"一个好的项目的构建离不开单元测试。为了帮助使用者构建出好的项目，hertz 当然也提供了单元测试的工具。\n原理和 golang …","ref":"/zh/docs/hertz/tutorials/basic-feature/unit-test/","tags":"","title":"单测"},{"body":"Hertz provides access and related methods to Go standard library http.Request and http.ResponseWriter, it is easy for users to integrate net/http to develop application.\nNote: This adaptation comes at a performance penalty\nExample package main import ( \"context\" \"fmt\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/adaptor\" ) func handler(w http.ResponseWriter, r *http.Request) { w.WriteHeader(200) _, err := w.Write([]byte(\"Hello World\")) if err != nil { fmt.Println(err) return } } func main() { h := server.Default() h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { req, err := adaptor.GetCompatRequest(\u0026c.Request) if err != nil { fmt.Println(err) return } // You may build more logic on req \tfmt.Println(req.URL.String()) // caution: don't pass in c.GetResponse() as it return a copy of response \trw := adaptor.GetCompatResponseWriter(\u0026c.Response) handler(rw, req) }) h.Spin() } http.Request    Function Function Signature Description     GetCompatRequest func GetCompatRequest(req *protocol.Request) (*http.Request, error) Build and fetch Go standard library http.Request from Hertz protocol.Request   CopyToHertzRequest func CopyToHertzRequest(req *http.Request, hreq *protocol.Request) Copy the URI, Host, Method, Protocol, Header of Go standard library http.Request to Hertz protocol.Request, The Body field will be adapted by sharing Reader    http.ResponseWriter    Function / Struct Function Signature Description     GetCompatResponseWriter func GetCompatResponseWriter(resp *protocol.Response) http.ResponseWriter Build and fetch Go standard library http.ResponseWriter from Hertz protocol.Response   compatResponse / compatResponse implements the http.ResponseWriter interface and has adaptations to Header, Write and WriteHeader functions    Handler Hertz pprof middleware provides adaptation methods for the Go standard library http.Handler and http.HandlerFunc, it is easy for users to adapt to Hertz app.HandlerFunc for development.\n   Function Function Signature Description     NewHertzHTTPHandlerFunc func NewHertzHTTPHandlerFunc(h http.HandlerFunc) app.HandlerFunc Used to convert Go standard library http.HandlerFunc to Hertz app.HandlerFunc   NewHertzHTTPHandler func NewHertzHTTPHandler(h http.Handler) app.HandlerFunc Used to convert Go standard library http.Handler to Hertz app.HandlerFunc    Refer to hertz-example and pprof for more information\n","categories":"","description":"","excerpt":"Hertz provides access and related methods to Go standard library …","ref":"/docs/hertz/tutorials/basic-feature/adaptor/","tags":"","title":"Adaptor"},{"body":"Hertz 提供了获取 Go 标准库的 http.Request 和 http.ResponseWriter 的方式及其相关方法，以便于用户集成 net/http 进行开发。\n注意：这种适配性是以性能损耗为代价的\n示例代码 package main import ( \"context\" \"fmt\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/adaptor\" ) func handler(w http.ResponseWriter, r *http.Request) { w.WriteHeader(200) _, err := w.Write([]byte(\"Hello World\")) if err != nil { fmt.Println(err) return } } func main() { h := server.Default() h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { req, err := adaptor.GetCompatRequest(\u0026c.Request) if err != nil { fmt.Println(err) return } // You may build more logic on req \tfmt.Println(req.URL.String()) // caution: don't pass in c.GetResponse() as it return a copy of response \trw := adaptor.GetCompatResponseWriter(\u0026c.Response) handler(rw, req) }) h.Spin() } http.Request    函数 函数签名 介绍     GetCompatRequest func GetCompatRequest(req *protocol.Request) (*http.Request, error) 通过 Hertz protocol.Request 构建并获取 Go 标准库 http.Request   CopyToHertzRequest func CopyToHertzRequest(req *http.Request, hreq *protocol.Request) 拷贝 Go 标准库 http.Request 的 URI，Host，Method，Protocol，Header 到 Hertz protocol.Request，对于 Body 属性会以共享 Reader 的方式进行适配    http.ResponseWriter    函数 / 结构体 函数签名 介绍     GetCompatResponseWriter func GetCompatResponseWriter(resp *protocol.Response) http.ResponseWriter 通过 Hertz protocol.Response 构建并获取 Go 标准库 http.ResponseWriter   compatResponse / compatResponse 结构体实现了 http.ResponseWriter 接口并对 Header，Write，WriteHeader 函数进行了适配    Handler Hertz 的 pprof 中间件提供了 Go 标准库 http.Handler 和 http.HandlerFunc 的适配方法，以便用户适配为 Hertz app.HandlerFunc 进行开发。\n   函数 函数签名 介绍     NewHertzHTTPHandlerFunc func NewHertzHTTPHandlerFunc(h http.HandlerFunc) app.HandlerFunc 用于将 Go 标准库 http.HandlerFunc 转换为 Hertz app.HandlerFunc   NewHertzHTTPHandler func NewHertzHTTPHandler(h http.Handler) app.HandlerFunc 用于将 Go 标准库 http.Handler 转换为 Hertz app.HandlerFunc    参考 hertz-example 和 pprof 以获取更多示例\n","categories":"","description":"","excerpt":"Hertz 提供了获取 Go 标准库的 http.Request 和 http.ResponseWriter 的方式及其相关方法，以便于用户 …","ref":"/zh/docs/hertz/tutorials/basic-feature/adaptor/","tags":"","title":"适配器"},{"body":"会议主题 ：CloudWeGo 社区会议 8.11\n参会人 ：li-jin-gou, GuangmingLuo, pkumza, ag9920, lsjbd, sinnera, welkeyever, YangruiEmma, CoderPoet, joway, zstone12, Yin Xuran, bodhisatan, Fan Guangyu, Zhang Guiyuan, ppzqh, HeyJavaBean, simon0-o, baiyutang, rogerogers, skyenought, cloudwegoIce, cyyolo, baize, Hchenn, Ivnszn, LemonFish\n会前必读 ：http://www.cloudwego.io/；https://github.com/cloudwego\n议程 1：新人自我介绍  新成员名单：@LemonFish 社区新成员进行自我介绍，主要包含个人基本情况、开源贡献经历和后续参与社区工作内容。   议程 2：对接远程配置中心的方案介绍 @sinnera  Issue 地址：https://github.com/cloudwego/kitex/issues/574 背景：Kitex 开源后一直不支持对接外面的配置中心，收到用户反馈有相关需求，比如框架内的服务治理策略以及自定义的配置都有需求对接配置中心，提供拉取和动态更新等功能。详细内容参见 Issue。 相关讨论：传统配置中心都会有类似的设计，对这套配置每做一次更新，就会发布一个新版本。如果用户想指定发布版本后，在某一个特定的实例上生效，可能就会产生线上同时有不同版本的配置生效的情况。相关问题后续会具体考虑，也可以到 Issue 下参与讨论。   议程 3：fastPB 开源项目简介 @Hchenn  Issue 地址：github.com/cloudwego/fastpb fastPB 项目是用生成代码对 PB 进行序列化和反序列化的仓库。官方的 PB 编辑码是通过反射进行的，这个项目编辑码是把所有的编码和解码具体操作通过生成代码的形式直接进行，这样就规避了反射。项目刚刚完成，具体的性能测试还在进行中。   议程 4：Hertz 服务注册、发现与负载均衡介绍 \u0026 新手任务 @li-jin-gou  Demo 地址：github.com/li-jin-gou/nacos-demo 背景：外部用户对 Hertz 服务注册发现呼声较高，内部的确也有这一套服务发现并且正在使用，所以开源出来。 服务注册：Registry 接口的大部分逻辑是参考 Kitex 的实现，因此接口是一样的。注册和取消注册的逻辑放在 Hertz Hook Function（run hook/shutdown hook）里面，启动时注册，关闭时取消注册。 服务发现：发现是配合 Client 使用的。发现接口分别是 Target/Resolve/Name，Target 就是唯一标识对应服务，这样会返回一个唯一的 Key；Resolve 通过唯一标识获取对应的实例；Name 内部用来和它对应的 Load Balance 做缓存，避免重复创建。 具体使用实例：github.com/li-jin-gou/nacos-demo/tree/main/example 扩展库：github.com/hertz-contrib/registry。对接 Nacos/ZK/ETCD 等其他注册中心的扩展会放到对应仓库，下周初会把文档补齐，会以 good-first-issue 的形式向社区提供。 补充：Hertz Registry 扩展与 Kitex 稍有不同，把子项目都放在了同一个仓库。因为 Hertz-contrib扩展库较多，拆分后维护成本较大。因此我们决定放在一个仓库里面，以不同的子项目形式存放。欢迎社区的同学一起来参与共建！   议程 5：registry-servicecomb 注册中心扩展介绍和演示 @bodhisatan  相关文档：ServiceComb服务注册发现 （附演示视频录屏） 注册关键逻辑：实现了一个 Register 接口。流程是注册服务，再注册服务实例，做一个异步的心跳保活，然后解除注册。 解除注册逻辑：如果 Address 是空，直接注销服务；如果 Address 不是空，先注销实例，然后取消心跳保活，通过 Endpoints 查找实例，查找出来之后用 instanceId 注销 MicroServiceInstances。 服务发现逻辑：调用了 FindMicroServiceInstances 找到下面所有的实例。   议程 6：CloudWeGo 一周年技术沙龙活动预告与介绍 @cloudwegoIce   相关链接：https://mp.weixin.qq.com/s/x0Y7-gn9kwpoDQayS2bo3w\n  背景：2021 年 9 月 CloudWeGo 正式开源，今年 9 月是正式开源一周年。一年内，CloudWeGo收获了 9000+ star，新增许多开源项目，还有即将新开源一个 Rust RPC 框架。我们会在开源一周年 Meetup 上介绍一年以来的开源历程。\n  四个议题：\n 高性能 RPC 框架 Kitex 内外统一的开源实践 大规模企业级 HTTP 框架设计和实践 新一代基于 Rust 语言的高性能 RPC 框架 开源社区的长期主义与新变化 - CloudWeGo 开源社区实践    地点及参与方式：\n 线上：直接报名参与，群里定时放出参与链接。 线下：北京字节跳动的工区，可以联系 cloudwegoIce 或刘佳同学注册报名。    ","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 8.11\n参会人 ：li-jin-gou, GuangmingLuo, pkumza, …","ref":"/zh/community/meeting_notes/2022-08-11/","tags":"","title":"CloudWeGo 社区会议 8.11"},{"body":"Stats Level:\n LevelDisabled, disable all events LevelBase, enable basic events LevelDetailed, enable basic events and detailed events.  Stats Level Default Stats Level:\n No tracer is available, LevelDisabled by default At least one tracer is available, LevelDetailed by default  Client tracing stats level control:\nimport \"github.com/cloudwego/kitex/client\" import \"github.com/cloudwego/kitex/pkg/stats\" ... baseStats := client.WithStatsLevel(stats.LevelBase) client, err := echo.NewClient(\"echo\", baseStats) if err != nil { log.Fatal(err) } Server tracing stats level control:\nimport \"github.com/cloudwego/kitex/server\" import \"github.com/cloudwego/kitex/pkg/stats\" ... baseStats := server.WithStatsLevel(stats.LevelBase) svr, err := echo.NewServer(baseStats) if err := svr.Run(); err != nil { log.Println(\"server stopped with error:\", err) } else { log.Println(\"server stopped\") } Stats introduction Basic Stats Event:\n RPCStart，（client/server）RPC call start RPCFinish，（client）RPC call finish  Detailed Stats Event(client):\n ClientConnStart, connection establishment start ClientConnFinish，connection establishment finish WriteStart, request send (serialization including) start WriteFinish, request send (serialization including) finish ReadStart, response receive (deserialization including) start WaitReadStart, response stream read start (Fast Codec only) WaitReadFinish, response stream read finish (Fast Codec only) ReadFinish, response receive (deserialization including) finish  Detailed Stats Event(server):\n ReadStart, request receive (deserialization including) start WaitReadStart, request stream read start (Fast Codec only) WaitReadFinish, request stream read finish (Fast Codec only) ReadFinish, request receive (deserialization including) start ServerHandleStart, handler process start ServerHandleFinish, handler process finish WriteStart, response send (serialization including) start WriteFinish, response send (serialization including) start  Timeline:\nclient stats events timeline:\nserver stats events timeline:\n","categories":"","description":"Kitex supports flexible enabling of basic and fine-grained Instrumentation.","excerpt":"Kitex supports flexible enabling of basic and fine-grained …","ref":"/docs/kitex/tutorials/basic-feature/tracing/","tags":"","title":"Instrumentation Control"},{"body":"The Diagnosis module is used to visualize the information in the service to facilitate troubleshooting and confirm the service status. Kitex defines an interface to register the diagnostic func, and developers can implement this interface to present diagnostic information. Presentation way like: output with log and query display with debug port. The open source version of Kitex does not provide a default extension temporarily, but some information that can be used for diagnosis is registered by default. The developers can also register more information for troubleshooting.\nExtension API // ProbeName is the name of probe. type ProbeName string // ProbeFunc is used to get probe data, it is usually a data dump func. type ProbeFunc func() interface{} // Service is the interface for debug service. type Service interface { // RegisterProbeFunc is used to register ProbeFunc with probe name  // ProbeFunc is usually a dump func that to dump info to do problem diagnosis,  // eg: CBSuite.Dump(), s.RegisterProbeFunc(CircuitInfoKey, cbs.Dump)  RegisterProbeFunc(ProbeName, ProbeFunc) } Register diagnostic information // new diagnosisi service var ds diagnosis.service = NewYourService() // eg: register dump func to get discovery instances. ds.RegisterProbeFunc(\"instances\", dr.Dump) // eg: wrap the config data as probe func, register func to get config info. ds.RegisterProbeFunc(\"config_info\", diagnosis.WrapAsProbeFunc(config)) Default registered diagnostic information in Kitex Kitex registers some diagnostic information for troubleshooting by default, as follows:\nconst ( // Common \tChangeEventsKey ProbeName = \"events\" ServiceInfoKey ProbeName = \"service_info\" OptionsKey ProbeName = \"options\" // Client \tDestServiceKey ProbeName = \"dest_service\" ConnPoolKey ProbeName = \"conn_pool\" RetryPolicyKey ProbeName = \"retry_policy\" ) Integrate into Kitex Specify your own diagnostic service through option: WithDiagnosisService.\n// server side svr := xxxservice.NewServer(handler, server.WithDiagnosisService(yourDiagnosisService)) // client side cli, err := xxxservice.NewClient(targetService, client.WithDiagnosisService(yourDiagnosisService)) ","categories":"","description":"","excerpt":"The Diagnosis module is used to visualize the information in the …","ref":"/docs/kitex/tutorials/framework-exten/diagnosis/","tags":"","title":"Extension of Diagnosis"},{"body":"埋点粒度：\n LevelDisabled 禁用埋点 LevelBase 仅启用基本埋点 LevelDetailed 启用基本埋点和细粒度埋点  埋点策略 \u0026 埋点粒度控制 默认埋点策略：\n 无 tracer 时，默认 LevelDisabled 有 tracer 时，默认 LevelDetailed  客户端埋点粒度控制：\nimport \"github.com/cloudwego/kitex/client\" import \"github.com/cloudwego/kitex/pkg/stats\" ... baseStats := client.WithStatsLevel(stats.LevelBase) client, err := echo.NewClient(\"echo\", baseStats) if err != nil { log.Fatal(err) } 服务端埋点粒度控制：\nimport \"github.com/cloudwego/kitex/server\" import \"github.com/cloudwego/kitex/pkg/stats\" ... baseStats := server.WithStatsLevel(stats.LevelBase) svr, err := echo.NewServer(baseStats) if err := svr.Run(); err != nil { log.Println(\"server stopped with error:\", err) } else { log.Println(\"server stopped\") } 埋点说明 基本埋点：\n RPCStart，（客户端 / 服务端）RPC 调用开始 RPCFinish，（客户端 / 服务端）RPC 调用结束  细粒度埋点（客户端）：\n ClientConnStart，连接建立开始 ClientConnFinish，连接建立结束 WriteStart，请求发送（含编码）开始 WriteFinish，请求发送（含编码）结束 ReadStart，响应接收（含解码）开始 WaitReadStart，响应二进制读取开始（仅适用于 Fast Codec） WaitReadFinish，响应二进制读取完毕（仅适用于 Fast Codec） ReadFinish，响应接收（含解码）完毕  细粒度埋点（服务端）：\n ReadStart，请求接收（含解码）开始 WaitReadStart，请求二进制读取开始（仅适用于 Fast Codec） WaitReadFinish，请求二进制读取完毕（仅适用于 Fast Codec） ReadFinish，请求接收（含解码）完毕 ServerHandleStart，handler 处理开始 ServerHandleFinish，handler 处理完毕 WriteStart，响应发送（含编码）开始 WriteFinish，响应发送（含编码）结束  时序图：\n客户端埋点时序图\n服务端埋点时序图\n","categories":"","description":"Kitex 支持灵活启用基本埋点和细粒度埋点。","excerpt":"Kitex 支持灵活启用基本埋点和细粒度埋点。","ref":"/zh/docs/kitex/tutorials/basic-feature/tracing/","tags":"","title":"埋点粒度"},{"body":"诊断模块是用于将服务中的信息可视化出来，便于问题排查，确认服务状态。Kitex 定义了接口用来注册诊断 func，扩展者可实现该接口来呈现诊断信息。呈现的方式如：输出日志、debug 端口查询展示。Kitex 开源版本暂未提供默认扩展，但默认注册了部分可用于诊断的信息，扩展者也可以注册更多的信息用于问题的排查。\n扩展接口 // ProbeName is the name of probe. type ProbeName string // ProbeFunc is used to get probe data, it is usually a data dump func. type ProbeFunc func() interface{} // Service is the interface for debug service. type Service interface { // RegisterProbeFunc is used to register ProbeFunc with probe name  // ProbeFunc is usually a dump func that to dump info to do problem diagnosis,  // eg: CBSuite.Dump(), s.RegisterProbeFunc(CircuitInfoKey, cbs.Dump)  RegisterProbeFunc(ProbeName, ProbeFunc) } 注册诊断信息 // new diagnosisi service var ds diagnosis.service = NewYourService() // eg: register dump func to get discovery instances. ds.RegisterProbeFunc(\"instances\", dr.Dump) // eg: wrap the config data as probe func, register func to get config info. ds.RegisterProbeFunc(\"config_info\", diagnosis.WrapAsProbeFunc(config)) Kitex 默认注册的诊断信息 Kitex 默认注册了部分诊断信息用于问题排查，具体如下：\nconst ( // Common \tChangeEventsKey ProbeName = \"events\" ServiceInfoKey ProbeName = \"service_info\" OptionsKey ProbeName = \"options\" // Client \tDestServiceKey ProbeName = \"dest_service\" ConnPoolKey ProbeName = \"conn_pool\" RetryPolicyKey ProbeName = \"retry_policy\" ) 集成到 Kitex 通过 option 指定自己的诊断服务，option: WithDiagnosisService。\n// server side svr := xxxservice.NewServer(handler, server.WithDiagnosisService(yourDiagnosisService)) // client side cli, err := xxxservice.NewClient(targetService, client.WithDiagnosisService(yourDiagnosisService)) ","categories":"","description":"","excerpt":"诊断模块是用于将服务中的信息可视化出来，便于问题排查，确认服务状态。Kitex 定义了接口用来注册诊断 func，扩展者可实现该接口来呈现诊 …","ref":"/zh/docs/kitex/tutorials/framework-exten/diagnosis/","tags":"","title":"诊断模块扩展"},{"body":"Cross-site request forgery (CSRF) is a method of attack that holds a user hostage to perform an unintended action on a currently logged-in Web application.\nHertz provides CSRF middleware to help you prevent cross-site request forgery attacks.\nInstall go get github.com/hertz-contrib/csrf Example package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New()) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } Config    Option Default Description     Secret “csrfSecret” Secret used to generate token.   IgnoreMethods “GET”, “HEAD”, “OPTIONS”, “TRACE” Ignored methods will be considered no protection required.   Next nil Next defines a function to skip this middleware when returned true.   KeyLookup “header:X-CSRF-TOKEN” KeyLookup is a string in the form of “:” that is used to create an Extractor that extracts the token from the request.   ErrorFunc func(ctx context.Context, c *app.RequestContext) { panic(c.Errors.Last()) } ErrorFunc is executed when an error is returned from app.HandlerFunc.   Extractor Default will create an Extractor based on KeyLookup. Extractor returns the csrf token. If set this will be used in place of an Extractor based on KeyLookup.    WithSecret The csrf middleware provides WithSecret to help users set a custom secret key for issuing token, which is csrfSecret by default.\nFunction Signature:\nfunc WithSecret(secret string) Option Default：csrfSecret\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() store := cookie.NewStore([]byte(\"store\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithSecret(\"your_secret\"))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } WithIgnoredMethods The csrf middleware provides WithIgnoredMethods to help users set up custom methods that do not need to be protected, the defaults are GET, HEAD, OPTIONS and TRACE.\nFunction Signature:\nfunc WithIgnoredMethods(methods []string) Option Default: {\"GET\", \"HEAD\", \"OPTIONS\", \"TRACE\"}\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"session\", store)) h.Use(csrf.New(csrf.WithIgnoredMethods([]string{\"GET\", \"HEAD\", \"TRACE\"}))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.OPTIONS(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"success\") }) h.Spin() } WithErrorFunc The csrf middleware provides WithErrorFunc to facilitate user-defined error handling logic.\nFunction Signature:\nfunc WithErrorFunc(f app.HandlerFunc) Option Default:\nfunc(ctx context.Context, c *app.RequestContext) { panic(c.Errors.Last()) } Sample Code:\npackage main import ( \"context\" \"fmt\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func myErrFunc(c context.Context, ctx *app.RequestContext) { if ctx.Errors.Last() == nil { err := fmt.Errorf(\"myErrFunc called when no error occurs\") ctx.String(400, err.Error()) ctx.Abort() } ctx.AbortWithMsg(ctx.Errors.Last().Error(), http.StatusBadRequest) } func main() { h := server.Default() store := cookie.NewStore([]byte(\"store\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithErrorFunc(myErrFunc))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } WithKeyLookUp The csrf middleware provides WithKeyLookUp to help users set keyLookup.\ncsrf is used to extract token from source (supported sources include header, param, query, form).\nThe format is \u003csource\u003e:\u003ckey\u003e and the default value is :header:X-CSRF-TOKEN.\nFunction Signature:\nfunc WithKeyLookUp(lookup string) Option Default: header:X-CSRF-TOKEN\"\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() store := cookie.NewStore([]byte(\"store\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithKeyLookUp(\"form:csrf\"))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } WithNext The csrf middleware provides WithNext to facilitate user-defined settings to skip the csrf middleware under certain conditions.\nFunction Signature:\nfunc WithNext(f CsrfNextHandler) Option Default:nil\nSample Code:\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func isPostMethod(_ context.Context, ctx *app.RequestContext) bool { if string(ctx.Method()) == \"POST\" { return true } else { return false } } func main() { h := server.Default() store := cookie.NewStore([]byte(\"store\")) h.Use(sessions.New(\"csrf-session\", store)) // skip csrf middleware when request method is post \th.Use(csrf.New(csrf.WithNext(isPostMethod))) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"success even no csrf-token in header\") }) h.Spin() } WithExtractor The csrf middleware provides WithExtractor for the user to get the csrf-token from the request via a custom method.\nFunction Signature:\nfunc WithExtractor(f CsrfExtractorHandler) Option Default:\nfunc CsrfFromHeader(param string) func(ctx context.Context, c *app.RequestContext) (string, error) { return func(ctx context.Context, c *app.RequestContext) (string, error) { token := c.GetHeader(param) if string(token) == \"\" { return \"\", errMissingHeader } return string(token), nil } } Sample Code:\npackage main import ( \"context\" \"errors\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func myExtractor(c context.Context, ctx *app.RequestContext) (string, error) { token := ctx.FormValue(\"csrf-token\") if token == nil { return \"\", errors.New(\"missing token in form-data\") } return string(token), nil } func main() { h := server.Default() store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithExtractor(myExtractor))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } ","categories":"","description":"","excerpt":"Cross-site request forgery (CSRF) is a method of attack that holds a …","ref":"/docs/hertz/tutorials/basic-feature/middleware/csrf/","tags":"","title":"CSRF"},{"body":"Cross-site request forgery（CSRF）是一种挟制用户在当前已登录的Web应用程序上执行非本意的操作的攻击方法。\nHertz 提供了 CSRF 中间件,可帮助您防止跨站点请求伪造攻击。\n安装 go get github.com/hertz-contrib/csrf 示例代码 package main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New()) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } 配置    配置项 默认值 介绍     Secret csrfSecret 用于生成令牌（必要配置）   IgnoreMethods “GET”, “HEAD”, “OPTIONS”, “TRACE” 被忽略的方法将将视为无需 csrf保护   Next nil Next 定义了一个函数，当返回真时，跳过这个 csrf 中间件。   KeyLookup header：X-CSRF-TOKEN KeyLookup 是一个\"：“形式的字符串，用于创建一个从请求中提取令牌的 Extractor。   ErrorFunc func(ctx context.Context, c *app.RequestContext) { panic(c.Errors.Last()) } 当 app.HandlerFunc返回一个错误时，ErrorFunc 被执行   Extractor 基于 KeyLookup 创建 Extractor返回csrf token。如果设置了这个，它将被用来代替基于KeyLookup的 Extractor。    WithSecret csrf 中间件提供了 WithSecret 用于帮助用户设置自定义秘钥用于签发 token ，默认为 csrfSecret。\n函数签名：\nfunc WithSecret(secret string) Option 默认值：csrfSecret\n示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() store := cookie.NewStore([]byte(\"store\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithSecret(\"your_secret\"))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } WithIgnoredMethods csrf 中间件提供了 WithIgnoredMethods 用于帮助用户设置自定义无需保护的方法，默认为 GET, HEAD, OPTIONS 和 TRACE。\n函数签名：\nfunc WithIgnoredMethods(methods []string) Option 默认值：{\"GET\", \"HEAD\", \"OPTIONS\", \"TRACE\"}\n示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithIgnoredMethods([]string{\"GET\", \"HEAD\", \"TRACE\"}))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.OPTIONS(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"success\") }) h.Spin() } WithErrorFunc csrf 中间件提供了 WithErrorFunc 方便用户自定义错误处理逻辑。\n函数签名：\nfunc WithErrorFunc(f app.HandlerFunc) Option 默认实现：\nfunc(ctx context.Context, c *app.RequestContext) { panic(c.Errors.Last()) } 示例代码：\npackage main import ( \"context\" \"fmt\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func myErrFunc(c context.Context, ctx *app.RequestContext) { if ctx.Errors.Last() == nil { err := fmt.Errorf(\"myErrFunc called when no error occurs\") ctx.String(400, err.Error()) ctx.Abort() } ctx.AbortWithMsg(ctx.Errors.Last().Error(), http.StatusBadRequest) } func main() { h := server.Default() store := cookie.NewStore([]byte(\"store\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithErrorFunc(myErrFunc))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } WithKeyLookUp csrf 中间件提供了 WithKeyLookUp 帮助用户设置 keyLookup。\ncsrf 用于从 source(支持的 source 包括 header 、param、query、form) 中提取 token。\n格式为 \u003csource\u003e：\u003ckey\u003e，默认值为：header：X-CSRF-TOKEN。\n函数签名：\nfunc WithKeyLookUp(lookup string) Option 默认值： header：X-CSRF-TOKEN\"\n示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() store := cookie.NewStore([]byte(\"store\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithKeyLookUp(\"form:csrf\"))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } WithNext csrf 中间件提供了 WithNext 方便用户自定义设置，以在特定条件下跳过 csrf中间件。\n函数签名：\nfunc WithNext(f CsrfNextHandler) Option 默认：nil\n示例代码：\npackage main import ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func isPostMethod(_ context.Context, ctx *app.RequestContext) bool { if string(ctx.Method()) == \"POST\" { return true } else { return false } } func main() { h := server.Default() store := cookie.NewStore([]byte(\"store\")) h.Use(sessions.New(\"csrf-session\", store)) // skip csrf middleware when request method is post \th.Use(csrf.New(csrf.WithNext(isPostMethod))) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"success even no csrf-token in header\") }) h.Spin() } WithExtractor csrf 中间件提供了 WithExtractor,供用户通过自定义的方法从请求中获取csrf-token。\n函数签名：\nfunc WithExtractor(f CsrfExtractorHandler) Option 默认实现：\nfunc CsrfFromHeader(param string) func(ctx context.Context, c *app.RequestContext) (string, error) { return func(ctx context.Context, c *app.RequestContext) (string, error) { token := c.GetHeader(param) if string(token) == \"\" { return \"\", errMissingHeader } return string(token), nil } } 示例代码：\npackage main import ( \"context\" \"errors\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/csrf\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func myExtractor(c context.Context, ctx *app.RequestContext) (string, error) { token := ctx.FormValue(\"csrf-token\") if token == nil { return \"\", errors.New(\"missing token in form-data\") } return string(token), nil } func main() { h := server.Default() store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"csrf-session\", store)) h.Use(csrf.New(csrf.WithExtractor(myExtractor))) h.GET(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, csrf.GetToken(ctx)) }) h.POST(\"/protected\", func(c context.Context, ctx *app.RequestContext) { ctx.String(200, \"CSRF token is valid\") }) h.Spin() } ","categories":"","description":"","excerpt":"Cross-site request forgery（CSRF）是一种挟制用户在当前已登录的Web应用程序上执行非本意的操作的攻击方法。 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/csrf/","tags":"","title":"CSRF"},{"body":"Casbin is a powerful and efficient open-source access control library that supports various access control models ( such as ACL/RBAC/ABAC) for enforcing authorization across the board.\nAccording to the user’s use scenario, we provide Casbin Middleware that adapted to Hertz.\nInstall go get github.com/hertz-contrib/casbin Import import \"github.com/hertz-contrib/casbin\" Example package main import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/casbin\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() // using sessions to store user info.  store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"session\", store)) auth, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.POST(\"/login\", func(ctx context.Context, c *app.RequestContext) { // verify username and password.  // ...  // store username (casbin subject) in session  session := sessions.Default(c) session.Set(\"name\", \"alice\") err := session.Save() if err != nil { log.Fatal(err) } c.String(200, \"you login successfully\") }) h.GET(\"/book\", auth.RequiresPermissions(\"book:read\", casbin.WithLogic(casbin.AND)), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }) h.POST(\"/book\", auth.RequiresRoles(\"user\", casbin.WithLogic(casbin.AND)), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you posted a book successfully\") }) h.Spin() } // subjectFromSession get subject from session. func subjectFromSession(ctx context.Context, c *app.RequestContext) string { // get subject from session.  session := sessions.Default(c) if subject, ok := session.Get(\"name\").(string); !ok { return \"\" } else { return subject } } Config By Casbin Middleware, hertz is capable of controlling user access permissions.\nuse this extension, you need to initialize middleware and use method that provided by this middleware to authorize.\nInitialize middleware NewCasbinMiddleware You need to provide Model, Policy and LookupHandler (handler that get subject) to initialize middleware.\nThis function will initialize *casbin.Enforcer by provided configs to perform authentication operation.\nThe function signature is as follows:\nfunc NewCasbinMiddleware(modelFile string, adapter interface{}, lookup LookupHandler) (*Middleware, error) Sample code:\nfunc exampleLookupHandler(ctx context.Context, c *app.RequestContext) string { // get subject from session  session := sessions.Default(c) if subject, ok := session.Get(\"name\").(string); !ok { return \"\" } else { return subject } } func main() { ... casbinMiddleware, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", exampleLookupHandler) if err != nil { log.Fatal(err) } ... } NewCasbinMiddlewareFromEnforcer You need to provide enforcer and LookupHandler (handler that get subject) to initialize middleware.\nThe function signature is as follows:\nfunc NewCasbinMiddlewareFromEnforcer(e casbin.IEnforcer, lookup LookupHandler) (*Middleware, error) Sample code:\nfunc exampleLookupHandler(ctx context.Context, c *app.RequestContext) string { // get subject from session  session := sessions.Default(c) if subject, ok := session.Get(\"name\").(string); !ok { return \"\" } else { return subject } } func main() { ... enforcer, err := casbinsdk.NewEnforcer(\"example/config/model.conf\", \"example/config/policy.csv\") if err != nil{ log.Fatal(err) } casbinMiddleware, err := casbin.NewCasbinMiddlewareFromEnforcer(enforcer, exampleLookupHandler) if err != nil { log.Fatal(err) } ... } Middleware method middleware provide methods that perform authentication operation.\nmethod parameter format is as follows:\nfunc (m *Middleware) exampleMiddlwareMethod(expression string, opts ...Option) app.HandlerFunc it contains expression and opts two params.\nparameters descriptions is as follows:\n  expression\nexpression has one or more params, each param is divided by space, the expression format is related to Logic (see option description),\nthe calculated final value of the expression is either True or False, True represents for has passed casbin middleware,\nFalse represents for has not passed casbin middleware.\nIf Logic is AND or OR, the format is:\n\"var 1 var2 var3 var4\", like \"book:read book:write\"\nIf Logic is CUSTOM, the format is :\n\"var1 opr1 var2 opr2 var3\" like \"book:read \u0026\u0026 book:write || book:all\"\n  opts\n   Option Description Default     WithLogic Logic is the logical operation (AND/OR/CUSTOM) used in permission checks that multiple permissions or roles are specified AND   WithPermissionParser PermissionParserFunc is used for parsing the permission to extract object and action usually PermissionParserWithSeparator(\":\")   WithPermissionParserSeparator PermissionParserSeparator is used to set separator that divide permission to object and action usually :   WithUnauthorized Unauthorized defined the response body for unauthorized responses func(ctx context.Context, c *app.RequestContext) { c.AbortWithStatus(consts.StatusUnauthorized) }   WithForbidden Forbidden defines the response body for forbidden responses func(ctx context.Context, c *app.RequestContext) { c.AbortWithStatus(consts.StatusForbidden) }      RequiresPermission Use Subject (provided by LookupHandler) and expression (see the following text) to check subject is whether satisfies the permission list relationship.\nvars inside expression is param list behind sub in Model :\n[request_definition] r = sub, xxx, xxx like:\n[request_definition] r = sub, dom, obj, act when use default PermissionParser, expression format should be like \"book:read\".\nlike:\n[request_definition] r = sub, dom, obj, act when use default PermissionParser, expression format should be like \"\"book1.com:book:read.\nThe function signature is as follows:\nfunc (m *Middleware) RequiresPermissions(expression string, opts ...Option) app.HandlerFunc Sample code:\nwhen user has book:read permission,\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\"), // passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read book:write\"), // not passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } RequiresRoles Use Subject (provided by LookupHandler) and expression (see the following text) to check roles to which the user belongs is whether satisfies the role list relationship.\nThe function signature is as follows:\nfunc (m *Middleware) RequiresRoles(expression string, opts ...Option) app.HandlerFunc Sample code:\nwhen user has role of user and reader,\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.POST(\"/book\", auth.RequiresRoles(\"user\"), // passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you posted a book successfully\") }, ) h.POST(\"/book\", auth.RequiresRoles(\"user reader\"), // passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you posted a book successfully\") }, ) h.POST(\"/book\", auth.RequiresRoles(\"user reader admin\"), // not passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you posted a book successfully\") }, ) ... } Attention: This method is only valid when use RBAC.\nOptions description WithLogic Logic is the logical operation (AND/OR/CUSTOM) used in permission checks that multiple permissions or roles are specified.\nThe function signature is as follows:\nfunc WithLogic(logic Logic) Option option:\nconst ( AND Logic = iota OR CUSTOM ) AND\nall variables in expression will perform Logic AND operation.\nSample code:\nwhen user has book:read permission,\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithLogic(casbin.AND)), // passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read book:write\", casbin.WithLogic(casbin.AND)), // not passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } OR\nall variables in expression will perform Logical OR operation.\nSample code:\nwhen user has book:read permission,\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithLogic(casbin.OR)), // passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read book:and\", casbin.WithLogic(casbin.OR)), // not passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } CUSTOM\nexpression will be parsed like C-like artithmetic/string expression。\nAttention:\nwhen using CUSTOM, use WithPermissionParser Option is forbidden, it is suggested using WithPermissionParserSeparator Option instead.\nSample code:\nwhen user has book:read permission,\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithLogic(casbin.CUSTOM)), // passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read \u0026\u0026 book:write\", casbin.WithLogic(casbin.CUSTOM)), // not passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read || book:write\", casbin.WithLogic(casbin.CUSTOM)), // passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"!book:read\", casbin.WithLogic(casbin.CUSTOM)), // not passed \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } WithPermissionParser PermissionParserFunc is used for parsing the permission to extract object and action usually.\nThe function signature is as follows:\nfunc WithPermissionParser(pp PermissionParserFunc) Option Sample code:\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book-read\", casbin.WithPermissionParser(func(str string) []string { return strings.Split(str, \"-\") }), ), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } WithPermissionParserSeparator PermissionParserSeparator is used to set separator that divide permission to object and action usually.\nThe function signature is as follows:\nfunc WithPermissionParserSeparator(sep string) Option Sample code:\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book-read\", casbin.WithPermissionParserSeparator(\"-\"), ), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } WithUnauthorized Unauthorized defined the response body for unauthorized responses.\nThe function signature is as follows:\nfunc WithUnauthorized(u app.HandlerFunc) Option Sample code:\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithUnauthorized(func(c context.Context, ctx *app.RequestContext) { ctx.AbortWithStatus(consts.StatusUnauthorized) }), ), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } WithForbidden Forbidden defines the response body for forbidden responses.\nThe function signature is as follows:\nfunc WithForbidden(f app.HandlerFunc) Option Sample code:\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithForbidden(func(c context.Context, ctx *app.RequestContext) { ctx.AbortWithStatus(consts.StatusForbidden) }), ), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } ","categories":"","description":"","excerpt":"Casbin is a powerful and efficient open-source access control library …","ref":"/docs/hertz/tutorials/basic-feature/middleware/casbin/","tags":"","title":"Casbin"},{"body":"Casbin 是⼀个强⼤的、⾼效的开源访问控制框架，其权限管理机制支持常用的多种访问控制模型，如 ACL/RBAC/ABAC 等。可以实现灵活的访问权限控制。\n针对用户的使用场景，提供 Casbin 中间件，对 Hertz 进行了适配。\n安装 go get github.com/hertz-contrib/casbin 导入 import \"github.com/hertz-contrib/casbin\" 示例代码 package main import ( \"context\" \"log\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/casbin\" \"github.com/hertz-contrib/sessions\" \"github.com/hertz-contrib/sessions/cookie\" ) func main() { h := server.Default() // 使用 session 存储用户信息.  store := cookie.NewStore([]byte(\"secret\")) h.Use(sessions.New(\"session\", store)) auth, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.POST(\"/login\", func(ctx context.Context, c *app.RequestContext) { // 校验用户名和密码.  // ...  // 存储用户名 (casbin 访问实体)  session := sessions.Default(c) session.Set(\"name\", \"alice\") err := session.Save() if err != nil { log.Fatal(err) } c.String(200, \"you login successfully\") }) h.GET(\"/book\", auth.RequiresPermissions(\"book:read\", casbin.WithLogic(casbin.AND)), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }) h.POST(\"/book\", auth.RequiresRoles(\"user\", casbin.WithLogic(casbin.AND)), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you posted a book successfully\") }) h.Spin() } // subjectFromSession 从 session 中获取访问实体. func subjectFromSession(ctx context.Context, c *app.RequestContext) string { // 获取访问实体  session := sessions.Default(c) if subject, ok := session.Get(\"name\").(string); !ok { return \"\" } else { return subject } } 配置 Hertz 通过使用 casbin 中间件，为服务端提供了控制用户访问权限的能力。\n使用该拓展时，需要先初始化中间件，然后使用中间件方法进行鉴权操作。\n初始化中间件 NewCasbinMiddleware 通过提供 Model 和 Policy 相关配置以及 LookupHandler（用于获取访问实体）来初始化中间件，\n该函数会根据提供的配置自动初始化 *casbin.Enforcer 用于鉴权操作。\n函数签名如下：\nfunc NewCasbinMiddleware(modelFile string, adapter interface{}, lookup LookupHandler) (*Middleware, error) 示例代码：\nfunc exampleLookupHandler(ctx context.Context, c *app.RequestContext) string { // 获取访问实体  session := sessions.Default(c) if subject, ok := session.Get(\"name\").(string); !ok { return \"\" } else { return subject } } func main() { ... casbinMiddleware, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", exampleLookupHandler) if err != nil { log.Fatal(err) } ... } NewCasbinMiddlewareFromEnforcer 通过提供 enforcer 以及 LookupHandler（用于获取访问实体）来初始化中间件。\n函数签名如下：\nfunc NewCasbinMiddlewareFromEnforcer(e casbin.IEnforcer, lookup LookupHandler) (*Middleware, error) 示例代码：\nfunc exampleLookupHandler(ctx context.Context, c *app.RequestContext) string { // 获取访问实体  session := sessions.Default(c) if subject, ok := session.Get(\"name\").(string); !ok { return \"\" } else { return subject } } func main() { ... enforcer, err := casbinsdk.NewEnforcer(\"example/config/model.conf\", \"example/config/policy.csv\") if err != nil{ log.Fatal(err) } casbinMiddleware, err := casbin.NewCasbinMiddlewareFromEnforcer(enforcer, exampleLookupHandler) if err != nil { log.Fatal(err) } ... } 中间件方法 中间件方法用来判断用户的具体权限逻辑。\n该中间件的方法参数格式如下：\nfunc (m *Middleware) exampleMiddlwareMethod(expression string, opts ...Option) app.HandlerFunc 其中包含 expression 和 opts 两个参数，\n参数说明如下：\n  expression\n表达式含有一个或多个变量，变量之间用空格分隔，表达式的具体格式与Logic（见后文选项说明）相关，\n表达式的计算最终值为 True or False，True 则代表通过鉴权中间件，False 则代表没有通过鉴权中间件，\n如 Logic 为 AND or OR，则格式为：\n\"var1 var2 var3 var4\"，比如 \"book:read book:write\"\n如 Logic 为 CUSTOM，则格式为：\n\"var1 opr1 var2 opr2 var3\"，比如 \"book:read \u0026\u0026 book:write || book:all\"\n  opts\n   选项 介绍 默认值     WithLogic Logic 是在 expression 中的逻辑操作(AND/OR/CUSTOM) AND   WithPermissionParser PermissionParserFunc 是用于解析 expression 中变量得出 obj 和 act 的函数 PermissionParserWithSeparator(\":\")   WithPermissionParserSeparator PermissionParserSeparator 是用于设置 expression 中变量内部的分隔符 :   WithUnauthorized Unauthorized 用于定义未通过授权中间件时的响应体（找不到访问实体） func(ctx context.Context, c *app.RequestContext) { c.AbortWithStatus(consts.StatusUnauthorized) }   WithForbidden Forbidden 用于定义访问到禁止访问资源的响应体（访问实体没有相应权限） func(ctx context.Context, c *app.RequestContext) { c.AbortWithStatus(consts.StatusForbidden) }      RequiresPermissions 寻找访问实体（Subject）及通过方法中提供的参数 expression （表达式中变量说明见下）判断访问实体所含有的权限是否满足expression中的权限集合的关系。\nexpression 中的变量为 Model 中\n[request_definition] r = sub, xxx, xxx sub 后面的参数集合，\n如：\n[request_definition] r = sub, obj, act 使用了默认的 PermissionParser 时，expression 中的变量格式应该是：\"book:read\"。\n如：\n[request_definition] r = sub, dom, obj, act 使用了默认的 PermissionParser 时，expression 中的变量格式应该是：\"book1.com:book:read\"。\n函数签名如下：\nfunc (m *Middleware) RequiresPermissions(expression string, opts ...Option) app.HandlerFunc 示例代码：\n用户只含有 book:read 权限时，\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\"), // 通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read book:write\"), // 不通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } RequiresRoles 寻找访问实体（Subject）及通过方法中提供的参数 expression （表达式中变量说明见下）判断访问实体所属的角色是否满足expression中的角色集合的关系。\nexpression中的变量为 RBAC 中的 rule 集合\n函数签名如下：\nfunc (m *Middleware) RequiresRoles(expression string, opts ...Option) app.HandlerFunc 示例代码：\n用户属于 user 和 reader 角色时，\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.POST(\"/book\", auth.RequiresRoles(\"user\"), // 通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you posted a book successfully\") }, ) h.POST(\"/book\", auth.RequiresRoles(\"user reader\"), // 通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you posted a book successfully\") }, ) h.POST(\"/book\", auth.RequiresRoles(\"user reader admin\"), // 不通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you posted a book successfully\") }, ) ... } 注意：此方法当且仅当使用了 Casbin 当中基于角色的访问控制模式（即 RBAC）时使用。\n选项说明 WithLogic Logic 是在 expression 中的逻辑操作(AND/OR/CUSTOM) 。\n函数签名：\nfunc WithLogic(logic Logic) Option 选项：\nconst ( AND Logic = iota OR CUSTOM ) AND\nexpression 中的所有变量进行逻辑与操作。\n示例代码：\n用户只含有 book:read 权限时，\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithLogic(casbin.AND)), // 通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read book:write\", casbin.WithLogic(casbin.AND)), // 不通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } OR\nexpression 中的所有变量进行逻辑或操作\n示例代码：\n用户只含有 book:read 权限时，\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithLogic(casbin.OR)), // 通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read book:and\", casbin.WithLogic(casbin.OR)), // 通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } CUSTOM\nexpression 为类C表达式。\n注意：\n使用该模式时，不可使用选项 WithPermissionParser（执行鉴权逻辑时会产生不可预期的错误），如有定义解析权限字符串之类的需求，建议使用选项 WithPermissionParserSeparator。\n示例代码：\n用户只含有 book:read 权限时，\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithLogic(casbin.CUSTOM)), // 通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read \u0026\u0026 book:write\", casbin.WithLogic(casbin.CUSTOM)), // 不通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"book:read || book:write\", casbin.WithLogic(casbin.CUSTOM)), // 通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) h.GET(\"/book\", m.RequiresPermissions(\"!book:read\", casbin.WithLogic(casbin.CUSTOM)), // 不通过 \tfunc(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } WithPermissionParser PermissionParserFunc 是用于解析 RequiresPermissions 方法中 expression 的变量的函数。\n函数签名：\nfunc WithPermissionParser(pp PermissionParserFunc) Option 示例代码：\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book-read\", casbin.WithPermissionParser(func(str string) []string { return strings.Split(str, \"-\") }), ), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } WithPermissionParserSeparator PermissionParserSeparator 是用于设置 expression 中变量内部的分隔符。\n函数签名：\nfunc WithPermissionParserSeparator(sep string) Option 示例代码：\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book-read\", casbin.WithPermissionParserSeparator(\"-\"), ), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } WithUnauthorized Unauthorized 用于定义未通过授权中间件时的响应体（找不到访问实体，即 LookupHandler 返回的结果为空）。\n函数签名：\nfunc WithUnauthorized(u app.HandlerFunc) Option 示例代码：\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithUnauthorized(func(c context.Context, ctx *app.RequestContext) { ctx.AbortWithStatus(consts.StatusUnauthorized) }), ), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } WithForbidden Forbidden 用于定义访问到禁止访问资源的响应体（访问实体没有相应权限）。\n函数签名：\nfunc WithForbidden(f app.HandlerFunc) Option 示例代码：\nfunc main(){ ... h := server.Default() m, err := casbin.NewCasbinMiddleware(\"example/config/model.conf\", \"example/config/policy.csv\", subjectFromSession) if err != nil { log.Fatal(err) } h.GET(\"/book\", m.RequiresPermissions(\"book:read\", casbin.WithForbidden(func(c context.Context, ctx *app.RequestContext) { ctx.AbortWithStatus(consts.StatusForbidden) }), ), func(ctx context.Context, c *app.RequestContext) { c.String(200, \"you read the book successfully\") }, ) ... } ","categories":"","description":"","excerpt":"Casbin 是⼀个强⼤的、⾼效的开源访问控制框架，其权限管理机制支持常用的多种访问控制模型，如 ACL/RBAC/ABAC 等。可以实现灵 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/casbin/","tags":"","title":"Casbin"},{"body":"Default implementation Kitex defines several interfaces in the package pkg/klog: Logger, CtxLoggerKey and FormatLogger. And it provides a default logger that implements those interfaces and can be accessed by calling klog.DefaultLogger().\nThere are global functions in the package pkg/klog that expose the ability of the default logger, like klog.Info, klog.Errorf and so on.\nNote that the default logger uses the log.Logger from the standard library as its underlying output. So the filename and line number shown in the log messages depend on the setting of call depth. Thus wrapping the implementation of klog.DefaultLogger may cause inaccuracies for these two values.\nInject your custom logger implementation You can use klog.SetLogger to replace the default logger.\nobs-opentelemetry provide logger implementation base on logrus and zap\nLogrus set logger impl\nimport ( kitexlogrus \"github.com/kitex-contrib/obs-opentelemetry/logging/logrus\" ) func init() { klog.SetLogger(kitexlogrus.NewLogger()) klog.SetLevel(klog.LevelDebug) ... } log with context\n// Echo implements the Echo interface. func (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) { klog.CtxDebugf(ctx, \"echo called: %s\", req.GetMessage()) return \u0026api.Response{Message: req.Message}, nil } view log\n{\"level\":\"debug\",\"msg\":\"echo called: my request\",\"span_id\":\"056e0cf9a8b2cec3\",\"time\":\"2022-03-09T02:47:28+08:00\",\"trace_flags\":\"01\",\"trace_id\":\"33bdd3c81c9eb6cbc0fbb59c57ce088b\"} Redirecting the Output of the Default Logger The klog.SetOutput can be used to redirect the output of the default logger provided by the pkg/klog package.\nFor example, to redirect the output of the default logger to a file name ./output.log under the launch directory, a possible implementation might be:\npackage main import ( \"os\" \"github.com/cloudwego/kitex/pkg/klog\" ) func main() { f, err := os.OpenFile(\"./output.log\", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) if err != nil { panic(err) } defer f.Close() klog.SetOutput(f) ... // continue to set up your server } ","categories":"","description":"Kitex supports default logger implementation, injection of custom loggers and redirection of default logger output.","excerpt":"Kitex supports default logger implementation, injection of custom …","ref":"/docs/kitex/tutorials/basic-feature/logging/","tags":"","title":"Logging"},{"body":"默认实现 Kitex 在 pkg/klog 里定义了 Logger、CtxLogger、FormatLogger 等几个接口，并提供了一个 FormatLogger 的默认实现，可以通过 klog.DefaultLogger() 获取到其实例。\npkg/klog 同时也提供了若干全局函数，例如 klog.Info、klog.Errorf 等，用于调用默认 logger 的相应方法。\n注意，由于默认 logger 底层使用标准库的 log.Logger 实现，其在日志里输出的调用位置依赖于设置的调用深度（call depth），因此封装 klog 提供的实现可能会导致日志内容里文件名和行数不准确。\n注入自定义 logger 实现 可以用 klog.SetLogger 来替换掉默认的 logger 实现。\nobs-opentelemetry 扩展下提供了基于 logrus 和 zap 的日志实现\nLogrus 设置 logger 为 logrus：\nimport ( kitexlogrus \"github.com/kitex-contrib/obs-opentelemetry/logging/logrus\" ) func init() { klog.SetLogger(kitexlogrus.NewLogger()) klog.SetLevel(klog.LevelDebug) ... } 将日志与 context 关联\n// Echo implements the Echo interface. func (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) { klog.CtxDebugf(ctx, \"echo called: %s\", req.GetMessage()) return \u0026api.Response{Message: req.Message}, nil } 日志输出\n{\"level\":\"debug\",\"msg\":\"echo called: my request\",\"span_id\":\"056e0cf9a8b2cec3\",\"time\":\"2022-03-09T02:47:28+08:00\",\"trace_flags\":\"01\",\"trace_id\":\"33bdd3c81c9eb6cbc0fbb59c57ce088b\"} 重定向默认 logger 的输出 可以使用 klog.SetOutput 来重定向 klog 提供的默认 logger 的输出。\n例如，要把默认 logger 的输出重定向到启动路径下的 ./output.log，可以这样实现：\npackage main import ( \"os\" \"github.com/cloudwego/kitex/pkg/klog\" ) func main() { f, err := os.OpenFile(\"./output.log\", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644) if err != nil { panic(err) } defer f.Close() klog.SetOutput(f) ... // continue to set up your server } ","categories":"","description":"Kitex 支持默认 logger 实现和注入自定义 logger 以及重定向默认 logger 输出。","excerpt":"Kitex 支持默认 logger 实现和注入自定义 logger 以及重定向默认 logger 输出。","ref":"/zh/docs/kitex/tutorials/basic-feature/logging/","tags":"","title":"日志"},{"body":"会议主题 ：CloudWeGo 社区会议 9.8\n参会人 ：GuangmingLuo, PureWhiteWu, ag9920, lsjbd, simon0-o, liu-song, ylck, CoderPoet, li-jin-gou, pkumza, jasondeng1997, Li Zheming, debug-LiXiwen, joway, Jacob953, Code:Z, HeyJavaBean, jayantxie, baiyutang, rogerogers, warthecatalyst, skyenought, baize, yiyun, Millione, ruokeqx\n会前必读 ：http://www.cloudwego.io/；https://github.com/cloudwego\n议程 1：CloudWeGo - Rust 开源项目集介绍 @PureWhiteWu  地址：github.com/cloudwego/volo Volo 是 CloudWeGo-Rust 开源项目集最主要的一个项目，里面包含三部分。一个是同名的 volo,包含了很多通用逻辑，Volo 里面还有一个 gRPC 框架和一个 Thrift 框架，它们的共同部分放在 volo 里面，我们可以用它扩展出很多不同的序列化协议和不同的 Transport 框架。Thrift 框架可以和 Kitex 完全兼容互调。gRPC 框架也是可以和业界的 Tonic、Kitex gRPC 等兼容。 Volo 里面抽象了一个 Motoro 库，这个库采用了 GAT 和 TAIT 特性。 Pilota 是纯 Rust 实现的一个高性能、可扩展、使用 Thrift 与 Protobuf 的编解码以及序列化的实现，不依赖 Protoc。它里面的设计很大程度上是和一个真正的编译器差不多的，设计了自己的 ir 层和 codegen 部分。想学习编译器的同学可以研究一下。 除了以上三个最主要的项目，还有一些相关项目。Metainfo 是用来传递元信息的基础库，Volo-rs 组织用来存放 Volo 相关的生态库，也欢迎大家一起贡献。如果有对 Volo 感兴趣的同学，可以直接加入用户群，随时在群里提问。   议程 2：CloudWeGo Community Membership 新变化 @PureWhiteWu  地址：https://github.com/cloudwego/community/blob/main/COMMUNITY_MEMBERSHIP.md 背景：首先，随着 CloudWeGo 子项目的扩充，每个子项目可能都有一些不同的维护者，因此以整个组织的形式管理这些权限或直接在仓库里面加权限不再合适；其次，之前 Member 和 Committer 混在一起，晋升层级较少，社区同学晋升空间有限。Approver 和 Maintainer 也需要更明确的定义。 我们的出发点是为了将在社交媒体平台上写文章宣传 CloudWeGo、但没有代码贡献的同学，与代码贡献者给区分开来，给予他们 Member 的身份，认可他们作为 CloudWeGo 社区的重要成员做出的贡献。同时对于提交代码的同学，他们也有了更加明确的权限和晋升路径的定义。这次规则更新既明确了晋升路径和晋升机制，又明确了每个层级的权利和要求。感兴趣的同学可以点击地址查看详细信息。   议程 3：Hertz 的 ReverseProxy 扩展介绍 @skyenought  PR 地址：https://github.com/cloudwego/cloudwego.github.io/pull/337 Hertz 的反向代理分 Server 和 Client，原生 Go 的 SDK 里面拥有反向代理功能，社区也有反向代理的需求，目前在文档建设阶段，准备开源。具体内容可以点击 PR 地址查看。  ","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 9.8\n参会人 ：GuangmingLuo, PureWhiteWu, ag9920, …","ref":"/zh/community/meeting_notes/2022-09-08/","tags":"","title":"CloudWeGo 社区会议 9.8"},{"body":"The ETag (or entity tag) HTTP response header is an identifier for a specific version of a resource. It lets caches be more efficient and save bandwidth, as a web server does not need to resend a full response if the content was not changed. Additionally, etags help to prevent simultaneous updates of a resource from overwriting each other (“mid-air collisions”). Hertz also provides Etag middleware that can operate on ETag, inspired by fiber’s implementation.\nInstall Download and install\ngo get github.com/hertz-contrib/etag Import into your code\nimport \"github.com/hertz-contrib/etag\" Example package main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/etag\" ) func main() { h := server.Default() h.Use(etag.New()) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong\") }) h.Spin() } Configuration    Configuration Default Description     WithWeak false Enable weak validator   WithNext nil Defines a function to skip etag middleware when return is true   WithGenerator nil Custom etag generation logic    WithWeak WithWeak will enable weak validator for ETag.\nFunction Signature:\nfunc WithWeak() Option Sample Code:\npackage main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/etag\" ) func main() { h := server.Default() h.Use(etag.New(etag.WithWeak())) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong\") }) h.Spin() } WithNext WithNext will skip etag middleware when the defined function returns true.\nFunction Signature:\nfunc WithNext(next NextFunc) Option Sample Code:\npackage main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/etag\" ) func main() { h := server.Default() h.Use(etag.New(etag.WithNext( func(ctx context.Context, c *app.RequestContext) bool { if string(c.Method()) == http.MethodPost { return true } else { return false } }, ))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong\") }) h.Spin() } WithGenerator WithGenerator will replace default ETag generation with yours.\nNote: you should not add W/ prefix to your custom ETag when used with WithWeak.\nFunction Signature:\nfunc WithGenerator(gen Generator) Option Sample Code:\npackage main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/etag\" ) func main() { h := server.Default() h.Use(etag.New(etag.WithGenerator( func(ctx context.Context, c *app.RequestContext) []byte { return []byte(\"my-custom-etag\") }, ))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong\") }) h.Spin() } Full Example Refer to the etag/example for full usage examples.\n","categories":"","description":"","excerpt":"The ETag (or entity tag) HTTP response header is an identifier for a …","ref":"/docs/hertz/tutorials/basic-feature/middleware/etag/","tags":"","title":"ETag"},{"body":"ETag HTTP 响应头是资源的特定版本的标识符。这可以让缓存更高效，并节省带宽，因为如果内容没有改变，Web 服务器不需要发送完整的响应。而如果内容发生了变化，使用 ETag 有助于防止资源的同时更新相互覆盖（“空中碰撞”）。 Hertz 也提供了可以对 ETag 进行操作的 ETag 中间件，参考了 fiber 的实现。\n安装 下载并安装\ngo get github.com/hertz-contrib/etag 导入\nimport \"github.com/hertz-contrib/etag\" 示例代码 package main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/etag\" ) func main() { h := server.Default() h.Use(etag.New()) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong\") }) h.Spin() } 配置    配置 默认值 介绍     WithWeak false 使用弱验证器   WithNext nil 定义一个 Next 函数，当返回值为 true 时跳过 etag 中间件   WithGenerator nil 自定义 ETag 生成逻辑    WithWeak etag 中间件提供了 WithWeak，用于使用弱验证器。\n函数签名：\nfunc WithWeak() Option 示例代码：\npackage main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/etag\" ) func main() { h := server.Default() h.Use(etag.New(etag.WithWeak())) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong\") }) h.Spin() } WithNext etag 中间件提供了 WithNext，当定义的 Next 函数返回值为 true 时，跳过 etag 中间件。\n函数签名：\nfunc WithNext(next NextFunc) Option 示例代码：\npackage main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/etag\" ) func main() { h := server.Default() h.Use(etag.New(etag.WithNext( func(ctx context.Context, c *app.RequestContext) bool { if string(c.Method()) == http.MethodPost { return true } else { return false } }, ))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong\") }) h.Spin() } WithGenerator etag 中间件提供 WithGenerator，以供用户自定义 ETag 的生成逻辑。\n注意：当与 WithWeak 一起使用时，不应该在你的自定义 ETag 前添加 W/ 前缀。\n函数签名：\nfunc WithGenerator(gen Generator) Option 示例代码：\npackage main import ( \"context\" \"net/http\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/hertz-contrib/etag\" ) func main() { h := server.Default() h.Use(etag.New(etag.WithGenerator( func(ctx context.Context, c *app.RequestContext) []byte { return []byte(\"my-custom-etag\") }, ))) h.GET(\"/ping\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"pong\") }) h.Spin() } 完整示例 完整用法示例详见 etag/example\n","categories":"","description":"","excerpt":"ETag HTTP 响应头是资源的特定版本的标识符。这可以让缓存更高效，并节省带宽，因为如果内容没有改变，Web 服务器不需要发送完整的响 …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/etag/","tags":"","title":"ETag"},{"body":"Business custom exceptions is convenient for users to use err that implements a specific interface to transmit business exceptions, so as to distinguish them from RPC exceptions. An RPC exception usually indicates a failure of an RPC request, such as timeout, circuit breaker, or current limit. From the RPC level, it is a failed request. But the business error belongs to the business logic level, at the RPC level, the request is actually successful. It is recommended for service monitoring to report RPC errors as request failures and business-level errors as success, and use the additional biz_status_code field to report business exception status codes. This ability has certain value for engineering practice.\nBizStatusError interface definition The built-in BizStatusErrorIface provides a business exception interfaces. The framework also provides default implementations, and users can also customize implementations. The gRPC business Error can implement GRPCStatusIface at the same time, so as to reuse the Detail of Status to transparently transmit richer business information.\ntype BizStatusErrorIface interface { BizStatusCode() int32 BizMessage() string BizExtra() map[string]string Error() string } type GRPCStatusIface interface { GRPCStatus() *status.Status SetGRPCStatus(status *status.Status) } Instructions for use You can use the NewBizStatusError or NewBizStatusErrorWithExtra function in the server handler to construct a business exception and return it as err. After that, on the client side, convert err back to BizStatusErrorIface through the FromBizStatusError function to obtain the required exception information.\nUsage example Use TTHeader as transport protocol:\n// Server side func (*MyServiceHandler) TestError(ctx context.Context, req *myservice.Request) (r *myservice.Response, err error) { // ...  err = kerrors.NewBizStatusError(404, \"not found\") return nil, err } svr := myservice.NewServer(\u0026MyServiceHandler{}, server.WithMetaHandler(transmeta.ServerTTHeaderHandler)) // Client side cli := myservice.MustNewClient(\"client\", client.WithTransportProtocol(transport.TTHeader), client.WithMetaHandler(transmeta.ClientTTHeaderHandler)) resp, err := cli.TestError(ctx, req) bizErr, isBizErr := kerrors.FromBizStatusError(err) To pass additional gRPC Detail, use NewGRPCBizStatusError or NewGRPCBizStatusErrorWithExtra to construct an exception:\n Note: gRPC users can still use NewBizStatusError or NewBizStatusErrorWithExtra if not needed to pass gRPC Detail.\n // Server side func (*Handler) Serve(ctx, Request) (Response, error) { bizErr := kerrors.NewGRPCBizStatusError(404, \"not found\") grpcStatusErr := bizErr.(kerrors.GRPCStatusIface) st, _ := grpcStatusErr.GRPCStatus().WithDetails(\u0026echo.Echo{Str: \"hello world\"}) grpcStatusErr.SetGRPCStatus(st) return nil, bizErr } // ... svr := myservice.NewServer(\u0026Handler{}) // Client side cli := myservice.MustNewClient(\"client\", client.WithTransportProtocol(transport.GRPC)) resp, err := cli.Serve(ctx, req) if err != nil { if bizErr, ok := kerrors.FromBizStatusError(err); ok { println(bizErr.BizStatusCode()) println(bizErr.BizMessage()) println(bizErr.(status.Iface).GRPCStatus().Details()[0].(*echo.Echo).Str) // ...  } } Framework implementation It relies on transport protocols to transparently transmit the error code and error information of business exceptions. Thrift and Kitex Protobuf rely on TTHeader, and Kitex gRPC relies on HTTP2.\n Thrift: use TTHeader Kitex Protobuf: use TTHeader gRPC: use HTTP2 Header  Framework handling TTHeader Three new string keys have been added, namely biz-status , biz-message and biz-extra.\nFor the server, if the user constructs an error through NewBizStatusError, fill the errorCode , message and extra information into biz-status, biz-message and biz-extra respectively;\nFor the caller, if biz-status != 0 in TTHeader, construct BizStatusErrorIface and return it to the user.\nStreaming - gRPC GRPC exceptions are passed through HTTP2 Header, statusCode and statusMessage correspond to grpc-status and grpc-message in the header respectively.\nIn order to achieve forward version compatibility and distinguish RPC exceptions of gRPC, additional fields biz-status and biz-extra are added on HTTP2 Header, which correspond to the errorCode and extra info of BizStatusErrorIface respectively, while errMessage reuses grpc-message fields.\nWhen the server returns a business exception, encode grpc-status as statusCode in the GRPCStatusIface interface implemented by business exceptions or codes.Internal, and also encode biz-status. In this way, after the upstream receives the response and finds that the biz-status header is set, the error can be converted into BizStatusErrorIface and returned to the client handler. Even if the upstream does not support business exceptions, the error returned by the server can still be handled relatively correctly, only the ability to identify business exceptions is lost.\n","categories":"","description":"Kitex has provided business custom exceptions since v0.4.3. This doc covers the interface definition, user usage, and framework implementation.","excerpt":"Kitex has provided business custom exceptions since v0.4.3. This doc …","ref":"/docs/kitex/tutorials/basic-feature/bizstatuserr/","tags":"","title":"Business Exception"},{"body":"业务自定义异常方便用户使用实现了特定接口的 err 来传递业务异常，以便与 RPC 链路异常做区分。RPC 异常通常表示一次 RPC 请求失败，比如超时、熔断、限流，从 RPC 层面是失败的请求， 但业务错误属于业务逻辑层面，在 RPC 层面其实是请求成功。服务监控建议对于 RPC 错误上报为请求失败，而业务层面错误，上报为请求成功，而使用额外的 biz_status_code 字段上报业务异常状态码。该能力对于工程实践具有一定的价值。\nBizStatusError 接口定义 内置 BizStatusErrorIface 提供自定义异常接口，框架同时提供默认实现，用户也可以自定义实现。gRPC 用户自定义的 Error 可同时实现 GRPCStatusIface ，以便复用 Status 的 Detail 用于透传更丰富的业务信息。\ntype BizStatusErrorIface interface { BizStatusCode() int32 BizMessage() string BizExtra() map[string]string Error() string } type GRPCStatusIface interface { GRPCStatus() *status.Status SetGRPCStatus(status *status.Status) } 用户使用 你可以在 server handler 使用 NewBizStatusError 或 NewBizStatusErrorWithExtra 函数构造业务异常并作为err返回。之后在 client 端通过 FromBizStatusError 函数将err转换回 BizStatusErrorIface 来获取需要的异常信息。\n用法示例 使用 TTHeader 作为传输协议：\n// Server side func (*MyServiceHandler) TestError(ctx context.Context, req *myservice.Request) (r *myservice.Response, err error) { // ...  err = kerrors.NewBizStatusError(404, \"not found\") return nil, err } svr := myservice.NewServer(\u0026MyServiceHandler{}, server.WithMetaHandler(transmeta.ServerTTHeaderHandler)) // Client side cli := myservice.MustNewClient(\"client\", client.WithTransportProtocol(transport.TTHeader), client.WithMetaHandler(transmeta.ClientTTHeaderHandler)) resp, err := cli.TestError(ctx, req) bizErr, isBizErr := kerrors.FromBizStatusError(err) 如需额外传递 gRPC Detail，可以使用 NewGRPCBizStatusError 或 NewGRPCBizStatusErrorWithExtra 来构造异常：\n 注：如无需传递 gRPC Detail，gRPC 用户仍可以使用 NewBizStatusError 或 NewBizStatusErrorWithExtra.\n // Server side func (*Handler) Serve(ctx, Request) (Response, error) { bizErr := kerrors.NewGRPCBizStatusError(404, \"not found\") grpcStatusErr := bizErr.(kerrors.GRPCStatusIface) st, _ := grpcStatusErr.GRPCStatus().WithDetails(\u0026echo.Echo{Str: \"hello world\"}) grpcStatusErr.SetGRPCStatus(st) return nil, bizErr } // ... svr := myservice.NewServer(\u0026Handler{}) // Client side cli := myservice.MustNewClient(\"client\", client.WithTransportProtocol(transport.GRPC)) resp, err := cli.Serve(ctx, req) if err != nil { if bizErr, ok := kerrors.FromBizStatusError(err); ok { println(bizErr.BizStatusCode()) println(bizErr.BizMessage()) println(bizErr.(status.Iface).GRPCStatus().Details()[0].(*echo.Echo).Str) // ...  } } 框架实现 依赖传输协议透传自定义异常的错误码和错误信息，Thrift 和 Kitex Protobuf 依赖 TTHeader，Kitex gRPC 依赖 HTTP2。\n Thrift：使用 TTHeader Kitex Protobuf：使用 TTHeader gRPC：使用 HTTP2 Header  框架处理 TTHeader 新增了三个 string key，分别是 biz-status 、 biz-message 和 biz-extra。\n对于服务端，如果用户通过 NewBizStatusError 构造了 error，将 errorCode、message 和 extra 信息分别装填到 biz-status、biz-message 和 biz-extra；\n对于调用端，如果 TTHeader 中 biz-status != 0，则构造 BizStatusErrorIface 返回给用户。\nStreaming - gRPC gRPC 的 RPC 异常是通过 HTTP2 Header 传递的，statusCode 和 statusMessage 分别对应 header 中的 grpc-status 和 grpc-message。\n为尽量做到前向兼容，同时区分 gRPC 的 RPC 异常，在其现有基础上额外增加 biz-status 和 biz-extra 字段，分别对应于 BizStatusErrorIface 的 errorCode 和 extra，而 message 则复用 grpc-message。\n在 server 返回自定义异常时，将 grpc-status 编码为业务异常实现的 GRPCStatusIface 接口中的 statusCode 或 codes.Internal，同时编码 biz-status。这样，上游收到响应后，发现设置了 biz-status header, 即可将错误转换为 BizStatusErrorIface 返回给 client handler。即使上游不支持自定义异常，也能相对正确地处理 server 返回的 error，只不过丢失了识别业务异常的能力。\n","categories":"","description":"Kitex 自 v0.4.3 版本提供了业务自定义异常功能，本文涵盖了相关接口定义、用户使用和框架实现介绍。","excerpt":"Kitex 自 v0.4.3 版本提供了业务自定义异常功能，本文涵盖了相关接口定义、用户使用和框架实现介绍。","ref":"/zh/docs/kitex/tutorials/basic-feature/bizstatuserr/","tags":"","title":"业务异常"},{"body":"会议主题 ：CloudWeGo 社区会议 9.22\n参会人 ：GuangmingLuo, simon0-o, liu-song, YangruiEmma, CoderPoet, li-jin-gou, wangbei98, FlyDangerFox, Authority, derek3, FGYFFFF, ppzqh, Code:Z, LemonFish, justlorain, HeyJavaBean, Yang Hong, baiyutang, rogerogers, skyenought, baize, Millione, chens\n会前必读 ：http://www.cloudwego.io/；https://github.com/cloudwego\n议程 1 ：新人自我介绍  新成员名单：@wangbei98 @justlorain @Yang Hong @chens @FlyDangerFox 社区新成员分别进行自我介绍，主要包含个人基本情况、开源贡献经历和后续参与社区工作内容。   议程 2：基于 Kitex 和 Hertz 的 bookinfo 全链路泳道 demo 介绍和演示 @CoderPoet  地址：   bookinfo（附演示 demo） https://github.com/cloudwego/biz-demo/pull/2 xDS https://github.com/kitex-contrib/xds/pull/5/files 项目的工程架构 github.com/CoderPoet/biz-demo/blob/feature%2Fbookinfo-proxyless-otel-demo/bookinfo/README_CN.md  背景：在 biz-demo 中使用 kitex 和 hertz 重写 bookinfo 项目。实现的目的是为了以实战的方式演示如何使用 xDS 实现全链路的流量泳道。这个项目是复刻社区的 bookinfo 的部署模式，分为 Productpage、Reviews、Details 以及 Ratings，使用 kitex 和 hertz 完全重写。Productpage 是用 Hertz Server 写的，并且内嵌了 Kitex Client。 Kitex Client 集成了 xDS 的模块，主要负责与控制面的 Istiod 做交互，Istiod 可以动态地根据 xDS 下发路由规则。具体路由规则以及工程架构可点击上方链接查看。 另一个 PR 对 xDS 本身做了优化，之前用 rpcinfo 的 tag 做灰度标识 Header 匹配，但不太符合日常场景，因为通常用 metadata 传递请求元数据，所以做了相应的改造。具体内容可点击查看上方链接查看。   议程 3：Hertz 新手任务介绍与 Cookbook 专项任务介绍 @li-jin-gou   单测任务：github.com/cloudwego/hertz/issues/257 相关文档：Hertz Cookbook\n  目前还有 10 个单侧任务任务待领取，后续也会继续放出扩展类或文档类的 first good issue，欢迎大家积极认领。\n  Cookbook 背景：当前文档建设过于简陋，易用性方面有待加强，需要持续优化，方便新手使用。Cookbook 分为官方文档和代码示例两部分，目前代码示例待完善。具体官方文档待建设部分及其完善标准可点击上方链接查看，后续欢迎大家积极认领文档任务，官网和文档贡献也是非常核心的社区贡献，优秀的 Contributor 也可以申请成为官网 \u0026 文档的 Committer。\n   议程 4：Hertz pprof 扩展介绍 @wangbei98  文档：Hertz-pprof 背景：   pprof 是一个可以对 Go 程序的 CPU 内存以及 Goroutine 运行时进行动态信息采样的工具包，采样后以数据的方式展示，从而帮助开发人员进行快速地定位问题。常见的 HTTP 框架以及 gRPC 框架都会有相应的 pprof 扩展。这个扩展的底层实现依赖于 Go 语言内部 runtime/pprof 包，进一步的在 net/http/pprof 包里面对上述的 Go 语言包进行封装，对外提供 HTTP 的服务。 在本项目中，为了在 Hertz 中引入 pprof 的能力，需要对 HTTP 包里面的 pprof 进一步封装。因为 HTTP 包里面 pprof 对外提供的是 http.Handler 以及 http.HandlerFunc，但是 Hertz 并不感知 HTTP 包里面的 http.Handler 以及 http.HandlerFunc，因此需要对其进行转换。具体实现过程请查看上方链接中的文档。  ","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 9.22\n参会人 ：GuangmingLuo, simon0-o, liu-song, …","ref":"/zh/community/meeting_notes/2022-09-22/","tags":"","title":"CloudWeGo 社区会议 9.22"},{"body":"cache is a middleware for caching HTTP Responses, which helps to improve the concurrent access capacity of the Server. Hertz also provides the adaptation of cache, supporting multi-backend, referring to gin-cache.\nInstall go get github.com/hertz-contrib/cache Import import \"github.com/hertz-contrib/cache\" Example  memory  func main() { h := server.New() // sets the global TTL value for items in the cache, which can be overridden at the item level  memoryStore := persist.NewMemoryStore(1 * time.Minute) // sets the TTL value for URI-based items in the cache  h.Use(cache.NewCacheByRequestURI(memoryStore, 2*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() }  redis  func main() { h := server.New() redisStore := persist.NewRedisStore(redis.NewClient(\u0026redis.Options{ Network: \"tcp\", Addr: \"127.0.0.1:6379\", })) h.Use(cache.NewCacheByRequestURI(redisStore, 2*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } Initialization cache provides three ways of initialization.\nNewCacheByRequestURI NewCacheByRequestURI is used to create middleware that caches response results with URI as the key.\nFunction Signature:\nfunc NewCacheByRequestURI(defaultCacheStore persist.CacheStore, defaultExpire time.Duration, opts ...Option) app.HandlerFunc Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestURI(memoryStore, 2*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } NewCacheByRequestPath NewCacheByRequestPath is used to create middleware that caches response results with URL as the key, discarding the query parameter.\nFunction Signature:\nfunc NewCacheByRequestPath(defaultCacheStore persist.CacheStore, defaultExpire time.Duration, opts ...Option) app.HandlerFunc Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestPath(memoryStore, 2*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } NewCache NewCache is used to create middleware for custom cache logic, and the cache key must be declared manually (required in conjunction with WithCacheStrategyByRequest).\nFunction Signature:\nfunc NewCache( defaultCacheStore persist.CacheStore, defaultExpire time.Duration, opts ...Option, ) app.HandlerFunc Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCache( memoryStore, 2*time.Second, cache.WithCacheStrategyByRequest(func(ctx context.Context, c *app.RequestContext) (bool, cache.Strategy) { return true, cache.Strategy{ CacheKey: c.Request.URI().String(), } }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } Configuration    Configuration Default Description     WithCacheStrategyByRequest nil Used to set custom caching policies   WithOnHitCache nil Used to set the callback function after a cache hits   WithOnMissCache nil Used to set the callback function for cache misses   WithBeforeReplyWithCache nil Used to set the callback function before returning the cached response   WithOnShareSingleFlight nil Used to set the callback function when the result of a SingleFlight is shared by the request   WithSingleFlightForgetTimeout 0 Used to set the timeout for SingleFlight   WithIgnoreQueryOrder false Used to set the order in which query parameters are ignored when using a URI as the cached Key   WithPrefixKey \"\" Used to set the prefix of the cache response key   WithoutHeader false Used to set whether response headers need to be cached    WithCacheStrategyByRequest Customize the cache policy by using WithCacheStrategyByRequest, including the cache key, storage medium, and expiration time.\nThis configuration assumes that the cache middleware is initialized via the cache.NewCache method.\nFunction Signature:\nfunc WithCacheStrategyByRequest(getGetCacheStrategyByRequest GetCacheStrategyByRequest) Option Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCache( memoryStore, 2*time.Second, cache.WithCacheStrategyByRequest(func(ctx context.Context, c *app.RequestContext) (bool, cache.Strategy) { return true, cache.Strategy{ CacheKey: c.Request.URI().String(), } }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithOnHitCache \u0026 WithOnMissCache Set the callback function for cache hits by using WithOnHitCache.\nSet the callback function for cache misses by using WithOnMissCache.\nFunction Signature:\nfunc WithOnHitCache(cb OnHitCacheCallback) Option func WithOnMissCache(cb OnMissCacheCallback) Option Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) var cacheHitCount, cacheMissCount int32 h.Use(cache.NewCacheByRequestURI( memoryStore, 2*time.Second, cache.WithOnHitCache(func(ctx context.Context, c *app.RequestContext) { atomic.AddInt32(\u0026cacheHitCount, 1) }), cache.WithOnMissCache(func(ctx context.Context, c *app.RequestContext) { atomic.AddInt32(\u0026cacheMissCount, 1) }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.GET(\"/get_hit_count\", func(ctx context.Context, c *app.RequestContext) { c.String(200, fmt.Sprintf(\"total hit count: %d\", cacheHitCount)) }) h.GET(\"/get_miss_count\", func(ctx context.Context, c *app.RequestContext) { c.String(200, fmt.Sprintf(\"total miss count: %d\", cacheMissCount)) }) h.Spin() } WithBeforeReplyWithCache Set the callback function before returning the cached response by using WithBeforeReplyWithCache.\nFunction Signature:\nfunc WithBeforeReplyWithCache(cb BeforeReplyWithCacheCallback) Option Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestURI( memoryStore, 2*time.Second, cache.WithBeforeReplyWithCache(func(c *app.RequestContext, cache *cache.ResponseCache) { cache.Data = append([]byte{'p', 'r', 'e', 'f', 'i', 'x', '-'}, cache.Data...) }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithOnShareSingleFlight \u0026 WithSingleFlightForgetTimeout Set the callback function when a SingleFlight result is requested to be shared by using WithOnShareSingleFlight.\nSet the timeout for SingleFlight by using WithSingleFlightForgetTimeout.\nFunction Signature:\nfunc WithOnShareSingleFlight(cb OnShareSingleFlightCallback) Option func WithSingleFlightForgetTimeout(forgetTimeout time.Duration) Option Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestPath( memoryStore, 10*time.Second, cache.WithOnShareSingleFlight(func(ctx context.Context, c *app.RequestContext) { hlog.Info(\"share the singleFlight result \" + string(c.Response.Body())) }), cache.WithSingleFlightForgetTimeout(1*time.Second), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { time.Sleep(3 * time.Second) c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithIgnoreQueryOrder Set the query parameter order of the URI to be ignored when creating a cache middleware using the NewCacheByRequestURI method by using WithIgnoreQueryOrder.\nFunction Signature:\nfunc WithIgnoreQueryOrder(b bool) Option Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestPath( memoryStore, 60*time.Second, cache.WithIgnoreQueryOrder(true), cache.WithOnHitCache(func(c context.Context, ctx *app.RequestContext) { hlog.Infof(\"hit cache IgnoreQueryOrder\") }), cache.WithOnMissCache(func(c context.Context, ctx *app.RequestContext) { hlog.Infof(\"miss cache IgnoreQueryOrder\") }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithPrefixKey Set the prefix of the response key by using WithPrefixKey.\nFunction Signature:\nfunc WithPrefixKey(prefix string) Option Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCache( memoryStore, 60*time.Second, cache.WithPrefixKey(\"prefix-\"), cache.WithOnHitCache(func(c context.Context, ctx *app.RequestContext) { resp := \u0026cache.ResponseCache{} memoryStore.Get(c, \"prefix-test\", \u0026resp) hlog.Info(\"data = \" + string(resp.Data)) }), cache.WithCacheStrategyByRequest(func(ctx context.Context, c *app.RequestContext) (bool, cache.Strategy) { return true, cache.Strategy{ CacheKey: \"test\", } }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithoutHeader Set whether the response header should be cached by using WithoutHeader, or cache the response header if it is false.\nFunction Signature:\nfunc WithoutHeader(b bool) Option Sample Code:\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCache( memoryStore, 60*time.Second, cache.WithoutHeader(true), cache.WithCacheStrategyByRequest(func(ctx context.Context, c *app.RequestContext) (bool, cache.Strategy) { return true, cache.Strategy{ CacheKey: \"test-key\", } }), cache.WithOnHitCache(func(c context.Context, ctx *app.RequestContext) { resp := \u0026cache.ResponseCache{} memoryStore.Get(c, \"test-key\", \u0026resp) hlog.Info(\"header = \" + string(resp.Header.Get(\"head\"))) hlog.Info(\"data = \" + string(resp.Data)) }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } Full Example Refer to the cache/example for full usage examples.\n","categories":"","description":"","excerpt":"cache is a middleware for caching HTTP Responses, which helps to …","ref":"/docs/hertz/tutorials/basic-feature/middleware/cache/","tags":"","title":"Cache"},{"body":"cache 是一个用于缓存 HTTP 响应的中间件，开启后有助于提高服务器的并发访问能力。Hertz 也提供了对 cache 的适配，支持 multi-backend，参考了 gin-cache 的实现。\n安装 go get github.com/hertz-contrib/cache 导入 import \"github.com/hertz-contrib/cache\" 示例代码  memory  func main() { h := server.New() // 设置全局的缓存过期时间（会被更细粒度的设置覆盖）  memoryStore := persist.NewMemoryStore(1 * time.Minute) // 设置针对以 URI 为 Key 的缓存过期时间  h.Use(cache.NewCacheByRequestURI(memoryStore, 2*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() }  redis  func main() { h := server.New() redisStore := persist.NewRedisStore(redis.NewClient(\u0026redis.Options{ Network: \"tcp\", Addr: \"127.0.0.1:6379\", })) h.Use(cache.NewCacheByRequestURI(redisStore, 2*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } 初始化 cache 中间件提供了三种初始化的方式。\nNewCacheByRequestURI 用于创建以 URI 为 Key 的缓存响应结果的中间件。\n函数签名：\nfunc NewCacheByRequestURI(defaultCacheStore persist.CacheStore, defaultExpire time.Duration, opts ...Option) app.HandlerFunc 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestURI(memoryStore, 2*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } NewCacheByRequestPath 用于创建以 URL 为 Key 的缓存响应结果的中间件，丢弃 query 参数。\n函数签名：\nfunc NewCacheByRequestPath(defaultCacheStore persist.CacheStore, defaultExpire time.Duration, opts ...Option) app.HandlerFunc 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestPath(memoryStore, 2*time.Second)) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } NewCache 用于创建自定义缓存逻辑的中间件，必须手动声明缓存的 Key（需要使用 WithCacheStrategyByRequest 配置参数）。\n函数签名：\nfunc NewCache( defaultCacheStore persist.CacheStore, defaultExpire time.Duration, opts ...Option, ) app.HandlerFunc 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCache( memoryStore, 2*time.Second, cache.WithCacheStrategyByRequest(func(ctx context.Context, c *app.RequestContext) (bool, cache.Strategy) { return true, cache.Strategy{ CacheKey: c.Request.URI().String(), } }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } 配置    配置 默认值 介绍     WithCacheStrategyByRequest nil 用于设置自定义的缓存策略   WithOnHitCache nil 用于设置缓存命中的回调函数   WithOnMissCache nil 用于设置缓存未命中的回调函数   WithBeforeReplyWithCache nil 用于设置返回缓存响应前的回调函数   WithOnShareSingleFlight nil 用于设置请求共享 SingleFlight 结果时的回调函数   WithSingleFlightForgetTimeout 0 用于设置 SingleFlight 的超时时间   WithIgnoreQueryOrder false 用于设置当使用 URI 为缓存的 Key 时，忽略 query 参数的顺序   WithPrefixKey \"\" 用于设置缓存响应 Key 的前缀   WithoutHeader false 用于设置是否需要缓存响应头    WithCacheStrategyByRequest 通过使用 WithCacheStrategyByRequest 自定义缓存策略，包括缓存的 Key、存储介质，以及过期时间。\n该配置生效的前提是，通过 cache.NewCache 方法初始化 cache 中间件。\n函数签名：\nfunc WithCacheStrategyByRequest(getGetCacheStrategyByRequest GetCacheStrategyByRequest) Option 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCache( memoryStore, 2*time.Second, cache.WithCacheStrategyByRequest(func(ctx context.Context, c *app.RequestContext) (bool, cache.Strategy) { return true, cache.Strategy{ CacheKey: c.Request.URI().String(), } }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithOnHitCache \u0026 WithOnMissCache 通过使用 WithOnHitCache 设置缓存命中的回调函数。\n通过使用 WithOnMissCache 设置缓存未命中的回调函数。\n函数签名：\nfunc WithOnHitCache(cb OnHitCacheCallback) Option func WithOnMissCache(cb OnMissCacheCallback) Option 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) var cacheHitCount, cacheMissCount int32 h.Use(cache.NewCacheByRequestURI( memoryStore, 2*time.Second, cache.WithOnHitCache(func(ctx context.Context, c *app.RequestContext) { atomic.AddInt32(\u0026cacheHitCount, 1) }), cache.WithOnMissCache(func(ctx context.Context, c *app.RequestContext) { atomic.AddInt32(\u0026cacheMissCount, 1) }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.GET(\"/get_hit_count\", func(ctx context.Context, c *app.RequestContext) { c.String(200, fmt.Sprintf(\"total hit count: %d\", cacheHitCount)) }) h.GET(\"/get_miss_count\", func(ctx context.Context, c *app.RequestContext) { c.String(200, fmt.Sprintf(\"total miss count: %d\", cacheMissCount)) }) h.Spin() } WithBeforeReplyWithCache 通过使用 WithBeforeReplyWithCache 设置返回缓存响应前的回调函数。\n函数签名：\nfunc WithBeforeReplyWithCache(cb BeforeReplyWithCacheCallback) Option 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestURI( memoryStore, 2*time.Second, cache.WithBeforeReplyWithCache(func(c *app.RequestContext, cache *cache.ResponseCache) { cache.Data = append([]byte{'p', 'r', 'e', 'f', 'i', 'x', '-'}, cache.Data...) }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithOnShareSingleFlight \u0026 WithSingleFlightForgetTimeout 通过使用 WithOnShareSingleFlight 设置请求共享 SingleFlight 结果时的回调函数。\n通过使用 WithSingleFlightForgetTimeout 设置 SingleFlight 的超时时间。\n函数签名：\nfunc WithOnShareSingleFlight(cb OnShareSingleFlightCallback) Option func WithSingleFlightForgetTimeout(forgetTimeout time.Duration) Option 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestPath( memoryStore, 10*time.Second, cache.WithOnShareSingleFlight(func(ctx context.Context, c *app.RequestContext) { hlog.Info(\"share the singleFlight result \" + string(c.Response.Body())) }), cache.WithSingleFlightForgetTimeout(1*time.Second), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { time.Sleep(3 * time.Second) c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithIgnoreQueryOrder 通过使用 WithIgnoreQueryOrder 设置当使用 NewCacheByRequestURI 方法创建缓存中间件时，忽略 URI 的 query 参数顺序（为 true 触发参数排序）。\n函数签名：\nfunc WithIgnoreQueryOrder(b bool) Option 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCacheByRequestPath( memoryStore, 60*time.Second, cache.WithIgnoreQueryOrder(true), cache.WithOnHitCache(func(c context.Context, ctx *app.RequestContext) { hlog.Infof(\"hit cache IgnoreQueryOrder\") }), cache.WithOnMissCache(func(c context.Context, ctx *app.RequestContext) { hlog.Infof(\"miss cache IgnoreQueryOrder\") }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithPrefixKey 通过使用 WithPrefixKey 设置响应 Key 的前缀。\n函数签名：\nfunc WithPrefixKey(prefix string) Option 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCache( memoryStore, 60*time.Second, cache.WithPrefixKey(\"prefix-\"), cache.WithOnHitCache(func(c context.Context, ctx *app.RequestContext) { resp := \u0026cache.ResponseCache{} memoryStore.Get(c, \"prefix-test\", \u0026resp) hlog.Info(\"data = \" + string(resp.Data)) }), cache.WithCacheStrategyByRequest(func(ctx context.Context, c *app.RequestContext) (bool, cache.Strategy) { return true, cache.Strategy{ CacheKey: \"test\", } }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } WithoutHeader 通过使用 WithoutHeader 设置是否需要缓存响应头，为 false 则缓存响应头。\n函数签名：\nfunc WithoutHeader(b bool) Option 示例代码：\nfunc main() { h := server.New() memoryStore := persist.NewMemoryStore(1 * time.Minute) h.Use(cache.NewCache( memoryStore, 60*time.Second, cache.WithoutHeader(true), cache.WithCacheStrategyByRequest(func(ctx context.Context, c *app.RequestContext) (bool, cache.Strategy) { return true, cache.Strategy{ CacheKey: \"test-key\", } }), cache.WithOnHitCache(func(c context.Context, ctx *app.RequestContext) { resp := \u0026cache.ResponseCache{} memoryStore.Get(c, \"test-key\", \u0026resp) hlog.Info(\"header = \" + string(resp.Header.Get(\"head\"))) hlog.Info(\"data = \" + string(resp.Data)) }), )) h.GET(\"/hello\", func(ctx context.Context, c *app.RequestContext) { c.String(http.StatusOK, \"hello world\") }) h.Spin() } 完整示例 完整用法示例详见 cache/example\n","categories":"","description":"","excerpt":"cache 是一个用于缓存 HTTP 响应的中间件，开启后有助于提高服务器的并发访问能力。Hertz 也提供了对 cache 的适配， …","ref":"/zh/docs/hertz/tutorials/basic-feature/middleware/cache/","tags":"","title":"Cache"},{"body":"会议主题 ：CloudWeGo 社区会议 10.20\n参会人 ：cloudwegoIce, ag9920, YangruiEmma, CoderPoet, li-jin-gou, Ivnszn, liuq19, FGYFFFF, ppzqh, I2ncE, Code:Z, HeyJavaBean, jayantxie, Yang Hong, baiyutang, skyenought, rogerogers, cyyolo, Bai Yang, chens, Millione\n会前必读 ：http://www.cloudwego.io/ ; https://github.com/cloudwego\n议程 1：CloudWeGo-Volo 0.2.0 新发版介绍 @Millione  相关链接：Volo v0.2.0 正式发布：新增支持 Windows Volo 已经正式支持 Windows。在 Volo 的共性方面，首先是关于错误处理，修复了对 Error 类型的约束，即在实现中间件时，对于 gRPC 以及 Thrift 返回的 Error 需要实现一个转换方法，就能转换到框架的 Error 类型中。这样有助于我们做整体的服务治理，还有一些错误判断之类的逻辑功能。 如果分为 Thrift 和 gRPC，volo-thrift 正式支持了 multiplex，与 Ping-pong 模型不同的是不需要发 Request 之后，再等收到一个 Response 才能继续发下一个 Request，multiplex 可以多发多收，用户使用时也只需要指定开启这个特性，使用起来基本无感；最后，在 Thrift 方面，还优化了 write_field_begin 函数，主要是把这个函数内联到我们的框架里面编译，这样在某些场景下有较好的编码优化。 在 gRPC 方面，volo-grpc 支持 uds，因为不需要经过 TCP 等协议开销，在同机上面的跨进程 gRPC 调用会更快，同时在使用 Service Mesh 场景时有好的兼容；同时，volo-grpc 支持 metainfo 进行元信息传递，这个主要是用来在 Client 和Server 端之间进行一些字段信息的传递，之前 gRPC 支持放进 Request Metadata 中，但后续大家都使用 metainfo 可以统一用户在 Thrift 和 gRPC 的使用体验；volo-grpc 增加对 service discovery 和 load balance 的支持，这是 RPC 框架需要的一些能力，这个提供了一些接口，大家如果想实现某些东西，可以根据接口更好地接入。 除此之外，还有两个改动之处。第一，之前 Rust 在编辑器里有一个 Bug，导致我们的 Nightly 版本一直锁定在 7 月 31 号。目前已被修复，Nightly 版本也不需要限定，在文件里面指定最新版本的 Nightly 即可。第二，在 gRPC 方面接口方法有所增加，还有一些参数名字有所改动。  相关地址：https://github.com/cloudwego/volo/blob/main/rust-toolchain.toml\n如果大家想参与共建 Volo，可以多关注 Issue，我们也可以提供解释说明。在 gRPC 方面，Volo 的功能还有欠缺，所以大家可以做的贡献是比较多的。  相关地址：https://github.com/cloudwego/volo/issues\n 议程二：Kitex 新增 metainfo 示例代码分享 @baiyutang  PR: https://github.com/cloudwego/kitex-examples/pull/42 背景：9 月初有同学提关于 metadata 元信息的问题，很多人不太清楚具体用法。 基于背景做了两方面的优化。第一，优化文档；第二，做了代码的示例。文档强调“必须使用支持元信息的透传的底层协议才可用”。代码层面在 Kitex-examples 里做了一个 metainfo 示例。元信息的传递分两类：正向 \u0026 反向，正向的是从客户端传到服务端。并且传递的信息分两种，一种是只传递到它请求的那个服务端，另一种是持续地往后传递。因此我在客户端设置了两个元信息，第一个是假设它请求的第一个服务能接收到，第二个是假设后续的所有的服务都能接收到，并且在服务端都做了判断。如用户想了解用法，通过示例就可以运行起来，优化了框架的使用体验。   议程三：Hertz Playbook 进展 \u0026 新晋 Committer 介绍 @li-jin-gou  当前文档建设的易用性方面有待加强，需要持续优化，方便新手使用。Hertz Playbook 建设正在进行中，大部分文档优化的任务已经分配出去，目前大部分处于 PR 状态，其余任务如果大家感兴趣的话可以联系 @li-jin-gou。 @I2ncE 自我介绍，目前已正式成为 Hertz Committer。   议程四：CSG 3 期 Rust Volo \u0026 Monoio 项目学习，活动介绍和进度分享 @cloudwegoIce  Issue: https://github.com/cloudwego/community/issues/45 CSG 三期是关于 8 月新开源的 Volo 框架以及 Volo 生态的一些项目，同时还有关注度非常高的 Monoio，都会在第三期里面进行相关的源码解读。第一期直播已经结束，可以关注 CloudWeGo 公众号回复 “Volo\" 查看回放地址。 第三期的第二和第三场直播会和 Rustcc 社区合作，我们会也把自己的优质项目推到 Rust 基金会和 Rust 中文社区，和他们做比较深度的合作。后续也会有一些新的 Volo 生态和 Rust 生态的 Committer 和 Contributor 加入到我们的社区例会和社区组织中。欢迎大家持续关注。  ","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 10.20\n参会人 ：cloudwegoIce, ag9920, YangruiEmma, …","ref":"/zh/community/meeting_notes/2022-10-20/","tags":"","title":"CloudWeGo 社区会议 10.20"},{"body":"会议主题 ：CloudWeGo 社区会议 11.3\n参会人 ：GuangmingLuo, Cheng Guozhu, welkeyever, YangruiEmma, liu-song, Chen Rui, li-jin-gou, joway, liuq19, Duslia, bodhisatan, L2ncE, Code:Z, justlorain, CarlCao17, HeyJavaBean, jayantxie, Yang Hong, baiyutang, skyenought, rogerogers, cyyolo, cloudwegoIce, chens, Bai Yang\n会前必读 ：http://www.cloudwego.io/ ; https://github.com/cloudwego\n议程一：Kitex 生成代码定制默认注入自定义 Suite 介绍 @jayantxie  官网链接：Extend the Templates of Service Generated Code 目前字节内部的治理逻辑会封装到 Suite 里面，通过直接生成代码的方式提供给用户，用户在启动的时候就不用手动地引入 Suite Option。为了方便外部用户在生成代码里面扩展这个功能，我们也提供了这样一个功能。用户在生成代码时，可以通过 -template-extension 传入一个 extensions.json 文件，这个文件可以把 Suite 的代码注入到生代码里。extensions.json 是一个 JSON 文件，实现的是 TemplateExtension 的对象，这个对象里面有一些已经完成定义、可以注入到特定位置的代码。 Example: https://www.cloudwego.io/docs/kitex/tutorials/code-gen/template_extension/#example 如果 Client 端需要注入一个 Suite，可以通过 extend_option 加一行代码，把用户自定义 package 里面的 Suite 注入进来，我们生成的代码里面就自动包含了这个 Suite，方便用户使用。具体字段含义是，通过 import_paths 导入包，extend_file 主要功能是可以在生成代码里面提供一些全局的工具函数，如果用户需要提供公共方法，那么可以在这里注入。Server 端与之类似，比如需要公司内限流之类的功能，也可以通过封装到 Server Suite 里面注入代码即可实现，业务不用再导入对应的包。   议程二：Kitex 自定义异常介绍 @jayantxie  Issue 地址：https://github.com/cloudwego/kitex/issues/511  官网：https://www.cloudwego.io/zh/docs/kitex/tutorials/basic-feature/bizstatuserr/\n背景：这是在 Kitex v0.4.3 提供的功能。我们内部对于用户自定义的异常和 RPC 异常做了区分，因此希望把这个功能提供给外部用户使用，能够将 RPC 错误和业务的错误区分开。在出现故障或排查问题的时候，可以方便找到是链路侧的故障还是业务侧的故障。因此我们对 Kitex 异常处理重新做了实现。 我们内置 BizStatusErrorIface 提供用户实现自定义异常接口，框架同时提供默认实现，用户只需要在 ServiceHandler 里返回 Error，就可以在 Kitex 处理的时候把它编码到 TTheader 或 grpc trailer 中。封装完成后通过 Server 传递到 Client 端，Kitex 在解码的时候会对 TTheader 或 trailer 里面字段做特殊处理，把它转成业务 Error，再返回给 Client。这种方式在中间件处理或治理采集时直接跳过了用户自定义异常的处理。因此我们通过在业务 handler 里面直接返回 BizStatusErrorIface 不会触发熔断和链路异常等情况，它仅用于用户之间业务 Error 的传递。 TTheader 用法说明：https://github.com/cloudwego/kitex/pull/613/files 因为对外我们没有默认封装使用的 MetaHandler 和协议，自定义异常又借助于 TTheader 或 grpc Handler 的实现，所以 TTheader 协议的用户需要在 Server 里面初始化的时候，手动地初始化 TTheader 的 MetaHandler。在 Client 初始化的时候，同样指定 TTheader 协议，然后加载 TTheader 的 MetaHandler，这样才可以解析对应的字段。在 Server 使用的时候如果遇到业务异常，可以直接在 Handler 里面返回 Error。它主要包含的信息有：StatusCode 业务的状态码；StatusMessage 业务侧信息。Client 侧提供了对 Error 的识别，收到 Error 后，可以通过 kerrors.FromBizStatusError 把它转换成业务异常。收到业务异常后，我们就可以对不同的状态码做特殊的处理。 grpc 的用法与之类似，grpc在 StatusError 里面提供了 Details 功能，所以我们在业务异常里面同样也提供了这个功能。用法可以参考代码示例：https://github.com/cloudwego/kitex/blob/develop/pkg/kerrors/bizerrors.go#L73。 补充：这个功能对于 Thrift 更建议的用法是 IDL 里面定义一个 Exception，这样用户可以很明确地构造它定义的 Exception。我们做这个支持不可能耦合于 Thrift 协议，PB 的 IDL 是没有这个能力的，因此提供了这样比较通用的方式。@YangruiEmma   议程三：Hertz Lark 扩展库介绍 @li-jin-gou  项目地址：https://github.com/hertz-contrib/lark-hertz  飞书开放平台文档：https://open.feishu.cn/document/ukTMukTMukTM/uETO1YjLxkTN24SM5UjN\nGo SDK 说明文档：https://github.com/larksuite/oapi-sdk-go/blob/v3_main/README.md\n背景：飞书开放平台有一个 Go SDK 说明文档，最初里面卡片和消息的回调配置介绍只有 Gin 框架的。有同学反馈找不到 Hertz 如何集成的说明，实际 Hertz 有这部分的能力，但是一直是内部的代码没有开源出来。之前用户通过这个平台点到 Go SDK 说明文档，并不能很方便地能找到对于 Hertz 的支持。所以和 Lark 负责 Go SDK 的同学说明情况后，和他们一起把 Lark 集成 Hertz 的能力开源出来。这个仓库目前放在了 Hertz 扩展库里面。如果大家感兴趣可以体验一下，在处理事件消息回调的情况下使用这个扩展会比较方便。 使用场景：处理卡片和消息事件行为的回调。基于 oapi-sdk-go 做了一层封装，方便用户使用框架接入 SDK。关注 Hertz 的同学也更方便找到相关的内容。  ","categories":"","description":"","excerpt":"会议主题 ：CloudWeGo 社区会议 11.3\n参会人 ：GuangmingLuo, Cheng Guozhu, welkeyever, …","ref":"/zh/community/meeting_notes/2022-11-03/","tags":"","title":"CloudWeGo 社区会议 11.3"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/releases/","tags":"","title":"New Releases"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/community/meeting_notes/","tags":"","title":"会议记录"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/community/weekly_report/","tags":"","title":"周报"},{"body":" CloudWeGo 开源一周年技术沙龙 🏅 2021-2022 CloudWeGo Awesome Contributor 评选 CloudWeGo：从开源、开放到企业落地 GitHub 9K Star！字节高性能开源微服务中间件 CloudWeGo 技术沙龙来了！  ","categories":"","description":"","excerpt":" CloudWeGo 开源一周年技术沙龙 🏅 2021-2022 CloudWeGo Awesome Contributor …","ref":"/zh/community/past_activities/","tags":"","title":"往期活动"},{"body":"In Volo 0.4.1, in addition to the usual bugfixes, some new features have been introduced.\nMore detailed Thrift Decode error messages Previous versions of Thrift Decode error messages reported only the most basic errors, without any context. For example, it contained the following structural relationships\nstructA{1:requiredBb.}structB{2:requiredCc.}structC{3:requiredstringa.}If an error occurs while decoding field a of struct C. In the previous version the error message was only reported for the field a, but in the current version the Decode error path message is reported in the process A -\u003e B -\u003e C, which makes it easier to catch bugs\nFramework stats information #149 adds more stats information for framework. Users can handle this data in the middleware itself, for example by logging or reporting to the monitoring system.\nSupport partial key listening in Discover for service discovery #155 Support for partial key listening in Discover for service discovery, which reduces unnecessary listening and improves performance.\nFull Release Note For the full Release Notes, please refer to: Volo Changelog\n","categories":"","description":"","excerpt":"In Volo 0.4.1, in addition to the usual bugfixes, some new features …","ref":"/blog/2023/03/20/volo-release-0.4.1/","tags":"","title":"Volo Release 0.4.1"},{"body":"Volo 0.4.1 版本中，除了常规 bugfix 之外，还有一些新的 feature 引入。\n更为详细的 Thrift Decode 错误信息 之前版本的 Thrift Decode 错误信息只会报告出最基本的错误，而不带有任何上下文。 比如含有如下结构关系\nstructA{1:requiredBb,}structB{2:requiredCc,}structC{3:requiredstringa,}在对结构C的字段a进行 Decode 如果发生错误。在之前的版本中错误信息只会报告针对出a字段的错误，而在现在的版本中会报告出 Decode 的错误信息链路是在 A -\u003e B -\u003e C 这个过程中发生的，会更方便信息的排查\n框架 stats 信息 #149 为框架增加了更多的 stats 信息。用户可以在中间件自行处理这些数据，比如进行日志记录或者上报到监控系统。\n在服务发现的 Discover 中支持部分 key 的监听 #155 在服务发现的 Discover 中支持部分 key 的监听，这样可以减少不必要的监听，提升性能。\n完整 Release Note 完整的 Release Note 可以参考：Volo Changelog\n","categories":"","description":"","excerpt":"Volo 0.4.1 版本中，除了常规 bugfix 之外，还有一些新的 feature 引入。\n更为详细的 Thrift Decode 错 …","ref":"/zh/blog/2023/03/20/volo-0.4.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Volo 0.4.1 版本发布"},{"body":"Introduction to Key Changes Feature 1. Fallback: Support fallback for client-side\nWhen the RPC requests fail, users usually have some degradation measures to ensure the effective response (for example, construct the default response after the request timeout or circuit breaker). Kitex’s Fallback supports the processing of all error requests. At the same time, because business errors are usually returned through the Resp (BaseResp field), Kitex also supports the processing of Resp. Refer to Fallback.\n2. Kitex - gRPC: Client add TLS option configuration\nSetup via client.WithGRPCTLSConfig option.\n3. Kitex - Tool\n Support customized scaffold templates, refer to Custom Scaffold Template Support specifying the directory for generating code, refer to Code Generation Tool -gen-path Support using protoc plugin, refer to Code Generation Tool -protobuf-plugin  Optimization 1. Loadbalance：Use Weighted Round Robin algo as default Loadbalance policy\nThe old version uses Weight Random to do the loadbalance by default. Random can achieve the global balance. However, in the case of a small number of server instances, there is a large probability of random continuous access to the same instance, resulting in an increase in the maximum concurrent requests of downstream nodes. Therefore, the new version adjusts the default policy to Weight Round Robin. Refer to Loadbalance\n2. Goroutine Resource of Connection Pool\nWhen the old version uses a long connection, each client corresponds to a goroutine resource cleaning connection. When there are many clients, it will cause too many goroutines. The new version changes to share the goroutine to avoid the number of goroutines increasing with the number of clients.\nOther Upgrade the frugal and pid dependency lib to support go 1.20.\n Full Release Log Feature  [#840] feat(fallback): support fallback ability for kitex client-side, usage guide refer to Fallback [#841] feat(tool): add GetResult() and GetFirstArgument() methods for service params of protobuf [#791] feat(tool): merge two ways of passing extensions, to support two ways at sametime [#797] feat(loadbalance): use smooth weighted round robin algo as default Loadbalance policy [#760] feat(grpc): support TLS config in kitex grpc client [#781] feat(tool): supports custom templates [#783] feat(ttheader): add encode logic for gdpr token in TransInfo [#775] feat(tool): support custom generate path [#687] feat(tool): add protoc plugin flag  Optimize  [#750] optimize(generic): generic call write zero value for required and default fields to meet the specification of apache thrift and keep consistent with normal thrift encode of Kitex. [#739] optimize(generic): modify the url routing to align with Hertz for HTTP generic call [#752] optimize(ttheader): attach part of ttheader binary into error when readKVInfo failed, which is useful for troubleshooting [#821] optimize(config): add DeepCopy() \u0026 Equals() to circuitbreaker.CBConfig and retry.Policy [#827] optimize: revise the remoteInfo of retry call, using the remoteInfo of the RPCCall that returns [#762] optimize(tool): add go mod auto replace to thrift 0.13 in thrift mode [#755] optimize: improve client error msg when ctx cancel or timeout [#756] optimize: use sync.Cond as the profiler event trigger [#753] optimize: add recover for client’s Close  Fix  [#734] fix(retry): fix the panic problem caused by concurrent read and write of rpcinfo under backup retry [#837 #842] fix(metahandler): adjust MetainfoHandler to the top of the MetaHandlers array to ensure that the logic of custom MetaHandlers that depends on MetainfoHandler works [#812] fix: use detectionHandler to perform protocol detection in windows environment to support gRPC [#851] fix: upgrade frugal to v0.1.6 for missing stop field [#845] fix: fix the problem that RPCStat report status as success when biz handler return err [#822] fix(loadbalance): don’t share balancer factory when loadbalance is defined by user [#732] fix(mux): mux server waits for shardqueue close before shutdown [#795] fix(grpc): zero first byte of grpc data frame, which could be random data from mcache [#668] fix: fix race problem in queue.go/queue @dugenkui03 [#743] fix: use sharedTicker for long conn pool to prevent goroutine numbers increase as the number of client increases [#799] fix(util): should return when get at least one GOPATH @StellarisW [#807] fix(codec): fix fastpb nil ptr when struct fields are all default values [#794] fix(tool): fix fastpb codegen by updating dependency [#787] fix(tool): the import did not use the new method to render when template append content [#785] fix(tool): remove useless combine service files [#754] fix: fix the usage of metainfo in grpc scene  Refactor  [#814 #843] refactor(trans): return error in onRead of defaultServerHandler and close conn in outer method [#816] refactor(utils): add utils.GetEnvLogDir and deprecate utils.GetLogDir  Test \u0026 Docs \u0026 Chore  [#839 #693] test: import mockey repo and add usage demo of mockey unit test [#806] test(transmeta):add some test cases for tansmeta package [#761] docs: update README.md @fuergaosi233 [#817, #832] chore: upgrade dependency lib to adapt go 1.20 [#772] chore: modify kitex gen code meta file name from kitex.yaml to kitex_info.yaml  ","categories":"","description":"","excerpt":"Introduction to Key Changes Feature 1. Fallback: Support fallback for …","ref":"/blog/2023/03/08/kitex-release-v0.5.0/","tags":"","title":"Kitex Release v0.5.0"},{"body":"重要变更介绍 功能 1. Fallback 功能: 支持 Client 侧的 Fallback 功能\n业务在 RPC 请求失败后通常会有一些降级措施保证有效返回（比如在请求超时、熔断后，构造默认返回），Kitex 的 Fallback 支持对所有异常请求进行处理。 同时，因为业务异常通常会通过 BaseResp 字段返回，所以也支持对 Resp 进行处理。详见 Fallback。\n2. Kitex - gRPC：Client 增加 TLS 的配置\n通过 client.WithGRPCTLSConfig option 配置。\n3. Kitex - 工具\n 支持自定义脚手架模板，详见： 自定义脚手架模板 支持指定生成代码的目录，详见： 代码生成工具 -gen-path 支持 protoc 插件选项，详见： 代码生成工具 -protobuf-plugin  优化 1. 负载均衡：使用权重轮询作为默认 Loadbalance 策略\n旧版本默认使用权重随机做 Loadbalance，Random 可以做到全局的均衡，但在服务端实例较少的情况下，随机有较大概率连续访问一个实例，导致下游节点最大并发请求数增加，所以新版本将默认策略调整为轮询。 详见：负载均衡。\n2. 连接池协程问题\n旧版本在使用长连接时，每个 client 对应一个协程资源清理连接，在 client 较多时会导致协程过多，新版本改为共享协程避免 goroutine 数量随着 client 数量增长。\n其他 升级 frugal, pid 库依赖以支持 go 1.20。\n 详细变更 Feature  [#840] feat(fallback): support fallback ability for kitex client-side, usage guide refer to Fallback [#841] feat(tool): add GetResult() and GetFirstArgument() methods for service params of protobuf [#791] feat(tool): merge two ways of passing extensions, to support two ways at sametime [#797] feat(loadbalance): use smooth weighted round robin algo as default Loadbalance policy [#760] feat(grpc): support TLS config in kitex grpc client [#781] feat(tool): supports custom templates [#783] feat(ttheader): add encode logic for gdpr token in TransInfo [#775] feat(tool): support custom generate path [#687] feat(tool): add protoc plugin flag  Optimize  [#750] optimize(generic): generic call write zero value for required and default fields to meet the specification of apache thrift and keep consistent with normal thrift encode of Kitex. [#739] optimize(generic): modify the url routing to align with Hertz for HTTP generic call [#752] optimize(ttheader): attach part of ttheader binary into error when readKVInfo failed, which is useful for troubleshooting [#821] optimize(config): add DeepCopy() \u0026 Equals() to circuitbreaker.CBConfig and retry.Policy [#827] optimize: revise the remoteInfo of retry call, using the remoteInfo of the RPCCall that returns [#762] optimize(tool): add go mod auto replace to thrift 0.13 in thrift mode [#755] optimize: improve client error msg when ctx cancel or timeout [#756] optimize: use sync.Cond as the profiler event trigger [#753] optimize: add recover for client’s Close  Fix  [#734] fix(retry): fix the panic problem caused by concurrent read and write of rpcinfo under backup retry [#837 #842] fix(metahandler): adjust MetainfoHandler to the top of the MetaHandlers array to ensure that the logic of custom MetaHandlers that depends on MetainfoHandler works [#812] fix: use detectionHandler to perform protocol detection in windows environment to support gRPC [#851] fix: upgrade frugal to v0.1.6 for missing stop field [#845] fix: fix the problem that RPCStat report status as success when biz handler return err [#822] fix(loadbalance): don’t share balancer factory when loadbalance is defined by user [#732] fix(mux): mux server waits for shardqueue close before shutdown [#795] fix(grpc): zero first byte of grpc data frame, which could be random data from mcache [#668] fix: fix race problem in queue.go/queue @dugenkui03 [#743] fix: use sharedTicker for long conn pool to prevent goroutine numbers increase as the number of client increases [#799] fix(util): should return when get at least one GOPATH @StellarisW [#807] fix(codec): fix fastpb nil ptr when struct fields are all default values [#794] fix(tool): fix fastpb codegen by updating dependency [#787] fix(tool): the import did not use the new method to render when template append content [#785] fix(tool): remove useless combine service files [#754] fix: fix the usage of metainfo in grpc scene  Refactor  [#814 #843] refactor(trans): return error in onRead of defaultServerHandler and close conn in outer method [#816] refactor(utils): add utils.GetEnvLogDir and deprecate utils.GetLogDir  Test \u0026 Docs \u0026 Chore  [#839 #693] test: import mockey repo and add usage demo of mockey unit test [#806] test(transmeta):add some test cases for tansmeta package [#761] docs: update README.md @fuergaosi233 [#817, #832] chore: upgrade dependency lib to adapt go 1.20 [#772] chore: modify kitex gen code meta file name from kitex.yaml to kitex_info.yaml  ","categories":"","description":"","excerpt":"重要变更介绍 功能 1. Fallback 功能: 支持 Client 侧的 Fallback 功能\n业务在 RPC 请求失败后通常会有一些 …","ref":"/zh/blog/2023/03/08/kitex-v0.5.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.5.0 版本发布"},{"body":"In version 0.6.0 of Hertz, in addition to regular iterative optimization, we also brought several important features.\nHTTP Trailer support In Hertz v0.6.0, we support encoding and parsing of HTTP Trailer.\n https://github.com/cloudwego/hertz-examples/tree/main/trailer\n  Write Trailer  // server func handler(c context.Context, ctx *app.RequestContext){ ctx.Response.Header.Trailer().Set(\"Hertz\", \"Good\") } // client req.Header.Trailer().Set(\"Hertz\", \"Good\")  Read Trailer  // server func handler(c context.Context, ctx *app.RequestContext){ ctx.Request.Header.Trailer().Get(\"Hertz\") } // client resp.Header.Trailer().Get(\"Hertz\") HTTP/1.1 supports for Response Writer hijacking In Hertz v0.6.0, we extended the HTTP/1.1 write request approach. Based on the original write request flow, we support users to hijack the Response Writer in the business handler/middleware to achieve a more flexible write request approach. In simple terms, all the original “underlying write” logic is unified behind the handler/middleware return, which has two obvious limitations.\n The user has no control over the timing of the request flush to the other end For the scenario of incremental data generation \u0026 real-time writing to the peer by chunk, the usage is relatively complicated and restrictive on top of the old architecture  Based on this, we extend a Writer that provides the ability to flush request headers and request bodies on its own, while providing support for users to send chunk data on demand. See https://github.com/cloudwego/hertz/pull/610 for a detailed implementation.\nMajor Changes  Added an interface definition that extends Writer, Writers that implement this interface can be used to hijack Response Writer: type ExtWriter interface { io.Writer Flush() error // Finalize will be called by framework before the writer is released.  // Implementations must guarantee that Finalize is safe for multiple calls.  Finalize() error }  Provides a Chunk Writer that implements the above interface (you can refer to this for similar requirements): chunkedBodyWrite HTTP/1.1 does the corresponding processing (skipping the default write request logic) for Response write operations where the Writer has been hijacked, and finally calls the Finalize() method of the ExtWriter interface to complete a request write back  Usage As above, Hertz provides a default ExtWriter implementation to meet the user’s active flush needs in the handler/middleware, and it is very simple to use.\nh.GET(\"/flush/chunk\", func(c context.Context, ctx *app.RequestContext) { // Hijack the writer of response  ctx.Response.HijackWriter(resp.NewChunkedBodyWriter(\u0026ctx.Response, ctx.GetWriter())) for i := 0; i \u003c 10; i++ { ctx.Write([]byte(fmt.Sprintf(\"chunk %d: %s\", i, strings.Repeat(\"hi~\", i)))) // nolint: errcheck  ctx.Flush() // nolint: errcheck  time.Sleep(200 * time.Millisecond) } }) Scaffolding Tool Usage Optimization \u0026 Best Practices In hz v0.6.0, we have made a number of optimizations to the organization of the generated code, allowing for a more flexible code organization\nMajor Optimization  The new command supports the “router_dir” option and works with the existing “handler_dir” and “model_dir” to fully customize the path to the IDL generation product; it also persists these custom options in the “.hz” file, which can be read automatically during update, reducing the complexity of the command Add the ability to search up the “go.mod” file so that hertz can share the same “go module” with other projects when it is a subproject Add the ability to reference third-party IDL products in the “handler”, so that IDL products can be maintained separately in the third-party repository and not stored in the project directory, further enhancing IDL management capabilities  Best Practices We have rewritten “biz-demo/easy-note” with “hz v0.6.0” to take advantage of the following hz features\n Generate hertz client call code for accessing “api server” based on IDL using the capabilities of “hz client” Reorganize the “api server” code with custom “router_dir”, “handler_dir”, and “model_dir” options, and remove the “biz” directory restriction Use the ability to “search up go.mod” so that “api server” can share the same “go module” as a subproject of “easy-note” Use the ability of “handler to refer to third-party IDL products” and the ability of “hz model” to store IDL products separately in the “easy-note” project and not in the “api server” subproject  Full Release Note The complete Release Note can refer to:\n Hertz: https://github.com/cloudwego/hertz/releases/tag/v0.6.0 Hz(scaffolding): https://github.com/cloudwego/hertz/releases/tag/cmd%2Fhz%2Fv0.6.0  ","categories":"","description":"","excerpt":"In version 0.6.0 of Hertz, in addition to regular iterative …","ref":"/blog/2023/03/02/hertz-release-v0.6.0/","tags":"","title":"Hertz Release v0.6.0"},{"body":"Hertz 0.6.0 版本中，除了常规迭代优化之外，我们还带来了多个重要 feature。\n支持 HTTP Trailer 在 Hertz v0.6.0 版本中，我们支持了 HTTP Trailer 的编码和解析。\n https://github.com/cloudwego/hertz-examples/tree/main/trailer\n  写 Trailer  // server 端 func handler(c context.Context, ctx *app.RequestContext){ ctx.Response.Header.Trailer().Set(\"Hertz\", \"Good\") } // client 端 req.Header.Trailer().Set(\"Hertz\", \"Good\")  读 Trailer  // server 端 func handler(c context.Context, ctx *app.RequestContext){ ctx.Request.Header.Trailer().Get(\"Hertz\") } // client 端 resp.Header.Trailer().Get(\"Hertz\") HTTP/1.1 支持 Response Writer 劫持 在 Hertz v0.6.0 版本中，我们扩展了 HTTP/1.1 写请求的方式，在原来写请求流程的基础之上，支持用户在业务 handler/中间件中劫持 Response Writer，实现更加灵活的写请求方式。 简单来说，原来所有的“底层写”逻辑统一放到 handler/中间件返回之后，这个带来两个比较明显的局限性：\n 用户无法控制请求真正 flush 到对端的时机 针对 chunk 方式增量产生数据 \u0026 实时写到对端的场景，在老的架构之上用法相对复杂，限制相对较多  基于此我们扩展出一套能够提供自行 flush 请求头和请求体的能力，同时提供了一个支持用户按需发送 chunk 数据的 Writer。详细实现参考：https://github.com/cloudwego/hertz/pull/610\n主要变更  增加了一个扩展 Writer 的接口定义，实现了这个接口的 Writer 都可以用作劫持 Response Writer： type ExtWriter interface { io.Writer Flush() error // Finalize will be called by framework before the writer is released.  // Implementations must guarantee that Finalize is safe for multiple calls.  Finalize() error }  提供了一个实现了上述接口的 Chunk Writer（有类似需求都可以参考这个来实现）：chunkedBodyWrite HTTP/1.1 具体写请求的地方针对被劫持了 Writer 的 Response 写操作做了对应的处理（跳过默认写请求逻辑），最后调用ExtWriter接口的Finalize()方法完成一次请求写回  使用方法 如上，Hertz 提供了一个默认的ExtWriter实现满足用户在 handler/中间件中的主动 flush 需求，使用方式也非常简单：\nh.GET(\"/flush/chunk\", func(c context.Context, ctx *app.RequestContext) { // Hijack the writer of response  ctx.Response.HijackWriter(resp.NewChunkedBodyWriter(\u0026ctx.Response, ctx.GetWriter())) for i := 0; i \u003c 10; i++ { ctx.Write([]byte(fmt.Sprintf(\"chunk %d: %s\", i, strings.Repeat(\"hi~\", i)))) // nolint: errcheck  ctx.Flush() // nolint: errcheck  time.Sleep(200 * time.Millisecond) } }) 脚手架使用优化 \u0026 最佳实践 在 hz v0.6.0 版本中，我们对生成代码的组织结构进行一系列的优化，从而可生成更加灵活的代码组织结构\n主要优化  new 命令支持 “router_dir” 选项，并配合已有的 “handler_dir”、“model_dir”，可完全自定义 IDL 生成产物的路径；并且会将这些自定义选项持久化到 “.hz” 文件中，可在 update 时自动读取，减少命令的复杂度 增加向上搜索 “go.mod” 文件的能力，从而使得 hertz 在作为一个子项目时可以和其他项目共享同一个 “go module” 增加 “handler” 中引用第三方 IDL 产物的能力，可将 IDL 产物放到第三方仓库单独维护，使其不在项目目录中存放，进一步增强 IDL 管理能力  最佳实践 我们利用 “hz v0.6.0” 重写了 “biz-demo/easy-note\"，主要利用了如下 hz 的特性\n 利用 “hz client” 的能力，基于 IDL 生成访问 “api server” 的 hertz client 调用代码 利用自定义 “router_dir”、 “handler_dir”、“model_dir” 选项，重新调整 “api server” 代码的组织结构，去掉 “biz” 目录的限制 利用 “向上搜索 go.mod” 的能力，使得 “api server” 可以作为 “easy-note” 的子项目共享同一个 “go module” 利用 “handler 引用第三方 IDL 产物” 的能力并配合 “hz model” 的能力，使得 IDL 产物单独存到到 “easy-note” 项目里，而并不存放到 “api server” 子项目里  完整 Release Note 完整的 Release Note 可以参考：\n Hertz: https://github.com/cloudwego/hertz/releases/tag/v0.6.0 Hz(脚手架): https://github.com/cloudwego/hertz/releases/tag/cmd%2Fhz%2Fv0.6.0  ","categories":"","description":"","excerpt":"Hertz 0.6.0 版本中，除了常规迭代优化之外，我们还带来了多个重要 feature。\n支持 HTTP Trailer 在 Hertz …","ref":"/zh/blog/2023/03/02/hertz-v0.6.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Hertz v0.6.0 版本发布"},{"body":"Background On September 8, 2021, ByteDance officially announced the open-sourcing of CloudWeGo. CloudWeGo is a set of microservices middleware developed by ByteDance, characterized by high performance, strong scalability, and high stability. It focuses on solving the difficulties of microservices communication and governance, and meets the demands of different businesses in different scenarios. On June 21, 2022, the CloudWeGo team has officially open-sourced Hertz, ByteDance’s largest HTTP framework. Hertz has gained a lot of attention from users since its release, and has received 3K+ stars by now. Many users have tested it themselves, and we are very grateful for your attention and support. This blog aims to share the scenarios and technical issues that developers need to be aware of when conducting load testing on Hertz. These suggestions can help users better optimize Hertz based on real HTTP scenarios to better fit their business needs and achieve optimal performance. Users can also refer to the official load testing project hertz-benchmark for more details.\nCharacteristics of HTTP Microservices Hertz was born out of large-scale microservices practice at ByteDance, and is naturally designed for microservices scenarios. Therefore, in the following, we will first introduce the characteristics of the HTTP microservices to facilitate developers' deeper understanding of Hertz’s design considerations.\n HTTP Communication Model  Communication between microservices typically follows a Ping-Pong model. In addition to conventional throughput performance metrics, developers also need to consider the average latency of each HTTP request. While increasing the number of machines can quickly resolve throughput bottlenecks, reducing latency, which significantly affects user experience, is not as easy.\nIn the environment of microservices, a single call often requires collaboration from multiple microservices. Even if each node has low latency, the final latency on the entire chain can be amplified. Therefore, latency is a more critical metric for developers to pay attention to in microservices. Hertz has made certain optimizations for latency while ensuring throughput.\n The Use of Long and Short Connections  Since establishing a TCP connection requires a three-way handshake, the overhead of creating a new connection for each request can be very high for latency-sensitive services. Therefore, it is recommended to use persistent connections to complete requests whenever possible. In HTTP 1.1, Long connections are also the default option. However, there is no silver bullet, as maintaining connections also consumes resources, and the horizontal scalability of persistent connections is not as good as that of short connections. Therefore, in some scenarios, long connections may not be suitable. For example, in a scenario where configurations need to be pulled periodically, the connection establishment delay may not have a significant impact on configurations, and it may be more appropriate to use short connections if horizontal scalability is a concern when the configuration center is under high load.\n Packet Size  The package size of a service depends on the actual business scenario. In HTTP scenarios, data can be placed in query, path, header, body, etc., and different locations have different effects on parsing. HTTP header is an identifier protocol, and the framework does not know how many headers there are until it finds a specific identifier. Therefore, the framework needs to receive all the headers before it can complete the parsing, which is not very friendly to the framework’s memory model. Hertz has also made special optimizations for header parsing, allocating enough buffer space for headers to reduce the overhead of cross-package copying during header processing.\nMeanwhile, in the internal statistics of online services at ByteDance, it was found that most packages are within 1K (but too small packages have no practical significance, such as a fixed return of “hello world”). At the same time, there is no upper limit on the size of large packages, and various package sizes are involved. Therefore, Hertz has focused on optimizing the performance (throughput and latency) of packages within the most commonly used range of 128k or less.\n Concurrency Quantity  Each instance may have multiple upstreams and will not only accept requests from a single instance. Moreover, HTTP 1 doesn’t support multiplexing, and each connection can only handle one request at a time. Therefore, the Server needs to accept multiple connections and process them simultaneously.\nDifferent services have different connection utilization rates. For example, load testing services have high connection utilization rates, and a new request is made immediately after the completion of the previous request. Some services have low connection utilization rates, even though they are long-lived, they are only used once. The connection models used by these two services are not the same.\nFor the former, the goroutine per connection model should be used to reduce the overhead of context switching. For the latter, a coroutine pool should be used to reduce the scheduling overhead of too many goroutines. Hertz supports both models, and users can choose the appropriate configuration based on their business needs.\nLoad Testing for HTTP Scenarios Using Scenarios That Resemble Real Usage There are many load testing projects on GitHub and performance testing reports available online, but they may not be tailored to your specific needs. For example, in a real-world scenario, would you create a project that only responds with hello world no matter what the client sends? Unfortunately, many load testing projects do just that.\nBefore conducting load testing, consider your actual usage scenarios, such as:\n Long vs Short Connections: Determine whether using long or short connections is more suitable for your scenario. Estimating Connection Usage: If using long connections and connection usage is high (which is the case in most scenarios), use the default configuration. If connection usage is low, consider adding the configuration option server.WithIdleTimeout(0) to modify the goroutine per connection model to a coroutine pool model and conduct comparative testing. Determining Data Location and Size: As mentioned earlier, data in different locations (such as query, header, body, etc.) and of different sizes can affect the framework’s performance. If the performance of all frameworks is similar, consider using a different data transmission location. Determining Concurrency Quantity: Some services are lightweight on business logic but heavy on framework, resulting in high framework concurrency. Conversely, some services are heavy on business logic but light on framework, resulting in low framework concurrency.  If you just want to test the performance of the framework, you can use the common scenario: long connection, high connection usage, 1k body, 100 concurrency, and so on. The hertz-benchmark repository also uses this default load test configuration. At the same time, the hertz-benchmark repository also provides configuration options for users to modify headers, body, and concurrency, making it easy to customize the load test to fit their own needs.\nDetermine the Target of Load Testing Measuring the performance of an RPC framework requires thinking from two perspectives: the Client perspective and the Server perspective. In a large-scale business architecture, the upstream Client may not necessarily use the downstream framework, and the downstream services called by developers are also likely to be different. This is even more complicated when considering the situation of Service Mesh.\nSome load testing projects usually conduct load testing for Client and Server processes in a hybrid deployment, and then obtain performance data for the entire framework, which may not be consistent with the actual operation in production.\nIf you want to conduct load testing the Server, you should give the Client as many resources as possible and push the Server to the limit, and vice versa. If both the Client and Server are only given 4 cores for load testing, developers will not be able to determine the performance data under which perspective, let alone provide actual reference for online services.\nUse Dedicated CPUs Although online applications usually share CPUs among multiple processes, in a load testing scenario, both the Client and Server processes are extremely busy. Sharing CPUs at this time will result in a large number of context switches, which will make the data less reliable and prone to large fluctuations.\nTherefore, we recommend isolating Client and Server processes on different CPUs or different dedicated machines. If you want to further avoid the impact of other processes, you can also use the nice -n -20 command to increase the scheduling priority of the load testing process.\nIn addition, if conditions permit, using physical machines instead of virtual machines on cloud platforms will make the test results more rigorous and reproducible.\nPerformance Data Reference On the premise of meeting the above requirements, we compared the load testing result of multiple frameworks based on the latest version. The pressure test code is in the hertz-benchmark repository. With the goal of fully filling the load of Server, Hertz has the lowest P99 latency of all the frameworks tested, and the throughput is also in the first tier and under continuous optimization.\n CPU: AMD EPYC 7Y83 64-Core Processor 2.7GHz  limits: server 4-CPUs，client 16-CPUS   OS：Debian GNU/Linux 10 (buster) Go 1.19 hertz v0.3.2，fasthttp v1.40.0， gin v1.8.1，fiber v2.38.1  Comparison of throughput and latency of four frameworks\nComparison of throughput and latency of three frameworks\nConclusion As a very large scale enterprise microservices HTTP framework, Hertz was designed to solve a variety of problems in the large-scale microservices scenario. In the process of promotion, we encountered all kinds of services and solved many kinds of problem. Based on those experience, we wrote this blog. As a developer, you are always welcome to choose the right tool for your own scenario based on the testing guide provided above. If you have any questions, feel free to raise an Issue.\n","categories":"","description":"The purpose of this blog is to share the scenarios and technical issues that developers need to know when they need to conduct load testing on Hertz. Based on current releases, this blog compares the various frameworks to provide performance reference data that will help you tune Hertz with real-world HTTP scenarios to better match business needs and maximize performance.","excerpt":"The purpose of this blog is to share the scenarios and technical …","ref":"/blog/2023/02/24/getting-started-with-hertz-performance-testing-guide/","tags":"","title":"Getting Started with Hertz: Performance Testing Guide"},{"body":"背景 2021 年 9 月 8 日，字节跳动宣布正式开源 CloudWeGo。CloudWeGo 是一套字节跳动内部微服务中间件集合，具备高性能、强扩展性和稳定性的特点，专注于解决微服务通信与治理的难题，满足不同业务在不同场景的诉求。 2022 年 6 月 21 日，Hertz 正式开源。日前，CloudWeGo 团队正式开源字节跳动最大的 HTTP 框架 Hertz。Hertz 自发布以来，得到了大量用户的关注，累计收获了 3K+ star。有很多用户自己进行了测试，感谢大家对我们的关注和支持。 本文旨在分享开发者在压测 Hertz 时需要了解的场景和技术问题。这些建议有助于用户更好地结合真实 HTTP 场景对 Hertz 进行调优，使之更贴合业务需要、发挥最佳性能。用户也可以参考官方提供的压测项目 hertz-benchmark 了解更多细节。\n微服务 HTTP 场景的特点 Hertz 诞生于字节跳动大规模微服务架构实践，面向的场景自然是微服务场景，因此下面会先介绍微服务 HTTP 场景的特点，方便开发者深入理解 Hertz 的设计思考。\n HTTP 通信模型  微服务间的通信通常以 Ping-Pong 模型为主，除了常规的吞吐性能指标外，每次 HTTP 的平均时延也是开发者需要考虑的点。吞吐达到瓶颈时可以通过增加机器快速解决，但对用户使用体验有显著影响的时延却没有那么容易降低。 在微服务场景下，一次调用往往需要多个微服务协作完成，即使每个节点延迟很低，最终汇聚到链路上的时延也会被放大，因此微服务场景下时延指标是开发者更应该关注的点。Hertz 在保证吞吐的前提下，也针对时延做了一定优化。\n 长短连接使用  由于 TCP 连接首次建立时需要三次握手，如果每个请求都建立新连接，这部分的开销是非常大的。因此对于时延敏感型服务，尽量使用长连接完成请求。在 HTTP 1.1 中，长连接也是默认的选项。 但是没有银弹，维持连接也需要消耗资源，长连接的水平扩展能力也不如短连接。因此，在某些场景下并不适合使用长连接，比如定时拉取配置的场景， 在这个场景下，建连时延对配置影响并不大，且当配置中心负载过高时，希望能够方便的进行水平扩容，这时短连接可能是一个更好的选择。\n 包体积大小  一个服务的包大小取决于实际的业务场景。HTTP 场景的数据可以放在 query、path、header、body 等地方，不同位置对解析造成的影响也不一样。 HTTP 的 header 是标识符协议，在没有找到特定的标识符之前，框架并不知道 header 还有多少，因此框架需要收到全部的 header 后才能够解析完成，对框架的内存模型不很友好。 Hertz 也针对 header 解析做了特殊的优化，分配足够的 buffer 空间给 header，减少 header 处理时跨包拷贝的开销。\n同时在字节跳动内部线上服务的统计中，发现大部分包在 1K 以内（但是太小的包没有实际意义，比如固定返回 “hello world”），同时大包场景上不封顶，各个包大小均有涉及，所以 Hertz 在最常用的 128k 以内的包的性能（吞吐和时延）进行了重点优化。\n 并发数量  每个实例的上游可能会有很多个，不会只接受某个实例的请求；而且，HTTP 1 的连接不能够多路复用，每条连接上只能同时处理一个请求。因此 Server 需要接受多个连接同时处理。 不同服务的连接使用率也不同，比如压测服务的连接使用率很高，一个请求完成后马上就会进行下一个请求；有的服务连接使用率很低，虽然是长连接，但是只使用一次。这两者使用的连接模型并不相同， 前者应使用 goroutine per connection 的模型减少上下文的切换，后者应使用协程池减少过多 goroutine 的调度开销。Hertz 也同时支持这两种场景，用户可以根据自己的业务场景选择合适的配置。\n针对 HTTP 场景进行压测 使用贴近自己的场景 Github 上的压测项目有很多，网络上也有很多性能测试报告，但是这些项目和测试不一定贴合自己。举个极端一点的例子，在真实场景中你会写一个项目无论 Client 发什么 Server 都只回 hello world 吗？很遗憾，很多的压测项目就是这么做的。\n在进行压测前，应考虑自己真正的使用场景，比如：\n 长短连接的使用 ：使用长连接还是短连接更符合自己的场景。 连接使用率的估算 ：如果使用长连接，且连接使用率很高（大部分场景），则使用默认配置即可；如果连接使用率很低，可以添加配置：server.WithIdleTimeout(0)，将 goroutine per connection 的模型修改为协程池模型，并进行对比测试。 数据位置及大小的确定 ：上面提到不同位置（如 query、header、body 等）及大小的数据对框架可能造成影响，如果所有框架的性能都比较一般，可以考虑换一个数据传输位置。 并发数的确定 ：有的服务属于轻业务重框架，这个时候框架的并发可能会很高；有的服务属于重业务轻框架，这个时候框架的并发可能会很低。  如果只是想看一下框架的性能，可以使用常规的场景：长连接、较高连接使用率、1k body、100 并发等。hertz-benchmark 仓库默认的压测配置也是如此。 同时 hertz-benchmark 仓库也开发给用户 header、body、并发数的配置，用户可以方便的修改这些配置完成贴合自己的压测。\n确定压测对象 衡量一个 RPC 框架的性能需要从两个视角分别去思考：Client 视角与 Server 视角。在大规模的业务架构中，上游 Client 不见得使用的也是下游的框架，而开发者调用的下游服务也同样如此，如果再考虑到 Service Mesh 的情况就更复杂了。\n一些压测项目通常会把 Client 和 Server 进程混部进行压测，然后得出整个框架的性能数据，这其实和线上实际运行情况很可能是不符的。\n如果要压测 Server，应该给 Client 尽可能多的资源，把 Server 压到极限，反之亦然。如果 Client 和 Server 都只给了 4 核 CPU 进行压测，会导致开发者无法判断最终得出来的性能数据是哪个视角下的，更无法给线上服务做实际的参考。\n使用独占 CPU 虽然线上应用通常是多个进程共享 CPU，但在压测场景下，Client 与 Server 进程都处于极端繁忙的状况，此时共享 CPU 会导致大量上下文切换，从而使得数据缺乏可参考性，且容易产生前后很大波动。\n所以我们建议是将 Client 与 Server 进程隔离在不同 CPU 或者不同独占机器上进行。如果还想要进一步避免其他进程产生影响，可以再加上 nice -n -20 命令调高压测进程的调度优先级。\n另外如果条件允许，相比云平台虚拟机，使用真实物理机会使得测试结果更加严谨与具备可复现性。\n性能数据参考 在满足上述要求的前提下，我们基于当前最新版本对多个框架进行了压测对比，压测代码在 hertz-benchmark 仓库。 在充分压满 Server 的目标下，Hertz 的 P99 延迟在所有压测框架中最低，吞吐也是属于第一梯队，且在持续优化中。\n CPU: AMD EPYC 7Y83 64-Core Processor 2.7GHz  运行限定 server 4-CPUs，client 16-CPUS   OS：Debian GNU/Linux 10 (buster) Go 1.19 hertz v0.3.2，fasthttp v1.40.0， gin v1.8.1，fiber v2.38.1  四个框架的吞吐和时延比较\n三个框架的吞吐和时延比较\n结语 作为一个超大规模企业级的微服务 HTTP 框架，Hertz 在设计之初就更倾向于解决大规模微服务场景下的各种问题。在推广过程中也遇到了各种各样的服务，踩了各种各样的坑，也是基于以上经验写了本文。 欢迎广大开发者基于本文提供的测试指南，针对自己的实际场景选择合适的工具。更多问题，请在 GitHub 上提 Issue 交流。\n","categories":"","description":"本文旨在分享开发者在压测 Hertz 需要了解的场景和技术问题，并且基于当前最新版本对多个框架进行了压测对比，提供了性能参考数据，有助于用户更好地结合真实 HTTP 场景对 Hertz 进行调优，使之更贴合业务需要、发挥最佳性能。","excerpt":"本文旨在分享开发者在压测 Hertz 需要了解的场景和技术问题，并且基于当前最新版本对多个框架进行了压测对比，提供了性能参考数据，有助于用户 …","ref":"/zh/blog/2023/02/24/http-%E6%A1%86%E6%9E%B6-hertz-%E5%AE%9E%E8%B7%B5%E5%85%A5%E9%97%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E5%8D%97/","tags":"","title":"HTTP 框架 Hertz 实践入门：性能测试指南"},{"body":"In Volo 0.3.2 version, in addition to general bugfixes, there are many improvements. In particular, it is very much appreciated that there are community contributors who have brought us important features.\nTrait support for Thrift asynchronous codec @ii64 brought us the definition of Thrift asynchronous codec Trait in #123 as well as the implementation of Binary and Apache Compact Protocol. Before that he also contributed the underlying implementation of codec to Pilota!\nSupport for gRPC graceful shutdown @iGxnon brought us support for gRPC graceful shutdown in #127!\nVersion update for metainfo and faststr In this release, we updated the versions of metainfo and faststr so that metainfo also supports faststr to minimize memory allocation and copy in as many scenarios as possible to optimize performance.\nfaststr is a string library we modify with reference to smol_str, which implements a zero-cost clone of immutable string.\nIn addition, FastStr has an incompatible change: previously it implemented From for all AsRef\u003cstr\u003e, but doing so causes the additional memory allocation and copy overhead when using into directly. In the new version of 0.2, we only implement From for 'static str、String、Arc\u003cstr\u003e、Arc\u003cString\u003e. There’s no overhead for these four types to use into to convert to FastStr, in a form that avoids memory allocation and copy problems inadvertently brought on by the user.\nThe old version of From essentially called FastStr::new(s), so if there was an incompatibility problem, you could simply call FastStr::new explicitly instead.\nPilota supports FastStr generation for Protobuf codec By supporting FastStr generation for Protobuf codec in Pilota, we can bring our performance optimization capabilities to PB and gRPC.\nAfter upgrading, we need to use use pilota::prost::message::Message; instead of use prost::Message; introduced previously.\nFull Release Notes For the full Release Notes, please refer to: Volo Changelog\n","categories":"","description":"","excerpt":"In Volo 0.3.2 version, in addition to general bugfixes, there are many …","ref":"/blog/2023/02/07/volo-release-0.3.2/","tags":"","title":"Volo Release 0.3.2"},{"body":"Volo 0.3.2 版本中，除了常规 bugfix 之外，还有多处改进。尤其是，有社区贡献者为我们带来了重要的 feature，非常感谢他们。\nThrift 异步编解码 Trait 支持 @ii64 在 #123 中为我们带来了 Thrift 异步编解码 Trait 的定义和 Binary、Apache Compact Protocol 的实现，在此之前他还为 Pilota 贡献了编解码的底层实现！\ngRPC graceful shutdown 支持 @iGxnon 在 #127 中为我们带来了 gRPC graceful shutdown 的支持！\nmetainfo 与 faststr 版本更新 在这个版本中，我们更新了 metainfo 和 faststr 的版本，使得 metainfo 也支持了 faststr，以在尽可能多的场景下减少内存分配和拷贝，以优化性能。\nfaststr 是我们参考 smol_str 改进的一个 string 库，实现了 immutable string 的零开销 clone。\n同时 FastStr 有一个不兼容变更：之前是为所有AsRef\u003cstr\u003e实现了From，但是这样做会导致直接使用into会带来额外的内存分配和拷贝开销。 在新的 0.2 版本中，我们只为 'static str、String、Arc\u003cstr\u003e、Arc\u003cString\u003e四种类型实现了From，这四种类型调用 into 到 FastStr 是零开销的，通过这种形式避免用户不经意间带来的内存分配和拷贝问题。\n旧版本的From本质上就是调用了FastStr::new(s)，因此出现不兼容问题的话，直接改为显式调用FastStr::new即可。\nPilota 中 Protobuf 编解码支持生成 FastStr 通过在 Pilota 中支持为 Protobuf 编解码生成 FastStr，我们可以将我们的性能优化能力带到 PB 和 gRPC 中。\n升级后，需要把原先引入的use prost::Message;改为use pilota::prost::message::Message;即可。\n完整 Release Note 完整的 Release Note 可以参考：Volo Changelog\n","categories":"","description":"","excerpt":"Volo 0.3.2 版本中，除了常规 bugfix 之外，还有多处改进。尤其是，有社区贡献者为我们带来了重要的 feature，非常感谢他 …","ref":"/zh/blog/2023/02/07/volo-0.3.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Volo 0.3.2 版本发布"},{"body":"In version 0.5.0 of Hertz, in addition to regular iterative optimization, we also brought several important features.\nNetwork layer and protocol layer support stream-based interface  https://github.com/cloudwego/hertz/pull/467\n In the Hertz v0.5.0 version, we have further enhanced the scalability of the Hertz transport layer \u0026 protocol layer, supporting the seamless connection of the stream-based transport layer protocol QUIC, and the HTTP3 protocol built on top of it. In addition, on this basis, we have added and improved functions such as “ALPN” (application layer protocol negotiation), “QUIC/TLS parallel monitoring” (QUIC/TLS parallel monitoring), “Alt-Svc” (alternative service).\nMajor Changes Transport layer On the basis of ensuring compatibility performance, we have added an abstract stream-based network connection interface StreamConn, and adjusted the interaction logic between the transport layer and the protocol layer to achieve the correct protocol layer for the distribution of connection types Processing (protocol server). For scenarios that need to monitor TCP (TLS) and UDP (QUIC) at the same time, we provide a WithAltTransporter option, which facilitates passing the backup transporter to the main transporter, and facilitates the ability to monitor QUIC/TLS in parallel.\nProtocol Layer Support adding a stream-based protocol layer implementation (protocol server) StreamServer, so as to build a corresponding processing protocol (HTTP/3) on top of the newly added stream-based transport layer extension. In order to facilitate the configuration of alternative service meta-information for a main protocol (HTTP/3), ProtocolSuite exposes the SetAltHeader interface. At the same time, we also designed the ALPN capability for StreamConn, so as to provide the ability of protocol negotiation in QUIC.\nCommon layer At the same time, we have added an auxiliary function that can convert with the Golang standard Handler in the general layer, so as to quickly port the implementation based on the Golang standard Handler to Hertz. The QUIC \u0026 HTTP/3 extension based on quic-go provided later /pull/1), the capabilities provided by this function are used.\nFeature Status The Hertz core library capability has been released, and the specific implementation will be released in the form of extension package, welcome to try~\nFor more detailed design instructions, please refer to: Hertz supports QUIC \u0026 HTTP/3\nScaffolding tools support generating hertz client code  https://github.com/cloudwego/hertz/pull/471\n In the v0.5.0 version of the scaffolding tool (Hz), we support the function of automatically generating the hertz client code based on IDL, and realize the one-click call of the HTTP request in the form of an RPC call. Instructions:\n For details, see: https://github.com/cloudwego/hertz-examples/tree/main/hz_client\n  Define the IDL  namespace go toutiao.middleware.hzClient struct QueryReq { 1: string QueryValue (api. query=\"query1\"); } struct Resp { 1: string Resp; } service Hertz121 { Resp QueryMethod(1: QueryReq request) (api. get=\"/query\", api. handler_path=\"get\"); }( api.base_domain=\"http://127.0.0.1:8888\"; ) Generate code  Based on the above IDL, the server and client codes can be generated separately:\nServer:\nhz new --idl=psm.thrift --handler_by_method -t=template=slim Client:\nhz client --idl=psm.thrift --model_dir=hertz_gen -t=template=slim --client_dir=hz_client Call the client code to initiate an HTTP request to realize the intercommunication between the client end and the server end  Full Release Note The complete Release Note can refer to:\n Hertz: https://github.com/cloudwego/hertz/releases/tag/v0.5.0 Hz(scaffolding): https://github.com/cloudwego/hertz/releases/tag/cmd%2Fhz%2Fv0.5.0  ","categories":"","description":"","excerpt":"In version 0.5.0 of Hertz, in addition to regular iterative …","ref":"/blog/2023/01/12/hertz-release-v0.5.0/","tags":"","title":"Hertz Release v0.5.0"},{"body":"Hertz 0.5.0 版本中，除了常规迭代优化之外，我们还带来了多个重要 feature。\n网络层和协议层支持基于流的接口  https://github.com/cloudwego/hertz/pull/467\n 在 Hertz v0.5.0 版本中，我们进一步加强了 Hertz 传输层 \u0026 协议层可扩展能力，支持无缝对接基于流的传输层协议 QUIC，以及在此之上构建的 HTTP3 协议。 此外，我们在此基础上还增加和完善了 “ALPN”(应用层协议协商)、“QUIC/TLS parallel monitoring”(QUIC/TLS并行监听)、“Alt-Svc”(备选服务) 等功能。\n主要变更 传输层 我们在保证兼容性能的基础之上增加了一个针对基于流（stream-based）的网络连接接口抽象StreamConn，同时调整传输层和协议层的交互逻辑，实现针对连接类型的分发正确的协议层处理（protocol server）。 针对需要同时监听监听 TCP（TLS）以及 UDP(QUIC)的场景我们提供了一个WithAltTransporter选项，方便将备用 transporter 传递到主 transporter 中，便于实现 QUIC/TLS 并行监听的能力。\n协议层 支持添加基于流的协议层实现（protocol server）StreamServer，以便于在新增的基于流的传输层扩展之上构建对应处理协议（HTTP/3）。 为了便捷的实现为某个主协议（HTTP/3）配置备选服务元信息，ProtocolSuite对外暴露SetAltHeader接口。 同时，我们也为StreamConn设计了 ALPN 能力，以便于在 QUIC 内提供协议协商的能力。\n通用层 同时我们在通用层中新增了能够与 Golang 标准 Handler 进行转换的辅助函数，以便于快速的将基于 Golang 标准 Handler 实现移植到 Hertz 中来。在之后提供的基于 quic-go 的 QUIC \u0026 HTTP/3 扩展中，就用到了这个函数提供的能力。\nFeature 状态 Hertz 核心库能力已经发布，具体实现后续将以扩展包的形式发布，欢迎试用~\n更多详细的设计说明可以参考：Hertz 支持 QUIC \u0026 HTTP/3\n脚手架工具支持生成 hertz client 代码  https://github.com/cloudwego/hertz/pull/471\n 在脚手架工具(Hz)的 v0.5.0 的版本，我们支持了基于 IDL 自动生成 hertz client 代码的功能，并实现了类 RPC 调用形式的 HTTP 请求一键调用。 使用方法：\n 具体详见：https://github.com/cloudwego/hertz-examples/tree/main/hz_client\n  定义 IDL  namespace go toutiao.middleware.hzClient struct QueryReq { 1: string QueryValue (api.query=\"query1\"); } struct Resp { 1: string Resp; } service Hertz121 { Resp QueryMethod(1: QueryReq request) (api.get=\"/query\", api.handler_path=\"get\"); }( api.base_domain=\"http://127.0.0.1:8888\"; ) 生成代码  可基于上述 IDL，分别生成 server 和 client 端代码：\nserver：\nhz new --idl=psm.thrift --handler_by_method -t=template=slim client：\nhz client --idl=psm.thrift --model_dir=hertz_gen -t=template=slim --client_dir=hz_client 调用 client 代码发起 HTTP 请求，实现 client 端和 server 端的互通  完整 Release Note 完整的 Release Note 可以参考：\n Hertz: https://github.com/cloudwego/hertz/releases/tag/v0.5.0 Hz(脚手架): https://github.com/cloudwego/hertz/releases/tag/cmd%2Fhz%2Fv0.5.0  ","categories":"","description":"","excerpt":"Hertz 0.5.0 版本中，除了常规迭代优化之外，我们还带来了多个重要 feature。 …","ref":"/zh/blog/2023/01/12/hertz-v0.5.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Hertz v0.5.0 版本发布"},{"body":"In Volo 0.3.0 version, in addition to regular bugfixes, we also brought several important features.\nService Trait refactoring In version 0.3.0 of Volo, we refactored Service Trait to make the implementation of Service Trait easier and provide more flexibility.\nSpecifically, we changed the definition of Service Trait from:\npubtraitService\u003cCx,Request\u003e{/// Responses given by the service. type Response;/// Errors produced by the service. type Error;/// The future response value. type Future\u003c'cx\u003e: Future\u003cOutput=Result\u003cSelf::Response,Self::Error\u003e\u003e+Send+'cxwhereCx: 'cx,Self: 'cx;/// Process the request and return the response asynchronously. fn call\u003c'cx,'s\u003e(\u0026'smutself,cx: \u0026'cxmutCx,req: Request)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx;}changed to:\npubtraitService\u003cCx,Request\u003e{/// Responses given by the service. type Response;/// Errors produced by the service. type Error;/// The future response value. type Future\u003c'cx\u003e: Future\u003cOutput=Result\u003cSelf::Response,Self::Error\u003e\u003e+Send+'cxwhereCx: 'cx,Self: 'cx;/// Process the request and return the response asynchronously. fn call\u003c'cx,'s\u003e(\u0026'sself,cx: \u0026'cxmutCx,req: Request)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx;}The most obvious change is that the self parameter of the Service Trait method call() is changed from \u0026mut self to \u0026self. The purpose of this is that if we relied on \u0026mut self before, we have to clone to take ownership before calling, and we need Service users to ensure that the overhead of Clone is low; in fact, this clone is completely unnecessary, and this decision should be handed over to the user to decide. If there is a need to change the internal state, they can lock it internally or use atomic, which can save the cost of cloning.\ngRPC multi-Service support In this version, we also support the scenario where the gRPC server supports multiple Services at the same time, and each Service can have its own layer; of course, the Server can also have a globally valid layer.\nIf a middleware needs to perceive the specific type of Request / Response and process it, or only for a single Service, it can be added as the Service’s own layer.\nThis is a breaking change. Users of previous versions may need to modify the code. Specifically, it needs to change from this:\n#[volo::main]asyncfn main(){letaddr: SocketAddr=\"[::]:8080\".parse().unwrap();letaddr=volo::net::Address::from(addr);volo_gen::proto_gen::hello::HelloServiceServer::new(S).run(addr).await.unwrap();}Change it to this:\nusestd::net::SocketAddr;usevolo_grpc::server::{Server,ServiceBuilder};#[volo::main]asyncfn main(){letaddr: SocketAddr=\"[::]:8080\".parse().unwrap();letaddr=volo::net::Address::from(addr);Server::new().add_service(ServiceBuilder::new(volo_gen::proto_gen::hello::GreeterServer::new(S)).build()).run(addr).await.unwrap();}gRPC Compression Thanks to @tuchg for bringing us gRPC compression and decompression support in #91 , if there is a requirement for the transmission size, this function can be used.\nThrift Codec refactoring In the previous Codec design, Thrift codec was specified by CodecType, which brought two problems:\n It is not easy to extend new protocol support, all supported protocols need to be implemented in the framework and hard-coded into CodecType; It is impossible to decouple and arrange the Transport and Serialize protocols. For example, if we want to support the TCompact protocol, then we need to add multiple variants: TTHeaderFramedCompact, TTheaderCompact, FramedCompact, Compact…  At the same time, the previous codec did not achieve Zero Copy, and there is room for improvement in performance.\nThis refactoring solves all the above problems at once. We no longer rely on CodecType to specify the codec method, but use the make_codec interface to specify the Codec generation method, so that we can easily Expand new protocol support, and also decouple and arrange Transport and Serialize protocols.\nFor details, please refer to codec documentation.\nThrift generated code default field change In the previous generated code, the binary type will generate Vec\u003cu8\u003e, and the string type will generate String, which will cause a clone to be performed when decoding and encoding, and the performance loss will be large; in this version, we will use these two The Rust type generated by default for this type has been changed to Bytes and FastStr to achieve full-link Zero Copy, because in practice we have observed absolutely Most of the binary and string in Request / Response will not be modified, and even if the user needs to modify, it is at the cost of one Clone, and the performance will not be worse than before.\nThis is a breaking change. Users of previous versions may need to modify the code after upgrading. Generally speaking, only need to modify the type according to the error message.\nIf there is still a need to generate String for string, you can add an annotation of pilota.rust_type=\"string\" to the corresponding field in the thrift idl file, as follows:\nstructItem{1:requiredstringname (pilota.rust_type=\"string\");}In addition, Pilota also supports other annotations. For details, please refer to: https://www.cloudwego.io/docs/pilota/guide/annotation/\nFull Release Note The complete Release Note can be referred to: https://github.com/cloudwego/volo/releases/tag/volo-0.3.0\n","categories":"","description":"","excerpt":"In Volo 0.3.0 version, in addition to regular bugfixes, we also …","ref":"/blog/2022/12/22/volo-release-0.3.0/","tags":"","title":"Volo Release 0.3.0"},{"body":"Volo 0.3.0 版本中，除了常规 bugfix 之外，我们还带来了多个重要 feature。\nService Trait 重构 Volo 0.3.0 版本中，我们对 Service Trait 进行了重构，使得 Service Trait 的实现更加简单，同时也提供了更多的灵活性。\n具体来看，我们将 Service Trait 的定义从：\npubtraitService\u003cCx,Request\u003e{/// Responses given by the service. type Response;/// Errors produced by the service. type Error;/// The future response value. type Future\u003c'cx\u003e: Future\u003cOutput=Result\u003cSelf::Response,Self::Error\u003e\u003e+Send+'cxwhereCx: 'cx,Self: 'cx;/// Process the request and return the response asynchronously. fn call\u003c'cx,'s\u003e(\u0026'smutself,cx: \u0026'cxmutCx,req: Request)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx;}改为了：\npubtraitService\u003cCx,Request\u003e{/// Responses given by the service. type Response;/// Errors produced by the service. type Error;/// The future response value. type Future\u003c'cx\u003e: Future\u003cOutput=Result\u003cSelf::Response,Self::Error\u003e\u003e+Send+'cxwhereCx: 'cx,Self: 'cx;/// Process the request and return the response asynchronously. fn call\u003c'cx,'s\u003e(\u0026'sself,cx: \u0026'cxmutCx,req: Request)-\u003e Self::Future\u003c'cx\u003ewhere's: 'cx;}最明显的改动是，Service Trait 的方法 call() 的 self 参数由 \u0026mut self 改为了 \u0026self。这样做的目的是，之前依赖 \u0026mut self 的话，在调用之前就得 clone 拿所有权才行，需要 Service 用户自己保证 Clone 的开销低；实际上，这个 clone 是完全没必要的，这个决策应该交给用户自己决定，如果真的有需求改变内部状态的话，自己内部加锁或者用 atomic 即可，这样可以节省 clone 的开销。\ngRPC 多 Service 支持 在这个版本中，我们还支持了 gRPC 服务端同时支持多个 Service 的场景，并且每个 Service 都可以有自己的 layer；当然，Server 也可以有全局有效的 layer。\n如果某个中间件需要感知到 Request / Response 的具体类型并且做处理的，或者只针对单个 Service 的，那么可以添加为 Service 自己的 layer 即可。\n这是一个 breaking change，使用之前版本的用户可能需要修改一下代码，具体来说需要从这样：\n#[volo::main]asyncfn main(){letaddr: SocketAddr=\"[::]:8080\".parse().unwrap();letaddr=volo::net::Address::from(addr);volo_gen::proto_gen::hello::HelloServiceServer::new(S).run(addr).await.unwrap();}改成这样：\nusestd::net::SocketAddr;usevolo_grpc::server::{Server,ServiceBuilder};#[volo::main]asyncfn main(){letaddr: SocketAddr=\"[::]:8080\".parse().unwrap();letaddr=volo::net::Address::from(addr);Server::new().add_service(ServiceBuilder::new(volo_gen::proto_gen::hello::GreeterServer::new(S)).build()).run(addr).await.unwrap();}gRPC Compression 感谢@tuchg在#91中为我们带来了 gRPC 的压缩和解压缩支持，如果对于传输大小有要求的场景，可以使用这个功能。\nThrift Codec 重构 在之前的 Codec 设计中，Thrift 的编解码指定的方式是通过CodecType来指定，这样带来了两个问题：\n 无法很轻松地扩展新的协议支持，所有的支持的协议都需要在框架中实现并硬编码到 CodecType 中； 无法将 Transport 和 Serialize 协议进行解耦和排列组合，举个例子，如果我们想要支持 TCompact 协议，那么我们就需要增加多个变体：TTHeaderFramedCompact、TTheaderCompact、FramedCompact、Compact……  同时，之前的编解码没有做到 Zero Copy，性能上也有可以提升的空间。\n这次的重构，一次性的解决了以上所有问题，我们不再依赖CodecType来指定编解码方式，而是通过make_codec这个接口来指定 Codec 的生成方式，这样我们就可以很轻松地扩展新的协议支持，同时也可以将 Transport 和 Serialize 协议进行解耦和排列组合。\n具体可以参考一下 codec 的文档。\nThrift 生成代码默认字段变更 之前的生成代码中，binary 类型会生成 Vec，string 类型会生成 String，这会导致在解码和编码的时候都需要进行一次 clone，性能损耗较大；在这个版本中，我们将这两个类型默认生成的 Rust 类型改为了 Bytes 和 FastStr，以此来实现全链路的 Zero Copy，因为在实践中我们观察到绝大多数 Request / Response 中的 binary 和 string 都是不会被修改的，而即使用户需要修改，也就是多一次 Clone 的代价，并不会比之前性能更差。\n这是一个 breaking change，使用之前版本的用户在升级后可能会需要修改一下代码，一般来说只需要根据报错信息修改一下类型即可。\n如果仍旧有需求要针对 string 生成 String 的话，可以在 thrift idl 文件中的对应字段加一个pilota.rust_type=\"string\"的 annotation，如下：\nstructItem{1:requiredstringname (pilota.rust_type=\"string\");}除此之外，Pilota 还支持了其它的 Annotation，详情可以参考：https://www.cloudwego.io/zh/docs/pilota/guide/annotation/\n完整 Release Note 完整的 Release Note 可以参考：https://github.com/cloudwego/volo/releases/tag/volo-0.3.0\n","categories":"","description":"","excerpt":"Volo 0.3.0 版本中，除了常规 bugfix 之外，我们还带来了多个重要 feature。\nService Trait …","ref":"/zh/blog/2022/12/22/volo-0.3.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Volo 0.3.0 版本发布"},{"body":" Preface: Kitex Proxyless enables the Kitex service to interact directly with istiod without envoy sidecar. It dynamically obtains service governance rules delivered by the control plane based on the xDS protocol and converts them to Kitex rules to implement some service governance functions, such as traffic routing. Based on Kitex Proxyless, Kitex can be managed by Service Mesh without sidecar. Besides, the governance rule Spec, governance control plane, governance delivery protocol, and heterogeneous data governance capability can be unified under multiple deployment modes. By rewriting the bookinfo project using Kitex and Hertz, it demonstrates how to implement a traffic lane using xDS protocol.\n 01 Introduction Kitex Proxyless Kitex is a Golang RPC framework open-sourced by ByteDance that already natively supports the xDS standard protocol and can be managed by Service Mesh in Proxyless way. Refer to this doc for detailed design: Proposal: Kitex support xDS Protocol. Official doc is also available here at Kitex/Tutorials/Advanced Feature/xDS Support\nKitex Proxyless Simply means that Kitex services can interact directly with istiod without envoy sidecar and dynamically obtain service governance rules delivered by the control plane based on the xDS protocol. And those rules will be translated into Kitex corresponding rules to implement some service governance functions (such as traffic routing which is the focus of this blog).\nBased on Kitex Proxyless, Kitex application can be managed by Service Mesh in a unified manner without sidecar, and thus the governance rule Spec, governance control plane, governance delivery protocol, and heterogeneous data governance capability can be unified under multiple deployment modes.\nTraffic Routing Traffic routing refers to the ability to route traffic to a specified destination based on its specific metadata identifier.\nTraffic routing is one of the core capabilities in service governance and one of the scenarios that Kitex Proxyless supports in the first place.\nThe approach of Kitex implementing traffic routing base on xDS is as follows:\nSpecific procedure:\n Add an xDS Router MW to Pick Cluster (routing) and watch LDS and RDS of target services. Aware of LDS changes and extract the Filter Chain and inline RDS in the LDS of the target service. Aware of RDS changes and obtain the route configuration of the target service based on VirtualHost and ServiceName matching. (Prefix, suffix, exact, and wildcard are supported) The routing rules in the matched RDS are traversed and processed. The routing rules are divided into two parts (refer to the routing specification definition) :   Match:  Path(required): Extract Method from rpcinfo for matching; HeaderMatcher(optional): Extract the corresponding metadata KeyValue from the metainfo and match it.   Route：  Cluster ：Standard Cluster. WeightedClusters(Weight routing) : cluster is selected according to weight within MW. Write the selected Cluster to the EndpointInfo.Tag for later service discovery.    As you can see, traffic routing is a process of selecting the corresponding SubCluster according to certain rules.\n02 Traffic Lane Based on traffic routing capability, we can extend many usage scenarios, such as: A/B testing, canary release, blue-green release, etc., and the focus of this paper: Traffic Lane.\nThe traffic lane can be understood as splitting a group of service instances in a certain way (such as deployment environment), and based on the routing capability and global metadata, so that traffic can flow in the specified service instance lanes in accordance with the exact rules (logically similar to lanes in a swimming pool). Traffic lane can be used for full-path grey release.\nIn Istio we typically group instances with DestinationRule subset, splitting a service into multiple subsets (e.g. Based on attributes such as version and region) and then work with VirtualService to define the corresponding routing rules and route the traffic to the corresponding subset. In this way, the single-hop routing capability in the lane is realized.\nHowever, traffic routing capability alone is not enough to realize traffic lane. We need a good mechanism to accurately identify the traffic and configure routing rules for each hop traffic based on this feature when a request spans multiple services.\nAs shown in the following figure: Suppose we want to implement a user request that is accurately route to the v1 version of service-b. The first thought might be to put a uid = 100 in the request header and configure the corresponding VirtualService to match the uid = 100 in the header.\nBut it has several obvious drawbacks for this approach:\n Not common enough: If a specific business attribute (such as uid) is used as a traffic route matching rule, the business attribute must be manually transmitted through the full path. This is highly intrusive to business and requires business cooperation. In addition, when we want to use other business attributes, all services on the full path need to change to adapt. Therefore, it is a very unusual practice. Routing rules are prone to frequent changes, resulting in rule overcrowding. Routing rules are identified by specific business attributes (for example: uid) is used as a traffic route matching rule. If you want to change a business attribute or set a routing rule for other users, you need to modify the original routing rule or repeatedly define multiple routing rules for different business attributes, which easily causes route rule overcrowding and is difficult to maintain.  Therefore, in order to achieve uniform traffic routing across the full path, we also need to use a more general traffic dyeing and the capability to transmit the dye identifier through the full path.\nTraffic Dyeing Traffic dyeing refers to marking the request traffic with a special identifier and carrying this identifier in the full request path. The so-called traffic lane means that all services in the path sets traffic routing rules based on the uniform gray traffic dyeing identifier so that the traffic can be accurately controlled in different lanes.\nUsually, traffic dyeing is done at the gateway layer, and the metadata in the original request is converted into corresponding dye identifiers according to certain rules (conditions and proportions).\n Dyeing by conditions: when the request metadata meets certain conditions (such as uid = 100 in the request header and cookie matching), the current request is marked with a dye identifier. Dyeing by proportions: the request is marked with a dye identifier in proportion.  With a unified traffic dyeing mechanism, we do not need to care about specific business attribute identifiers when configuring routing rules. We only need to configure routes based on the dye identifiers. The specific service attributes are abstracted into conditional dyeing rules to be more universal. Even if the business attributes change, the routing rules do not need to change frequently.\nDye Identifier Transmitting The dyed identifier is usually transmitted through the Tracing Baggage, which is used to pass business custom KV attributes through the entire call chain (full-path), such as traffic dyeing identifiers and business identifiers such as AccountID.\nWe usually use the Tracing Baggage mechanism to transmit the corresponding dye identifiers through the full-path. Most of the Tracing frameworks support the Baggage concept, such as: OpenTelemetry, Skywalking, Jaeger, etc.\nWith a set of universal full-path transmitting mechanism, the service only needs to config the tracing once, and there is no need to adapt every time the service attribute identifier changes.\nNext part introduces and demonstrates how to implement the traffic lane based on Kitex Proxyless and OpenTelemetry Baggage by using a specific engineering example.\n03 Demo Introduction：Bookinfo The demo is a rewriting of the Istio Bookinfo project using Hertz and Kitex:\n Use istiod as the xDS server and the entry for CRD configuration and delivery. Use wire to implement dependency injection; Use opentelemetry to implement full path tracing; Use Kitex-xds and opentelemetry baggage to implement a traffic lane in proxyless mode; Implement a Bookinfo UI using arco-design and react.  Business Architecture In keeping with Bookinfo, the overall business architecture is divided into four separate microservices:\n productpage - This microservice calls details and reviews; details - This microservice contains information about the book; reviews - This microservice contains book related reviews. It also calls ratings; ratings - This microservice contains ratings information consisting of book reviews.  reviews are available in three versions:\n The v1 version calls the ratings service and uses one ⭐️ to display the ratings. The v2 version invokes the ratings services, and use five ⭐⭐⭐⭐⭐⭐ to display the ratings. The v3 version won’t call the ratings service  Diagram of Traffic Lanes The whole call chain is divided into 2 lanes:\n Base lane: Undyed traffic is routed to the base lane. Branch lane: dyed traffic is routed to the branch lane of reviews-v2 -\u003eratings-v2.  Traffic Dyeing The gateway is responsible for traffic dyeing. For example, the request with uid=100 in the request header is dyed and carries baggage of env=dev.\nThe dye mode may vary according to different gateways. For example, when we select istio ingress as the gateway, we can use EnvoyFilter + Lua to write the gateway dye rules.\nWorkload Labeling  Label the workload with corresponding version identifier.  Take service reviews as an example. You only need to label the corresponding pod with version: v1.\nSet a series of subsets for the service based on the DestinationRule:   Productpage: v1 Reviews: v1、v2、v3 Ratings: v1、v2  Traffic Routing Rules The gateway has already dyed the request header with uid=100 and automatically loaded env=dev baggage, so we only need to match the route according to the header. Here is an example of the route rule configuration:\nCheck the Effect  Base Lane  Requests without uid=100 header in the inbound traffic are automatically routed to the base lane, which is a round-robin of v1 and v3 of reviews service resulting in a round-robin score of 0 and 1.\nBranch Lane  We use the mod-header plug-in of the browser to simulate the scenario where the uid=100 is carried in the inbound traffic request header.\nClick the refresh button again, you can find that the request hits the branch lane, and the traffic lane takes effect successfully.\n04 Summary and Outlook So far, we have implemented a complete full-path traffic lane based on Kitex Proxyless and OpenTelemetry. And we can set corresponding routing rules for Kitex based on Istio standard governance rule Spec without Envoy sidecar.\nIn addition to traffic routing capabilities, Kitex Proxyless is also continuously iterating and optimizing to meet more requirements for data plane governance capabilities. As an exploration and practice of Service Mesh data plane, Proxyless not only can enrich the deployment form of data plane, but also hopes to continuously polish Kitex, enhance its ability in open source ecological compatibility, and create a more open and inclusive microservice ecosystem.\n05 Relevant Project Here is a list of the projects involved in the demo:\n biz-demo: https://github.com/cloudwego/biz-demo kitex: https://github.com/cloudwego/kitex hertz: https://github.com/cloudwego/hertz kitex-xds: https://github.com/kitex-contrib/xds kitex-opentelemetry: https://github.com/kitex-contrib/obs-opentelemetry hertz-opentelemetry: https://github.com/hertz-contrib/obs-opentelemetry  This demo has been submitted in the biz-demo repository, and will be optimised continuously. biz-demo will include some complete demos based on CloudWeGo technology stack with certain business scenarios. The original intention is to provide valuable references for enterprise users to use CloudWeGo in production. Contributors are always welcomed to participate in the contribution of CloudWeGo biz-demo. Let’s try something fun together.\n","categories":"","description":"This blog mainly introduces the realization of traffic routing based on Kitex Proxyless and the bookinfo demo rewrote with Kitex and Hertz. The purpose is to demonstrate how to use xDS to realize traffic lane in a practical way.","excerpt":"This blog mainly introduces the realization of traffic routing based …","ref":"/blog/2022/12/20/kitex-proxyless-practicetraffic-lane-implementation-with-istio-and-opentelemetry/","tags":"","title":"Kitex Proxyless Practice：Traffic Lane Implementation with Istio and OpenTelemetry"},{"body":"Feat  [#206] feat: connection flush support write timeout. [#182] feat: dial in ipv6 only.  Fix  [#200] fix: fd not detach when close by user. [#196] fix: limit iovecs max to 2GB(2^31). [#179] fix: length overflow. [#183] fix: dont check epollout when epollerr.  ","categories":"","description":"","excerpt":"Feat  [#206] feat: connection flush support write timeout. [#182] …","ref":"/blog/2022/11/09/netpoll-release-v0.3.0/","tags":"","title":"Netpoll Release v0.3.0"},{"body":"Feat  [#206] feat: 连接 Flush 接口支持写超时设置。 [#182] feat: 支持在 ipv6 only 环境下创建连接。  Fix  [#200] fix: 修复 #166 中的代码错误：close fd 没有正确的被 detach。 [#196] fix: 系统 io 调用使用 int32 存储 size, 超限调用会导致 EINVAL。 [#179] fix: 修复 buffer 长度 int32 溢出的问题。 [#183] fix: 当 EPOLLERR 发生时，跳过检查 EPOLLOUT。  ","categories":"","description":"","excerpt":"Feat  [#206] feat: 连接 Flush 接口支持写超时设置。 [#182] feat: 支持在 ipv6 only 环境下创 …","ref":"/zh/blog/2022/11/09/netpoll-v0.3.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Netpoll v0.3.0 版本发布"},{"body":" 导语：Kitex Proxyless 是 Kitex 服务能够不借助 envoy sidecar 直接与 istiod 交互，基于 xDS 协议动态获取控制面下发的服务治理规则，并转换为 Kitex 对应规则来实现一些服务治理功能，如流量路由。基于 Kitex Proxyless，能够实现 Kitex 无需代理就可以被 ServiceMesh 统一管理，进而实现多种部署模式下的治理规则 Spec、治理控制面、治理下发协议、异构数据治理能力的统一。本文在 biz-demo 中使用 Kitex 和 Hertz 重写 bookinfo 项目，以实战的方式演示了如何使用 xDS 实现全链路的流量泳道。\n 01 引言 Kitex Proxyless  Kitex 是字节开源的 Golang RPC 框架，已经原生支持了 xDS 标准协议，支持以 Proxyless 的方式被 ServiceMesh 统一纳管。\n 详细设计见： Proposal: Kitex support xDS Protocol · Issue #461 · cloudwego/kitex 具体使用方式见官方文档   Kitex Proxyless 简单来说就是 Kitex 服务能够不借助 envoy sidecar 直接与 istiod 交互，基于 xDS 协议动态获取控制面下发的服务治理规则，并转换为 Kitex 对应规则来实现一些服务治理功能（例如本文的重点：流量路由）。\n基于 Kitex Proxyless，让我们实现 Kitex 能够无需代理就可以被 ServiceMesh 统一管理，进而实现多种部署模式下的治理规则 Spec、治理控制面、治理下发协议、异构数据治理能力的统一。\n流量路由  流量路由是指，能够将流量根据其自身特定的元数据标识路由到指定目的地。\n 流量路由属于服务治理中比较核心的能力之一，也是 Kitex Proxyless 优先支持的场景之一。\nKitex 基于 xDS 实现流量路由的方案大致如下：\n具体流程：\n 增加一个 xDS Router MW 来负责 Pick Cluster（路由），并 watch 目标服务的 LDS 及 RDS。 感知 LDS 变化，并提取目标服务的 LDS 中的 Filter Chain 及其 inline RDS。 感知 RDS 变化，根据 VirtualHost 和 ServiceName 来匹配（支持前缀、后缀、精确、通配），获取目标服务的路由配置。 遍历处理匹配到的 RDS 中的路由规则，路由规则主要分为两部分（参考：路由规范定义）：    Match （支持前缀、后缀、精确、通配等），目前版本我们支持以下两种即可：\n Path（必须项）：从 rpcinfo 提取 Method 进行匹配； HeaderMatcher（可选项）：从 metainfo 中提取对应元数据 KeyValue，并进行匹配。    Route：\n Cluster ：标准 Cluster。 WeightedClusters（权重路由） ：MW 内根据权重来选择 cluster。 将选择到的 Cluster 写入 EndpointInfo.Tag，用于之后的服务发现。    可以看到，流量路由其实是一个根据一定规则选择对应 SubCluster 的流程。\n02 全链路泳道 基于流量路由能力，我们可以延伸出很多使用场景，如：A/B 测试、金丝雀发布、蓝绿发布等等，以及本文重点：全链路泳道。\n全链路泳道可以理解成是对一组服务实例按照一定方式进行拆分（例如部署环境），并基于全链路灰度路由能力，让流量能够精准按照规则在指定服务实例泳道中流动（逻辑上如同游泳场中的泳道）。\n在 Istio 中我们一般会通过 DestinationRule 的 subset 对实例进行分组，将一个服务拆分成不同子集（例如：按照版本、区域等属性拆分），然后配合 VirtualService 来定义对应的路由规则，将流量路由到对应子集中，从而完成泳道中的单跳路由能力。\n不过单单只有流量路由能力，还不足以实现全链路泳道，因为当一个请求跨越多个服务的时候，我们需要有一个比较好的机制能够准确识别出该流量，并基于这个特征来为每一跳流量配置路由规则。\n如下图所示：假设我们要实现一个用户的请求能够精确灰度到 service-b 的 v1 版本。最先想到的做法可能是所有请求都带上 uid = 100 的请求头，然后配置对应 VirtualService 来根据 header 里的 uid = 100 匹配。\n但这样的做法有几个明显的缺点：\n 不够通用：以具体某个业务属性标识（如：uid）作为流量路由匹配规则，我们需要将这个业务属性手动在全链路里透传，这本身对业务侵入性较大，需要业务配合改造。并且当我们要使用其他业务属性的时候，又需要全链路业务都改造一遍，可想而知，是非常不通用的做法。 路由规则容易频繁变动，容易造成规则臃肿：以具体某个业务属性标识（如：uid）作为流量路由匹配规则，假设我们要换一个业务属性，或者给其他用户设置路由规则的时候，得去改造原有的路由规则，或者针对不同业务属性重复定义多套路由规则，很容易就会造成路由臃肿，以至于难以维护。  因此，要实现全链路的流量路由统一，我们还需要额外借助一个更通用的流量染色与染色标识全链路透传能力。\n流量染色  流量染色是指对请求流量打上特殊标识，并在整个请求链路中携带这个标识，而所谓的全链路泳道，就是整个链路基于统一的灰度流量染色标识来设置流量路由规则，使得流量能够精准控制在不同泳道中。\n 通常我们会在网关层进行流量染色，通常会根据原始请求中的元数据，来进行一定规则（条件、比例）转换成对应的染色标识。\n 按条件染色：当请求元数据满足一定条件之后，就给当前请求打上染色标识，如：请求头中 uid = 100、cookie 匹配等等。 按比例染色：按照一定比例，给请求打上染色标识。  有了一套统一的流量染色机制之后，我们配置路由规则的时候，就不需要关心具体的业务属性标识了，只需要根据染色标识来配置即可。\n将具体的业务属性抽象成条件染色规则，使其更通用，即使业务属性发生了变化，路由规则也无需再频繁变动了。\n染色标识全链路透传  染色标识通常会依靠 Tracing Baggage 来透传，Baggage 是用于在整个链路中传递业务自定义 KV 属性，例如传递流量染色标识、传递 AccountID 等业务标识等等。\n 要实现流量染色标识在全链路透传，我们通常会借助 Tracing Baggage 机制，在全链路中传递对应染色标识，大部分 Tracing 框架都支持 Baggage 概念机能力，如：OpenTelemetry、Skywalking、Jaeger 等等。\n有了一套通用的全链路透传机制，业务方就只需要接入一遍 tracing 即可，无需每次业务属性标识发生变化就配合改造一次。\n下面会借助一个具体的工程案例介绍，来介绍并演示如何基于 Kitex Proxyless 和 OpenTelemetry Baggage 实现全链路泳道功能。\n03 案例介绍：Bookinfo  该案例是使用 Hertz、Kitex 重写经典的 Istio Bookinfo 项目：\n 使用 istiod 来作为 xDS server，作为 CRD 配置和下发的入口； 使用 wire 来实现依赖注入； 使用 opentelemetry 来实现全链路追踪； 使用 Kitex-xds 和 opentelemetry baggage 来实现 proxyless 模式下的全链路泳道; 使用 arco-design 和 react 实现一个 Bookinfo UI。   架构 整体架构与 Bookinfo 保持一致，分为四个单独的微服务：\n productpage. 这个微服务会调 details 和 reviews 两个微服务； details. 这个微服务中包含了书籍的信息； reviews. 这个微服务中包含了书籍相关的评论。它还会调用 ratings 微服务； ratings. 这个微服务中包含了由书籍评价组成的评级信息。  reviews 微服务有 3 个版本：\n v1 版本会调用 ratings 服务，并使用 1 颗 ⭐️ 显示评分； v2 版本会调用 ratings 服务，并使用 5 颗 ⭐️⭐️⭐️⭐️⭐️⭐️ 显示评分； v3 版本不会调用 ratings 服务。  泳道示意图 整体区分成 2 个泳道：\n 基准泳道：未被染色的流量会被路由到基准泳道中。 分支泳道：被染色的流量会被路由到 reviews-v2 -\u003eratings-v2 的分支泳道中。  流量染色 网关统一负责对流量进行染色，例如请求 header 中 uid=100 的流量都统一进行染色，为请求携带上 env=dev 的 baggage。\n染色方式可以根据不同的网关实现具体选择，例如当我们选择 istio ingress 作为网关的时候，我们可以借助 EnvoyFilter + Lua 的方式来编写网关染色规则。\n为服务实例打标  为对应 workload 打上对应 version 标识。   以 reviews 为例，只需要给对应 pod 打上 version: v1 的 label 即可。\n 基于 DestinationRule 为服务设置一系列的 subsets：    Productpage: v1 Reviews: v1、v2、v3 Ratings: v1、v2   流量路由规则 网关已经将请求头中携带了 uid=100 的流量进行了染色，自动带上了 env=dev 的 baggage，因此我们只需要根据 header 进行路由匹配即可，下面是具体的路由规则配置示例：\n查看效果 基准泳道 入口流量请求头中不带 uid=100 的请求，会自动路由到基准泳道服务，reviews v1 和 v3 服务间轮询，展示的效果是评分为 0 或 1 随机。\n分支泳道  我们这边通过浏览器 mod-header 插件，来模拟入口流量请求头中携带了 uid=100 的场景。  再点击刷新按钮，可以发现请求打到了分支泳道，流量泳道功能成功生效。  04 总结与展望 至此我们已经基于 Kitex Proxyless 与 OpenTelemetry 实现了一个完整的全链路泳道，并且无需借助 Envoy sidecar，就能基于 Isito 标准治理规则 Spec，来为 Kitex 设置对应的路由规则了。\n当然，除了满足流量路由能力之外，Kitex Proxyless 也在持续迭代优化，满足更多数据面治理能力需求。Proxyless 作为一种 ServiceMesh 数据面探索和实践，除了能够丰富网格数据面部署形态之外，也希望可以不断打磨 Kitex，增强其在开源生态兼容方面的能力，打造一个开放包容的微服务生态体系。\n05 相关项目链接 下面是该案例涉及的项目清单：\n biz-demo: https://github.com/cloudwego/biz-demo kitex: https://github.com/cloudwego/kitex hertz: https://github.com/cloudwego/hertz kitex-xds: https://github.com/kitex-contrib/xds kitex-opentelemetry: https://github.com/kitex-contrib/obs-opentelemetry hertz-opentelemetry: https://github.com/hertz-contrib/obs-opentelemetry  该完整案例已提交在 biz-demo 仓库中，感兴趣的同学可以前往查阅。biz-demo 会包含一些基于 CloudWeGo 技术栈且具备一定业务场景的完整 Demo，初衷是能够为企业用户在生产中使用提供有价值的参考，非常欢迎更多同学能够参与到 CloudWeGo 相关场景与案例的贡献中来，一起来做一些有意思的尝试。\n","categories":"","description":"本文主要介绍了基于 Kitex Proxyless 实现流量路由，从而在 biz-demo 中使用 Kitex 和 Hertz 重写 bookinfo 项目，实现的目的是以实战的方式演示如何使用 xDS 实现全链路的流量泳道。","excerpt":"本文主要介绍了基于 Kitex Proxyless 实现流量路由，从而在 biz-demo 中使用 Kitex 和 Hertz …","ref":"/zh/blog/2022/11/08/kitex-proxyless-%E4%B9%8B%E6%B5%81%E9%87%8F%E8%B7%AF%E7%94%B1%E9%85%8D%E5%90%88-istio-%E4%B8%8E-opentelemetry-%E5%AE%9E%E7%8E%B0%E5%85%A8%E9%93%BE%E8%B7%AF%E6%B3%B3%E9%81%93/","tags":"","title":"Kitex Proxyless 之流量路由：配合 Istio 与 OpenTelemetry 实现全链路泳道"},{"body":"Introduction to Key Changes Feature  Extend the Generated Code of client/server: Add a new feature which can extend generated client.go/server.go with config file. It is applicable to the scenario for customizing the unified suite. See Extend the Templates of Service Generated Code for details. Biz Customized Exception : Add supporting to return customized biz error which can distinguish with RPC error. See Business Exception, Proposal. Request Profiler : Add a new feature to do profiler for requests which can be used for cost statistics. Context Middleware : Add Context Middleware which is used for adding request-level middlewares.  Optimization  Frugal Performance Optimization : Support frugal precompile (pretouch) when new client or server, which is to reduce the impact of dynamic compilation on latency. Connpool Optimiztion : Refactor connection pool to improve the idle connections cleanup.   Full Release Log Feature  [#691] feat(client): add context middleware which is used for adding request-level middlewares. [#649] feat(connpool): new long connection pool with minIdle config and idle connections cleanup. [#672] feat(grpc): add kitex grpc metadata api to get header, tailer, and peer address metadata. [#613] feat(exception): support customized biz error which can distinguish with RPC error. [#670] feat(exception): support error format. [#678] feat(tool): add git and record param for cmd. [#662] feat(tool): support frugal precompile (pretouch) when new client or server. [#657] feat(tool): support template extension. [#527] feat(profiler): profiler for rpc request which can be used for cost statistics.  Optimize  [#690] optimize(meta): remove error logic for adding default metaHandler in #503. [#638] optimize(generic): httppb generic support map/list elem type as struct. [#641] optimize(tool): add warnings comments for oneway methods.  Fix  [#611] fix(client): fix resource leaks caused by Finalizer not being triggered in the scenario where clients are created frequently. [#698] fix(connpool): adjust globalIdle based on the number of connections decreased during the Get. [#636] fix(connpool): CloseCallback and statistical reporting of connection pool are invalid when the connection pool is reset in ForwardProxy. [#647] fix(grpc): update grpc connection window size when initial and synchronize grpc pr #5459. [#639] fix(generic): marshalling list in generic and enabling forJSON reader option for MapThriftGeneric. [#655] fix(generic): numeric constant parsing fails when used as generic default value. [#654] fix(frugal): fix compilation error when using lower go version. [#682] fix(profiler): profiler stops pprof profile. [#637] fix(tool): fix imports in handler.go template. [#630] fix(tool): remove redundant kitex comments for file that do not declare an interface. [#627] fix(tool): fix import missing when having different alias for the same path.  Refactor  [#651] refactor(server): server handler read/write interface return new context.  Docs  [#656] docs: remove wrong message in CONTRIBUTING.md. [#683] docs(kerrors): fix kerrors WithCauseAndExtraMsg method comment. [#625] chore: fix grammar of pull request template. [#623] chore: modify the template of pull request.  Test \u0026 CI  [#646] test: fix ut failure caused by InitRPCInfoFunc not setting rpcinfo. [#680] test: fix retry test race. [#661] test: make wpool tests more stable. [#643] test: add test for detection server handler. [#632] test: replace handwritten mock classes with gomock auto-generated classes. [#697] chore(ci): fixed skywalking-eyes version. [#652] chore(ci): delete repeated tests to reduce unit tests cost times. [#588] chore(ci): support codecov.  ","categories":"","description":"","excerpt":"Introduction to Key Changes Feature  Extend the Generated Code of …","ref":"/blog/2022/11/02/kitex-release-v0.4.3/","tags":"","title":"Kitex Release v0.4.3"},{"body":"重要变更介绍 功能  扩展 client/server 生成模板 ：新增 client/server 模板扩展功能，可以通过配置定制，适用于统一定制 suite 场景，详见扩展 Service 代码生成模板。 业务异常 ：新增业务自定义异常支持，可区分于 RPC 异常返回 error，使用详见业务异常，背景详见Proposal。 请求 Profiler ：新增功能可用于为不同的 RPC 请求提供成本分析统计的能力。 Context Middleware : 新增 Context Middleware，用于请求粒度添加 Middleware。  优化  Frugal 性能优化 ：支持在创建 Client/Server 阶段进行 Frugal “预编译”，减少动态编译对延迟的影响。 连接池优化 ：重构连接池，完善空闲连接清理能力。   详细变更 Feature  [#691] feat(client): 为 Client 添加上下文中间件，用于请求粒度添加中间件。 [#649] feat(connpool): 长连接池的新实现，支持最小空闲连接数及空闲连接清理。 [#672] feat(grpc): 为 kitex grpc 添加了元信息传递相关 api，包括 header，tailer，以及 peer 远端地址的获取接口。 [#613] feat(exception): 支持用户自定义异常用以区分 RPC 异常。 [#670] feat(exception): 支持 DetailError 格式化。 [#678] feat(tool): 为 kitex cmd 添加 git 和 record 参数。 [#662] feat(tool): 支持在创建 client 或者 server 的时候进行 frugal “预编译” (pretouch)。 [#657] feat(tool): 支持模板拓展。 [#527] feat(profiler): 为不同的 RPC 请求提供成本分析统计的能力。  Optimize  [#690] optimize(meta): 移除 #503 添加 default metahandler 的错误逻辑。 [#638] optimize(generic): httppb 泛化支持 map/list 元素类型为 struct。 [#641] optimize(tool): 给 oneway 方法增加警告注释。  Fix  [#611] fix(client): 在频繁重复创建 Client 场景下，修复由于 finalizer 未触发执行导致的资源泄漏。 [#698] fix(connpool): 根据 Get 返回的连接数减少值来调整 globalIdle。 [#636] fix(connpool): 修复当连接池在 ForwardProxy 实现中被重置后，连接池的 CloseCallback、统计上报失效的问题。 [#647] fix(grpc): 修复 grpc 连接级别窗口初始化时没有通知对端的问题，并同步了 grpc pr #5459。 [#639] fix(generic): 泛化调用支持 list 类型，map 读泛化增加 forJSON 选项。 [#655] fix(generic): 数值型常量作为泛化默认值时无法被正确解析。 [#654] fix(frugal): 修复较低版本 go 编译失败的问题。 [#682] fix(profiler): 修复 profiler 停止 pprof profile 采集的问题。 [#637] fix(tool): 修复 handler.go 模板里的 imports。 [#630] fix(tool): 对于没有声明 “service” 的 pb 文件，去掉生成文件末尾冗余的 kitex 声明。 [#627] fix(tool): 修复当一个 import 拥有不同的别名时 import 会丢失的问题。  Refactor  [#651] refactor(server): 重构 server trans handler 的 read/write 接口，返回新的 context。  Docs  [#656] docs: 删除 CONTRIBUTING 文档中的错误信息。 [#683] docs(kerrors): 修改了 kerrors WithCauseAndExtraMsg 方法注释。 [#625] chore: 修正 pull request 模板的语法问题。 [#623] chore: 修改 pull request 模板。  Test \u0026 CI  [#646] test: 修复 InitRPCInfoFunc 未设置 rpcinfo 导致的单测失败。 [#680] test: 修复重试单测的 race 问题。 [#661] test: 增强 wpool 测试稳定性。 [#643] test: 为 detection server handler 添加测试。 [#632] test: 用 gomock 自动生成类替换手动编写的 mock 类。 [#697] chore(ci): 固定 skywalking-eyes 版本号。 [#652] chore(ci): 删除重复的测试，以减少单测所花费的时间。 [#588] chore(ci): 支持 codecov。  ","categories":"","description":"","excerpt":"重要变更介绍 功能  扩展 client/server 生成模板 ：新增 client/server 模板扩展功能，可以通过配置定制，适用于 …","ref":"/zh/blog/2022/11/02/kitex-v0.4.3-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.4.3 版本发布"},{"body":"Feature  [#289] feat: render support IndentedJSON. [#304] feat: support errors format for the recovery middleware. [#278] feat: add compile tag for json implementation. [#239] feat: add retry extension for client. [#265] feat: add closeNoResetBuffer method for standard network. [#258] feat: errors support format.  Optimize  [#295] optimize: ignore flushing error when connection is closed or reset. [#322] optimize: modify the default log of the recovery middleware. [#266] optimize(hlog): distinguish systemlogger and defaultlogger. [#280] optimize: add listening log when using standard lib.  Refactor  [#318] refactor: add SetRetryIf to remain compatible.  Test  [#299] test: enrich ut for pkg/protocol/header.go. [#290] test: enrich ut for pkg/app/server/option.go. [#274] test: increase internal/bytesconv unit test statement coverage. [#285] test: enrich unit tests for pkg/protocol/request.go. [#271] test: ut supplementary for pkg/network. [#264] test: add ut for hertz/pkg/common/adaptor. [#267] test(pkg/common/config): pkg/common/config test coverage.  Docs  [#328] docs: add lark extension to readme.md. [#325] docs: update performance data in README and README_cn. [#307] docs(README): add hertz extensions list.  Style  [#316] style: remove empty comments for license.  Chore  [#272] chore: upgrade sonic version. [#310] chore: change license header style to avoid format error of buildtag from CI check.  ","categories":"","description":"","excerpt":"Feature  [#289] feat: render support IndentedJSON. [#304] feat: …","ref":"/blog/2022/10/28/hertz-release-v0.4.0/","tags":"","title":"Hertz Release v0.4.0"},{"body":"Feature  [#289] feat: render 支持 IndentedJSON。 [#304] feat: recovery 中间件支持用户自定义错误输出格式。 [#278] feat: 增加编译 tag 控制实际使用的 json 库。 [#239] feat: 给 client 扩展复杂重试能力。 [#265] feat: 在标准网络库扩展上添加 CloseNoResetBuffer 方法。 [#258] feat: 支持 errors 的格式化。  Optimize  [#295] optimize: 服务端忽略客户端主动断连的写错误。 [#322] optimize: 修改 recovery 中间件的默认日志。 [#266] optimize(hlog): 区分系统日志和默认日志，提供更自由的 logger 定制化能力。 [#280] optimize: 使用标准库时 listen 前添加日志。  Refactor  [#318] refactor: 添加 SetRetryIf 保持兼容。  Test  [#299] test: 提高对 hertz/pkg/protocol/header 的单测覆盖率。 [#290] test: 为 pkg/app/server/option.go 补充单元测试。 [#274] test: 增加 internal/bytesconv 包测试覆盖率，覆盖率从 1.68% 提高到了 82.35%。 [#285] test: 给 pkg/protocol/request.go 文件单测覆盖率 51.31% 提高到 85.3%。 [#271] test: 为 pkg/network 补充单元测试。 [#264] test: 增加对 hertz/pkg/common/adaptor 的单测，覆盖率从 76.6% 提高到了 92.3%。 [#267] test(pkg/common/config): 增加 pkg/common/config 包测试覆盖率。  Docs  [#328] docs: 添加 lark 扩展到 readme.md。 [#325] docs: 更新 README 和 README_cn 的性能数据。 [#307] docs(README): 将 Hertz 扩展添加到 readme 列表中。  Style  [#316] style: 去掉 license 顶层的空注释。  Chore  [#272] chore: 更新 sonic 版本。 [#310] chore: 修改注释信息为行注释避免 buildtag 格式问题的导致 ci 报错。  ","categories":"","description":"","excerpt":"Feature  [#289] feat: render 支持 IndentedJSON。 [#304] feat: recovery 中间 …","ref":"/zh/blog/2022/10/28/hertz-v0.4.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Hertz v0.4.0 版本发布"},{"body":" [#61] optimize volo-thrift code, remove unnecessary generic parameters. [#63] remove TAIT elision lifetime required after nightly-2022-10-20. [#73] remove useless liftetime parameter in LoadBalance:: InstanceIter. [#65] feat: upgrade clap to 4. [#72] feat: add writev support for volo net conn.  ","categories":"","description":"","excerpt":" [#61] optimize volo-thrift code, remove unnecessary generic …","ref":"/blog/2022/10/26/volo-release-v0.2.1/","tags":"","title":"Volo Release v0.2.1"},{"body":" [#61] 优化了 Volo-Thrift 的代码，移除了一些不必要的泛型参数，简化代码。 [#63] 跟进了 2022-10-20 后 nightly 编译器不再允许 TAIT elition lifetime 的问题。 [#73] 绕过了 Rust 编译器的 #100013 issue: non-defining opaque type use in defining scope。 [#65] feat: 升级 Volo-cli 的 clap 版本到 4.x。 [#72] feat: 为 volo::net::Conn 支持了 writev 操作。  ","categories":"","description":"","excerpt":" [#61] 优化了 Volo-Thrift 的代码，移除了一些不必要的泛型参数，简化代码。 [#63] 跟进了 2022-10-20 …","ref":"/zh/blog/2022/10/26/volo-v0.2.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Volo v0.2.1 版本发布"},{"body":"Feature  [#31] Support Windows. [#26] feat: add sd and lb for grpc. [#45] feat(grpc): support uds. [#32] feat: grpc support metainfo. [#30] feat: grpc server add layer_front(). [#42] feat(thrift): support multiplex.  Optimize  [#53] fix: write_field_begin args.  Fix  [#34] fix: connect timeout. [#46] retry IO error only. [#33] fix: grpc middleware error constraints.  ","categories":"","description":"","excerpt":"Feature  [#31] Support Windows. [#26] feat: add sd and lb for grpc. …","ref":"/blog/2022/10/18/volo-release-v0.2.0/","tags":"","title":"Volo Release v0.2.0"},{"body":"Feature  [#31] 支持 Windows。 [#26] volo-grpc 增加对 service discovery 和 load balance 的支持。 [#45] volo-grpc 支持 uds。 [#32] volo-grpc 支持 metainfo 进行元信息传递。 [#30] volo-grpc Server 增加 layer_front 方法。 [#42] volo-thrift 支持 multiplex。  Optimize  [#53] 优化 write_field_begin 函数。  Fix  [#34] 修复连接超时设置。 [#46] 增加对可重试错误的判断。 [#33] volo-grpc 修复对 Error 类型的约束。  ","categories":"","description":"","excerpt":"Feature  [#31] 支持 Windows。 [#26] volo-grpc 增加对 service discovery …","ref":"/zh/blog/2022/10/18/volo-v0.2.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Volo v0.2.0 版本发布"},{"body":"字节跳动内部 Go HTTP 框架的变迁 在正式开始介绍第一部分的内容之前，先展示一组关键词。2020 年初 Hertz 立项，2020 年 10 月，Hertz 发布第一个可用版本 。 2022 年 6 月，Hertz 正式开源。 截至目前，Hertz 在字节内部已经支撑超过 1.4 万个业务服务 ， 日峰值 QPS 超过 5000 万 。\nHertz 不仅支持业务服务，同时还会横向支持字节内部的各种基础组件，包括但不限于字节跳动服务网格控制面、公司级别压测平台以及 FaaS，还包括各种业务网关等等。 Hertz 的高性能和极强的稳定性可以支撑业务复杂多变的场景。在公司内部 Hertz 接替了大量基于 Gin 框架开发的存量服务，大幅度降低了业务资源使用成本以及服务延时，助力公司层面的降本增效。\n下面我们可以从 Hertz 出现的背景以及 Hertz 的设计目标和思路体会到，Hertz 的出现绝不是偶然。\n基于 Gin 封装 众所周知，字节内部使用 Golang 比较早，在大约 2014 年左右，公司就已经开始尝试做一些 Golang 业务的转型。2016 年，我们基于已开源的 Golang HTTP 框架 Gin 框架，封装了 Ginex，这是 Ginex 刚开始出现的时期。\n同时，2016 年还是一个开荒的时代，这个时期框架伴随着业务快速野蛮地生长，我们的口号是“大力出奇迹”，把优先解决业务需求作为第一要务。Ginex 的迭代方式是业务侧和框架侧在同一个仓库里面共同维护和迭代。\n问题显现 2017 - 2019 年期间，也就是 Ginex 发布之后，问题逐渐显现。主要有以下几点：\n 迭代受开源项目限制  Ginex 是一个基于 Gin 的开源封装，所以它本身在迭代方面是受到一些限制的。一旦有针对公司级的需求开发，以及 Bugfix 等等，我们都需要和开源框架 Gin 做联合开发和维护，这个周期不能完全由我们自己控制。\n 代码混乱膨胀、维护困难  由于我们和业务同学共同开发和维护 Ginex 框架，因此我们对于控制整个框架的走向没有完全的自主权，从而导致了整体代码混乱膨胀，到后期我们发现越来越难维护。\n 无法满足性能敏感业务需求  另外，我们能用 Gin 做的性能优化非常少，因为 Gin 的底层是基于 Golang 的一个原生库，所以如果我们要做优化，需要在原生库的基础上做很多改造，这个其实是非常困难的。\n 无法满足不同场景的功能需求  我们内部逐渐出现了一些新的场景，因此会有对 HTTP Client 的需求，支持 Websocket、支持 HTTP/2 以及支持 HTTP/3 等等需求，而在原生的 Ginex 上还是很难扩展的这些功能需求。\n魔改开源框架 逐渐地，某些业务线开始做初步的尝试，他们会对另外的一些开源框架进行魔改。比较典型的例子是有一些业务线尝试基于 Fasthttp 进行魔改，Fasthttp 是一款主打高性能的开源框架，基于它进行魔改可以短期内帮助业务解决问题。 这种魔改现象带来的问题是，框架魔改是一些业务线自发的行为，各个业务线可能会基于自身业务特性进行各自维护，从而导致维护成本上升非常严重。\n到这里我们仿佛陷入了 Ginex 的怪圈。如前段时间爆火的电视剧《开端》一样，我们仿佛是从一辆开往学院南路的 45 路公交车上醒来，发现自己要前往公司进行下一代 Ginex 框架的维护工作。\n大家也可以思考一下，如果是你来应对这样的场景，你会怎么做呢？\n小结 第一章节的内容总结如下：\n 早期基于开源框架封装  基于早期开源的 Golang HTTP 框架，实现了 Ginex 的封装。\n 随着实践发展，问题逐渐出现  框架混乱膨胀，框架的维护越来越困难，业务的新需求无法得到很好地满足。\n 为了解决问题出现基于另外的开源框架魔改的萌芽  我们需要思考如何跳出魔改的怪圈，把字节内部的企业级框架做得更好。\n另外，还有一个遗留问题，就是应该如何跳出这个魔改的怪圈呢？这个问题第二章节会为大家进行解答。\n企业级 HTTP 框架的设计考量和落地思路 跳出怪圈 为了跳出魔改的怪圈，我们决定从以下三个方面开始着手。\n 自主研发  既然 Ginex 是因为基于开源框架 Gin，没法做一些灵活的控制，那我们就改为完全自主研发框架。自主研发框架的代码全链路自主可控，也可以避免引入任何三方不可控因素，这样我们能够对自己的框架有一个比较完备的掌控力。\n 质量控制  下图列举了一些常规的质量控制手段。我要着重强调的是模糊测试，模糊测试在字节内部是广泛应用于 Hertz 框架的稳定性测试中。它的核心点在于 通过一系列的模拟服务，尝试模拟出线上用户在使用我们的框架时， 实际遇到的一些场景和使用方式 。然后通过一些随机的算法，生成尽可能复杂、覆盖各种 Case 的场景，这可以让我们 检测出一些潜在的问题 。这套测试也在 Hertz 早期的质量建设中，帮助我们将一些问题防患于未然。\n 严格准入  既然 Ginex 的问题是大家都在向里面写入内容，那么我们可以控制入口，建立一套完备的需求开发以及 Review 的闭环，控制迭代的整体流程，从而控制代码准入。同时我们配备统一的需求管理以及严格的发版准入规范，做一个标准的公司级别的框架。\n举一个比较形象的例子，如果我们把下一代框架比作一个人——“框架人”，自主研发表示这个“框架人”首先会拥有对自己身体的主导权，他不会受到来自于环境或者他人的影响； 质量控制表示“框架人”能够定期体检，提早发现一些潜在的疾病，将其扼杀于摇篮；严格准入表示“框架人”有科学的饮食摄入和自律的生活习惯。可想而知，如果我们能够做到以上三点，我们的“框架人”就能够拥有一个健康的体魄。\n痛点梳理 明确了应该如何跳出怪圈之后，我们还应该明确知道这个框架要具备哪些功能和特性，也就是首先应该聚焦到框架的核心痛点上。“框架人”不能只有健康的体魄，还应该拥有有趣的思想和灵魂。 一个成熟的框架不仅仅要应对来自业务侧的需求 ，如功能需求、性能需求和易用稳定等，还要考虑框架自身的发展 ，而这一点恰恰是我们在 Ginex 的迭代过程中忽略的。\n如下图右侧金字塔所示，最上层是高效支撑 ，毋庸置疑框架的存在肯定是为了支撑我们的业务需求。中间层是一个质量保证的红线框架，框架需要保证它自身的质量， 只有以高质量完成的框架才能有自信承担字节内部的 5000 万 QPS，以及各种各样的使用场景。金字塔的最底层是长期、可持续性发展 ，这也是作为未来想要保持持续迭代的框架最重要的一点。\n框架科学发展观 基于上一部分，我们可以进一步梳理出框架的需求痛点。痛点主要有两个方面：\n 多样的需求：支撑支撑各个业务线及基础设施 （横向扩展性）。 灵活的结构：贯穿 HTTP 生命周期的掌控力 （纵向模块化）。  在此基础上进一步抽象出框架的 科学发展观 ：\n 聚类需求：面向通用能力展开设计。 跳出局部：针对一些复杂问题，在更大范围内寻求最优解。  后续我会针对这个科学发展观进一步阐述 Hertz 究竟是如何实现的。\n小结 第二章节的内容总结如下：\n 跳出怪圈  引入“框架人”的概念，帮助大家理解框架的自研、质量控制和严格准入。\n 痛点梳理  为“框架人”注入有趣的灵魂，框架需要应对来自业务侧的多样化需求，还要保证自己的可持续性发展。\n 框架科学发展观  需求聚类，跳出局部。\nHertz 的核心特点 Hertz 框架是如何实现第二章节中提到的框架痛点和科学发展观的呢？本章节将具体进行介绍。\n分层抽象 首先介绍 Hertz 框架的架构设计。下图是一个请求从建立、连接到完成的全过程。左侧是客户端，右侧是服务端 ，在我们发起链接建立请求之后，链接建立完成； 之后客户端发起请求到服务端，服务端进行路由处理，然后将路由导向业务逻辑处理；业务逻辑处理完毕后，服务端返回这个请求，完成一次 HTTP 请求的调用。\n那么在这个过程中我们的框架到底做了哪些事情呢？从图中不难发现，首先框架进行了链接处理 ，其次是协议处理 ，之后基于路由做了逻辑分发， 即路由处理 ，最后做了业务逻辑处理 。我们把框架做成一个结构之后会发现，这个结构包含的就是这四部分。\n基于这个逻辑，我们可以看一下 Hertz 的整体架构图。如下图所示，从下往上看红线框圈住的部分，可以发现这就是上文提到的请求建立的全过程。各层的能力及作用如下：\n 传输层 Transport：抽象网络接口； 协议层 Protocol：解析请求，渲染响应编码； 路由层 Route：基于URL进行逻辑分发； 应用层 Application：业务直接交互，出现大量 API。  我们可以看到图中除了中间部分包含的四层，左右两侧各有两列。右侧是通用层 Common ，主要负责提供通用能力、常用的日志接口、链路追踪以及一些配置处理相关的能力等。 左侧是 Hertz 的代码生成工具 Hz，又称脚手架工具 ，它可以帮助我们在内部 基于 IDL 快速地生成项目骨架 ，以加速业务迭代。\nHertz 的分层设计是能够和代码组织结构一一映射的。下图是 Hertz 仓库里面的代码组织结构，可以看到根目录下的 cmd 包里面存放着 Hz 工具， 在 pkg 包下存放着上述主要四层以及通用层 Common。因此同学们看到架构设计图之后，可以直接在 Github 学习 Hertz 的代码。\n总体来说，Hertz 的架构设计理念就是 “简洁有序，保证让所有开发者轻松理解，在开发的过程中持续贯彻” 。\n易用可扩展 那么基于 Hertz 的架构设计，应该如何展开易用性和可扩展性呢？下图是 Hertz 架构主要四个层级的抽象。\n 应用层  应用层提供了一些通用能力，包括绑定请求、响应渲染、服务发现/注册/负载均衡以及服务治理等等。其中，洋葱模型中间件的核心目的是让业务开发同学基于这个中间件快速地给业务逻辑进行扩展， 扩展方式是可以在业务逻辑处理前和处理后分别插桩埋点做相应处理。一些比较有代表性的应用，包括日志打点、前置的安全检测，都是通过洋葱模型中间件进行处理的。\n 路由层  路由层也是非常通用的，主要提供静态路由、参数路由、为路由配置优先级以及路由修复的能力，如果我们的路由层没办法满足用户需求， 它还能支撑用户做自定义路由的扩展。但实际应用中这些路由能力完全能够满足绝大多数用户的需求。\n 协议层  Hertz 同时提供 HTTP/1.1 和 HTTP/2，HTTP/3 也是我们在建设中的能力，我们还会提供 Websocket 等 HTTP 相关的多协议支持 ，以及支持完全由业务决定的自定义协议层扩展 。\n 传输层  目前我们已经内置了两个高性能的传输层实现。一个是基于 CloudWeGo 开源的高性能网络库 Netpoll 的传输层扩展，另一个是支持基于标准库的传输层扩展。此外，我们也同样能支持在传输层上进行自定义传输层协议扩展 。\n下图每一层中标红的能力都能够体现出，我们能够在框架的任何一个分层上支撑用户做最大程度的自由定制，这样可以最大程度地满足企业级内部用户和潜在用户的业务需求。 如果同学们想要深入了解 Hertz，可以参考 CloudWeGo 官网的 Hertz 部分，上述所有内容均有具体描述。\n性能探索 在性能方面，Hertz 又是如何在自主可控的范围内做高性能探索的呢？\n场景描述 熟悉 Hertz 代码的同学会发现，我们的 HTTP/1.1 协议借鉴了一些 Fasthttp 的优化思路和手段。HTTP/1.1 协议中的 Header 为不定长数据段，往往需要解析到最后一行，才能够确定是否完成解析。 同时，为了减少系统调用次数，提升整体解析效率，涉及 IO 操作时，我们通常引入带 buffer 的 IO 数据结构。如下图所示，它的核心点是最下层的 buffer，buffer 是一个类似于一块完整的内存空间，我们可以将 IO 读到的数据放进这个空间做暂存。\nbufio.Reader 的问题 这样做出现的问题是，原生的 bufio.Reader 长度是固定的，请求的 Header 大小超出 buffer 长度后，.Peek() 方法直接报错 (ErrBufferFul)，无法完成既定语义功能。\n一些可能的解 对于上述问题，其实有一些可能的解决方法：\n 直接利用 bufio.Reader 的局限当做 Feature，通过 buffer 大小作为 Header 大小的限制。如果超出这个大小，Header 直接解析报错，这也是 Fasthttp 的做法。 但实际上超出 buffer 长度后报错会导致我们没办法处理这部分请求，从而导致框架 功能受限 。 header 解析带状态，暂存中间数据，通过在上层堆叠额外复杂度的方式突破 bufio 本身的限制。但是暂存中间态会涉及到一些内存的拷贝，必然会导致 性能受限 。  真实使用环境复杂多变 字节内部的使用场景非常多，我们不仅要支持各种业务线的开发，还要支持一些横向的基础组件。不同的业务，不同的场景，数据规模各异。 如何成为通用且高效的地解决 bufio.Reader 的问题成为 Hertz 面临的内部重要挑战。我们既然已经站在 Fasthttp 这个“巨人”的肩膀上了，能否往前再走一步呢？\n答案是肯定的。基于内部的使用场景，同时结合 Netpoll 的优势，我们设计出了 自适应 linked buffer ，并且用它替代掉了原生的 bufio.Reader。 从下图可以看到，我们的 buffer 不再是一个固定长度的 buffer，而是一条链，这条链上的每一个 buffer 大小能够根据线上真实请求进行动态扩缩容调整 ，同时搭配 Netpoll 中基于 LT 触发的模型做数据预拷贝 。 从实施效果上来看，这个自适应调整能够让我们的业务方完全无感地支撑任何他们的业务特性。也是因为我们能够将 buffer 进行动态扩缩容调整，从而能够保证在协议层最大程度做到零拷贝协议解析 ，这能够带来整体解析上的性能提升，时延也会更低。\n针对 HTTP/1.1 进行中的优化 因为目前在字节内部 HTTP/1.1 还是一个比较主流的协议，所以我们基于 HTTP/1.1 做了很多尝试。\n首先是协议层探索 。我们正在尝试基于 Header Passer 的重构 ，把解析 Header 的流程做得更高效。我们还尝试了做一些传输层预解析 ，将一些比较固化的逻辑下沉到传输层做加速。\n其次是传输层探索 。这包括使用 writev 整合发送 Header \u0026 Body 达到减少系统调用次数的目的，以及通过新增接口整合 .Peek() + .Skip() 语义，在内部提供一个更高效的实现。\nHertz Benchmark 下图是 Benchmark 的开源数据。左侧第一张图是在同等的机器环境上，Hertz 和横向的框架 Gin、Fasthttp 极限 QPS 比较情况，蓝线是 Hertz 处于较高极限 QPS 的状态。 第二张图是 TP99 时延状态，第三张图是 TP999 时延状态，可以看到 Hertz 的整体时延是处于一个更低的水平上。\n字节跳动服务网格控制面从 Gin 迁移至 Hertz CloudWeGo 公众号曾发布关于字节跳动服务网格控制面的文章，讲述字节跳动服务网格从 Gin 框架迁移到 Hertz 的落地实践。下图是他们代码展示的真实收益，从 Gin 框架替换成为 Hertz 框架后， CPU 流量从大概快到 4K 降到大约只有 2.5K，Goroutine 数量从 6w 降到不足 100 个 ，Goroutine 稳定性得到极大地提升。 同时替换成 Hertz 后，框架相关的开销已经基本消失，服务网格在线上稳定承载了超过 13M QPS 的流量 。\n字节跳动服务网格基于 Hertz 框架的实践：https://mp.weixin.qq.com/s/koi9q_57Vk59YYtO9cyAFA\n小结 第三章节的内容总结如下：\n 分层抽象  解构 HTTP 框架，分层解耦。\n 易用可扩展  提供了更丰富 API 和足够灵活的拓展能力，在每一层抽象中都提供了一个足够灵活的扩展能力应对可能的需求。\n 自主可控的高性能探索  自适应 buffer，零拷贝解析，未来将会进行更多的高性能探索。\n未来规划和挑战 我认为 Hertz 未来的发展规划主要围绕以下几个方面：首先，打造泛 HTTP 框架 。我们的最终目标是希望 Hertz 能够解决在 HTTP 领域内的所有问题；其次，助力 CloudWeGo ，希望 Hertz 能够助力 CloudWeGo 打造一个企业级云原生微服务矩阵；最后希望 Hertz 能够持续服务更多的用户 。\n总结 本次分享的主要内容总结如下：\n 字节跳动内部 Go HTTP 框架的变迁：从基于开源封装，到开启自研之路； 企业级 HTTP 框架的设计考量和落地思路：破圈、需求提炼、框架科学发展观； Hertz 核心特点：分层抽象、易用可扩展、自主可控的性能探索； Hertz 未来的规划和挑战：框架持续打磨、助力 CloudWeGo、服务更多用户。  最后欢迎对 Hertz 感兴趣的同学积极参与到 CloudWeGo 社区中，我们一起完善 Hertz，共同建设 CloudWeGo！\n","categories":"","description":"本文描述了字节跳动内部的大规模企业级 HTTP 框架 Hertz 的设计实践，包括 Hertz 的项目起源、架构设计、功能特性，性能表现等方面。","excerpt":"本文描述了字节跳动内部的大规模企业级 HTTP 框架 Hertz 的设计实践，包括 Hertz 的项目起源、架构设计、功能特性，性能表现等方 …","ref":"/zh/blog/2022/09/27/%E5%8A%A9%E5%8A%9B%E5%AD%97%E8%8A%82%E9%99%8D%E6%9C%AC%E5%A2%9E%E6%95%88%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%BC%81%E4%B8%9A%E7%BA%A7-http-%E6%A1%86%E6%9E%B6-hertz-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E8%B7%B5/","tags":"","title":"助力字节降本增效，大规模企业级 HTTP 框架 Hertz 设计实践"},{"body":"Feature  [#198] feat: add the function to get the client dialer name. [#251] feat: add a startup log to display the name of the loaded network library.  Refactor  [#238] refactor: refactor the client logic initialize for HostClient and TLSHostClient.  Optimize  [#226] optimize: add a warning log for illegal status code.  Fix  [#249] fix: add channel signal judge to allow onShutdownHook to complete or timeout. [#232] fix: fix some trailing slash redirect bugs.  Chore  [#217] chore: update pr template.  ","categories":"","description":"","excerpt":"Feature  [#198] feat: add the function to get the client dialer name. …","ref":"/blog/2022/09/20/hertz-release-v0.3.2/","tags":"","title":"Hertz Release v0.3.2"},{"body":"Feature  [#198] feat: 添加获取 Hertz client dialer 名称的方法。 [#251] feat: Hertz server 启动日志添加网络库的名称。  Refactor  [#238] refactor: 重构 Hertz client 初始化 HostClient 和 TLSHostClient 的逻辑。  Optimize  [#226] optimize: 使用 “warning” 日志提示非法的 http 状态码。  Fix  [#249] fix: 修复 Hertz server 优雅退出时无法执行完全部 hook 函数的问题。 [#232] fix: 修复路由尾斜线重定向在边缘情况失效的问题。  Chore  [#217] chore: 更新提交 PR 时的填写模板。  ","categories":"","description":"","excerpt":"Feature  [#198] feat: 添加获取 Hertz client dialer 名称的方法。 [#251] feat: …","ref":"/zh/blog/2022/09/20/hertz-v0.3.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Hertz v0.3.2 版本发布"},{"body":"由内至外 - 开源过渡 很多同学可能刚刚了解 CloudWeGo，先介绍一下 CloudWeGo 和 Kitex 的关系。\nCloudWeGo 和 Kitex Kitex 是 CloudWeGo 开源的第一个微服务框架，它是一个 支持多协议的 Golang RPC 框架 ，从网络库、序列化库到框架的实现基本完全自研的。 特别地，Kitex 对 gRPC 协议的支持使用了 gRPC 官方的源码，但是我们对 gRPC 的实现做了 深度且定制的优化 ，所以 Kitex 支持的 gRPC 协议性能优于 gRPC 官方框架。 同时这也是 Kitex 与目前已经开源的、支持 gRPC 协议的其他 Golang 框架的主要差异。如果用户想使用 gRPC 又对性能有很高的要求，那么 Kitex 框架将会是一个很不错的选择。\n继 Kitex 开源后，今年 CloudWeGo 又陆续开源了 Golang HTTP 框架 Hertz，Rust RPC 框架 Volo，同时围绕这些微服务框架和微服务的一些通用能力， 我们还开源了一些高性能的基础库。关于更多 CloudWeGo 开源的子项目，可以进入 CloudWeGo 官网详细了解。\nCloudWeGo 官网：https://www.cloudwego.io/\n根据社区同学反馈，在一些开源群里大家会讨论 Kitex 会不会是一个字节跳动的开源 KPI 项目呢？它的稳定性、持续性能够得到保障吗？我可以负责任地讲，Kitex 不是一个 KPI 项目，它是来自字节跳动内部大规模实践的真实项目。 在 Kitex 开源后始终保持内外统一，基于内外代码的统一我们保证了 Kitex 的持续迭代。为了进一步消除大家的顾虑，下面具体介绍一下 Kitex 的诞生和开源历程。\nKitex 发展历史 2014 年，字节跳动开始引入 Golang。2015 年，字节跳动内部的服务化开启。在 RPC 调用的场景选择了 Thrift 协议，在内部开始支持 RPC 框架。2016 年，第一个 Golang RPC 框架 Kite 正式发布。 通常在一个公司高速发展的初期，基础能力都是为了快速支持需求落地，面对的需求场景也较单一，设计上不会有较多考量，其实这也是合理的，因为探索阶段并不完全清楚还需要支持哪些场景，过多的考虑反而会出现过度设计的问题。\n但是，随着业务场景复杂化，需求也会多样化，而且接入服务及调用量逐年增长，Kite 已经不足以支持后续的迭代，在线上服役三年多后，2019 年我们开启了新的项目 Kitex，2020 年初发布了正式版本，在 2020 年底字节内部已经有 1w+ 服务接入 Kitex。\n从 2014 年到 2020 年，Golang 已经是字节跳动内部主要的业务开发语言，应该是业界 Golang 应用最多的公司。我们的服务框架支持着数万个 Golang 微服务的可靠通信， 经过数量众多的微服务和海量流量的验证，我们已经有了较为成熟的微服务最佳实践，于是考虑将内部的实践开源出去丰富云原生社区的 Golang 产品体系。 在 2021年，我们以 CloudWeGo 品牌正式开源了第一个服务框架 Kitex。截至今年 8 月，Kitex 已经为字节跳动内部 6w+ 的服务提供支持， 峰值 QPS 达到上亿级别 。\n大家或许还有疑问，完整的微服务体系离不开基础的云生态，无论在公有云、私有云，都需要搭建额外的服务以很好地支持微服务的治理，比如治理平台、注册中心、配置中心、监控、链路跟踪、服务网格等，而且还存在一些定制的规范。 字节跳动自然也有完善的内部服务支持微服务体系，但这些服务短期还无法开源，那 CloudWeGo 如何内外维护一套代码，统一迭代呢？\n关于这个问题，我们看一下 Kitex 的模块划分。Kitex 的模块分为三个部分：中间是 Kitex 主干部分 Kitex Core ，它定义了框架的层次结构、接口核心逻辑的实现以及接口的默认实现； 左边的 Kitex Tool 则是与生成代码相关的实现，我们的生成代码工具就是编译这个包得到的，其中包括 IDL 的解析、校验、代码生成、插件支持等。 不过为了便于用户使用同时提供更友好的扩展，主要能力也做了拆分作为基础库独立开源，如 Thriftgo、Thrift-validator 插件、Fastpb； 右边的 Kitex Byted 是对字节内部基础能力集成的扩展实现，我们在开始就将内部的能力作为扩展收敛到一个 package 下。\n如此，我们就可以将 Kitex Core 和 Tool 部分开源出去。我们将代码做了拆分，Kitex 的核心代码和工具部分迁移到开源库，集成内部扩展的模块作为 Kitex 的扩展保留在内部库，同时内部库封装一层壳保证内部用户可以无感知地升级。\n那么 Kitex 的开源就只是代码拆分这么简单吗？显然不是。2021 年 2 月，我们开始筹备 Kitex 的开源，虽然基于 Kitex 的扩展性，我们可以与内部基础设施集成的能力解耦，但是 Kitex 仍然依赖内部的一些基础库，如果要开源必须先开源基础库的能力。 所以我们首先做了依赖库的梳理，与相关的同学合作首先开源了 bytedance/gopkg 库。这个库由 CloudWeGo 与字节跳动的语言团队合作维护，里面包含也了对 Golang 标准库能力的增强，感兴趣的同学可以关注使用。\nbytedance/gopkg: https://github.com/bytedance/gopkg\n在 gopkg 库开源后，我们调整代码进行开源适配。2021 年 7 月，Kitex 正式开源，在内部发布中版本使用开源库。 但 Kitex 毕竟支持了内部几万的微服务，我们必须要确保内部服务在这个变更后可以平滑过渡，所以在开源初我们没有对外官宣，在确认稳定性后，2021 年 9 月，Kitex 正式对外官宣开源 。\n介绍了 Kitex 诞生、开源的历程，希望能够解除外部同学关于“Kitex 会不会是一个 KPI 项目？”的顾虑。\n开源的价值 第一部分的最后，简单讲一下开源能为我们带来的价值。 Kitex 不是为了开源而实现的，但它的实现是面向开源的。 Kitex 本身是一个经过内部大规模实现的项目， 我们希望 Kitex 开源后能帮助更多用户在内部快速搭建微服务，同时开源能让我们收集更多社区和企业的反馈，也能吸引外部开发者共建， 促进 Kitex 面向多元场景支持的演进，丰富产品能力，然后能在更多场景和企业得到落地，这是一个正向循环，互利共赢的过程。\n开源一年变更回顾 框架的衡量指标 在介绍 Kitex 开源一年变更前，先分享一下框架的衡量指标，这是大家在选择一个框架时要考虑的。\n 扩展性  如果一个框架与内部能力强耦合，就无法移植到其他平台，或框架的支持场景单一也无法进行扩展，这样的框架很难得到外部的使用。\n 易用性  框架的易用性体现在两个方面。第一是面向业务开发者 ，如果一个框架在使用过程中需要让用户关注很多框架的细节，那么对研发效率要求很高的团队可能无法接受。 第二是面向框架的二次开发者 ，他们需要对框架做一些定制支持，如果框架提供的扩展能力过于宽泛，扩展成本很高，或者可扩展的能力不够多，那么这个框架也是存在局限性的。\n 功能的丰富度  虽然基于扩展性可以对框架进行定制，但不是所有开发者都有足够的精力做定制开发，如果框架本身对各种扩展能力提供了不同选择的支持，对于开发者来说只需要根据自己的基础设施进行组合就能在自己的环境中运行。\n 高性能  前面三点是初期选择框架需要重点关注的指标，但随着服务规模和资源消耗变大，性能就成了不容忽视的问题。从长期的角度来说，选择框架的时候一定要关注性能，否则后续只能面临框架替换的问题，或者被迫对这个框架做定制维护。\n关于以上四点框架的衡量指标，虽然 Kitex 目前还没做到最好，但是这四个要素都是 Kitex 设计和实现中一直在兼顾的，我们不会顾此失彼。\n功能特性 下面就几个开源一年来重要的功能特性进行介绍。\nProxyless Proxyless 是 Kitex 面向开源场景提供的支持。在 Kitex 开源初期，我们内部讨论过是否要支持 xDS 对接 Istio，对于外部用户来说，使用 Istio 可以快速搭建一套基本的微服务架构， 解决服务发现、流量路由、配置下发等问题，但是如果使用完整的 Istio 的解决方案，就要引入 Envoy，这会增加运维成本，而且直接使用官方的 Envoy 方案对性能有损，会引入额外的 CPU 开销且增加延迟。 如果 Kitex 能直接对接 Istio，既能让用户享受到部分 Istio 的能力，又可以避免 Envoy 带来的性能损失和部署运维成本。 但是在开源初期，我们没有看到很明确的用户诉求，因此没有对此做高优的支持。\n后来 gRPC 官方也发布了 Proxyless 的支持，同时 Istio 的官方也将 Proxyless 作为使用 Istio 的一种方式。Kitex 现在也已完成支持，目前主要是对接服务发现， xDS 支持的扩展单独开源到了 kitex-contrib/xds 库中，后续还会完善。大家可以根据 README 了解如何使用 Kitex 对接 Istio。\nJSON 和 Protobuf 泛化调用支持 之前，Kitex 支持了应用在网关场景的 HTTP 泛化，以及支持了应用在一些通用服务场景的 Map 和二进制泛化。开源后，根据用户的需求反馈又新增了 JSON 和 Protobuf 的泛化。\nProtobuf 的泛化也是应用在 API 网关的场景。原来的 HTTP 泛化传输的数据格式是 JSON，但是 JSON 的序列化体积大、效率低，对性能有影响，所以很多移动端的接口选择使用 Protobuf 传输数据，因此增加了 Protobuf 泛化的支持。\n目前 Kitex 的泛化主要针对后端的 Thrift 服务，无论是 Protobuf、Map 还是 JSON，Kitex 都会在调用端结合 IDL 解析，将这些数据映射编码为 Thrift 包发给后端服务。\n那么为什么把泛化放在调用端而不是服务端呢？大家广泛了解的泛化都是服务端对泛化请求做了解析处理，当然调用端也要相应地提供泛化的 Client。 但是泛化面向的是通用服务，泛化使用成本其实是比较高的，它并不适用于普通的 RPC 场景，而通用服务面向的是所有后端的服务，有 Golang/Java/C++/Python/Rust，如果每一种语言框架都支持泛化，成本是非常高的。 就算各个语言都对泛化做了支持，框架版本收敛又是一个漫长的过程，对于通用服务来说，对接所有的服务就显得不太现实。综合以上原因，泛化放在调用端支持。\n重试能力增强 去年开源时，Kitex 已经支持了重试功能。之前支持的重试有两类，一个是超时重试，一个是 Backup Request。\n对于超时来重试来说，我们只会对超时这一种异常进行重试，但为了进一步提高请求成功率，用户希望对其他的异常也进行重试，或者用户可能会定义一些用户请求的状态码，结合用户状态码进行重试， 在这种情况下，显然我们只支持超时重试是不满足用户需求的。基于这个背景， Kitex 新增了指定结果重试 ，用户可以指定其他异常或指定某一类 Response，框架会结合用户指定的结果进行重试。\n其次，用户在配置重试时，如果通过代码配置的方式设置重试，它会对整个 Client 的所有 RPC 方法生效，但是用户希望针对不同的 RPC 方法应用不同的重试策略，甚至同一个方法也希望可以采用不同的重试策略， 因为不同链路上发起的同一个方法的请求对指标要求也会不同。比如有些想使用 Backup Request 减少延迟，有些想做异常重试提高成功率，对于这种情况， Kitex 新的版本支持了请求粒度配置重试 。\n下图是使用示例。以请求粒度重试配置为例，比如 RPC 方法是 Mock，那么我们在发起 RPC 调用的时候，在后面可以配置一个 callopt 指定重试策略，此次请求就会使用这个重试策略。\nThrift Validator Thrift-gen-validator 是 Thriftgo 的一个工具插件，它可以根据 Thrift IDL 中定义的注解描述约束给对应的 struct 生成 IsValid() error 方法，校验值的合法性。 通常做 RPC 调用的时候，用户可能会对一些字段校验合法性，用户如果直接写这些校验代码，投入的成本会很高。所以我们就提供了注解支持， 只要用户在 IDL 中根据规范定义注解，Kitex 就可以帮助用户生成校验代码 。\n下图是代码生成的命令和一个 IDL 注解定义示例，在生成代码的时候指定 Thrift Validator 的插件，我们的插件工具就会解析注解，为用户生成这一套合法性校验的代码。 目前我们也将 Thrift Validator 的功能贡献给了 Apache Thrift。\n性能优化 介绍完几个重要的功能特性，再介绍几个在性能上的优化特性。\nThrift 高性能编解码 Frugal 是一个无需生成编解码代码、基于 JIT 的高性能动态 Thrift 编解码器。 虽然我们针对官方 Thrift 编解码已经做了优化，支持了 FastThrift，这个在我们开源前发布的优化实践里也有介绍， 但我们希望能有进一步的性能提升，参考我们开源的高性能 JSON 库 Sonic 的设计，实现了 Thrift JIT 编解码器。下图中的表格是 Frugal 结合 Kitex 与 FastThrift 的性能对比。\n可以看到在大部分场景 RPC 性能表现都较优。除了性能上的优势，Frugal 还有另一个优势是无需生成编解码生成代码。Thrift 的生成代码比 Protobuf 繁重，一个复杂的 IDL 代码生成文件可以达到几万行， 而这些代码本来对用户来说无需关注，却需要由用户来维护。Frugal 只需要生成结构体代码，不需生成编解码代码，就大大解决了这个问题。\n关于如何在 Kitex 中使用 Frugal，可以参考仓库的 Readme。当然用户也可以单独使用 Frugal 作为 Thrift 高性能编解码器，Kitex 后续也会考虑默认使用 Frugal。\nProtobuf 高性能编解码 虽然我们内部主要支持 Thrift，但开源之后我们发现外部用户对于 Protobuf 或 gRPC 的关注会更多，所以参考 Kitex FastThrift 的优化思路，重新实现了 Protobuf 的生成代码。 在 v0.4.0 版本，如果用户使用 Kitex 的工具生成 Protobuf 的代码，就会默认生成 Fastpb 的编解码代码，在发起 RPC 调用的时候，Kitex 也会默认使用 Fastpb。\n下图是 Fastpb 与官方 Protobuf 序列化的性能对比，可以看到无论是编码还是解码，在效率和内存分配上，Fastpb 都远远优于官方 Protobuf 序列化库。\ngRPC 性能优化 开源初期，我们对 gRPC 整体稳定性和性能的关注是比较少的。因为内部使用的场景不是很多。开源后收到了很多外部同学的反馈， 所以我们针对 gRPC 做了一个专项的问题治理以及性能优化。今年中旬我们已经把相关的优化正式提交到开源库，在 v0.4.0 版本发布。\nKitex v0.4.0: https://mp.weixin.qq.com/s/ezifbQkHcZQP6MygmJABYA\n下图中左侧是优化前 Kitex-gRPC 和官方 gRPC 框架对 Unary 请求的压测吞吐对比，在并发比较低的情况下，Kitex 的吞吐并不具有优势， 使用 Fastpb 的时候，Kitex 的吞吐表现会好一些，但低并发的吞吐依然低于官方 gRPC。在优化之后，吞吐对比如右图所示。相比优化前吞吐提升 46% - 70%，相比官方 gRPC 框架，吞吐高 51% - 70%。\n下图中右侧是优化后 Unary 请求的延迟对比，在吞吐比官方 gRPC 高出很多的情况下，Kitex 的延迟也显著低于官方的 gRPC。同时就 Kitex 自身而言，在优化后延迟表现也好了很多。\n我们再看下 Streaming 请求的压测性能对比，优化前 Streaming 请求的表现同样在低并发的情况下，相对 gRPC 框架没有优势。 经过优化后，Kitex 吞吐显著高于官方 gRPC，如下图，同时低并发下吞吐高但延迟持平，增加并发后能看到延迟出现分叉。所以在性能上， Kitex 支持的 gRPC 协议相对官方有明显的优势。\n虽然在部分功能上，Kitex 还没有完全对齐，但是目前已经可以满足大部分的场景需求，我们后续也会继续进行功能对齐。\n社区共建完善生态及企业落地 社区共建的 Kitex 扩展生态 开源后，我们很欣慰得到了很多开发者的关注，坦白说内部团队精力有限，无法快速建立起面向外部用户的 Kitex 扩展生态。但是一年以来借助社区的力量， Kitex 在 服务注册/发现、 可观测性、服务治理几部分的扩展得到了很多补充，尤其是服务注册/发现相关的扩展，目前开源的主流注册中心都已完成对接， 虽然在功能丰富度上我们还有待加强，但结合已有的支持，对于外部用户已经具备了搭建微服务架构的能力。\n衷心感谢积极参与 CloudWeGo 社区建设的同学们！关于 Kitex 相关的生态支持，大家可以进入 kitex-contrib 了解更多的开源仓库。\n对接外部企业，协助落地 我们开源的初衷是为了助力其他外部企业快速地搭建企业级的云原生架构。开源后，森马、华兴证券、贪玩游戏、禾多科技先后主动与我们联系，反馈使用问题、提出需求， 的确让我们发现了一些和内部场景不一样的问题，需要我们去关注、支持和优化，我们很开心 Kitex 能在这些企业内部得到应用。 在今年 6 月 25 日的 CloudWeGo Meetup 中，森马和华兴证券的研发同学也分享了他们使用 Kitex 的内部实践。\n森马：https://mp.weixin.qq.com/s/JAurW4P2E3NIduFaVY6jew\n华兴证券：https://mp.weixin.qq.com/s/QqGdzp-7rTdlxedy6bsXiw\n除了以上企业，还有一些公司也私下向我们咨询过使用问题，我们非常感谢这些企业用户的支持，以及向我们提出的反馈信息。 如第一部分所讲，收集社区和企业的反馈可以促进 Kitex 面向多元场景支持的演进，企业用户如果有相关需求，欢迎联系我们。\n如何使用 Kitex 与内部基础设施集成 这里再简单介绍下如何使用 Kitex 与大家的内部基础设施集成。以字节内部为例，内部仓库里有开源库中的扩展实现，集成内部的能力， 在 bytedSuite 中，我们针对不同场景对 Kitex 进行初始化。如下面的代码示例，用户只需要在构造 Client 和 Server 时增加一个 option 配置就可以完成集成， 不过为了让用户完全不需关注内部能力的集成，我们将该配置放在了生成的脚手架代码中，关于配置如何内嵌在生成代码中，后续我们也会开放出来，方便外部的框架二次开发者能以同样的方式为业务开发同学提供集成能力。\n总结和展望 总结 本次分享主要介绍了以下内容：\n Kitex 如何保持内外统一地从内部应用较广的框架转为开源框架； 开源一年以来发布了哪些重要的功能特性，做了哪些性能优化； 借助社区的力量现在 Kitex 的周边生态如何、企业落地情况以及如何使用 Kitex 优雅地集成内部能力。  展望  与社区同学共建，持续丰富社区生态； 结合工程实践，为微服务开发者提供更多便利； 完善好 BDThrift 生态，持续优化 Protobuf/gRPC； 更多特性支持或开源，ShmIPC、QUIC、Protobuf 泛化…  ","categories":"","description":"本文介绍了高性能 RPC 框架 CloudWeGo-Kitex 的起源与发展历史，以及开源一年以来的功能特性变更、社区共建生态成果、企业落地实践等方面。","excerpt":"本文介绍了高性能 RPC 框架 CloudWeGo-Kitex 的起源与发展历史，以及开源一年以来的功能特性变更、社区共建生态成果、企业落地 …","ref":"/zh/blog/2022/09/20/%E9%AB%98%E6%80%A7%E8%83%BD-rpc-%E6%A1%86%E6%9E%B6-cloudwego-kitex-%E5%86%85%E5%A4%96%E7%BB%9F%E4%B8%80%E7%9A%84%E5%BC%80%E6%BA%90%E5%AE%9E%E8%B7%B5/","tags":"","title":"高性能 RPC 框架 CloudWeGo-Kitex 内外统一的开源实践"},{"body":"概述 CloudWeGo 开源一周年以来收获了超过 1w 的 star 数，这一年 CloudWeGo 从项目的数量、性能的提升、社区的活跃、生态的拓展等各个方面都有一些整体的变化。 同时，通过一周年的开源，我们收获了非常多的开源社区用户，这些用户在社区里也提供了很多项目的使用反馈。基于这些反馈，我们发现随着技术发展和用户业务的不停迭代，用户需求也在发生着变化。 因此我们梳理了新一代关于云原生微服务用户的画像，作为指导我们社区持续演进的重要参考。\nCloudWeGo 开源一周年的变化 全景图 CloudWeGo 是一套由字节跳动开源的云原生微服务架构中间件集合。在 2021 年 9 月正式推出的时候，只开源了 Kitex 高性能 RPC 框架、高性能网络库 Netpoll，还有相关的辅助工具和基础库。\n经过一年的建设，CloudWeGo 社区目前有 11 个重点项目齐头并进。我们不仅有 Kitex 框架，还有基于 HTTP 相关的高性能框架 Hertz，同时开源了高性能的 Rust RPC 框架 Volo，这也是国内首个开源 Rust RPC 框架。\n从 CloudWeGo 开源的项目也能感受到我们对性能的极致追求，我们不仅开源了框架相关的项目，同时也把深度优化的一些编解码库、网络库都进行了开源。 在 CloudWeGo 整体的项目中，始终都保持着三高的特性，即 高性能 、高可靠性和 高扩展性 。\n与此同时，这一年我们也在致力于开源社区的建设：\n 易用性  CloudWeGo 非常重视整个项目的易用性建设。我们有非常完整的官方文档体系，包括整体的扩展和 Example 的建设，以及各大云厂商生态的对接等。\n 落地支持  为了帮助更多对高性能微服务架构有需求的用户，能够让他们真实地把高性能的技术解决方案落地，我们提供了 Benchmark 的性能测试和选型参考，同时提供免费的企业支持，帮助用户解决自己业务特异性上的一些问题。\n 活动 \u0026 布道  为了让更多有需求的用户能够在社区找到高性能技术解决方案，我们开设了相关的活动和布道体系的建设。在 CloudWeGo 开源一周年之际，项目整体收获了很多用户支持，也收获了很多企业用户的使用反馈。\nCloudWeGo 开源社区的长期主义 高性能技术解决方案的持续探索 CloudWeGo 开源一周年的历程，其实就是对高性能技术解决方案持续探索的历程。\n  CloudWeGo 从 2021 年 9 月 8 日正式开源。推出高性能的 RPC 框架 Kitex、配合 Kitex 使用的高性能网络库 Netpoll、基于 Thrift 代码生成工具 Thriftgo 和基础库 Sonic。 2022 年 5 月，开源了基于 JIT 的编解码工具 Frugal。Kitex 配合 Frugal 的使用，能够带来 5 倍的性能提升。 2022 年 6 月，开源高性能 HTTP 框架 Hertz。Hertz 不仅仅是一个 高性能的HTTP 的开源框架，同时也是一个超大规模的企业落地实践。在我们内部的网关场景下，替换 Hertz 框架之后的 CPU 使用节省了超过 40%。 2022 年 7 月，我们响应社区呼声最高的关于 Protobuf 的性能优化，带来了高性能的 Protobuf 序列化反序列化库 FastPB，再次对相关的性能进行提升。 开源一周年之际，我们又进行了更深度的高性能框架能力探索，开源了国内首个 Rust RPC 框架 Volo。   CloudWeGo 开源一周年的时间线，隐藏着 CloudWeGo 社区运营的第一个长期主义关键词：高性能技术解决方案的持续探索 。\n活跃 \u0026 高可靠性的长期承诺 CloudWeGo 开源一年来，收获了超过 1w 的 star 数，整个社区的活跃度也有了飞速提升。\n社区保持着 2-3 个月发布一次中版本的发版频率，PR 和 Issue 数量在开源一年的时间内实现稳步提升，从每月 47 条 PR 合入增加到每月超过 160 条 PR 合入。\n其实高活跃的社区并不少见，但是我们社区还有一个关键词：坚持活跃 \u0026 高可靠性的长期承诺。CloudWeGo 社区对可靠性的坚持，要求我们不仅要维持活跃，还要保持活跃且可靠。\nCloudWeGo 开源社区一直保持着我们所有的开源项目内外一致的承诺，同时我们开源到外部的所有能力和项目都是在内部经过可靠性验证的。这也正是 CloudWeGo 开源社区坚持的另一个长期主义。\n高易用性设计 我们非常希望 CloudWeGo 开源出来的高性能技术解决方案，能够更好地帮助更多用户搭建自己的微服务架构体系。因此，CloudWeGo 在社区建设上围绕着易用性建设做了非常多的拓展：\n CloudWeGo 文档建设  首先，在文档建设方面，CloudWeGo 官网上线了近 3 万字较为完善的文档体系。内容覆盖从 1 分钟快速上手，到各个相关模块的基本特性介绍，再到一些拓展能力的建设。\n其次，我们为了达到真正的开箱即用，节省用户对接各个扩展项目的使用成本，上线了 Kitex 和 Hertz 相关的 Example，帮忙建设了相关从注册发现，到各个中间件使用的一些开箱即用的 Demo。\n另外，为了提升更多开发者的使用体验，官网也上线了静态文档的搜索能力。\n CloudWeGo 生态建设  想在内部构建一套完整的云原生微服务架构体系，仅仅使用 CloudWeGo 的一个框架项目，是远远不够的。因此，CloudWeGo 在易用性方面大力拓展相关的生态建设。\n CloudWeGo 在 2021 年加入 CNCF Landscape，希望给用户一个更加明确的产品定位。同时，支持对接各大云厂商，为 CloudWeGo 项目的用户提供更多公有云的使用选择。 为帮助大家减少相关的使用成本，我们非常积极地和上下游的开源项目进行深度合作，建设了一整套微服务开源供应链的合作体系，搭建了 CloudWeGo 框架对接各个项目的相关 Demo 和开箱即用的 Example。 从考虑未来发展的角度而言，当企业落地了一整套微服务架构之后，可能会存在易用性或性能方面的问题。当出现更好的技术解决和性能提升方案，基于原有架构的耦合和复杂度，很难推进新的架构进行整体的迭代。 因此，我们也非常积极地在推进建设云原生微服务治理的整体标准。希望更多的项目，能够形成统一的接入和对接的标准，从而在未来的一些新的、更高性能的技术解决方案的迁移和过渡上，能够让迁移和使用成本降到最低。   CloudWeGo 的开发者活动  CloudWeGo 项目包括整个社区都对高性能有非常热烈的追求。因此，我们也在不停地迭代。\nCloudWeGo 一直在不断追求高性能框架以及高性能技术解决最新方案。每次上线新的技术解决方案和一些相关能力之后，我们都期望让更多的用户知道这些方案是怎样的，让用户能够更便捷地学习到一些相关的技术指南。\n因此，我们针对性地设计了 CloudWeGo Study Group 学习计划，这是为了将一些全新的性能解决方案进行体系化的学习分享，即通过一些类似于从框架入门到核心能力的解读、再到一些学习路径的分享以及扩展知识的相关介绍对外开放给社区。\n我们会提供一份完整的学习资料，降低用户学习新的技术解决方案的成本，也能够让用户了解到自己的学习是否适合其业务场景。在整个学习和使用的过程中，降低最终学习的时长，通过体系化的学习更快地理解技术方案的性能亮点和需要学习的相关点。\n小结 CloudWeGo 开源社区坚持的长期主义：\nCloudWeGo 的用户 基于开源社区长期主义的坚持，CloudWeGo 自 2021 年 9 月开源，至今开源 1 年，获得超过 1w star，支持完成了证券、电商、中台、社交、游戏、AI 等行业企业客户的落地使用。\nCloudWeGo 的贡献者 在活跃的社区氛围下，我们收获了从最初刚开源只有 20 个内部贡献者，到现在已经有了超过 200 个代码贡献者。这些贡献者在深度使用了 CloudWeGo 开源项目之后，也为 CloudWeGo 开源项目贡献了大量生态方面相关对接能力。\n贡献者体系更新 基于越来越多的贡献者在我们的开源社区里做了大量深度贡献，CloudWeGo 开源社区在一周年的周年庆之际，推出 全新的贡献者激励体系 。\n我们新增开放了三个角色体系，希望通过这种完善的角色机制，赋予社区开发者更多的社区治理权限。同时我们也鼓励更多的贡献者能够成为项目的维护者，希望长期的维护者能够真正带领我们的项目持续进行高性能的优化和相关的演进。\n贡献者多样化 在开源项目的运营和维护中，包括开源社区的建设，不仅仅是依赖代码贡献者的参与，还有很多其他方面的贡献，其中包括企业支持场景的贡献、布道活动的贡献、整体活动组织的贡献等多元参与。 这些贡献者在 CloudWeGo 社区也是被大力支持的，因此我们专门针对多元贡献上线了 CloudWeGo 年度激励计划。\n社区在 8 月份刚刚完成了 2021 - 2022 年度 CloudWeGo Awesome Contributor 的评选，我们非常荣幸地收获了 84 位年度优秀贡献者。 在完成了社区的提名与公示后，这些同学已经顺利成为了 CloudWeGo 年度优秀贡献者，之后我们会为这些优秀贡献者送上 CloudWeGo 一周年的荣誉纪念徽章。\nCloudWeGo 社区遇到的问题 正是因为社区较高的活跃度以及众多贡献者的参与，大量用户加入了 CloudWeGo 社区。我们逐渐发现用户的使用场景开始慢慢发生了拓展。 从最初可能只是想了解一下微服务的框架、单独一个项目如何去落地和使用，到后来慢慢变成探索一整套微服务架构的设计，以及多个项目之间的实践配合和相关生态能力的建设。\n这些其实是非常体系化、大规模的需求，因此我们联合一些企业用户进行了相关场景的实践贡献。CloudWeGo 之前支持了包括证券、电商、AI 和各个行业用户场景落地，我们也和这些企业用户进行了相关场景的梳理。\nCloudWeGo 的企业用户贡献 华兴证券 案例链接：https://www.cloudwego.io/zh/cooperation/huaxingsec/\n华兴证券的张天老师团队向社区贡献了来自证券行业使用 Kitex 完成混合云部署下跨机房使用场景的案例。\n我们在跟张天老师团队合作的时候发现，他们遇到的最大的问题是有的业务部署在金融云机房上，有的业务部署在私有机房上，所以存在跨机房调用的问题。 因为他们使用 K8s 集群，还会出现同集群调用和跨集群调用的问题。整个调用的链路非常长，这中间就会出现很多不可观测的问题，当出现问题的时候，排查难度就极其大。\n于是张天老师团队在和 CloudWeGo 合作之后，整体搭建了一个 Kitex + K8s 的可观测性系统，也将相关的搭建实践贡献到了开源社区。感兴趣的同学可以通过 CloudWeGo 公众号查看相关的企业案例和最终的实践场景。\n森马 案例链接：https://www.cloudwego.io/zh/cooperation/semir/\nCloudWeGo 和森马共同梳理了与电商行业相关的一个整体使用场景。非常感谢森马团队，贡献了电商行业使用 Kitex 接入 Istio，以提高对高并发订单处理能力的使用场景。\n森马团队还贡献了基于微服务架构的两种模式，为有相关高性能业务需求的用户提供了服务网格 + Kitex 治理模式相关的选型依据，并且给出了相关的压测报告，也给社区有相同需求的小伙伴提供重要参考。\n飞书 案例链接：https://www.cloudwego.io/zh/cooperation/feishu/\nHertz 开源后，很多用户会问到内部网关平台架构的设计思路，包括内部网关平台如何配合 Hertz 整体使用？\n飞书之前是一个 all-in-one 的套件开发模式，各个业务团队会将业务代码提交到飞书网关平台的代码仓里面，由飞书网关相关的同学来做 web 逻辑的开发。 这就导致他们所有的服务都是融在一起的，没有办法做到发布隔离，极大地阻碍了网关平台架构的演进和迭代速度。\n因此，飞书团队将前端 Node 单体服务做了微前端架构拆分，配合 Kitex 泛化调用各个业务的微服务，实现了各个业务发布完全隔离，这使得他们不再依赖网关平台的业务开发，进而加快了整个网关业务迭代的速度。\n来自社区的用户具体问题 我们非常感谢企业用户贡献的相关问题，CloudWeGo 配合企业用户的场景案例也获得了社区用户的众多好评。与此同时，有更多的用户也提出了新的问题，这些问题非常具体。\n通过总结发现，这些问题具有显著的业务特异性。我们也很好奇这些用户在内部到底是如何搭建其微服务体系的？\n因此我们开始梳理 CloudWeGo 开源社区的云原生微服务用户画像。\n新一代云原生微服务用户画像 我们将社区的用户大概分成了三种类型：\n 字节跳动  字节跳动是我们目前最大的用户。字节跳动的线上微服务数量已经超过了 10 万，服务端峰值 QPS 已经达到了数亿的级别，业务复杂性非常大，存在跨语言、跨平台、跨终端、跨集群、跨机房等多种复杂的问题。\n同时字节跳动内部有非常完善的微服务架构体系，整体的微服务治理已经全面迈入了 2.0 的时代，用微服务框架配合服务网格携手并进。\n在这个场景之下，字节跳动最大的需求就是高性能和可扩展性，这也是 CloudWeGo 作为字节跳动内部孵化的一个优秀的高性能技术解决方案最初开源时所具有的特性。\n 处于转型期的用户  社区里数量最大的群体，这些用户可能是电商的、证券的、后台的以及一些创业公司，他们的节点数量不是特别多，可能在 5-1000 以内， 线上微服务数量处于 5000 以内的水平，但这些用户可能本身就是云原生架构，或者已经在往这方面做一些相关的迁移。\n这类用户在 CloudWeGo 开源社区的诉求，主要是针对业务的特异性方面存在高性能相关的需求。\n 非云原生架构企业用户  这一类用户属于非云原生架构的企业，他们的服务可能还没有完全云化，具有一定的历史迁移负担。这类用户着重会优先考虑如何将自己的服务迁移上云。\n因此可以看到，第二类用户是目前社区数量最大，且最需求最迫切的一类用户。\n我们认为理想状态下用户整个云原生架构体系的搭建过程：\n 第一个阶段：服务上云  类似第三类用户，当前面临的问题就是怎么把自己的业务迁移上云。\n 第二个阶段：云原生部署  类似第二类社区大量的用户，其实已经是云原生部署的企业，用到了相关容器化和编排调度的技术。\n 第三个阶段：微服务架构  继续往前演进，开始搭建相关的微服务架构，以及会做服务的拆分和通信的治理。\n 第四个阶段：微服务治理  当用户在线上有了一定数量的微服务之后，会开始出现依赖管理和一致性保障的问题。\n但是我们在跟用户沟通过程中发现，这其实不是一种绝对意义上的区分。\n因为很多公司其实并不是完全属于其中一种状态，而是一种长久的中间态，公司的业务会处于不同的状态。同时，我们在和相关用户进行深度的沟通时，发现这些业务场景其实并不是完全不可复制的，而是具有一定的行业聚合性和相似性。\n于是，我们开始探索如何通过社区更好地帮助这些开发者解决痛点问题，这也正是 CloudWeGo 开源社区接下来整体的演进方向。\n持续演进的 CloudWeGo 开源社区 CloudWeGo 1.0 社区搭建的主要方向，是将字节跳动内部孵化的高性能框架解决方案触达给更多的用户，让更多对高性能解决方案有需求的用户能够真正地在内部落地和使用这些方案。\n当我们发现用户出现特异性的行业需求后，ClouWeGo 2.0 希望社区建设以开发者服务为主，能真正地帮助到社区的开发者，解决其在微服务治理过程中遇到的一些真实存在的问题。\n 行业解决方案  通过用户问题、场景和解决方案的行业共建，形成社区的 Go 云原生微服务最佳实践，希望能够针对有特异性需求的用户给到一定的参考。\n 易用性建设  我们会持续和开源链条的上下游深入合作，建设云原生微服务相关的标准治理。致力于后续易用性的建设，希望能够给到成本更低的迁移，以及建立后期维护的治理标准。\n 持续投资高性能方案  继续维持 CloudWeGo 开源社区的长期主义。我们会深入投入对高性能解决方案的持续探索，也会在 Rust 领域持续开展相关生态和开源的建设，共建 Rust 中国的开源生态。\n基于此，引出 CloudWeGo 开源社区 2.0：\nCloudWeGo 2.0 的阶段，我们希望社区能够跨越项目边界，真正能够帮助社区用户搭建一套高性能的微服务治理架构和整体的微服务治理体系：\n 通过 Go 领域相关微服务治理的标准和最佳实践的建设，为一些通用性技术和行业最佳实践提供参考； 对接开源项目上下游进行深度合作，极大地提升整个项目的易用性； 推进高性能 Rust 解决方案的落地，持续探索 Rust 高性能技术解决方案，构建 Rust 相关生态。  如果大家对 CloudWeGo 开源社区，以及刚才提到的一些技术解决方案、企业的落地支持有任何的疑问，可以关注 CloudWeGo 公众号， 我们会在公众号上发布一些新闻动态以及各个相关场景的案例报道，同时我们也会在公众号上提供相关的技术支持。感谢大家的关注！\n","categories":"","description":"本文介绍了 CloudWeGo 开源社区的运营模式，以及社区的长期主义与新变化。","excerpt":"本文介绍了 CloudWeGo 开源社区的运营模式，以及社区的长期主义与新变化。","ref":"/zh/blog/2022/09/13/%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E7%9A%84%E9%95%BF%E6%9C%9F%E4%B8%BB%E4%B9%89%E4%B8%8E%E6%96%B0%E5%8F%98%E5%8C%96-cloudwego-%E5%BC%80%E6%BA%90%E7%A4%BE%E5%8C%BA%E5%AE%9E%E8%B7%B5/","tags":"","title":"开源社区的长期主义与新变化 — CloudWeGo 开源社区实践"},{"body":"CloudWeGo 选择 Rust 语言进行探索的原因 CloudWeGo 正式官宣新一代 Rust RPC 框架 Volo 开源！CloudWeGo 为什么会选择 Rust 这门语言进行探索呢？本文首先介绍一下其中的原因。\nGo 的代价  深度优化困难  Volo 早期的团队成员来自于 Kitex 项目（CloudWeGo 开源的 Golang 微服务 RPC 框架）。当时我们投入了大量的时间和精力优化 Kitex 以及其他相关基础库的性能，最终却发现实现 Go 的深度优化有些困难。 我们仅仅可以做一些算法层面和实现层面的优化，如果想往下继续做其他层面的优化，比如指令层面的优化，是很难以低成本的方式实现的。而且在大多数情况下很多优化是要和 runtime 以及编译器作斗争的。\n 工具链和包管理不够成熟  例如，使用 Kitex 框架时需要先使用对应的 kitex 工具生成代码，才能正常编译使用。虽然这种情况可能在 Frugal 工具成熟之后有所改善，但是在 IDL 有更新的情况下，还是需要使用 kitex 重新生成对应的结构体。 这个问题并不是 Kitex 的问题，而是 Go 语言本身的问题，Go 语言在编译时没有提供类似的能力。\n 抽象能力较弱  Go 语言的抽象能力是比较弱的，而且 Go 语言里面的抽象并不是零成本抽象，而是有代价的抽象。\n那么使用 Go 语言需要付出的三个代价具体应该如何理解呢？下面进行具体分析。\n深度优化困难 如图所示，这是 Kitex 项目生成代码的简单示例。这两段代码的目的是在解析出错的时候，把一些信息返回给上层。在 Kitex 新版本代码公开之后， 业务团队同学反映他们线上序列化和反序列化这部分的性能相差了 20%，经排查之后，我们发现了这个改动。\nKitex 新版本的代码 Kitex 旧版本的代码 这个改动的本意是希望能给客户提供更多错误上下文的信息。但是它带来了什么问题呢？如下图，它把汇编代码直接一对一地生成到主流程之中，也就是说 Go 语言的编译器会逐行逐句地进行翻译，并且不会做重排。\n那么这会带来什么问题呢？由于我们主流程中的代码与正常流程相比变多了，所以我们重点关注一下 L1-icache-load-misses 这一行， 新版本的代码比旧版本的代码在 L1 指令 cache 层面 cache-misses 高出 20%，这也就是我们的代码效率降低 20% 的原因。那么我们是如何解决这个问题的呢？\n我们的解决方案如下图所示。在 err != nil 的情况下，直接手动加一条 goto 语句，把所有错误处理这部分的代码放到函数末尾，即 return 之后。 这相当于在编译器没有实现指令重排的情况下，用人工方式做一次指令重排。最后优化的效果是非常明显的，可以看到 cache-misses 比之前的那一次还要降低 25%。\n上述例子只是使用 Go 语言时在做深度优化方面遇到的难题。在抽象能力方面，使用 Go 语言也会遇到一些困难。\n零成本抽象(Zero-Cost Abstraction) 什么是零成本抽象呢？使用 C++ 和 Rust 的同学对这个概念可能有所了解。零成本抽象是指我们不需要对没有使用的功能付出编译和运行的开销，也就是用户不需要给没有使用的东西付费。 对应地，如果用户对于已经使用的东西也没有再继续优化的空间，因为它已经默认提供了最佳实践。总结如下：\n 不用的东西，不需要为之付出代价； 用到的东西，你也不可能做得更好。  那么为什么说 Go 语言里面没有零成本抽象呢？以 Thrift 编解码为例，我们最开始使用的是 Apache Thrift，它为了支持多种不同 Protocol、Transport 组合， 抽象出了 TProtocol Interface、TTransport Interface，但 Kitex 直接依赖具体的 BinaryProtocol 的实现（struct）。可以试想，Apache Thrift 这么做的代价是什么呢？这就是 Go 里面 Interface 带来的代价。\nGo 里面 Interface 是动态分发的，也就是运行时通过类型元数据和指针去动态调用所需方法，它会在运行时多做一次内存寻址。但这并不是最关键的，最关键的是它会使得编译器没有办法 inline 以及没有办法做很多优化。 一般比较注重性能的语言都会同时提供静态分发和动态分发两种方式的抽象能力，但是 Go 语言只提供了 Interface 动态分发能力，也就可以理解为在 Go 语言中抽象和性能是不可兼得的，这也就是 Go 语言抽象能力比较弱的原因。\nSonic Sonic 是 CloudWeGo 开源的一个 JSON 库，这个库有很多 CloudWeGo 的用户都使用过。最初这个库组成部分如下图所示，有 2/3 的代码都是 Assembly 汇编。\n在 Sonic 库中仅有的 27% 的 Go 源代码如下图所示。虽然它被统计到了 Go 代码中，但实际上是汇编代码。所以我们可以总结出，世界上最快的 Go 语言程序大概就是用汇编代码写就的。\n性能最好的 Go JSON 库 尽管 Sonic 里面采用了各种黑科技，甚至有 2/3 的代码都是经过人工精调的汇编代码，但是 Sonic 的综合性能还是不如 Rust 最通用的 Serde JSON 库。 如图所示，绿色柱状图代表 Serde JSON 库，蓝色柱状图代表 Sonic 库。根据这个 Benchmark，即使是和 C、C++ 的库相比，用 Rust 语言编写的这个库在各方面综合表现也是最佳的。\n试想，又有多少 Go 组件能够得到如此大量的人力投入从而进行深度优化呢？这只是一个例子，其实我们之前在 Kitex 中的很多优化也是要和编译器以及 runtime 作斗争的。因此我们认识到在 Go 语言中想做深度优化是非常困难的。\n关于 Rust 我们为什么要选择 Rust 这门语言呢？在解答这个问题之前，要先了解这门语言。所以先介绍一下 Rust 语言的发展历史。\nRust 的历史 Rust 语言由 Graydon Hoare 私人研发，他是 Mozilla 做编程语言的工程师，专门给语言开发编译器和工具集。当时 Mozilla 要开发 Servo 引擎，想要保证安全的同时又能拥有高性能， 于是就选择了 Rust 语言。2010 - 2015 年期间，Rust 是有 GC 的，后来社区一致表示支持 Rust 必须要有高性能，所以 GC 被取缔。2015 年，Rust 发布 1.0 版本，这也表示正式官宣 Rust 的稳定性。\nRust 是以三年为单位进行社区规划和迭代的。2015 - 2018 年，Rust 达成了生产力的承诺，也就是它的工具文档还有编译器变得更加智能，也对开发者更加友好了。 2018 - 2021 年，Rust 做了更多异步生态的完善。之前的 Rust 是没有异步生态的，但是自 2018 年开始，它正式引入了异步功能。\nRust 2024 2021 - 2024 年，Rust 有一个 2024 规划，主题叫做 Scaling Enpowerment（扩展授权）。之所以取这个名字，是因为 Rust 有一个目标——“empower everyone to build reliable and efficient software”。 Rust 最关注也是大家经常诟病的一点，就是 Rust 的整个学习曲线非常陡峭，所以在这个规划中写道 “Flatten the learning curve”。\nRust 三大优势 在 2022 年，很多开源项目已经呈现爆炸式增长。我们了解到 Rust 这门语言后，发现它有三大非常重要的优势：第一是高性能；第二是很强的安全性；第三是协作方便。 因此我们想尝试在服务端使用 Rust 语言开发微服务，以此解决我们面临的一些性能上的问题。\n 性能  很多用户都对性能有很高的要求，也想知道 Rust 的性能如何。下图是各语言的 Benchmark 对比结果，可以看出 Rust 的性能是非常优秀的，远超过 Go 语言，甚至比 C++ 的性能更好。\n当然我们要着重说明，这个 Benchmark 要求所有语言必须使用相同的算法，并且不得经过额外优化。毕竟如果都用汇编代码写，其实各语言性能相差无几。 但是在真正的开发过程中，又有多少代码能够经过那么大量的人工精细优化呢？另外，有人可能会对 Rust 的性能比 C 和 C++ 更优秀产生质疑，其实这也是因为 Rust 对于程序员的输入要求得更加严格，所以编译器可以做更进一步的优化。\n 安全性  因为在 Rust 语言的安全性方面可查阅到大量资料，因此不再过多赘述。只阐述一个重要结论：Rust 1.0 之后，在非 Unsafe 代码中是不可能出现内存安全问题的。 这个结论是通过数学证明过的，因此非常可靠。我们应该如何理解这个结论呢？可以从它的推论入手，即：一切内存/并发安全问题，都是 unsafe 代码导致的。 也就是如果真的出现安全问题，我们可以限制在一个非常小的范围内进行排查。因为毕竟绝大多数的 Rust 语言代码都是 Safe Rust，而不是 Unsafe Rust。\n 协作  Rust 是一门真正通过工程实践形成的语言，它有非常 智能的编译器 、 完善的文档 、集群的工具链和 成熟的包管理 ，因此 Rust 非常适合协作。 我们在使用时可以专注于逻辑功能的实现，而不用担心内存安全和并发安全的问题等等。还有非常重要的一点就是可以限制别人的代码，因为如果别人的代码有内存安全问题或并发安全问题，将无法进行编译。 所以在做 Code Review 时，我们只需关注逻辑上的功能正确性就可以，因为只要能够通过编译提交上来的代码，安全性是不必担心的。 这虽然是 Rust 语言的优点，但也给使用者带来一些不便之处。我们常听说 Rust 开发者很难，也正是因为编译。\nRust 的影响力 如下图，Rust 已经连续七年位居 Stack Overflow 最受开发者喜爱的编程语言榜榜首。此外，有一个非常重量级的项目叫做 “Rust for Linux”， 除了 C 语言之外，Rust 是 Linux 内核迄今为止接受的唯一语言。这些成绩足以看出 Rust 在开源业界的重量级和影响力。\n创建 RPC 框架 Volo 的原因 明确了 CloudWeGo 选择 Rust 语言的原因以及 Rust 的优势，我也阐述一下创造 Volo 框架的原因以及 Volo 的特点。\n生态现状 创造 Volo 框架与当时的生态情况是有关的。我们当时调研过整个社区的生态，发现没有生产可用的 Async Thrift 实现。哪怕是社区中最成熟的 Tonic 框架，它的服务治理功能也是比较弱的，而且易用性也不够强。 更重要的是当时在 Rust 语言社区，还没有基于 Generic Associated Type（GAT，Rust 语言最新的⼀个重量级 Feature）和 Type Alias Impl Trait（TAIT，另⼀个重量级 Feature）的易用性强的抽象。\n易用性 为什么单独说明 GAT 和 TAIT 这两个特性呢？按照 Rust 官方团队的说法，这是自 Rust 1.0 以来语言层面和 Type System 层面最大的变化。 举例简单说明，下图是一个现有的社区方案，代码是没有使用 GAT 和 TAIT 的超时中间件的编写，我们可以发现如果要保证性能不受损耗，需要编写大量代码。\n而在 Volo 框架中，因为采用了 GAT 和 TAIT 这两个特性，编写代码如下图所示。我们可以明显对比出代码量和易用性方面的差距是非常明显的。 Rust 以难学难用而闻名，我们希望尽可能地降低用户使用 Volo 框架和 Rust 语言编写微服务的难度，提供给用户最符合人体工程学和直觉的编码体验，因此我们把框架易用性作为重要目标之一。 只有让大家真正地使用 Volo，Volo 才能体现它的价值。所以 Volo 框架 基于 GAT 和 TAIT 特性 ， 大大提升了用户编写中间件的便利程度 。\n除此之外，我们提供了 Volo 命令行工具生成默认 Layout ，并且 Volo 的命令行工具提供 IDL 管理的能力 ，这在业界是首例。 我们还提供了过程宏等能够再度降低 Service 编写难度的功能。当然还有很多其他的精心设计，比如很多 API 都是尽量以最符合人体工程学的方式给出的，也可以避免误用。\n扩展性  基于 Service 的抽象  受益于 Rust 强大的表达和抽象能力，开发者可以基于非常灵活的 Service 抽象，用统一的形式对 RPC 的元信息请求和响应做一些处理，比如服务发现、负载均衡等服务治理功能都是直接实现 Service 即可。\n 基于 RPC 元信息的控制  另外，在我们的框架设计中，所有框架行为都是受到 RPC 元信息控制的。因此我们只要在 Service 中对 RPC 元信息进行修改，就能直接控制框架的行为，从而实现所需的功能。\n下图是 Volo 自带的负载均衡中间件实现中最关键的一部分，即红色线框圈出的代码。只要把 Load Balance 选出来的地址放到 RPC 元信息中就可以，其他代码可以直接忽视掉。\n性能 如果过多谈论框架的性能对比，容易引战。但是基于 Rust 语言的性能优势以及 CloudWeGo 团队对于极致性能的追求，我们可以预想到 Volo 的性能也是非常高的。\n如果把 Volo 和 Kitex 进行跨语言的对比也是不太公平的，但是因为很多用户都关注性能数据，为了让使用者对 Volo 框架的性能有大致的了解，我们只给出比较简单的性能数据。 在与 Kitex 相同的测试条件（限制 4C）下，Volo 极限 QPS 为 35W。同时，我们内部正在验证基于 Monoio（CloudWeGo 开源的 Rust Async Runtime）的版本，极限 QPS 可以达到 44W。\n当然还有很多其他的性能指标，比如响应时间也是非常影响用户体验的。所以除了 Benchmark，我们选取了由 Go 迁移到 Volo 框架的两个业务，呈现真实的业务落地收益。\n 业务 A（Proxy 类） 。A 业务的 IO 比较多，迁移到 Volo 框架后的各方面数据如下：   CPU Usage 630% -\u003e 380% MEM 9GB -\u003e 2GB P99 150-200ms -\u003e 20-35ms AVG 4-5ms -\u003e 1.5ms  可以看出不论是 CPU、内存还是延时的指标，都有非常明显的提升。下图中间红线代表 Volo 上线的时间，也就是红线左侧这一部分是 Go 的指标，红线右侧是 Rust 的指标，左右对比可以更直观看出 Volo 框架给业务 A 带来的收益。\n业务 B（有大量业务逻辑） 。业务 B 是一个计算密集型的业务，使用 Volo 框架后 CPU 400% -\u003e 130%。因此在计算密集型的业务中，CPU 的提升更加明显。  相关生态 随着 Volo 框架开源，一起开源的所有生态如下：\n Volo 是 RPC 框架的名字，包含了 Volo-Thrift 和 Volo-gRPC 两部分。 Volo-rs 组织 ：Volo 的相关生态。 Pilota ：Volo 使用的 Thrift 与 Protobuf 编译器及编解码的纯 Rust 实现（不依赖 protoc）。 Motore ：Volo 参考 Tower 设计的，使用了 GAT 和 TAIT 的 middleware 抽象层。 Metainfo ：Volo 用于进行元信息透传的组件，定义了一套元信息透传的标准。  全景图如下：\n仓库地址 以下是所有相关生态的仓库地址。欢迎大家来提 Issue 或 PR，一起共建 Volo！\n Volo：https://github.com/cloudwego/volo Volo-rs：https://github.com/volo-rs Pilota：https://github.com/cloudwego/pilota Motore：https://github.com/cloudwego/motore Metainfo：https://github.com/cloudwego/metainfo  Rust 语言和 Go 语言如何选择 了解 Volo 框架后，关于 Rust 语言和 Go 如何选择的问题，我有一些主观的建议和想法。\n和 C++、Go 对比 如果 Go 的服务想用另一种语言重写，目前还是 Rust 语言和 C++ 可选性高一些，因此我将这三种语言进行对比，以期为面临选择编程语言的用户提供一些参考。\n在学习难度方面，Rust 语言和 C++ 学习难度比较高，而 Go 语言的学习难度比较低。\n在性能方面，Rust 语言和 C++ 的性能比较高。我给 Go 语言的性能评级为中等，毕竟和 Python 这些服务相比，Go 语言还是要强很多的。\n在安全性方面，C++ 的安全性比较低，Go 语言安全性中等，Rust 语言安全性比较高。因为 Go 语言 虽然能够通过 GC 防住一些内存安全的问题，但是它没有办法防住类似 Data Race 这种并发安全的问题， 而且大多数时候这类问题其实很难排查。Rust 能够做到可防可控，应防尽防，只要有内存安全问题或并发安全问题，都无法成功编译。\n在协作方面，Rust 语言的协作能力比较高，Go 语言和 C++ 的协作等级是中等。首先，C++ 没有官方提供的包管理工具，它必须借助第三方社区提供的包管理工具，但是不同的项目使用的包管理工具可能是不一样的， 所以这是对用户来说非常不便的；其次，在开发者可以保证自己的代码没有 Bug、符合最佳实践的情况下，还是不可避免地会和一些第三方的库以及比较老旧社区一流的库产生交集，并且产生混用的情形； 最后，如果涉及到大型项目，需要团队协作开发，我们无法保证团队中其他人写出的代码也不存在内存安全问题。至于 Go 语言，它的编译时及工具链的能力相对来说比较弱，因此也定级为中等。\n在特性和使用成本方面，用户应该都有所了解，不再过多赘述。从使用成本上来讲，我的评级为给 C++ 为高使用成本，Go 语言和 Rust 语言的使用成本是中等。C++ 的业务上线之后经常出状况， 而且排查问题困难是很常见的情况。而使用 Go 语言做一些通用的编程是可以的，但是一旦涉及到定制化的需求在实现上就有一定的困难，比如需要根据不同的平台系统做系统级编程， 使用 Go 语言做起来就非常麻烦。语言只是工具，我们还是要根据不同的场景选用更为合适的语言。\n那么 Go 语言和 Rust 语言的使用成本为什么是中等呢？因为我们不能只关注编写代码的效率，还要考虑运维和 Debug 的成本。Go 语言可能也会产生 Panic，我们内部也经常会有一些并发的问题，然后需要不断地排查。 而 Rust 语言前置了这部分成本，相比于其他语言框架在上线之后测试、保证稳定性，我们把这部分的时间精力用在了开发期间，这样也避免了线上事故带来的损失。因此我给 Go 语言和 Rust 语言评定的使用成本是中等。\nRust \u0026 Go 如果将 Rust 语言和 Go 语言单独做对比，我们应该如何解读它们呢？这是一个非常经典的问题。可以尝试从以下四方面考虑：\n 合作关系，取长补短  我们团队认为其实二者并不是对立关系，而是合作关系，它们是取长补短的。毕竟语言只是工具，很多时候我们只是需要一个更加得心应手的工具而已。\n (性能 » 开发效率) || (安全性 » 开发效率) -\u003e Rust  对于需要极致性能，重计算的应用，以及需要稳定性并能接受一定开发速度损失的应用，推荐使用 Rust，Rust 在极致性能优化和安全性上的优势可以在这类应用中得以发挥。\n 迭代速度要求高 -\u003e Go  对于性能不敏感的应用、重 IO 的应用以及需要快速开发快速迭代胜过稳定性的应用，推荐使用 Go 语言，这种应用使用 Rust 并不会带来明显的收益。\n 考虑团队技术储备和人才储备  当然，还有一个很重要的考虑因素，是团队现有的技术栈，即技术储备和人才储备。\n小结 希望以上内容能让大家初步了解 Volo 以及相关的生态。目前 Volo 还处于早期发展阶段，欢迎各位感兴趣的同学加入我们，共同建设 CloudWeGo 以及 Rust 开源社区。 我们诚心期待更多开发者加入，也期待 Volo 能够助力越来越多的企业快速构建云原生架构。\n","categories":"","description":"本文介绍了 CloudWeGo-Volo 的起源、设计和实现，以及基于 Rust 语言的探索实践，包括 Go 的代价有哪些，Rust 的优势有哪些。","excerpt":"本文介绍了 CloudWeGo-Volo 的起源、设计和实现，以及基于 Rust 语言的探索实践，包括 Go 的代价有哪些，Rust 的优势 …","ref":"/zh/blog/2022/09/06/%E9%80%89%E6%8B%A9-go-%E8%BF%98%E6%98%AF-rustcloudwego-volo-%E5%9F%BA%E4%BA%8E-rust-%E8%AF%AD%E8%A8%80%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%AE%9E%E8%B7%B5/","tags":"","title":"选择 Go 还是 Rust？CloudWeGo-Volo 基于 Rust 语言的探索实践"},{"body":"Volo 是字节跳动服务框架团队研发的轻量级、高性能、 可扩展性强、易用性好的 Rust RPC 框架，使用了 Rust 最新的 GAT 和 TAIT 特性。\n在字节内部，Volo 已经落地多个业务和基础组件，并且取得了超预期的性能收益（与 Go 版本对比，不那么公平）。\nVolo 与其它 CloudWeGo 开源项目一样，坚持内外维护一套代码，为开源使用提供了强有力的保障。同时，我们观察到 Rust 开源社区在 RPC 框架这块还比较薄弱， Volo 的开源希望能为社区的完善贡献一份力量，同时也能完善 CloudWeGo 生态矩阵，为追求性能、安全性和最新技术的开发者、企业以及 Rustaceans 开发 RPC 微服务、搭建云原生分布式系统提供强有力的支持。\n本文会为大家简单介绍 Volo 及其相关生态，并为大家提供一个简单的 Rust 与 Go 的选型建议。\n01 项目缘起 其实 Volo 的创始成员来自于 Kitex 团队（CloudWeGo 开源的 Go RPC 框架），当时我们在 Go 上做了非常深度的性能优化，也因此深刻感受到了在 Go 上做性能优化所面临的阻碍。 因此，我们选择了 Rust，期望能够给需求极致性能、安全和指令级掌控能力的业务一个合适的选择。而 RPC 框架是分布式系统中重要的组成部分，Volo 就这么诞生了。\n02 特性 高性能 Rust 以高性能和安全著称，我们在设计和实现过程中也时刻以高性能作为我们的目标，尽可能降低每一处的开销，提升每一处实现的性能。\n首先要说明，和 Go 的框架对比性能是极不公平的，因此我们不会着重比较 Volo 和 Kitex 的性能，并且我们给出的数据仅能作为参考，希望大家能够客观看待。 同时，由于在开源社区并没有找到另一款成熟的 Rust 语言的 Async 版本 Thrift RPC 框架，而且性能对比总是容易引战，因此我们希望尽可能弱化性能数据的对比，仅会公布我们自己极限 QPS 的数据。\n在和 Kitex 相同的测试条件（限制 4C）下，Volo 极限 QPS 为 35W。同时，我们内部正在验证基于 Monoio（CloudWeGo 开源的 Rust Async Runtime）的版本，极限 QPS 可以达到 44W。\n从我们线上业务的火焰图来看，得益于 Rust 的静态分发和优秀的编译优化，框架部分的开销基本可以忽略不计（不包含 syscall 开销）。\n基于 GAT 设计 我们热爱并追随最新的技术，Volo 的核心抽象使用了 Rust 最新的 GAT 特性，在这个过程中我们也借鉴了 Tower 的设计。Tower 是一个非常优秀的抽象层设计，适用于非 GAT 的情况下。在此我们非常感谢 Tower 团队。\nTower：https://github.com/tower-rs/tower\n通过 GAT，我们可以避免很多不必要的 Box 内存分配，以及提升易用性，给用户提供更友好的编程接口和更符合人体工程学的编程范式。\n我们的核心抽象如下：\n由于使用了 Rust 的 GAT 特性，因此我们可以解决返回异步 Future 带来的生命周期问题。同时，如果配合 type_alias_impl_trait 使用，效果更佳，比如实现 Timeout 可以使用如下方式：\n易用性好 Rust 以难学难用而闻名，我们希望尽可能降低用户使用 Volo 框架以及使用 Rust 语言编写微服务的难度，提供最符合人体工程学和直觉的编码体验。因此，我们把易用性作为我们重要的目标之一。\n比如，我们提供了 Volo 命令行工具，用于初始化项目以及管理 IDL。同时，我们将 Thrift 及 gRPC 拆分为两个独立（但共用一些组件）的框架，以提供最符合不同协议语义的编程范式及接口。\n我们还提供了 #[service] 宏（可以理解为不需要 Box 的 async_trait）来使得用户可以无心理负担地使用异步来编写 Service 中间件。\n通过这个宏，我们编写 Service 中间件可以简化到如下图：\n扩展性强 受益于 Rust 强大的表达和抽象能力，通过灵活的中间件 Service 抽象，开发者可以以非常统一的形式，对 RPC 元信息、请求和响应做处理。\n比如，服务发现、负载均衡等服务治理功能，都可以以 Service 形式进行实现，而不需要独立实现 Trait。\n相关的扩展，我们会放在 github.com/volo-rs 组织下，也欢迎大家贡献自己的扩展到 volo-rs。\n03 生态系统 Volo 是 RPC 框架的名字，随着 Volo 一起开源的有以下几个项目：\n Volo-rs：Volo 的相关生态。 Pilota：Volo 使用的 Thrift 与 Protobuf 编译器及编解码的纯 Rust 实现（不依赖 protoc）。 Motore：Volo 参考 Tower 设计的、使用了 GAT 和 TAIT 的 middleware 抽象层。 Metainfo：Volo 用于进行元信息透传的组件，期望定义一套元信息透传的标准。  04 选型建议 “什么情况下应该用 Rust、什么情况下应该用 Go？”这是一个非常经典的问题。在 Volo 团队看来，Rust 和 Go 并不是对立关系，而是合作关系，取长补短。\n对于性能不敏感的应用、重 IO 的应用以及需要快速开发快速迭代胜过稳定性的应用，推荐使用 Go，这种应用使用 Rust 并不会带来明显的收益。\n对于 需要极致性能，重计算的应用，以及需要稳定性并能接受一定开发速度损失的应用，推荐使用 Rust，Rust 在极致性能优化和安全性上的优势可以在这类应用中得以发挥。\n当然，还有一个很重要的考虑因素，是团队现有的技术栈，即技术储备和人才储备。\n05 总结 希望本文能让大家对于 Volo 及相关生态有一个基本的了解。同时，Volo 还处于早期阶段，欢迎各位感兴趣的同学一起加入，共同建设 CloudWeGo 及 Rust 开源社区，向 Volo 提交 Issue 和 PR 一起来共建。 我们诚心期待更多的开发者加入，也期待 Volo 助力越来越多的企业快速构建云原生架构。如果企业客户想内部试用，我们可以排期提供专项技术支持和交流。\n参考资料   Volo 概览: https://github.com/cloudwego/volo\n  Volo Tutorial: https://www.cloudwego.io/zh/docs/volo/\n  Volo 文档: https://docs.rs/volo\n  Volo-rs 组织: https://github.com/volo-rs\n  ","categories":"","description":"本文介绍了字节跳动正式开源 Rust RPC 框架 — Volo，并着重介绍了项目的起源，主要特性以及相关生态。","excerpt":"本文介绍了字节跳动正式开源 Rust RPC 框架 — Volo，并着重介绍了项目的起源，主要特性以及相关生态。","ref":"/zh/blog/2022/08/30/%E5%9B%BD%E5%86%85%E9%A6%96%E4%B8%AA%E5%9F%BA%E4%BA%8E-rust-%E8%AF%AD%E8%A8%80%E7%9A%84-rpc-%E6%A1%86%E6%9E%B6-volo-%E6%AD%A3%E5%BC%8F%E5%BC%80%E6%BA%90/","tags":"","title":"国内首个基于 Rust 语言的 RPC 框架 — Volo 正式开源！"},{"body":"Feature  [#182] feat: add service registration \u0026 service discovery \u0026 load balancing. [#6] feat: add zookeeper register. [#7] feat: add nacos registry. [#8] feat: Support Hertz to use Consul for service discovery and registration. [#9] feat: add polaris registry. [#14] feat: add etcd registry. [#15] feat: support servicecomb. [#16] feat: support service registration and discovery with Netflix Eureka.  Refactor  [#175] refactor: distinguish between global dialer and local dialer.  Optimize  [#205] optimize: func checkPathValid returns true if the path is valid.  Test  [#174] test: correcting TestRouterMiddlewareAndStatic.  Fix  [#190] fix: modify the same middleware name. [#192] fix: fix the problem of the same package name in handler. [#208] fix: deregister failed when service shutdown. [#202] fix: get wrong local loopback IPv6. [#196] fix: typo. [#155] fix: name_style_thrift. [#169] fix: thrift namespace. [#184] fix: hijack conn throw timeout err when using standard network lib. [#162] fix: generate router register error.  Chore  [#189] Revert “fix: generate router register error”. [#203] add v6 support for AddMissingPort function. [#186] chore: support codecov.  ","categories":"","description":"","excerpt":"Feature  [#182] feat: add service registration \u0026 service discovery \u0026 …","ref":"/blog/2022/08/29/hertz-release-v0.3.0/","tags":"","title":"Hertz Release v0.3.0"},{"body":"Feature  [#182] feat: 添加服务注册 \u0026 服务发现 \u0026 负载均衡。 [#6] feat: 添加 zookeeper 服务注册与发现的扩展。 [#7] feat: 添加 nacos 服务注册与发现的扩展。 [#8] feat: 添加 Consul 服务注册与发现的扩展。 [#9] feat: 添加 polaris 服务注册与发现的扩展。 [#14] feat: 添加 etcd 服务注册与发现的扩展。 [#15] feat: 添加 servicecomb 服务注册与发现的扩展。 [#16] feat: 添加 eureka 服务注册与发现的扩展。  Refactor  [#175] refactor: 区别全局默认 dialer 和 client 局部 dialer（指定了 dialer 的 client 不再受全局 dialer 改变而改变）修改全局 dialer 影响面较大，标记 deprecated，后续统一到 client 初始化时传参指定 dialer 方式修改局部 dialer，以及移除了功能完全被 dialer 覆盖的 dialFunc 扩展。  Optimize  [#205] optimize: 更改默认返回值。  Test  [#174] test: 修正 TestRouterMiddlewareAndStatic 单测。  Fix  [#190] fix: 修改同名的路由组。 [#192] fix: 修复 handler 中的引用相同包名的问题，并把获取 unique 变量名的方法单独提出来。 [#208] fix: 当服务停止时修复取消注册失败。 [#202] fix: 获取到了错误的 IPv6 本地回环地址。 [#196] fix: 修复 typo。 [#155] fix: 修复thrift的命名方式，struct name 与 thriftgo 的 namestyle 保持一致。 [#169] fix: 修复 thrift 的 namespace 尾缀包含\".thrift\"的问题。 [#184] fix: 修复使用标准网络库劫持连接时的超时错误。 [#162] fix: 修复 IDL 中定义的路由最后一级为\"/“时的报错。  Chore  [#189] 回滚 cloudwego/hertz#162 的修改。 [#203] AddMissingPort 函数增加对裸 v6 地址的处理。 [#186] 支持 codecov。  ","categories":"","description":"","excerpt":"Feature  [#182] feat: 添加服务注册 \u0026 服务发现 \u0026 负载均衡。 [#6] feat: 添加 zookeeper 服务 …","ref":"/zh/blog/2022/08/29/hertz-v0.3.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Hertz v0.3.0 版本发布"},{"body":"Introduction to Key Changes Feature  Retry enhancement: Support user-defined result retry; Support request-level configuration (priority is higher than Neptune). See retry guide for details Frugal (Thrift): Support default value of IDL; No codec code is supported by using frugal. See frugal for details Tool-Protobuf: Support depend on external libraries with go_package, see Notes for Using Protobuf IDLs; Support Guess IDL type from the file extension, it is unnecessary to specify the type param when generating the protobuf code Fastpb(protobuf): Support fastpb to optimize performance of protobuf, and it is integrated into Kite by default. See fastpb for details Generic Call: Support HTTP+Protobuf generic call Kitex lib supports Windows: You can use kitex running on Windows (Kitex tool still doesn’t support)  Optimization \u0026 Bugfix  Performance Optimization: gRPC unary throughput increased by 46-70%, and 51% - 70% higher than the official gRPC framework throughput. See benchmark for details Generic Call: Support default value defined in thrift IDL for HTTP / Map / JSON Generic   Full Release Log Feature  [#571] feat(protobuf): integrate fastpb into kitex, refer to doc. [#592] feat(generic): add default value defined in thrift idl for HTTP/Map/JSON generic call. [#600] feat(thrift): support no codec gen-code when using frugal. [#607, #610] feat(proxyless): add option for xDS extension. Support traffic route, timeout config and service discovery based on xDS. [#541] feat(trans): Add the go net extension to the transport layer, and choose it as the transmission mode by default in Windows OS. [#540] feat(retry): support retry with specified error or response and add retry option for setup method retry policy. [#533] feat(generic): js_conv annotation of generic call supports map type conversion.  Optimize  [#522, #538, #605] perf(grpc): optimize performance for gRPC protocol. [#590] optimize(tool): guess IDL type from file extension. [#559] optimize(timeout): use wrap func to check timeout err in timeout middleware which can ignore logs customized timeout err. [#581] optimize(tool): kitex tool usage add cmd example.  Bugfix  [#564] fix(oneway): discard oneway conn after sending complete, or subsequent requests that send to the same connection may get blocked until the oneway request gets processed by the server. [#577, #584, #602] fix(rpcinfo): fix rpcinfo reuse problem in longconn scene. [#578] fix: fix long pool dump panic. [#583] fix(tool): fix misusing of package name in protobuf generated code. [#587] fix(tool): skip proto files with external import paths when generates code. [#594] fix(generic): support the tag format of the escape double quotes in single quotes to be compatible with the logic of the old version. [#595] fix: fix nil union panic in BLength. [#589, #596] fix(frugal): fix frugal build tag.  Refactor  [#566] refactor(metainfo): remove noused metakeys of HTTP2 Header. [#593] refactor(trans): support specify Listener for server by option WithListener, the priority is higher than WithServiceAddr. [#582] refactor(tool): use templates by embedding and export APIs for external usage for kitex tool.  Test  [#579] test: add ut for long pool dump function. [#608] test: fix data race in TestClientConnDecoupledFromApplicationRead. [#609] test: fix gonet ut avoid testing port conflicts. [#480] test: add unit test for client package.  Chore  [#558] ci: fix setup-python github action. [#487] ci: workflow add golangci-lint. [#580] chore: fix the typos in remote module about go net. [#601] chore: fixed some typos and replaced some defunct functions. [#604] chore: upgrade fastpb to v0.0.2. [#603] chore: upgrade frugal to v0.1.2.  Dependency Change github.com/cloudwego/frugal v0.1.1 -\u003e v0.1.3\ngithub.com/cloudwego/netpoll v0.2.5 -\u003e v0.2.6\ngithub.com/cloudwego/thriftgo v0.1.2 -\u003e v0.2.0\ngoogle.golang.org/protobuf v1.26.0 -\u003e v1.28.0\ngithub.com/choleraehyq/pid v0.0.13 -\u003e v0.0.15\nnew imported:\ngithub.com/cloudwego/fastpb v0.0.2\ngithub.com/jhump/protoreflect v1.8.2\n","categories":"","description":"","excerpt":"Introduction to Key Changes Feature  Retry enhancement: Support …","ref":"/blog/2022/08/26/kitex-release-v0.4.0/","tags":"","title":"Kitex Release v0.4.0"},{"body":"重要变更介绍 功能  重试功能增强：支持自定义结果重试；支持请求粒度配置重试，详见 重试指南 Frugal(thrift): 支持了 IDL 默认值；使用 Frugal 可以支持不生成编解码代码，详见 frugal Tool-Protobuf：结合 go_package 配置支持依赖外部库，详见 protobuf IDL 的注意事项；支持从文件扩展名猜测 IDL 的类型，生成 proto 代码时无需再指定 type 参数 Fastpb(protobuf): 支持 fastpb 优化 pb 编解码，并默认集成到 Kitex，详见 fastpb 泛化调用：支持 HTTP+Protobuf 泛化调用 Kitex 依赖库支持 Windows：便于 Windows 环境运行（工具暂未支持）  优化和修复  性能优化：gRPC Unary 吞吐提升 46-70%，相比官方 gRPC 吞吐高 51%-70%，详见 benchmark  泛化调用：HTTP / Map / JSON 泛化调用支持了 Thrift 默认值   详细变更 Feature  [#571] 功能(protobuf): 默认集成 fastpb 到 Kitex，详情参考 doc。 [#592] 功能(generic): HTTP/Map/JSON 泛化调用支持 Thrift 默认值。 [#600] 功能(thrift): 支持当使用 frugal 时不生成编解码代码。 [#607, #610] 功能(proxyless): 提供 xDS 扩展的接口。支持基于 xDS 的流量路由，超时配置及服务发现。 [#541] 功能(trans): 传输层增加 go net 作为扩展，并在 Windows OS 下作为默认网络库。 [#540] 功能(retry): Retry 支持指定 error 或 resp 重试，同时新增 option 用来支持为方法设置重试策略。 [#533] 功能(generic): 泛化调用 js_conv 注解支持 map 类型转换。  Optimize  [#522, #538, #605] 优化(grpc): 优化 gRPC 协议性能。 [#590] 优化(tool): 支持从文件扩展名猜测 IDL 的类型。 [#559] 优化(timeout): 在超时中间件中使用超时封装方法判断底层超时，用来忽略一些定制超时错误日志。 [#581] 优化(tool): Kitex 命令增加使用示例。  Bugfix  [#564] 修复(oneway): 当 oneway 请求发送完毕后，关闭对应的连接，否则后续的发送到该连接上的请求会被阻塞在 server 端，直到 server 端把上一个 oneway 请求处理完。 [#577, #584, #602] 修复(rpcinfo): 修复长连接场景下 rpcinfo 复用问题。 [#578] 修复: 修复 long pool dump 可能导致 panic 的问题。 [#583] 修复(tool): 修复 protobuf 生成代码引用了错误的 package 名字的问题 [#587] 修复(tool): 生成代码的时候跳过指定了外部 import path 的 proto 文件。 [#594] 修复(generic): 泛化调用支持单引号中双引号带转义符的 tag 格式以兼容旧版本逻辑。 [#595] 修复: 修复 union 为 nil 时 BLength 会 panic 的问题。 [#589, #596] 修复(frugal): 修复 frugal build tag。  Refactor  [#566] refactor(metainfo): 移除 HTTP2 header 中没有使用的 meta keys。 [#593] refactor(trans): 服务端支持通过 WithListener 配置 listener，其优先级高于 WithServiceAddr。 [#582] refactor(tool): kitex 工具以文件嵌入方式使用模板并导出部分 API 供外部使用。  Test  [#579] test: 长连接池 dump 增加单测。 [#608] test: 修复 TestClientConnDecoupledFromApplicationRead 的 data race 问题。 [#609] test: 修复 gonet 单测中的端口冲突问题。 [#480] test: 给 client package 增加单测。  Chore  [#558] ci: 修复 ci 中 setup-python 的问题。 [#487] ci: Workflow 中增加 golangci-lint。 [#580] chore: 修复 remote 模块中 go net 相关的错误拼写。 [#601] chore: 修复错误拼写并替换掉一些功能重复的代码。 [#604] chore: 升级 fastpb 到 v0.0.2。 [#603] chore: 升级 frugal 到 v0.1.2。  Dependency Change github.com/cloudwego/frugal v0.1.1 -\u003e v0.1.3\ngithub.com/cloudwego/netpoll v0.2.5 -\u003e v0.2.6\ngithub.com/cloudwego/thriftgo v0.1.2 -\u003e v0.2.0\ngoogle.golang.org/protobuf v1.26.0 -\u003e v1.28.0\ngithub.com/choleraehyq/pid v0.0.13 -\u003e v0.0.15\n新增\ngithub.com/cloudwego/fastpb v0.0.2\ngithub.com/jhump/protoreflect v1.8.2\n","categories":"","description":"","excerpt":"重要变更介绍 功能  重试功能增强：支持自定义结果重试；支持请求粒度配置重试，详见 重试指南 Frugal(thrift): 支持了 IDL …","ref":"/zh/blog/2022/08/26/kitex-v0.4.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.4.0 版本发布"},{"body":"Feature  [#124] feat: add option to remove hijackConnPool. [#116] feat: update for template. [#130] feat: add a warning log for invalid character in Cookie.Value. [#143] feat: custom signal to graceful shutdown [#114] feat: release buffer in standard network method. [#112] feat: parse post args in bodystream. [#105] feat: client abstracts hostclient layer. [#92] feat: hz support windows. [#102] feat: client removes default retry logic.  Optimize  [#111] optimize: pre-allocate slice when calling bytesconv.AppendHTTPDate. [#128] optimize: remove useless judgement. [#108] optimize: avoid parsing regular expression repeatedly.  Chore  [#125] Update pr-check.yml.  Fix  [#104] fix: use defer to guarantee that mutex will be unlocked. [#96] fix: ci exec /bin/license-eye: exec format error  Style  [#103] style: fixed the typo “ungzipped” to “gunzipped”. [#90] style: use const var and remove duplicate type conversions.  Refactor  [#94] refactor: use appendCookiePart to simplify code.  Docs  [#97] docs: use comma to separate \u0026\u0026 remove extra space.  ","categories":"","description":"","excerpt":"Feature  [#124] feat: add option to remove hijackConnPool. [#116] …","ref":"/blog/2022/07/22/hertz-release-v0.2.0/","tags":"","title":"Hertz Release v0.2.0"},{"body":"Feature  [#124] feat: 增加参数控制是否使用 hijackConnPool。 [#116] feat: update 也可使用模板更新 handler 及 middleware。 [#130] feat: 如果 Cookie.Value 中存在非法字符，则打印告警日志。 [#143] feat: 增加一个接口支持自定义信号捕捉逻辑，以便根据场景调节优雅退出需要应对的信号类型。 [#114] feat: 标准网络库 Read 方法中调用 connection.Release()，防止在多次少量调用 Read 方法时不回收内存导致的 OOM。 [#112] feat: 修正了 x-www-form-urlencoded 编码下无法读到 bodystream 类型数据。 [#105] feat: client 为 ALPN 和 http2 抽象出协议层 HostClient。client 删除 readbuffersize 和 writebuffersize 配置项。 [#92] feat: hz 命名行工具支持 windows。 [#102] feat: Hertz client 关闭默认的重试逻辑。  Optimize  [#111] optimize: 调用 bytesconv.AppendHTTPDate 时，为切片预分配容量，以防止产生额外的拷贝。 [#128] optimize: 去掉路由树中无用逻辑。 [#108] optimize: 通过提前调用 regexp.MustCompile，避免程序重复解析正则表达式。  Chore  [#125] chore: 更新 license check 方式。  Fix  [#104] fix: cacheLock 可能会因潜在发生的 panic 导致解锁失败。 [#96] fix: ci 可能被调度到 arm 机器上导致报错 exec format error。  Style  [#103] style: 修正不符合语义的错误拼写 “Ungzipped”。 [#90] style: 常量替换和去掉了重复的类型转换。  Refactor  [#94] refactor: 使用 appendCookiePart 函数简化代码。  Docs  [#97] docs: 文档标点符号优化。  ","categories":"","description":"","excerpt":"Feature  [#124] feat: 增加参数控制是否使用 hijackConnPool。 [#116] feat: update 也 …","ref":"/zh/blog/2022/07/22/hertz-v0.2.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Hertz v0.2.0 版本发布"},{"body":"01 前言 Hertz 是字节跳动服务框架团队研发的超大规模的企业级微服务 HTTP 框架，具有高易用性、易扩展、低时延等特点。在经过了字节跳动内部一年多的使用和迭代后，如今已在 CloudWeGo 正式开源。 目前，Hertz 已经成为了字节跳动内部最大的 HTTP 框架，线上接入的服务数量超过 1 万，峰值 QPS 超过 4 千万。除了各个业务线的同学使用外，也服务于内部很多基础组件， 如：函数计算平台 FaaS、压测平台、各类网关、Service Mesh 控制面等，均收到不错的使用反馈。在如此大规模的场景下，Hertz 拥有极强的稳定性和性能，在内部实践中某些典型服务， 如框架占比较高的服务、网关等服务，迁移 Hertz 后相比 Gin 框架，资源使用显著减少，CPU 使用率随流量大小降低 30%—60%，时延也有明显降低。\nHertz 坚持 内外维护一套代码 ，为开源使用提供了强有力的保障。通过开源， Hertz 也将丰富云原生的 Golang 中间件体系，完善 CloudWeGo 生态矩阵， 为更多开发者和企业搭建云原生化的大规模分布式系统，提供一种现代的、资源高效的的技术方案。\n本文将重点关注 Hertz 的架构设计与 功能特性 。\n02 项目缘起 最初，字节跳动内部的 HTTP 框架是对 Gin 框架的封装，具备不错的易用性、生态完善等优点。随着内部业务的不断发展，高性能、多场景的需求日渐强烈。 而 Gin 是对 Golang 原生 net/http 进行的二次开发，在按需扩展和性能优化上受到很大局限。因此，为了满足业务需求，更好的服务各大业务线， 2020 年初，字节跳动服务框架团队经过内部使用场景和外部主流开源 HTTP 框架 Fasthttp、Gin、Echo 的调研后，开始基于自研网络库 Netpoll 开发内部框架 Hertz， 让 Hertz 在面对企业级需求时，有更好的性能及稳定性表现，也能够满足业务发展和应对不断演进的技术需求。\n03 架构设计 Hertz 设计之初调研了大量业界优秀的 HTTP 框架，同时参考了近年来内部实践中积累的经验。为了保证框架整体上满足：1. 极致性能优化的可能性；2. 面对未来不可控需求的扩展能力， Hertz 采用了 4 层分层设计，保证各个层级功能内聚，同时通过层级之间的接口达到灵活扩展的目标。整体架构图如图 1 所示。\n图1 Hertz 架构图 Hertz 从上到下分为：应用层、路由层、协议层和传输层，每一层各司其职，同时公共能力被统一抽象到公共层（Common），做到跨层级复用。 另外，同主库一同发布的还有作为子模块的 Hz 脚手架，它能够协助使用者快速搭建出项目核心骨架以及提供实用的构建工具链。\n应用层 应用层是和用户直接交互的一层，提供丰富易用的 API，主要包括 Server、Client 和一些其他通用抽象。Server 提供了注册 HandlerFunc、Binding、Rendering 等能力；Client 提供了调用下游和服务发现等能力； 以及抽象一个 HTTP 请求所必须涉及到的请求（Request）、响应（Response）、上下文（RequestContext）、中间件（Middleware）等等。 Hertz 的 Server 和 Client 都能够提供中间件这样的扩展能力。\n应用层中一个非常重要的抽象就是对 Server HandlerFunc 的抽象。早期，Hertz 路由的处理函数 （HandlerFunc）中并没有接收标准的 context.Context，我们在大量的实践过程中发现， 业务方通常需要一个标准的上下文在 RPC Client 或者日志、Tracing 等组件间传递，但由于请求上下文（RequestContext）生命周期局限于一次 HTTP 请求之内，而以上提到的场景往往存在异步的传递和处理， 导致如果直接传递请求上下文，会导致出现一些数据不一致的问题。为此我们做了诸多尝试，但是因为核心原因在于请求上下文（RequestContext）的生命周期无法优雅的按需延长， 最终在各种设计权衡下，我们在路由的处理函数签名中增加一个标准的上下文入参，通过分离出生命周期长短各异的两个上下文的方式，从根本上解决各种因为上下文生命周期不一致导致的异常问题，即：\n路由层 路由层负责根据 URI 匹配对应的处理函数。\n起初，Hertz 的路由基于 httprouter 开发，但随着使用的用户越来越多，httprouter 渐渐不能够满足需求，主要体现在 httprouter 不能够同时注册静态路由和参数路由， 即 /a/b， /:c/d 这两个路由不能够同时注册；甚至有一些更特殊的需求，如 /a/b、/:c/b ，当匹配 /a/b 路由时，两个路由都能够匹配上。\nHertz 为满足这些需求重新构造了路由树，用户在注册路由时拥有很高的自由度：支持静态路由、参数路由的注册；支持按优先级匹配，如上述例子会优先匹配静态路由 /a/b；支持路由回溯， 如注册 /a/b、/:c/d，当匹配 /a/d 时仍然能够匹配上；支持尾斜线重定向，如注册 /a/b，当匹配 /a/b/ 时能够重定向到 /a/b 上。 Hertz 提供了丰富的路由能力来满足用户的需求，更多的功能可以参考 Hertz 配置文档。\n协议层 协议层负责不同协议的实现和扩展。\nHertz 支持协议的扩展，用户只需要实现下面的接口便可以按照自己的需求在引擎（Engine）上扩展协议， 同时也支持通过 ALPN 协议协商的方式注册。Hertz 首批只开源了 HTTP1 实现，未来会陆续开源 HTTP2、QUIC 等实现。 协议层扩展提供的灵活性甚至可以超越 HTTP 协议的范畴，用户完全可以按需注册任意符合自身需求的协议层实现，并且加入到 Hertz 的引擎中来，同时，也能够无缝享受到传输层带来的极致性能。\n传输层 传输层负责底层的网络库的抽象和实现。\nHertz 支持底层网络库的扩展。Hertz 原生完美适配 Netpoll，在时延方面有很多深度的优化，非常适合时延敏感的业务接入。Netpoll 对 TLS 能力的支持有待完善，而 TLS 能力又是 HTTP 框架必备能力， 为此 Hertz 底层同时支持基于 Golang 标准网络库的实现适配，同时支持网络库的一键切换，用户可根据自己的需求选择合适的网络库进行替换。如果用户有更加高效的网络库或其他网络库需求，也完全可以根据需求自行扩展。\n网络库的扩展： https://www.cloudwego.io/zh/docs/hertz/tutorials/framework-exten/advanced-exten/network-lib/\nHz 脚手架 与 Hertz 一并开源的还有一个易用的命令行工具 Hz，用户只需提供一个 IDL，根据定义好的接口信息，Hz 便可以一键生成项目脚手架，让 Hertz 达到开箱即用的状态； Hz 也支持基于 IDL 的更新能力，能够基于 IDL 变动智能地更新项目代码。目前 Hz 支持了 Thrift 和 Protobuf 两种 IDL 定义。命令行工具内置丰富的选项，可以根据自己的需求使用。 同时它底层依赖 Protobuf 官方的编译器和自研的 Thriftgo 的编译器，两者都支持自定义的生成代码插件。如果默认模板不能够满足需求，完全能够按需定义。\n未来，我们将继续迭代 Hz，持续集成各种常用的中间件，提供更高层面的模块化构建能力。给 Hertz 的用户提供按需调整的能力，通过灵活的自定义配置打造一套满足自身开发需求的脚手架。\nCommon 组件 Common 组件主要存放一些公共的能力，比如错误处理、单元测试能力、可观测性相关能力（Log、Trace、Metrics 等）。对于服务可观测性的能力，Hertz 提供了默认的实现，用户可以按需装配； 如果用户有特殊的需求，也可以通过 Hertz 提供的接口注入。比如对于 Trace 能力，Hertz 提供了默认的实现，也提供了将 Hertz 和 Kitex 串起来的 Example。如果想注入自己的实现，也可以实现下面的接口：\nExample： https://github.com/cloudwego/hertz-examples/blob/main/tracer/README.md\n04 功能特性 中间件 Hertz 除了提供 Server 的中间件能力，还提供了 Client 中间件能力。用户可以使用中间件能力将通用逻辑（如：日志记录、性能统计、异常处理、鉴权逻辑等等）和业务逻辑区分开，让用户更加专注于业务代码。 Server 和 Client 中间件使用方式相同，使用 Use 方法注册中间件，中间件执行顺序和注册顺序相同，同时支持预处理和后处理逻辑。\nServer 和 Client 的中间件实现方式并不相同。对于 Server 来说，我们希望减少栈的深度，同时也希望中间件能够默认的执行下一个，用户需要手动终止中间件的执行。 因此，我们将 Server 的中间件分成了两种类型，即不在同一个函数调用栈（该中间件调用完后返回，由上一个中间件调用下一个中间件，如图 2 中 B 和 C）和在同一个函数调用栈的中间件（该中间件调用完后由该中间件继续调用下一个中间件，如图 2 中 C 和 Business Handler）。\n图2 中间件链路 其核心是需要一个地方存下当前的调用位置 index，并始终保持其递增。恰好 RequestContext 就是一个存储 index 合适的位置。 但是对于 Client，由于没有合适的地方存储 index，我们只能退而求其次，抛弃 index 的实现，将所有的中间件构造在同一调用链上，需要用户手动调用下一个中间件。\n流式处理 Hertz 提供 Server 和 Client 的流式处理能力。HTTP 的文件场景是十分常见的场景，除了 Server 侧的上传场景之外，Client 的下载场景也十分常见。 为此，Hertz 支持了 Server 和 Client 的流式处理。在内部网关场景中，从 Gin 迁移到 Hertz 后，CPU 使用量随流量大小不同可节省 30%—60% 不等，服务压力越大，收益越大。 Hertz 开启流式功能的方式也很容易，只需要在 Server 上或 Client 上添加一个配置即可，可参考 CloudWeGo 官网 Hertz 文档的流式处理部分。\n由于 Netpoll 采用 LT 的触发模式，由网络库主动将将数据从 TCP 缓冲区读到用户态，并存储到 buffer 中，否则 epoll 事件会持续触发。 因此 Server 在超大请求的场景下，由于 Netpoll 持续将数据读到用户态内存中，可能会有 OOM 的风险。HTTP 文件上传场景就是一个典型的场景，但 HTTP 上传服务又是很常见的场景， 因此我们支持标准网络库 go net，并针对 Hertz 做了特殊优化，暴露出 Read() 接口，防止 OOM 发生。\n对于 Client，情况并不相同。流式场景下会将连接封装成 Reader 暴露给用户，而Client 有连接池管理，那这样连接就多了一种状态，何时关连接，何时复用连接成了一个问题。 由于框架侧并不知道该连接何时会用完，框架侧复用该连接不现实，会导致串包问题。由于 GC 会关闭连接，因此我们起初设想流式场景下的连接交由用户后，由 GC 负责关闭，这样也不会导致资源泄漏。 但是在测试后发现，由于 GC 存在一定时间间隔，另外 TCP 中主动关闭连接的一方需要等待 2RTT，在高并发场景下会导致 fd 被打满的情况。 最终我们提供了复用连接的接口，对于性能有场要求用户，在使用完连接后可以将连接重新放入连接池中复用。\n05 性能表现 Hertz 使用字节跳动自研高性能网络库 Netpoll，在提高网络库效率方面有诸多实践，参考已发布文章 字节跳动在 Go 网络库上的实践 。 除此之外，Netpoll 还针对 HTTP 场景进行优化，通过减少拷贝和系统调用次数提高吞吐以及降低时延。为了衡量 Hertz 性能指标，我们选取了社区中有代表性的框架 Gin（net/http）和 Fasthttp 作为对比，如图3所示。 可以看到，Hertz 的极限吞吐、TP99 等指标均处于业界领先水平。未来，Hertz 还将继续和 Netpoll 深度配合，探索 HTTP 框架性能的极限。\n图3 Hertz 和其他框架性能对比 06 一个Demo 下面简单演示一下 Hertz 是如何开发一个服务的。\n 首先，定义 IDL，这里使用 Thrift 作为 IDL 的定义（也支持使用 Protobuf 定义的 IDL），编写一个名为 Demo 的 service。这个服务有一个 API: Hello，它的请求参数是一个 query，响应是一个包含一个 RespBody 字段的 Json。  接下来我们使用 Hz 生成代码，并整理和拉取依赖。  填充业务逻辑，比如我们返回 hello，${Name}，那我们在 biz/handler/example/hello_service.go 中添加以下代码即可。  编译并运行项目。  到现在一个简单的 Hertz 项目已经生成，下面我们来测试一下。\n以上 Demo 可以在 Hertz-Examples 中查看，之后就可以愉快地构建自己的项目了。\n07 后记 希望以上的分享能够让大家对 Hertz 有一个整体上的认识。同时，我们也在不断地迭代 Hertz、完善CloudWeGo 整体生态。欢迎各位感兴趣的同学们加入我们，共同建设 CloudWeGo。\n08 参考资料 Hertz Doc：https://www.cloudwego.io/zh/docs/hertz/\n官网文章：字节跳动在 Go 网络库上的实践 \n","categories":"","description":"本文介绍了字节跳动开源 Go HTTP 框架 Hertz 的项目起源、架构设计、功能特性以及性能表现。","excerpt":"本文介绍了字节跳动开源 Go HTTP 框架 Hertz 的项目起源、架构设计、功能特性以及性能表现。","ref":"/zh/blog/2022/06/21/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%BC%80%E6%BA%90-go-http-%E6%A1%86%E6%9E%B6-hertz-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E8%B7%B5/","tags":"","title":"字节跳动开源 Go HTTP 框架 Hertz 设计实践"},{"body":"今天，经过了字节跳动内部一年多的使用和迭代，高性能企业级 HTTP 框架—— Hertz，已在 CloudWeGo 正式开源啦！Hertz 已经成为了字节跳动内部最大的 HTTP 框架，线上接入的服务数量超过 1 万， 峰值 QPS 超过 4 千万，具有 高易用性 、 易扩展 、低时延的特点。对于字节跳动服务框架团队和 CloudWeGo 而言，Hertz 将不仅仅是一个开源项目，它也是一个真实的超大规模企业级实践。\n项目地址：https://github.com/cloudwego/hertz\n未来，字节跳动基础架构团队将以 Hertz 开源库为主进行迭代，坚持内外维护一套代码，统一进行迭代演进，为用户提供更好的体验。\n01 Hertz 概述 Hertz 是一个超大规模的企业级微服务 HTTP 框架，具有高易用性、易扩展、低时延等特点。最初，字节跳动内部的 HTTP 框架是对 Gin 框架的封装，具备不错的易用性、生态完善等优点。 随着内部业务的不断发展，对高性能、多场景的需求日渐强烈。而 Gin 是对 Golang 原生 net/http 进行的二次开发，在按需扩展和性能优化上受到很大局限。 因此，为了满足业务需求，更好的服务各大业务线，2020 年初，字节跳动服务框架团队经过内部对使用场景和外部主流开源 HTTP 框架 Fasthttp、Gin、Echo 的调研后， 开始基于自研网络库 Netpoll 开发内部框架 Hertz，让 Hertz 在面对企业级需求时，有更好的性能及稳定性表现，也能够满足业务发展和应对不断演进的技术需求。 2021 年 7 月，Hertz 正式上线 1.0 版本。\n在经历了字节跳动内部一年多的使用后，Hertz 框架成为了字节跳动内部最大的 HTTP 框架，线上接入的服务数量超过 1 万，峰值 QPS 超过 4 千万。 Hertz 除了业务线的同学使用外，也服务于内部很多基础组件，如：函数计算平台 FaaS、压测平台、各类网关、Service Mesh 控制面等，均收到不错的使用反馈。 在如此大规模的场景下，Hertz 拥有极强的稳定性和性能，bug 和 kernel case 也几乎暴露无遗并进行修复。同时 Hertz 坚持的内外维护一套代码，也为开源出去的 Hertz 框架提供了强有力的保障。\n下面是 Hertz 的一些特性：\n  稳定性\nHertz 在如此大规模的场景下，每一个 PR 的合入、每一次发版都要慎之又慎，稍有不慎便可能造成千万甚至更多的损失。我们制定了规范的 PR、发版流程，每次合入代码需要由有经验的同学审核。 即便如此，为了降低风险，我们也搭建了各种测试场景，包括兼容性、高并发、大小包等场景，每次的 PR、发版都需要测试一段时间，充分测试，将每次发版的风险减少到最低。\n  高易用性\n在开发过程中，快速写出正确的代码往往是重要的。Hertz 在设计 API 时，考虑到用户的使用习惯，参考业界主流框架使用 API 的方式，并加以优化。在 Hertz 在迭代过程中，积极听取用户意见，持续打磨框架， 比如很多用户希望 Client 也有 Trace 的能力，为此，Hertz Client 支持了中间件能力；在代理场景中，Hertz Client 也支持了流式处理。 在做中间件和流式处理设计时，也考虑到用户实际使用习惯，帮助用户更快地写出正确的代码。Hertz 也提供了命令行工具，一键生成代码，提高框架的易用性。\n  易扩展\nHertz 采用了分层设计，提供了较多的接口以及默认的扩展实现，用户也可以自行扩展，详情可参考 CloudWeGo 官网的 Hertz 扩展部分。 同时得益于框架的分层设计，框架的扩展性也会大很多。目前仅将稳定的能力开源给社区，更多的规划参考 RoadMap。\n  低延时\nHertz 默认使用自研的高性能网络库 Netpoll，在一些特殊场景中，相较于 go net，Hertz 在 QPS、时延上均具有一定优势。关于性能数据，可参考下图 Echo 数据。 在内部实践中，某些典型服务，如框架占比较高的服务、网关等服务，迁移 Hertz 后相比 Gin 框架，资源使用显著减少，CPU 使用率随流量大小降低 30%—60%。 关于详细的性能数据，可参考：https://github.com/cloudwego/hertz-benchmark。\n 命令行工具  Hertz 提供了一个简单易用的命令行工具 Hz，用户只需提供一个 IDL，根据定义好的接口信息，Hz 便可以一键生成项目脚手架，开箱即用使用 Hertz；Hz 也提供更新能力，用户的 IDL 如果发生改变，Hz 可以更新脚手架。 目前 Hz 支持了 Thrift 和 Protobuf 两种 IDL 定义。命令行工具内置丰富的选项，可以根据自己的需求使用。 同时它底层依赖 Protobuf 官方的编译器和自研的 Thriftgo 的编译器，两者都支持自定义的生成代码插件。如果觉得默认模板不能够满足的需求，可以自定义生成的模板。\n  自 Hertz 发布以来，内部反响优异。在内部，除最常见的前后端通信场景外，还涉及网关、上传、下载、代理等场景；所用到的交互模式除 ping-pong 外，还有 streaming、chunk 等； 使用的协议除 HTTP1 外，还有 HTTP2、Websocket 等。这些复杂的交互场景和交互模式都对 Hertz 的 Server 和 Client 的可用性和稳定性提出了不小的挑战。 为此，Hertz 快速响应用户需求；搭建稳定性测试服务尽可能模拟线上真实复杂场景；较高的单测覆盖率保证代码逻辑正常。\n02 内外版本维护 字节跳动内部有着完善的微服务体系，团队非常重视开源建设和承诺，Hertz 和 CloudWeGo 中的开源项目 Kitex 相同，保持内外一致，项目的核心能力均迁移至开源库中， 在内部仅封装一层壳帮助企业内无感升级，以保证对开源长期维护的承诺，并且所有开源特性，都会在内部的稳定性验证后才会开源出来。\n后续，团队将持续以 Hertz 开源库为主进行迭代，及时响应社区需求与问题，为用户提供更好的体验和使用保障。\n对于 Hertz 的开发者来说，Hertz 同样支持对框架进行灵活的扩展，以适应业务需求。我们也欢迎外部的开发者将自己的贡献提交到社区当中，在社区进行开源共建，共同打造一款有着完善生态、极致性能和高易用性的 HTTP 框架。\n03 RoadMap 对于基础架构团队而言，Hertz 不仅仅是一个开源项目，它也是一个真实的超大规模企业级实践项目。通过开源，我们希望 Hertz 能丰富云原生社区的 Golang 中间件体系， 完善 CloudWeGo 生态矩阵，为更多开发者和企业搭建云原生化的大规模分布式系统，提供一种现代的、资源高效的的技术方案。\n如前文所述，目前 Hertz 只开源了内部经过稳定性验证的部分，未来，我们会进一步推动其走向完善：\n 云原生能力支持。支持 xDS API，从 Istio 动态获取服务配置。 多协议的支持。Hertz 目前只开源了 HTTP1 的部分，未来我们还会开源其他协议，如：HTTP2、Websocket、ALPN 等，为开发者提供更多场景的微服务需求支持。如果有需求也可以提交 issue 告诉我们，让我们知道您的需求以便快速支持。 更好用的命令行工具。我们将继续迭代 Hz，持续集成各种常用的中间件，提供模块化构建能力，用户可以按需选择所需组件。 更完善的生态支持。由于 Hertz 没有采用 go net 的数据结构，需要更多的生态支持。第一批开源我们只开源了 CORS、Trace、Metrics 等生态。未来我们还将支持包括反向代理、Session 等生态。 结合内外部用户需求，持续迭代。项目开源后，我们也会根据开发者需求开展迭代。  欢迎大家向 Hertz 提交 issue 和 PR 一起来共建。\n我们诚心期待更多的开发者加入，也期待 Hertz 助力越来越多的企业快速构建云原生架构。我们也真诚欢迎企业用户迁移使用，我们会提供专项技术支持和交流，欢迎入群咨询。\n04 相关链接   项目地址: https://github.com/cloudwego/hertz\n  周边生态: https://github.com/hertz-contrib\n  ","categories":"","description":"本文介绍了字节跳动正式开源超大规模的企业级微服务 HTTP 框架 — Hertz。","excerpt":"本文介绍了字节跳动正式开源超大规模的企业级微服务 HTTP 框架 — Hertz。","ref":"/zh/blog/2022/06/21/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%9A%84%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BE%AE%E6%9C%8D%E5%8A%A1-http-%E6%A1%86%E6%9E%B6-hertz-%E6%AD%A3%E5%BC%8F%E5%BC%80%E6%BA%90/","tags":"","title":"超大规模的企业级微服务 HTTP 框架 — Hertz 正式开源！"},{"body":"Feature  [#31] feat: close connection after responding to the short-connection request. [#44] feat: add the VisitAllCustomHeader method. [#59] feat: support windows. [#70] feat: add code generator hz. [#64] feat: add adaptor for Hertz Request \u0026 Response to net/http Request \u0026 ResponseWriter. [#45] feat: add ctx.Body().  Optimize  [#57] optimize: use http.TimeFormat as layout for http date, which can avoid more copying. [#58] optimize: add remote address to the error log when server processes the error. [#41] optimize: use CtxErrorf instead of ‘Errorf’ when server panic.  Refactor  [#37] refactor: unify the entry of setting request options to prevent options uninitialized from causing panic. [#52] refactor: omit redundant nil check around loop. [#33] refactor: simplify code in AddMissingPort. [#27] refactor: use errors.NewPublic rather than fmt.Errorf. [#34] refactor: remove fshandler and related tests.  Style  [#29] style(*): fix typos.  Docs  [#60] docs: add icon in README.md and README_cn.md. [#54] docs: Update README.md.  ","categories":"","description":"","excerpt":"Feature  [#31] feat: close connection after responding to the …","ref":"/blog/2022/06/20/hertz-release-v0.1.0/","tags":"","title":"Hertz Release v0.1.0"},{"body":"Feature  [#70] feat: 增加 hz 脚手架。 [#64] feat: 增加 Hertz Request \u0026 Response 到 net/http Request \u0026 ResponseWriter 的适配器。 [#45] feat: 添加 ctx.Body() 方法。 [#44] feat: 在 request header 上添加 VisitAllCustomHeader 方法，使得传入的函数 f 只作用在用户自定义的 header 上（除了 cookie, host, content-length, content-type, user-agent 和 connection 以外的 header）。 [#59] feat: 支持 windows 开发环境。  Refactor   [#37] refactor: 统一设置 request options 的入口，防止 options 未初始化导致 panic。\n  [#52] refactor: 去掉 for 循环中多余的判空。\n  [#33] refactor: 当子串长度确定为 1 时，可以直接调用 strings.IndexByte 函数而不是像 strings.Index 一样先调用 len() 判断子串长度后再调用 strings.IndexByte 函数； 为省去整型数字转字符串的工作，可以将相关变量直接定义成 string 类型而不是 int 类型； net 包下的 JoinHostPort 函数会再次判断 ‘:’ 是否在 addr 中，如果不在则将 host 与 port 相关字符串连接起来。然而在 AddingMissingPort 函数中调用 net.JoinHostPort 时，':' 应不在 addr 中。所以在此可以不调用 net.JoinHostPort，而是直接连接 host 和 port 信息。\n  [#27] refactor: 当字符串不需要格式化时，使用 hertz 的 errors.NewPublic 创建 error 而不是使用 fmt.Errorf。\n  Style  [#29] style(*): 修正拼写错误。  Optimize  [#57] optimize: 使用 http.TimeFormat 格式化 HTTP 中的 Date 信息，避免产生更多的复制。 [#58] optimize: 服务端错误日志中添加对端地址。 [#41] optimize(recovery): 使用 ‘CtxErrorf’ 代替 ‘Errorf’ 当服务 panic。  Docs  [#60] docs: readme 文件中添加 icon。  ","categories":"","description":"","excerpt":"Feature  [#70] feat: 增加 hz 脚手架。 [#64] feat: 增加 Hertz Request \u0026 …","ref":"/zh/blog/2022/06/20/hertz-v0.1.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Hertz v0.1.0 版本发布"},{"body":"Feature  [#473] feat(grpc): support short connection for gRPC unary. [#431] feat(limiter): extend outside limiter implementation and fix problems of rate limiter of multiplexed server.  Optimize  [#465] optimize(ttheader): set remote address for client-side after decoding TTHeader. [#466] optimize(mux): wrap ErrReadTimeout with ErrRPCTimeout in mux scenario. [#425] optimize(limiter): promise tokens of the first second don’t exceed limit significantly.  Bugfix  [#485] fix(grpc): fix the incorrect integer conversion. [#474] fix(trans): fix detection handler panic when conn inactive early. [#445] fix(retry): race problems of callTimes in retry and some fields of rpcStats. [#471] fix(retry): callCosts race in backup request.  Test  [#404] test: add unit test for pkg/retry. [#439, #472] test: add unit test for pkg/remote/remotecli. [#462, #457] test: add unit test for pkg/remote/trans/nphttp2/grpc. [#420] test: add ut for pkg/remote/trans/nphttp2.  Refactor  [#464] refactor(ttheader): change protocol id of Kitex Protobuf in TTHeader and promise the change is compatible with the old version.  Chore  [#453, #475] chore: upgrade netpoll and bytedance/gopkg. [#458] chore: fix ci reviewdog and pr ut didn’t run. [#454] chore: use self-hosted ci to optimize speed. [#449] chore: fix github issue template.  Style  [#486] style(trans): add comment for detection trans handler.  Docs  [#482] docs: update FAQ of readme.  Dependency Change  github.com/cloudwego/netpoll: v0.2.2 -\u003e v0.2.4  ","categories":"","description":"","excerpt":"Feature  [#473] feat(grpc): support short connection for gRPC unary. …","ref":"/blog/2022/06/02/kitex-release-v0.3.2/","tags":"","title":"Kitex Release v0.3.2"},{"body":"Feature  [#473] 功能 (grpc): 为 Kitex gRPC unary 模式增加短连接功能。 [#431] 功能 (limiter):  支持自定义的限流实现，接口增加了请求参数的传递； 修复多路复用场景下 Server 的 QPS 限流器问题，添加基于 OnMessage 的限流； 调整默认的限流生效时机，只有使用框架 QPS 限流且非多路复用的场景下，才使用基于 OnRead 的限流。    Optimize  [#465] 优化 (ttheader): Client 端在 TTHeader 解码结束后赋值 Remote Address (用于 Proxy 场景请求失败时获取对端地址)。 [#466] 优化 (mux): 连接多路复用场景的 ErrReadTimeout 用 ErrRPCTimeout 封装返回。Proxy 场景请求失败时获取对端地址)。 [#425] 优化 (limiter): 优化限流实现，保证第一秒的 Tokens 不会大幅超过限制。  Bugfix  [#485] 修复 (grpc): 修复 grpc 内不恰当的 int 类型转换。 [#474] 修复 (trans): 在 detection handler 中增加检测。当 OnInactive 比 OnActive 先发生，或者 OnActive 返回 error 时，防止空指针 panic。 [#445] 修复 (retry):  修复重试中 callTimes 字段的 race 问题； 修复 rpcStats 中一些字段的 race 问题。   [#471] 修复 (retry): 修复在 backup request 中的一个 race 问题。  Test  [#404] test: 增加 pkg/retry 的单测。 [#439, #472] test: 增加 pkg/remote/remotecli 的单测。 [#462, #457] test: 增加 pkg/remote/trans/nphttp2/grpc 的单测。 [#420] test: 增加 pkg/remote/trans/nphttp2 的单测。  Refactor  [#464] refactor (ttheader): 修改 Kitex Protobuf 在 TTHeader 中的 protocolID，同时保证该变更与低版本的兼容性。  Chore  [#453, #475] chore: 更新 netpoll 和 bytedance/gopkg 的版本。 [#458] chore: 修复了 reviewdog 失效的问题与 fork pr 单测的问题。 [#454] chore: 现在的 CI 受限于 github runner 的性能经常会失败，尝试改成 self-hosted runner 来提升性能。 [#449] chore: 更新 issue template，修改为更适合 Kitex 项目的问题模板。  Style  [#486] style (trans): 为 detection trans handler 增加注释信息。  Docs  [#482] docs: 在 Readme 中增加 FAQ 链接。  Dependency Change  github.com/cloudwego/netpoll: v0.2.2 -\u003e v0.2.4  ","categories":"","description":"","excerpt":"Feature  [#473] 功能 (grpc): 为 Kitex gRPC unary 模式增加短连接功能。 [#431] …","ref":"/zh/blog/2022/06/02/kitex-v0.3.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.3.2 版本发布"},{"body":"从 CloudWeGo 谈云原生时代的微服务与开源  本文整理自罗广明在 DIVE 全球基础软件创新大会 2022 的演讲分享，主题为《从 CloudWeGo 谈云原生时代的微服务与开源》。\n 01 项目创造的思考与哲学 我们团队经常会被人问到，你们为什么创造一个新的项目？我认为这是一个哲学问题。\n纵观整个开源社区，每个时间段都会有各种各样的项目被重复地创造出来，这其中的大部分项目很快便销声匿迹了，只有一部分项目能够存活下来。 当旁观者看到这样一番景象时，渐渐地，越来越多的人停留于项目搜寻，而放弃了成为项目创作者的机会。久而久之，我们开始忧虑下一代是否还会有新的项目可以使用？难道未来在同一领域，一个项目就能统一整个市场？\n其实，在程序员的世界里，参考旧的项目来创造新的项目一点都不可耻。创造不仅意味着思考、权衡与设计，更需要我们贡献项目的特殊与差异。这其中涌现了很多后起之秀，正是他们促成了开源社区的多样性。 “每一行代码都是一次精心的设计”是我们对优秀创造者的最佳赞誉。而一项优秀的代码设计往往包含两个最基本的特性：正确性和可维护性。同时，这两种特性恰恰又对应了两种不同的人格。\n第一种人格，设计者与实现者，其驾驭是相对简单的，只要功能实现，通过测试，运行正确就算完成了。然而，第二种人格，阅读者和维护者，却要求更高的代码质量，更明晰的代码结构和更好的扩展性。 只有同时具备这两种人格，开发者才能游刃有余地创造出一个优秀的项目。\n优秀的项目被创造出来意味着什么呢？千千万万的用户可以评估并且使用它。这也从侧面表明了开源本身可以避免更多项目被重复地创造出来。\n02 CloudWeGo 简介 CloudWeGo 是字节跳动基础架构团队开源出来的项目，它是一套可快速构建企业级云原生架构的中间件集合，它专注于微服务通信与治理，具备高性能、可扩展、高可靠的特点，且关注易用性。\nCloudWeGo 在第一阶段开源了四个项目：\n Kitex：高性能、强可扩展的 Golang RPC 框架 Netpoll：高性能、I/O 非阻塞、专注于 RPC 场景的网络框架 Thriftgo：Golang 实现的 thrift 编译器，支持插件机制和语义检查 Netpoll-http2：基于 Netpoll 的 HTTP/2 实现  除了这几个主要项目外，CloudWeGo 紧随其后陆续开源了 Kitex-benchmark、Netpoll-benchmark、 Thrift-gen-validator、Kitex-examples 、Netpoll-examples等项目。\n鉴于文章篇幅有限，下文将重点介绍 CloudWeGo 核心项目 Kitex。\n从演进历史来看，2014 年，字节跳动技术团队引入 Golang 解决长连接推送业务面临的高并发问题，两年后，内部技术团队基于 Golang 推出了一个名为 Kite 的框架，同时对开源项目 Gin 做了一层很薄的封装，推出了 Ginex。 这两个框架极大推动了 Golang 在公司内部的应用。此后，围绕性能和可扩展性设计，字节跳动重构 Kite，并在次年 10 月完成并发布Kitex，投入到内部应用中。据悉，截至 2021 年 9 月，线上有 3w+ 微服务使用 Kitex，大部分服务迁移新框架后可以收获 CPU 和延迟上的收益。\n从架构上看，Kitex 主要分为两部分。其中 Kitex Core 是它的的主干逻辑，定义了框架的层次结构、接口，还有接口的默认实现。 最上面 Client 和 Server 是对用户暴露的，包含 Option 配置以及其初始化的逻辑；中间的 Modules 模块是框架治理层面的功能模块和交互元信息，而 Remote 模块是与对端交互的模块，包括编解码和网络通信。 另一部分 Kitex Tool 则是对应生成代码相关的实现，生成代码工具就是编译这个包得到的，里面包括 IDL 解析、校验、代码生成、插件支持、自更新等。\n从功能与特性这两个角度来看，主要可以分为以下七个方面：\n 高性能：网络传输模块 Kitex 默认集成了自研的网络库 Netpoll，性能相较使用 go net 有显著优势；除了网络库带来的性能收益，Kitex 对 Thrift 编解码也做了深度优化。关于性能数据可参考 kitex-benchmark。 扩展性：Kitex 设计上做了模块划分，提供了较多的扩展接口以及默认的扩展实现，使用者也可以根据需要自行定制扩展，更多扩展能力参见 CloudWeGo 官网文档。Kitex 也并未耦合 Netpoll，开发者也可以选择其它网络库扩展使用。 消息协议：RPC 消息协议默认支持 Thrift、Kitex Protobuf、gRPC。Thrift 支持 Buffered 和 Framed 二进制协议；Kitex Protobuf 是 Kitex 自定义的 Protobuf 消息协议，协议格式类似 Thrift；gRPC 是对 gRPC 消息协议的支持，可以与 gRPC 互通。除此之外，使用者也可以扩展自己的消息协议。 传输协议：传输协议封装消息协议进行 RPC 互通，传输协议可以额外透传元信息，用于服务治理，Kitex 支持的传输协议有 TTHeader、HTTP2。TTHeader 可以和 Thrift、Kitex Protobuf 结合使用；HTTP2 目前主要是结合 gRPC 协议使用，后续也会支持 Thrift。 多消息类型：支持 PingPong、Oneway、双向 Streaming。其中 Oneway 目前只对 Thrift 协议支持，双向 Streaming 只对 gRPC 支持，后续会考虑支持 Thrift 的双向 Streaming。 服务治理：支持服务注册/发现、负载均衡、熔断、限流、重试、监控、链路跟踪、日志、诊断等服务治理模块，大部分均已提供默认扩展，使用者可选择集成。 Kitex 内置代码生成工具，可支持生成 Thrift、Protobuf 以及脚手架代码。原生的 Thrift 代码由本次一起开源的 Thriftgo 生成，Kitex 对 Thrift 的优化由 Kitex Tool 作为插件支持。Protobuf 代码由 Kitex 作为官方 protoc 插件生成 ，目前暂未单独支持 Protobuf IDL 的解析和代码生成。  简单总结一下，CloudWeGo 不仅仅是一个开源的项目，也是一个真实的、超大规模的企业级最佳实践。它源自企业，所以天生就适合在企业内部落地；它源自开源，最终也拥抱了开源，从 Go 基础库，到 Go 网络库和 Thrift 编译器，再到上层的服务框架，以及框架拥有的所有企业级治理能力，均对外开放开源。\n03 CloudWeGo 的微服务治理 微服务架构是当前软件开发领域的技术热点。大系统终究会拆解成小系统，“合久必分，分而治之”，传统行业的系统架构大多都是庞大的单体架构，微服务是架构发展过程中一个非常自然的演变状态。\n那么，什么是微服务治理呢？众说纷纭，业界没有达成一个共识。广义上，服务治理关注服务生命周期相关要素，包括服务的架构设计、应用发布、注册发现、流量管理，监控与可观测性、故障定位、安全性等； 又或将其分为架构治理、研发治理、测试治理、运维治理、管理治理。狭义上，服务治理技术包括服务注册与发现、可观测性、流量管理、安全、控制。 后续主要是从狭义上服务治理的角度出发，展开介绍 Kitex 相关的思考和探索。\n服务注册与发现 Kitex 并不提供默认的服务注册发现，体现了框架的中立特征。Kitex 支持自定义注册模块和发现模块，使用者可自行扩展集成其他注册中心和服务发现实现，该扩展分别定义在 Pkg/Registry 和 Pkg/Discovery 下。\nKitex 服务注册扩展接口如下所示，更多详情可以查看官网框架扩展 -\u003e 服务注册扩展。\nKitex 服务发现扩展接口如下所示，更多详情可以查看官网框架扩展 -\u003e 服务发现扩展。\n截止日前，Kitex 已经通过社区开发者的支持，完成了 ETCD、ZooKeeper、Eureka、Consul、Nacos、Polaris 多种服务发现模式，当然也支持 DNS 解析以及 Static IP 直连访问模式，建立起了强大且完备的社区生态，供用户按需灵活选用。\n特别鸣谢 @li-jin-gou @liu-song @baiyutang @duduainankai @horizonzy @Hanson 等几位社区贡献者对上述服务发现扩展库的实现与支持。更多代码详情可以查看 https://github.com/kitex-contrib 。\n熔断 前面介绍了 Kitex 服务注册与发现机制，这一点对于业务接入框架非常重要，缺少这一环节微服务之间无法实现互通。那么熔断对于微服务有什么作用呢？\n在微服务进行 RPC 调用时，下游服务难免会出错，当下游出现问题时，如果上游继续对其进行调用，既妨碍了下游的恢复，也浪费了上游的资源。为了解决这个问题，可以设置一些动态开关，当下游出错时，手动的关闭对下游的调用，然而更好的办法是使用熔断器，自动解决这个问题。\nKitex 提供了熔断器的实现，但是没有默认开启，需要用户主动开启后即可使用。\nKitex 大部分服务治理模块都是通过 Middleware 集成，熔断也是一样。Kitex 提供了一套 CBSuite，封装了服务粒度的熔断器和实例粒度的熔断器。\n 服务粒度熔断：按照服务粒度进行熔断统计，通过 WithMiddleware 添加。服务粒度的具体划分取决于 Circuit Breaker Key，即熔断统计的 Key，初始化 CBSuite 时需要传入 GenServiceCBKeyFunc。 默认提供的是 circuitbreaker.RPCInfo2Key，该 Key 的格式是 fromServiceName/toServiceName/method，即按照方法级别的异常做熔断统计。 实例粒度熔断：按照实例粒度进行熔断统计，主要用于解决单实例异常问题，如果触发了实例级别熔断，框架会自动重试。  熔断器的思路很简单根据 RPC 成功或失败的情况，限制对下游的访问。通常熔断器分为三个时期：CLOSED、OPEN、HALFOPEN。当RPC 正常时，为 CLOSED； 当 RPC 错误增多时，熔断器会被触发，进入 OPEN；OPEN 后经过一定的冷却时间，熔断器变为 HALFOPEN；HALFOPEN 时会对下游进行一些有策略的访问， 然后根据结果决定是变为 CLOSED，还是 OPEN。总的来说三个状态的转换大致如下图：\n关于 Kitex 熔断器实现的更多细节和原理，可以查看官网基本特性 -\u003e 熔断器章节。\n限流 如果说熔断是从客户端出发保护调用链，以防止系统雪崩，那么限流则是一种保护服务端的措施，防止上游某个 Client 流量突增导致 Server 过载。\nKitex 支持限制最大连接数和最大 QPS。在初始化 Server 的时候，增加一个 Option：\n其中 MaxConnections 表示最大连接数，MaxQPS` 表示最大 QPS，此外，Kitex 还提供了动态修改限流阈值的能力。\nKitex 分别使用了 ConcurrencyLimiter 和 RateLimiter 对最大连接数和最大 QPS 进行限流，其中 ConcurrencyLimiter 采用了简单的计数器算法，RateLimiter 采用了“令牌桶算法”。\n限流状态的监控也是重要的一环，Kitex 定义了 LimitReporter 接口，用于限流状态监控，例如当前连接数过多、QPS 过大等。如有需求，用户需要自行实现该接口，并通过 WithLimitReporter 注入。\n请求重试 Kitex 提供三类重试：超时重试、Backup Request，建连失败重试。其中建连失败是网络层面问题，由于请求未发出，框架会默认重试，下面重点介绍前两类重试的使用。需要注意的是，因为很多的业务请求不具有幂等性，这两类重试不会作为默认策略，用户需要按需开启。\n 超时重试：错误重试的一种，即客户端收到超时错误的时候，发起重试请求。 Backup Request：客户端在一段时间内还没收到返回，发起重试请求，任一请求成功即算成功。Backup Request 的等待时间 RetryDelay 建议配置为 TP99，一般远小于配置的超时时间 Timeout。  服务中的长尾请求增加了服务的整体延迟，而长尾请求占比很低，如上图所示，一个真实服务的延迟分布，能明显看出长尾现象，最大延迟 60ms，而 99% 服务可以在 13ms 返回。 当请求延迟达到 13ms 的时候就已经进入长尾请求，这个时候我们可以再发出一条请求，这条请求大概率会在 13ms 内返回，任意一次请求返回我们就认为请求成功，即通过增加适当的负载，大大减少了响应时间的波动。 关于超时重试和 Backup Request 的优缺点以及适用场景，可见下表：\n负载均衡 Kitex 默认提供了两种负载均衡算法实现：\n WeightedRandom：这个算法使用的是基于权重的随机策略，也是 Kitex 的默认策略。它会依据实例的权重进行加权随机，并保证每个实例分配到的负载和自己的权重成比例。 ConsistentHash：一致性哈希主要适用于对上下文（如实例本地缓存）依赖程度高的场景，如希望同一个类型的请求打到同一台机器，则可使用该负载均衡方法。  ConsistentHash 在使用时，需要注意如下事项：\n 下游节点发生变动时，一致性哈希结果可能会改变，某些 Key 可能会发生变化； 如果下游节点非常多，第一次冷启动时 Build 时间可能会较长，如果 RPC 超时短的话可能会导致超时； 如果第一次请求失败，并且 Replica 不为 0，那么会请求到 Replica 上；而第二次及以后仍然会请求第一个实例。  可观测性 框架自身不提供监控打点实现，提供了 Tracer 接口，用户可以根据需求实现该接口，并通过 WithTracer Option 注入到框架中。\nKitex 的监控打点、Metrics 上报以及链路追踪，都可以通过上述接口进行扩展。\n目前 kitex-contrib 组织下提供了 Prometheus 的监控扩展， OpenTracing 的链路追踪扩展， 以及 OpenTelemetry 可观测性全家桶（Metrics + Tracing + Logging）扩展实现，用户可以按需接入相应的扩展。\n微服务框架与服务网格 服务框架是传统微服务技术的核心所在。早期微服务技术中的服务注册、发现、调用、治理、观测都离不开服务框架。这也带来了一些问题，比如业务研发者需要感知并使用服务框架的服务治理能力，框架版本升级困难，框架越来越重难于维护等等。\n服务网格（Service Mesh） 是将无侵入服务治理定义的更为深入的微服务架构方案，被称为第二代微服务架构。通过将微服务治理能力以独立组件（Sidecar）整合并下沉到基础设施，服务网格可以实现应用业务逻辑与服务治理逻辑完全分离，这也使支持多语言、热升级等高阶特性变得顺理成章。\n进入云原生时代，随着服务网格技术的逐步发展，我们也要用发展的眼光进行架构规划和设计，微服务框架和服务网格未来必定会是并存的，统一组成服务治理体系。 在字节跳动，服务治理体系就是由服务框架和服务治理组成。以 Golang 服务为例，CloudWeGo 提供业务强相关、强侵入的服务治理， 字节 Service Mesh 提供业务弱相关、弱侵入的服务治理，相互搭配，相互协商，既解决了业务开发所需的脚手架和开发模式，又让服务治理的接入更加容易。\n与此同时，在服务网格和服务框架同时使用的场景下，服务框架必须要支持灵活卸载治理能力，服务网格也需要保证功能的稳定性。在未来技术的演进方向上，服务框架也主要专注于编解码、通信效率、多协议支持等方面，而服务网格则可以深入更多无侵入的服务治理功能研发中。\n此外，在大规模场景下，针对服务治理新功能的研发需求决策，我们往往还需要考虑以下因素：\n 性能: 大部分业务很在意，也是团队一直努力的重点； 普遍性:需要评估是不是所有业务都需要的能力； 简洁: 通俗说，我们不太希望引入太多的线上问题或者太复杂的使用说明文档； ROI：功能迭代、产品升级需要考虑整体投资回报率。  04 CloudWeGo 的开源之路 字节内部版本的 Kitex 是依赖于开源版本的 Kitex，因此可以理解为 Kitex 内外同源，不存在两个 Kitex。\n开源的原因 回到开篇的问题，为什么要创造一个新的项目，并且开源 CloudWeGo 呢？\n首先，CloudWeGo 里面的项目都是在字节内部经过大规模落地实践验证的，开源后每个功能的迭代也都是第一时间在内部使用验证过的，是一个真正的企业级落地项目，开源用户和字节内部业务使用的是同一套服务框架； 其次，CloudWeGo 提供的功能，尤其是协议支持和服务治理，都是能解决真实业务痛点的，每一行代码优化都能实实在在地提升用户服务的性能； 最后，CloudWeGo 的研发也借鉴了一些知名开源项目的设计思路，同时也依赖一些开源项目的实现，我们把 CloudWeGo 开源出去也是为了回馈社区，给开源社区贡献一份力量。\nCloudWeGo 在设计之初，就同时考虑了正确性和可维护性，除了代码逻辑的正确性，高质量的代码、明晰的代码结构和优良的扩展性一直都是 CloudWeGo 追求的方向和实践的信条。\nCloudWeGo 服务于用户、需求驱动，为用户提供开箱即用的服务框架及相关中间件，希望可以服务于更多企业和独立开发者，避免用户重复创造。\n开源的历程 CloudWeGo 自 2021 年 9 月 8 日正式对外官宣，主要子项目 Kitex 先后发布 v0.1.0 和 v0.2.0，支持了许多新的功能，对性能、代码、文档也相继做了许多优化。 截止到 2022 年 4 月，距离首次官宣 7 个月，仅 CloudWeGo-Kitex 就收获了 4000 个 Star，累计近 50 个 Contributors，达到了一个新的里程碑，这很有趣，并且十分振奋人心，不是吗？\nCloudWeGo 团队自开源之初就非常重视社区建设，“Community Over Code” 也是 CloudWeGo 社区所遵循的文化和目标。\n从搭建用户群，建设官网和文档，积极维护项目 Issue，及时处理新的 PR，再到我们与贡献者的深入沟通和对他们的培养，每一个动作都体现我们的决心。为了推进社区建设规范化和标准化，CloudWeGo 团队先后创建了 Community 仓库用来定义社区成员晋升机制以及存档社区材料。\n为了践行公开透明和开源开放的开源文化，搭建开放的对话与交流平台，CloudWeGo 组织了社区双周例会，在例会上同步社区近期计划并积极听取社区成员的建议，与社区贡献者讨论相关技术方案实现。\n截止目前，通过社区 Maintainer 的培养、Contributor 的主动申请、社区管理委员会的投票审批，已经正式通过了 5 位 Committer 的加入申请，极大地壮大了 CloudWeGo 社区核心力量，他们为社区的发展作出了重大贡献。\n后续的规划 CloudWeGo 在 2021 年底收录进入 CNCF Landscape，丰富了 CNCF 在 RPC 领域的生态，给全球用户在做技术选型时提供了一套新的选择。\n尽管取得了一些小小的成绩，但是 CloudWeGo 仍旧还是一个年轻的项目，开源贵在持之以恒、长期建设，CloudWeGo 团队也会持续完善，继续向前。\n从社区建设方面来看，CloudWeGo 团队将继续提供更多新人友好的 Good-first-issue，坚持组织社区例会，定期举办开源技术沙龙，提供更易于理解的技术文档，另外也将继续欢迎更多新的开发者参与到社区建设中来。\n从开源规划来看，HTTP 框架 Hertz 开源在即，还有更多中间件小工具、扩展库也都在持续开源中。此外，CloudWeGo 主创团队还研发了一套 Rust RPC 框架，正在内部落地实践验证中，在不久的将来，也将对外开源。\n从功能研发计划来看，以 Kitex 为例，将继续以内外部用户需求为驱动力，持续开发新的功能并迭代完善已有的功能。其中，包括支持连接预热、自定义异常重试、对 Protobuf 支持的性能优化，支持 xDS 协议等。\n从开源生态来看，目前 Kitex 已经完成了诸多开源项目的对接，未来也将会按需支持更多开源生态。 此外，CloudWeGo 也在和国内外主流公有云厂商进行合作对接，提供开箱即用、稳定可靠的微服务托管与治理产品的基座；CloudWeGo 也积极与国内外软件基金会开展合作和交流，探索新的合作模式。\nCloudWeGo 未来可期，我们期待更多用户使用我们的项目，也期待有更多开发者可以加入共建 CloudWeGo 社区，共同见证云原生时代一个初生但了不起的微服务中间件和开源项目。\n","categories":"","description":"本文将从 CloudWeGo 的角度，介绍云原生时代的微服务与开源的关系，以及 CloudWeGo 在微服务开源领域的探索与实践。","excerpt":"本文将从 CloudWeGo 的角度，介绍云原生时代的微服务与开源的关系，以及 CloudWeGo 在微服务开源领域的探索与实践。","ref":"/zh/blog/2022/05/26/%E4%BB%8E-cloudwego-%E8%B0%88%E4%BA%91%E5%8E%9F%E7%94%9F%E6%97%B6%E4%BB%A3%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%8E%E5%BC%80%E6%BA%90/","tags":"","title":"从 CloudWeGo 谈云原生时代的微服务与开源"},{"body":"字节微服务框架的挑战和演进 2014 年以来，字节跳动内部业务的快速发展，推动了长连接推送服务，它们面临着高并发的业务需求问题，对性能和开发效率都有很高要求。当时的业务，大部分都是由 Python 开发，难以应对新出现的问题。 项目负责人在一众现存的技术栈中选择了 Golang 这一门新兴的编程语言，快速解决了性能和开发效率的问题。随后，字节跳动内部开始逐渐推广使用 Golang 进行服务开发。\n2016 年， 第一代 Golang RPC 框架 Kite 正式发布。Kite 是一个基于 Apache Thrift 进行包装的 RPC 框架，它在 Facebook 开源的 Thrift 之上提供了结合字节跳动内部基础设施的治理功能， 同时还提供了一套简单易用的生成工具。随着 Kite 的发展，业务开始大规模使用 Golang。然而，在业务发展的过程中，由于研发专注于实现业务需求，对于框架的可维护性考量不足，Kite 逐渐背上了一些技术包袱， 越来越难以满足业务在高性能和新特性方面的需求。因此我们决定对 Kite 进行重新设计，于是出现了 Kitex。\n2020 年，Kitex 在内部发布了 v1.0.0，并且直接接入了 1,000+ 服务。由于 Kitex 的优秀性能和易用性，Kitex 在内部得到了大规模发展。 直到 2021 年年中，字节跳动内部已有 2w+ 服务使用了 Kitex。因此，我们决定全面优化 Kitex，将其实践成果进行开源，反馈给开源社区。\n字节跳动 Golang RPC 框架的演进 Kite 的缺陷 Kite 作为字节跳动第一代 Golang RPC 框架，主要存在以下缺陷：\n Kite 为了快速支持业务发展需求，不可避免地耦合了部分中台业务的功能； Kite 对 Go modules 支持不友好（Go modules 在 2019 年才进入语言核心）； Kite 自身的代码拆分成多仓库，版本更新时推动业务升级困难； Kite 强耦合了早期版本的 Apache Thrift，协议和功能拓展困难； Kite 的生成代码逻辑与框架接口强耦合，成为了性能优化的天花板。  因此，业务的快速发展和需求场景的多样化，催生了新一代 Golang RPC 框架 Kitex。\nKitex Kitex 的架构主要包括四个部分：Kitex Tool、Kitex Core、Kitex Byted、Second Party Pkg。\n Kitex Core 是一个携带了一套微服务治理功能的 RPC 框架，它是 Kitex 的核心部分。 Kitex Byted 是一套结合了字节跳动内部基础设施的拓展集合。通过这一套拓展集合，Kitex 能够在内部支持业务的发展。 Kitex Tool 是一个命令行工具，能够在命令行生成我们的代码以及服务的脚手架，可以提供非常便捷的开发体验。 Second Party Pkg，例如 Netpoll， Netpoll-http2，是 Kitex 底层的网络库，这两个库也开源在 CloudWeGo 组织中。  Kitex 的架构设计 总的来说， Kitex 主要有五个特点：面向开源、功能丰富、灵活可拓展、支持多协议、高性能。\n面向开源 由于之前已经体验过了 Kite 维护的各种问题，我们在立项之初就考虑到了未来可能会开源 Kitex。因此，我们设计的第一个宗旨就是不将 Kitex 和公司内部的基础设施进行强耦合或者硬编码绑定。 Kitex Core 是一个非常简洁的框架，公司内部的所有基础设施都以拓展的方式注入到 Kitex Core 里。即使我们现在已经开源了，它也以这种形式存在。 公司内部基础设施的更新换代，和 Kitex 自身的迭代是相互独立的，这对于业务来说是非常好的体验。同时，在 Kitex 的接口设计上，我们使用了 Golang 经典的 Option 模式， 它是可变参数，通过 Option 能够提供各种各样的功能，这为我们的开发和业务的使用都带来了非常大的灵活性。\nKitex 的功能特性 治理能力 Kitex 内置了丰富的服务治理能力，例如超时熔断、重试、负载均衡、泛化调用、数据透传等功能。业务或者外部的用户使用 Kitex 都是可以开箱即用的。 如果你有非常特殊的需求，你也可以通过我们的注入点去进行定制化操作，比如你可以自定义中间件去过滤或者拦截请求，定义跟踪器去注入日志、去注入服务发现等。 在 Kitex 中，几乎一切跟策略相关的东西都是可以定制的。\n以服务发现为例，Kitex 的核心库里定义了一个 Resolver interface 。任何一个实现了这四个方法的类型都可以作为一个服务发现的组件，然后注入到 Kitex 来取代 Kitex 的服务发现功能。 在使用时，客户端只需要创建一个 Resolver 的对象，然后通过 client.WithResolver 注入客户端，就可以使用自己开发的服务发现组件。\nKitex 的一个创新之处是使用 Suite 来打包自定义的功能，提供一键配置基础依赖的体验。\n它能在什么地方起作用呢？例如，一个外部企业想要启用或者接入 Kitex， 它不可能拥有字节跳动内部的所有基础设施。那么企业在使用的时候肯定需要定制化，他可能需要定义自己的注册中心、负载均衡、连接池等等。 如果业务方要使用这些功能的话，就需要加入非常非常多的参数。而 Suite 可以通过一个简单的类一次性包装这些功能，由此，业务方使用时，仍然是以单一的参数的方式添加，十分方便。 又例如，我现在开发一个叫 mysuite 的东西，我可能提供一个特殊的服务发现功能，提供了一个拦截的中间件，还有负载均衡功能等。 业务方使用时，不需要感知很多东西去配置，只需要添加一个 Suite 就足够了，这点非常方便一些中台方或者第三方去做定制。\n示例 多协议 Kitex 网络层基于高性能网络库 Netpoll 实现。在 Netpoll 上，我们构建了 Thrift 和 Netpoll-http2；在 Thrift 上，我们还做了一些特殊的定制，例如，支持 Thrift 的泛化调用，还有基于 Thrift 的连接多路复用。\n多协议 代码生成工具 和 Kitex 一同出现的，还有我们开发的一个简单易用的命令行工具 kitex。如果我们写了一个 IDL，只需要提供一个 module 参数和一个服务名称，kitex 就会为你生成服务代码脚手架。\n目前 Kitex 支持了 Protobuf 和 Thrift 这两种 IDL 的定义。命令行工具内置丰富的选项，可以进行项目代码定制；同时，它底层依赖 Protobuf 官方的编译器，和我们自研的 Thriftgo 的编译器，两者都支持自定义的生成代码插件。\nKitex 的性能表现 字节跳动内部 RPC 框架使用的协议主要都是基于 Thrift，所以我们在 Thrift 上深耕已久。结合自研的 Netpoll 能力，它可以直接暴露底层连接的 buffer。 在此基础上，我们设计出了 FastRead/FastWrite 编解码实现，测试发现它具有远超过 apache thrift 生成代码的性能。整体而言，Kitex 的性能相当不错，今年 1 月份的数据如下图所示， 可以看到，Kitex 在使用 Thrift 作为 Payload 的情况下，性能优于官方 gRPC，吞吐接近 gRPC 的两倍；此外，在 Kitex 使用定制的 Protobuf 协议时，性能也优于 gRPC。\nKitex/gRPC 性能对比（2022 年 1 月数据） Kitex：一个 demo 下面简单演示一下 Kitex 是如何开发一个服务的。\n首先，定义 IDL。这里使用 Thrift 作为 IDL 的定义，编写一个名为 Demo 的 service。方法 Test 的参数是 String，它的返回也是 String。 编写完这个 demo.thrift 文件之后，就可以使用 Kitex 在命令行生成指定的生成代码。如图所示，只需要传入 module name，service name 和目标 IDL 就行了。\n定义 IDL 随后，我们需要填充业务逻辑。文件中除了第 12 行，全部代码都是 Kitex 命令行工具生成的。通常一个 RPC 方法需要返回一个 Response，例如这里需要返回一个字符串，那么我们给 Response 赋值即可。 接下来需要通过 go mod tidy 把依赖拉下来，然后用 build.sh 构建，就可以启动服务了。Kitex 默认的接听端口是 8888。\n定义 Handler 方法 编译、运行 对于刚刚启动的服务端，我们可以写一个简单的客户端去调用它。服务端写完之后，写客户端也是非常方便的。 这里同样是 import 刚刚生成的生成代码，创建 Client、指定服务名字、构成相应的参数，填上“ Hello，word！” ，然后就可以调用了。\n编写 Client Kitex 在字节内部的落地 与内部基础设施的集成 谈到落地，第一步就是 Kitex 和字节跳动内部的基础设施进行结合。字节跳动内部的所有基础设施都是以依赖的方式注入到 Kitex 的。 我们将日志、监控、tracing 都定义为 tracer，然后通过 WithTracer 这个 Option 将其注入到 Kitex 里；服务发现是 WithResolver；Service Mesh 则是 WithProxy 等。 字节跳动内部的基础设施都是通过 Option 被注入到 Kitex 的，而且所有的 Option 都是通过前面说的 Suite 打包，简单地添加到业务的代码里完成。\n与内部基础设施的集成 内部落地的经典案例：合并部署 这里介绍一个内部落地的经典案例：合并部署。其背景是，在开发微服务时，由于业务拆分和业务场景的多样化，微服务容易出现过微的情况。 当服务数量越来越多，网络传输和序列化开销就会越来越大，变得不可忽视。因此，Kitex 框架需要考虑如何减小网络传输和序列化的开销。\n字节跳动基础架构经过一系列的探索和实践，最终推出了合并部署的机制。它的思路是：将有强依赖关系的服务进行同机部署，减少它们之间的调用开销。理论上说起来比较简单，实际过程中需要非常多的组件进行配合。\nKitex 的做法是：首先，它会依赖一套中心化的部署调度和流量控制；其次，我们开发了一套基于共享内存的通信协议，它可以使得我们两个不同的服务在同一台机器部署时，不需要通过网络进行数据传输，直接通过共享内存，减少额外的数据拷贝。\n在服务合并部署的模式下，我们需要特殊的服务发现和连接池的实现、定制化的服务启动和监听逻辑。这些在 Kitex 框架里都是通过依赖注入的方式给添加进来的。 Kitex 服务在启动过程中会感知到我们 PaaS 平台提供的指定的环境变量。当它察觉到自己需要按合并部署的方式启动之后，就会启动一个预先注入的特定 Suite，随后将相应的功能全都添加进来再启动，就可以执行我们的合并部署。\n那么，它的效果如何呢？在 2021 年的实践过程中，我们对抖音的某个服务约 30% 的流量进行了合并，服务端的 CPU 的消耗减少了 19%， TP99 延迟下降到 29%，效果相当显著。\n内部落地的经典案例：合并部署 微服务框架推进的痛点  升级慢  大家可能好奇 Kitex 在字节跳动内部推广是不是很顺畅？其实并不是。作为一个相对而言比较新的框架， Kitex 和其它新生项目一样，在推广的过程中都会遇到同样的问题。 特别是， Kitex 作为一个 RPC 框架，我们提供给用户的其实是一个代码的 SDK, 我们的更新是需要业务方的用户去感知、升级、部署上线，才能最终体现在他们的服务逻辑里，因此具有升级慢的问题。\n 召回慢  同时，因为代码都是由研发人员编写，如果代码出现了 bug，我们就需要及时地去感知定位问题，通知负责人去更新版本。因此，会有召回慢的问题。\n 问题排查困难  业务方的用户在写代码时，他们其实往往关注的是自己的业务逻辑，他们不会深入理解一个框架内部的实现。所以如果出现问题，他们往往会不知所措，需要依赖我们的业务同学才能进行相应的问题排查。所以会有问题排查困难的问题。\n针对升级慢，我们有两个操作。一是，代码生成工具支持自动更新：当用户在使用时，我们会检查最新版本，然后直接将我们的版本更新到最新版本，这样可以及时把我们的框架新 feature、bug fix 直接推送到业务方； 二是，用户群发版周知：我们有一个几千人的用户群，当有了新版本，我们会在用群里周知，可以最大范围的覆盖到我们的目标用户。\n针对召回慢，我们有三个操作。一是，我们在线上建立完整的版本分布统计，监控所有服务上线部署的框架的版本； 二是，我们会跟 PaaS 平台合作，在服务上线时进行卡点操作，检查它们使用的框架版本是不是有 bug，是否需要拦截；三是，针对有问题的版本，我们会及时封禁，及时推动用户更新。\n针对问题排查困难，我们有两个操作。一是，我们积累了非常丰富的 Wiki 和问题排查手册，例如超时问题、 协议解析问题等。 二是，如果遇到难以解决的问题，我们在线上服务默认开启了 Debug 端口，保证框架开发同学可以第一时间赶到现场去排查。\nKitex 在字节内部的发展 数据显示，在 2020 年，v1.0 版本发布的初始阶段，用户的接受度比较低。直到 2020 年 6 月，线上接受 Kitex 的数量还不到 1000。 随后进入快速发展的阶段，到 2021 年年初，累积接近 1w+ 的服务开始使用 Kitex。2021 年底，4w+服务使用 Kitex。\nKitex 的开源实践 开源工作主要包括代码、文档和社区运营三个层面。\n代码层面\n 代码拆分、脱敏； 内部仓库引用开源仓库，避免内外多副本同时维护； 在开源过程中确保内部用户平滑切换、体验无损；  文档层面\n 重新梳理用户文档，覆盖方方面面； 建立详尽的用例仓库(CloudWeGo/Kitex-examples)。  社区运营\n 官网建设； 组建用户群，进行答疑解惑； 飞书机器人对接 Github 的 Issue 管理、PR 管理之类的业务，可以快速响应； 对优秀贡献者进行奖励。  在以上努力下，CloudWeGo/Kitex 仓库目前收获了 4.1k+ stars；kitex-contrib 获得多个外部用户贡献的仓库；CloudWeGo 飞书用户群近 950 个用户……\n未来展望 首先，我们仍然会持续向开源社区反馈最新的技术进展。例如在 Thrift 协议上，虽然对 Thrift 的编解码已经做到非常极致的优化了，我们还在探索利用 JIT 手段来提供更多的性能提升； 在 Protobuf 上，我们会补足短板，将在 Thrift 方面的优化经验迁移到 Protobuf 上，对 Protobuf 的生成代码和编解码进行优化； Kitex 后续也会进一步融入云原生社区，所以也在考虑支持 xDS 协议。 其次，我们会去拓展更多的开源组件，去对接现存的云原生社区的各种常用的或者热门组件。最后，我们也会尝试去对接更多的公有云基础设施，使得用户在公有云上使用 Kitex 时能够拥有愉悦的体验。\n","categories":"","description":"本文介绍了随着字节跳动内部业务的快速发展，字节微服务框架面临的挑战，以及为了应对这些挑战做了哪些演进，最后介绍了面向开源的 Kitex 的功能特性和内部落地的经典案例等。","excerpt":"本文介绍了随着字节跳动内部业务的快速发展，字节微服务框架面临的挑战，以及为了应对这些挑战做了哪些演进，最后介绍了面向开源的 Kitex 的功 …","ref":"/zh/blog/2022/05/19/%E5%AD%97%E8%8A%82%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E7%9A%84%E6%8C%91%E6%88%98%E5%92%8C%E6%BC%94%E8%BF%9B/","tags":"","title":"字节微服务框架的挑战和演进"},{"body":"Overview Fixed Panic when “peer Close \u0026 local user Close” occurs simultaneously\nSeverity Level Middle\nDescription Fixed concurrency issues in extreme scenarios.\nScenario: “peer Close \u0026 local user Close” occurs at the same time, and C.onClose executes lock(user), and Poller also executes p.detaches (all three conditions are met)\nWhen two goroutines execute op.Control(PollDetach) at the same time, op.unused will be executed twice.\nWhen the program is idle, it is possible that c.onclose has completed the close callback, freeop has been reused, and the state becomes inuse again. That’s when the op.unused in p.detaches is executed; This will incorrectly set the operator of a new connection to 0, causing all subsequent op.do to fail in an infinite loop.\nSolution Poller no longer executes detach asynchronously to ensure that it does not run concurrently with C.onclose and the changes are performance-neutral.\nAffected Components netpoll-v0.2.2\nkitex-v0.3.0\nCVE None\nReferences  https://github.com/cloudwego/netpoll/issues/149 https://github.com/cloudwego/netpoll/pull/142  ","categories":"","description":"Netpoll Panic","excerpt":"Netpoll Panic","ref":"/security/safety-bulletin/detail/cloudwego-sa-2022-2/","tags":"","title":"CloudWeGo-SA-2022-1"},{"body":"简介 修复当“对端关闭 \u0026 本端 user Close” 同时发生时出现 Panic 的问题\n严重级别 Middle\n描述 修复极端场景下的并发问题：\n场景：“对端关闭 \u0026 本端 user Close” 同时发生，并且 c.onClose 执行的是 lock(User)，同时 poller 也执行到了 p.detaches (三个条件同时满足)\n这时候会有两个 goroutine 同时执行 op.Control(PollDetach)，因此 op.unused 会被执行两次。\n当程序比较闲时，有可能 c.onClose 已经执行完 close callback 了，freeop 并且已经被复用，又变成 inuse 状态；而这时候 p.detaches 里的 op.unused 才开始执行；这样就会把一个新连接的 operator 错误的置成 0 ，导致后续的 op.do 全失败，变成死循环。\n解决办法 poller 不再异步执行 detach，以保证不会和 c.onClose 并发，改动是性能无损的。\n影响组件 netpoll-v0.2.2\nkitex-v0.3.0\nCVE 无\n参考链接  https://github.com/cloudwego/netpoll/issues/149 https://github.com/cloudwego/netpoll/pull/142  ","categories":"","description":"Netpoll Panic","excerpt":"Netpoll Panic","ref":"/zh/security/safety-bulletin/detail/cloudwego-sa-2022-2/","tags":"","title":"CloudWeGo-SA-2022-2"},{"body":"Feature  [#366, #426 ] feat(client): support warming-up for kitex client [#395 ] feat(mux): support gracefully shutdown in connection multiplexing [#399 ] feat(protobuf): add fastpb protocol API and support it in the pkg/remote/codec module  Optimise  [#402 ] optimize(connpool): export getCommonReporter in pkg/remote/connpool [#389 ] optimize(rpcinfo): fill TransportProtocol, PackageName fields into RPCInfo of the server side after decoding  Bugfix  [#413 ] fix(mux): set PayloadCodec for sendMsg in NetpollMux trans handler to fix generic request codec error.issue #411 [#406 ] fix(grpc): fix the sending and receiving logic about http2 framer, such as preventing the peer unable to receive the framer in time [#398 ] fix(utils): fix the bug that Dump() func in ring.go can’t dump the accurate data in ring shards [#428 ] fix(trans): close connection when flush data fails to avoid memory leak  Tool  [#340 ] tool(protobuf): redesign and implement new protobuf gen code called fastpb which doesn’t use reflection and only supports proto3  Chore  [#396 ] chore: replace cespare/xxhash with xxhash3 from bytedance/gopkg [#400 ] chore: upgrade go version of workflow to 1.18 [#407 ] chore: add a separate file to declare the use of gRPC source code  Test  [#401 ] test: add ut for kitex/server package [#393 ] test: add ut for pkg/remote/bound package [#403 ] test: add netpollmux unit test [#401 ] test: add klog unit test [#392 ] test(utils): add UT for utils and fix inaccurate err throw in json.go [#373, #432, #434 ] test(grpc): add gRPC transport unit tests, promoting the coverage to 76% [#424 ] test(transmeta): supplementary of unit tests for http2 and ttheader implementations of MetaHandler/StreamingMetaHandler in pkg/transmeta.  Dependency Change  github.com/cloudwego/netpoll: v0.2.0 -\u003e v0.2.2 github.com/bytedance/gopkg: 20210910103821-e4efae9c17c3 -\u003e 20220413063733-65bf48ffb3a7  ","categories":"","description":"","excerpt":"Feature  [#366, #426 ] feat(client): support warming-up for kitex …","ref":"/blog/2022/04/29/kitex-release-v0.3.0/","tags":"","title":"Kitex Release v0.3.0"},{"body":"Feature  [#366, #426 ] 功能(client): 客户端支持预热操作 [#395 ] 功能(mux): 连接多路复用支持优雅关闭 [#399 ] 功能(protobuf): 定义 fastpb protocol API 并在编解码模块对应支持  Optimise  [#402 ] 优化(connpool): 导出 pkg/remote/connpool 里的 getCommonReporter [#389 ] 优化(rpcinfo)：填充由 defaultCodec 解码得到的 rpcinfo 中缺失的 Invocation().PackageName, Invocation().ServiceName and Config().TransportProtocol 字段  Bugfix  [#413 ] 修复(mux): 在 NetpollMux transHandler 中设置 sendMsg的PayloadCodec，以修复泛化请求编码报错问题issue #411 [#406 ] 修复(grpc): 修复 http2 framer 的读写逻辑，例如避免对端无法及时收到 framer [#398 ] 修复(utils)：修复了 Dump() 接口无法 dump 出 ring 里所有数据的 bug [#428 ] 修复(trans)：当写入失败时，关闭连接以避免内存泄漏  Tool  [#340 ] tool(protobuf): 重新设计并实现 Protobuf 生成代码，不使用反射完成编解码，当前仅支持 proto3  Chore  [#396 ] chore: 用 bytedance/gopkg 里的 xxhash3 替换掉 cespare/xxhash [#400 ] chore: 升级 workflow 的 go 版本到 1.18 [#407 ] chore: 单独增加文件对 grpc 源码使用做声明  Test  [#401 ] test: 补充 kitex/server 的单测 [#393 ] test: 补充 pkg/remote/bound package 单测 [#403 ] test: 补充 netpollmux package 单测 [#401 ] test: 补充 klog package 单测 [#392 ] test: 补充 utils package 单测 [#373, #432, #434 ] test: 补充 gRPC transport 部分的单测，单测覆盖率提升到 76% [#424 ] test: 补充 transmeta 实现 handler 的单元测试  Dependency Change  github.com/cloudwego/netpoll: v0.2.0 -\u003e v0.2.2 github.com/bytedance/gopkg: 20210910103821-e4efae9c17c3 -\u003e 20220413063733-65bf48ffb3a7  ","categories":"","description":"","excerpt":"Feature  [#366, #426 ] 功能(client): 客户端支持预热操作 [#395 ] 功能(mux): 连接多路复用支持 …","ref":"/zh/blog/2022/04/29/kitex-v0.3.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.3.0 版本发布"},{"body":"Improvement  Fix: reduce costs of SetNumLoops Chore: update mcache and ci Feat: recycle caches when LinkBuffer is closed  Fix  Fix: send\u0026close ignored by OnRequest Fix: fill lost some data when read io.EOF Fix: check is active when flush  Doc  Doc: update guide.md Doc: restate the definition of Reader.Slice Doc: fix replace examples url  Revert  Revert “feat: change default number of loops policy (#31)”  ","categories":"","description":"","excerpt":"Improvement  Fix: reduce costs of SetNumLoops Chore: update mcache and …","ref":"/blog/2022/04/28/netpoll-release-v0.2.2/","tags":"","title":"Netpoll Release v0.2.2"},{"body":"Improvement  Fix: Loops 缩容不再全部重置 Chore: mcache bsr 计算使用 math/bits.Len 代替，以提升性能。 Feat: 修复 LinkBuffer Close 时没有回收 caches 的问题（不是内存泄漏）  Fix  Fix: 修复短链接 send\u0026close 场景无法触发 OnRequest 回调的问题 Fix: 修复 zcReader 读到 io.EOF 后丢失部分数据的问题 Fix: 修复 flush 没有检查连接关闭的问题  Doc  Doc: 更新了用户文档 Doc: 增加了 Reader.Slice 的定义描述 Doc: 修复了 examples 中的死链  Revert  Revert: 重置了 loops 初始化数量  ","categories":"","description":"","excerpt":"Improvement  Fix: Loops 缩容不再全部重置 Chore: mcache bsr 计算使用 math/bits.Len  …","ref":"/zh/blog/2022/04/28/netpoll-v0.2.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Netpoll v0.2.2 版本发布"},{"body":" 导语：2022 年 3 月，NextArch 基金会正式成立微服务技术小组，致力于推动微服务技术和开源生态的持续发展，根据各个企业在微服务生产实践中遇到的问题，针对不同行业和应用场景输出标准化解决方案， 并且联合 PolarisMesh、TARS、go-zero、GoFrame、CloudWeGo 和 Spring Cloud Tencent 等开源社区提供开箱即用的实现，降低终端用户的使用门槛。 来自腾讯、字节跳动、七牛云、快手、BIGO、好未来和蓝色光标等多家企业的技术专家已经加入技术小组，欢迎更多企业和开源社区加入。\n 2021 年 11 月，Linux 基金会正式成立 NextArch 基金会，共计 40 余家企业或单位联合参与了该基金会的筹建工作，并作为首批共建和支持单位加入，目前已增至 53 家企业。NextArch 基金会致力于在异构基础设施、多元化技术栈和混合云场景下的构建下一代技术架构，始终秉承一个开放中立的治理模式，发展适合企业数字化转型的开源生态。\n微服务是下一代架构的关键部分，越来越多企业采用微服务架构。市场调研表明，随着企业数字化转型持续深入，2023 年微服务云市场的规模达到 18.8 亿美元，从 2018 到 2023 年的复合年增长率达到 22.4%。众所周知，微服务相比于传统架构具有诸多优势，但是，我们在微服务实施的各个环节中都可能面临问题。\n为了降低微服务架构的落地成本，来自腾讯、快手、字节跳动、好未来、七牛云和蓝色光标等多家企业的技术专家在 NextArch 基金会成立微服务技术小组，共同探讨各自企业在微服务领域中遇到的问题，分享大家在生产过程中的实践经验，并且面向不同的应用场景和终端用户，联合相关开源社区输出标准化的解决方案。\n在采用微服务架构之前，我们需要思考为什么采用微服务架构，并不是所有的开发团队和发展阶段都适合采用微服务架构。通常，采用微服务架构可以解决以下问题：首先，开发团队具有一定的规模，所有成员共同开发一个单体应用的内耗太高，如果采用微服务架构，每个服务可以由单个或者少数成员独立负责。第二，业务系统的功能模块很多，耦合在一起会增加测试和部署的成本，任何一个模块故障也会导致整个系统故障。第三，功能模块之间的负载无法隔离，容易互相影响，没有办法针对热点模块的计算层或者存储层进行扩容。\n如果我们采用微服务架构，单个服务是⾮常简单的，但是，分布式服务之间的功能调用远⽐单体应用内部更加复杂。在单体应用中，⼀个函数可以调⽤其他任何一个公共函数。在微服务架构中，一个函数只可以调⽤同⼀个微服务的函数。如何实现分布式服务之间的通信是微服务架构的首要问题，构建高性能、高可用的远程调用能力并不容易。值得庆幸的是，已经有 grpc、thrift、tars、go-zero、GoFrame、cloudwego/kitex 和 spring cloud 等大量开源的分布式服务开发框架，这些框架可以帮助终端用户快速地构建微服务。不幸的是，仅仅把服务开发出来并且跑通是不够的，保障大规模服务的稳定运营还需要考虑诸多问题，例如：在分布式架构中如何处理基础设施以及应用层的各种异常、如何实现大规模服务的无损发布和流量调度，如何定位和分析复杂调用链路中出现的问题等。对于中大型企业来说，还存在异构的开发技术栈和运行时环境，存在跨地域和混合云的架构要求，如何在更加复杂的应用场景中解决上述问题，面临更多的挑战。\n目前，这个方向还没有开箱即用的解决方案，终端用户必须在不同的基础设施和适当的工具之间做出抉择，才能解决各种问题。近日，NextArch 微服务技术小组向基金会提交了首个提案，根据各自企业在分布式或者微服务生产实践中的经验和痛点，面向多语言、多框架和异构基础设施，针对不同行业和应用场景输出微服务落地的标准化方案，并且依托相关开源社区提供推荐实现，方便终端用户落地。我们也期待更多企业和开源社区加入 NextArch 基金会，共同探讨分布式或者微服务治理的标准化方案。\n部分 NextArch Microservice SIG 成员引文： PolarisMesh 单家骏\n腾讯云专家工程师，具备 10 年以上中间件研发经验。北极星开源社区（PolarisMesh）联合发起人，负责开源项目的技术规划、代码开发和社区运营等工作。\n自分布式架构发展至今，微服务成为了复杂业务系统的首选模式，在企业得到了充分的生产落地，然而各个微服务框架及工具链，对于微服务治理体系的理解存在差异性，使得业务系统在实现微服务治理上存在较大的成本，同时也不利于微服务技术的沉淀及长期发展。北极星是腾讯自研和开源的微服务治理框架，覆盖了腾讯内部 90% 以上的业务，解决了业务系统因多语言、多框架以及业务差异性所带来的服务治理不一致的问题，在腾讯内部完成了服务发现和治理的标准化。我们期望通过加入 NextArch 基金会这样一个中立组织，可以讨论业界微服务治理的相关实践及解决方案，沉淀出标准化的服务治理体系，促进微服务生态的进一步发展，也期望北极星开源社区可以推动并承载微服务治理标准体系的落地。\ngo-zero 万俊峰\n万俊峰，七牛云技术副总裁，go-zero 开源社区/go-zero 作者。负责 go-zero 框架的规划、代码编写、代码 review、工具链规划、社区建设、开源推广\n微服务在发展了这么多年之后，已经呈现出百花齐放的状态，各种微服务框架和治理能力在很多公司都得到了充分的落地，并带来了巨大的业务价值。但当前的现状也没有形成足够的技术共识和规范，我们需要进一步提炼和抽象微服务的能力，并加以标准化。这样可以更好的沉淀经验，并将各语言的微服务框架提供规划化对接，从而推动微服务技术的进一步发展。同时也期望在 SIG 组织能够更多的讨论微服务落地的各种最佳实践，也期望能够通过 go-zero 开源社区帮助推动共识的微服务治理标准落地。\nGoFrame 郭强\n腾讯高级工程师，GoFrame 开源框架项目发起人及主要贡献者，负责 GoFrame 框架发展规划、社区建设维护、核心代码开发。GoFrame 是一款模块化、高性能、企业级的 Go 基础开发框架。\n微服务是一种架构设计思想，目的是为了有效解决业务复杂度提高带来的项目架构问题。微服务需要解决的不仅是技术问题，也是项目协作问题。在\"微服务化\"过后，项目架构将引入更多的痛点：职责边界界定、服务高效通信、分布事务处理、微服务化治理、服务版本管理、项目迭代协作等等。微服务思想发展至今，这些痛点的解决方案已比较成熟，并且大同小异。NextArch 微服务 SIG 需要做的是在这些方案之上分析共性之处，形成统一化和规范化的解决方案。以帮助企业更快速地实现微服务化，同时，也需要提供一些最佳实践，帮助企业提高在服务化后的项目管理手段。80% 的解决方案抽象，20% 的最佳实践沉淀。\nCloudWeGo 罗广明\n字节跳动微服务架构师，CloudWeGo 开源负责人。CloudWeGo 是一套由字节跳动开源的、可快速构建企业级云原生架构的中间件集合，专注于解决微服务通信与治理的难题，具备高性能、可扩展、高可靠的特点。\n微服务技术发展至今，业界涌现出一大批微服务开发框架、技术和最佳实践。这个多样化是不可避免的，没有一个微服务开发框架能够统一所有的语言，但是微服务架构里面所涉及的服务治理体系，却可以做到统一和规范化。NextArch 微服务 SIG 正是在这样的背景下诞生了，旨在提供统一服务治理体系，解决共性问题，将促进微服务框架和技术的进一步演进和发展。\n","categories":"","description":"CloudWeGo 加入 NextArch 基金会微服务技术小组，推动微服务技术和开源生态的持续发展，针对不同行业和应用场景输出标准化解决方案。","excerpt":"CloudWeGo 加入 NextArch 基金会微服务技术小组，推动微服务技术和开源生态的持续发展，针对不同行业和应用场景输出标准化解决方 …","ref":"/zh/blog/2022/04/01/cloudwego-%E5%8A%A9-nextarch-%E5%9F%BA%E9%87%91%E4%BC%9A%E6%8E%A8%E5%8A%A8%E6%A0%87%E5%87%86%E5%8C%96%E5%BB%BA%E8%AE%BE/","tags":"","title":"CloudWeGo 助 NextArch 基金会推动标准化建设"},{"body":"云原生时代，各行各业的基础架构都在经历微服务架构转型，研发效率和稳定性是所有互联网公司需要考虑的问题。开发者想要搭建微服务，离不开配套的微服务治理，如治理平台、监控、链路跟踪、注册/发现、配置中心、服务网格等。 随着 Golang 逐渐成为云原生时代的主要编程语言，基于 Golang 的微服务中间件在开源社区有着较强的诉求。\n字节跳动也同样面临这些问题。2014 年，字节跳动引入 Golang 解决长连接推送业务面临的高并发问题，两年后，内部技术团队基于 Golang 推出了一个名为 Kite 的框架， 同时对开源项目 Gin 做了一层很薄的封装，推出了 Ginex。字节跳动基础架构/服务框架团队负责人成国柱在 QCon 2021 的分享中表示，这两个原始框架的推出，极大推动了 Golang 在公司内部的应用。\n但是由于关联技术迭代和业务诉求增加，深度耦合的 Kite 和 Thrift ，很难从网络模型或编解码层面改造优化，继续支持新特性势必会造成代码臃肿、迭代受阻问题。 2019 年下半年，字节跳动技术团队开始重新设计 Golang RPC 框架，同时为了在网络通信上有更好的性能并能支持连接多路复用、感知连接状态，自研了网络库 Netpoll。\n字节跳动重构 Kite 为 Kitex ，围绕性能和可扩展性设计，并在次年 10 月完成发布，投入到内部应用中。 据悉，截至 2021 年 9 月，线上有 3w+ 微服务使用 Kitex，大部分服务迁移新框架后可以收获 CPU 和延迟上的收益。\n“在 Kitex 得到内部广泛使用后，我们决定围绕微服务逐步把我们的实践开源出去，并且对外保持统一。 ”字节跳动 CloudWeGo 技术专家谈道，“但微服务相关的项目较多，每个项目单独开源对外部用户并不友好，因此我们以 CloudWeGo 作为项目名，逐步将内部整个微服务体系开源，内外统一使用开源库，各项目以开源库为主进行迭代。”\n2021 年 9 月 8 日，字节跳动宣布正式开源 CloudWeGo。\n中间件“工具箱”CloudWeGo CloudWeGo 是一套字节跳动内部微服务中间件集合，具备高性能、强扩展性和稳定性的特点，专注于解决微服务通信与治理的难题，满足不同业务在不同场景的诉求。 此外，CloudWeGo 也重视与云原生生态的集成，支持对接 K8s 注册中心、Prometheus 监控以及 OpenTracing 链路追踪等。\n目前，CloudWeGo 第一批开源了四个项目：Kitex、Netpoll、Thriftgo 和 netpoll-http2， 以 RPC 框架 Kitex 和网络库 Netpoll 为主。Kitex 内置了部分治理策略以及丰富的扩展接口，便于融入微服务体系中；Netpoll 主要面向对高性能有诉求的场景。\nCloudWeGo 的每一个组件都可以单独使用。“很多人担心 Kitex 是一个很重的框架，其实 Kitex 没有耦合任何其他组件包括 Netpoll，Kitex 内置的一些治理能力，用户也可以选择性集成。 Netpoll 作为一个网络库，其他 RPC 框架、HTTP 框架都可以单独接入使用。Thriftgo 是 Thrift IDL 解析和代码生成器，也是独立的工具，并且提供插件机制，用户可定制生成代码。” 字节跳动 CloudWeGo 技术专家表示，“我们会继续开源其他内部项目，如 HTTP 框架 Hertz、基于共享内存的 IPC 通信库 ShmIPC 等，提供更多场景的微服务需求支持。”\nCloudWeGo 的优势和局限 微服务中间件和业务紧密联系，是整个业务架构的基础，在进行技术选型时必须慎重。业内公认的选型标准关键在于两方面：\n 能解决实际业务问题和上生产抗流量，且易用性高、可治理、成熟稳定 技术是开源的，且开源项目的 star 数、项目活跃度（Issue\u0026PR）、文档更新频率、发版周期稳定可靠  CloudWeGo 的优势在于，已经在字节跳动经过大规模生产流量验证，有可以参考的稳定性和可靠性实际案例。“CloudWeGo 的特点之一是高性能，但实际上在开发之初它经常遇到性能瓶颈， 于是内部专门进行了网络库、Thrift 序列化的专项优化，优化的过程会比较漫长，一个瓶颈点要花很长时间反复测试调整实现，我们也发过两篇文章《字节跳动 Go RPC 框架 Kitex 性能优化实践》和《字节跳动在 Go 网络库上的实践》分享了优化实践。”字节跳动 CloudWeGo 技术专家表示。\n据悉，与同类型项目相比，CloudWeGo 开发团队不仅考虑了高性能、强扩展性，还考虑到了易用性。“以 Kitex 为例，目前从治理功能的多样性上不及一些开源框架， 从性能、扩展性、使用体验多维度综合来看，Kitex 具有一定的优势。Kitex 支持多协议，由于内部以 Thrift 为主，Kitex 对 Thrift 支持也做了性能优化， 如果使用 Thrift，Kitex 将是最佳的选择。”字节跳动 CloudWeGo 技术专家告诉 InfoQ。\n此外，为了遵守长期投入承诺，内外维护一套代码、统一迭代，字节跳动已经将与内部生态没有耦合的项目直接迁移到 CloudWeGo 开源库，并将内部依赖调整为开源库。 而对于需要集成治理能力融入微服务体系的 Kitex，开源团队则对内外部代码做了拆分，把 Kitex 的核心代码迁移到开源库，内部库封装一层壳保证用户无感知升级， 而集成内部治理特性的模块则作为 Kitex 的扩展保留在内部库。未来，字节跳动也会持续把已经在内部经过稳定性验证的新特性，迁移到开源库。\n在字节跳动内部，为了便于 Kitex 融入内部的治理体系，Kitex 面向内部提供了 Byted Suite 扩展，集成内部的注册中心、配置中心、监控等，内部 ServiceMesh 已经得到了大规模落地， Kitex 会根据服务的信息判断是否是 ServiceMesh 模式，若是，Kitex 则会卸载治理组件，治理能力下沉至 Mesh 中。 为了提高与 ServiceMesh 通信的性能，Kitex 单独扩展 TransHandler 模块集成内部实现的 ShmIPC，与 ServiceMesh 通信走 ShmIPC ，后续 Kitex 对 ShmIPC 的扩展以及 ShmIPC 库也会开源出来。\n不过 CloudWeGo 依然有自己的局限性。字节跳动 CloudWeGo 技术专家告诉 InfoQ：CloudWeGo 功能的丰富度和多样性还不够，还需要进一步完善，字节跳动技术团队会收集外部用户的需求，评估排期支持，期待更多的开发者加入。 目前 Kitex Server 性能优势明显，但 Client 相比 Server 性能表现不佳，后续会重点对 Client 进行优化。此外，基于不同的语言框架，默认场景必须能兼容互通而非性能最佳。 “刚开源时得到大家的关注，看到一些压测对比显示 Kitex 性能表现一般，主要是压测场景未对齐，后续我们也会考虑面向开源尽量提供性能较优的策略。”\n“开源”不是为了“完成 KPI ” 目前，CloudWeGo 在社区中也比较有活力。据悉，在未被正式宣布开源前，一个月内 Kitex 收获了 1.2k stars，Netpoll 收获了 700+ stars。 9 月 8 日，字节跳动正式宣布开源 CloudWeGo 后，截至 10 月初，项目整体 star 数已经超过 4800，且已被收录进 CNCF landscape。\n字节跳动 CloudWeGo 技术专家表示：“我们收到了来自社区的大量反馈，如很多用户对 Protobuf 的诉求较为强烈，我们已经针对这个问题，计划开展 Kitex 对 Protobuf 支持的性能优化。 欢迎大家向 CloudWeGo 提交 issue 和 PR，共建 CloudWeGo。我们也为企业和组织使用 Kitex 和 Netpoll 设置了专项支持，希望 CloudWeGo 将来能真正成为通用的、可落地的微服务通信与治理开源方案。”\n关于开源，字节跳动 CloudWeGo 技术专家的观点旗帜鲜明：“完成 KPI 不是这个项目开源的目的。健康的开源模式注重开放共享，共同成长和长期主义。CloudWeGo 认同个体参与、社区价值以及开源共同体带来的归属感。”\n“字节跳动作为开源项目的受益者、参与者，也希望成为开源项目的推动者、主导者，将内部优秀的最佳实践反馈给开源社区，与社区共同建设、丰富基础架构领域开源生态，为广大开发者和企业在技术选型时提供更多更优的选择。” 字节跳动 CloudWeGo 技术专家谈道，“我们拥抱开源的文化，倾听社区的反馈，积极响应用户的需求，并且提供友好的中英文文档和快速开发 guideline，为社区开发者快速深入了解 CloudWeGo 以及参与贡献提供便利与支持。”\n项目地址：https://github.com/cloudwego\n受访嘉宾: 字节跳动 CloudWeGo 技术专家罗广明、杨芮、马子昂\n原文链接: https://www.infoq.cn/article/9ixlu4kjapg3ufhymm3j\n","categories":"","description":"本文通过访谈的方式以外部视角介绍字节跳动微服务中间件 CloudWeGo 的开源背景、优势和局限以及开源目标等。","excerpt":"本文通过访谈的方式以外部视角介绍字节跳动微服务中间件 CloudWeGo 的开源背景、优势和局限以及开源目标等。","ref":"/zh/blog/2022/03/28/%E4%B8%80%E6%96%87%E4%BA%86%E8%A7%A3%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6-cloudwego/","tags":"","title":"一文了解字节跳动微服务中间件 CloudWeGo"},{"body":"In the cloud native era, infrastructures across all industries are undergoing a microservice architecture transformation, and all internet companies are concerned about R\u0026D efficiency and stability. Developers who want to build microservices can never forgo supporting microservice governance, such as governance platforms, monitoring, tracing, registration/discovery, configuration centers, service mesh, etc. With Golang gradually becoming the dominating programming language in the cloud native era, there is a strong demand for Golang-based microservices middleware in the open source community.\nByteDance also faces these problems. In 2014, ByteDance introduced Golang to solve the high concurrency problem faced by push services with persistent connections; and two years later, the technical team launched a framework called Kite based on Golang, and rolled out Ginex after lightly encapsulating the open-source project Gin. In QCon 2021, Guozhu Cheng, the head of ByteDance’s infrastructure/service framework team, said that the launch of these two original frameworks has greatly promoted Golang’s adoption within the company.\nHowever, due to evolutions of related technologies and demanding business requirements, the deeply coupled Kite and Thrift are difficult to be transformed and improved on the network model or codec level, and therefore continuous feature delivery will inevitably cause code bloat and blocked iterations. In the second half of 2019, the ByteDance technical team began to redesign the Golang RPC framework. At the same time, in order to get better performance in network communication, support connection multiplexing and sense connection status, they developed their own network library Netpoll.\nByteDance refactored Kite as Kitex, designed revolving around performance and scalability, and released it in October 2020 for internal use. As of September 2021, there are 30, 000+ online microservices using Kitex, most of which can benefit from boosted CPU and alleviated latency after using the new framework.\n“After Kitex became widely used within ByteDance, we decided to gradually entail our practice open-source revolving around microservices and keep it in line with the outside.” ByteDance CloudWeGo technical experts said, “But there are many microservice-related projects, and each project is open-source alone, which is not friendly to external users. So we named the project as CloudWeGo and gradually enabled the entire internal microservice system to be open-source, using open-source libraries internally and externally. Each project iterates mainly with open-source libraries.”\nOn September 8, 2021, ByteDance officially announced the open source CloudWeGo.\nCloudWeGo CloudWeGo is a set of microservice middleware developed by ByteDance with high performance, strong scalability and stability. It focuses on microservice communication and governance, and meets the demands of different businesses in various scenarios. CloudWeGo also focuses on integration with the cloud native ecology, supporting K8s registry, Prometheus, and OpenTracing.\nCloudWeGo currently has 4 repositories: Kitex, Netpoll, Thriftgo and netpoll-http2, featuring the RPC framework – Kitex and the network library – Netpoll. Kitex is equipped with built-in governance strategies and expansion interfaces for frictionless integrations into the microservice system. Netpoll is aimed at scenarios where demand high performance.\nEach component of CloudWeGo can be used separately. “Many people worry that Kitex would be a heavy-weight framework. In fact, Kitex does not couple any other component including Netpoll. Users can also optionally integrate some of Kitex’s built-in governance functions. Netpoll is a network library that can work separately with other RPC frameworks and HTTP frameworks. Thriftgo is a Thrift IDL parser and code generator. It is also a stand-alone tool and provides a customizable, plug-in mechanism for the code generation.” ByteDance CloudWeGo technical experts said, “We will continue to move all other internal projects to the open-source track, such as HTTP framework Hertz, shared memory-based IPC communication library ShmIPC, etc., to provide microservices support for wider scenarios.”\nAdvantages \u0026 Disadvantages The close connection between microservice middleware and business is the foundation of the entire business architecture; so the selection of technology requires special care. Our selection criteria mainly depend on two aspects：\n It can address practical business problems and is ready for production with massive traffic, and is easy to use, governable, mature and stable. The technology is open-source; and the number of Stars, project activity (Issues \u0026 PRs), document update frequency, and release cycle of the open-source project are stable and reliable.  The advantage of CloudWeGo is that it has already been tested with massive traffic amid the real production deployment in ByteDance. Providing a practical example that can be referred to attest for its stability and reliability. “One of the characteristics of CloudWeGo is high performance, but at the beginning of the development, we often confront performance bottlenecks. So we improved network library and Thrift serialization specifically. The optimization process was prolonged, with a bottleneck taking a long time to test and fine-tune repetitively. We have also published two articles “ByteDance Go RPC Framework Kitex Performance Optimization Practice” and “ByteDance on the Go Network Library Practice” to share our optimization practices.” ByteDance CloudWeGo technical experts said.\nCompared to similar projects, the CloudWeGo R\u0026D team considered not only its performance and strong scalability, but also ease of use. “Taking Kitex as an example, it is currently inferior to some open-source frameworks in terms of the diversity of governance functions. But from the perspective of performance, scalability, and user experience, Kitex showcases the following advantages. Kitex supports a variety of protocols, because it mainly applies Thrift. Kitex has also made performance improvements for Thrift support. If using Thrift, Kitex will be the best choice.” ByteDance CloudWeGo technical experts remark on the benefits of using CloudWeGo.\nIn addition, in order to uphold a key principle of maintaining one set of code internally and externally, iterating them as a whole, ByteDance has directly migrated projects without coupling the internal ecology to the CloudWeGo open-source library, and adapt the internal dependency for the open-source library. For Kitex, which requires integrated governance functions into the microservice system, the open-source team split the internal and external code, migrating Kitex’s core code to the open source library. The internal library encapsulates a shell to ensure that updates are transparent to users. And the modules that integrate internal governance features are retained in the internal library as extensions of Kitex. In the future, ByteDance will continue to migrate new features that have been internally validated for stability to open-source libraries.\nInside ByteDance, in order to facilitate Kitex’s integration into the internal governance system, Kitex provides a Byted Suite extension, integrating the internal registry, configuration center, monitoring, etc. Internal Service Mesh has been implemented on a large scale. Kitex determines whether it is a Service Mesh mode based on the information of the service, if so, Kitex will uninstall the governance components, and the governance functions will sink into Service Mesh. As an attempt to speed up the performance of communication with Service Mesh, Kitex separately extends the TransHandler module to integrate the self-developed ShmIPC, and communicates with Service Mesh through ShmIPC. Subsequently, Kitex’s extension to ShmIPC and the ShmIPC library will also be open-source.\nHowever, CloudWeGo has its own limitations. ByteDance CloudWeGo technical experts told InfoQ: The richness and diversity of CloudWeGo functions are not enough, pending further improvement. ByteDance’s technical team will solicit the needs of external users, provide support, and welcome more developers to contribute. At present, the performance advantages of Kitex Server are obvious, but the performance of the Client side with Server, and we will focus on improving the Client in the future. The primary goal is to make default scenarios compatible with each other, with negligible performance overhead. “The launch of the open source has attracted public attention, and we observed some stress test comparisons showing that Kitex performance was mediocre, mainly because the stress test scenario was not aligned. We will consider providing better performance strategies for the open-source community.”\nOpen Source is Not About Completing KPIs At present, CloudWeGo is dynamic in the community. Before the official announcement of open source, Kitex gained 1.2k stars and Netpoll gathered 700+ stars within one month. After ByteDance officially announced the open source CloudWeGo on September 8, as of early October, the overall number of stars in the project has exceeded 4,800 and has been included in the CNCF landscape. The overall star number of the project has exceeded 4800, and it has been included in the CNCF landscape.\nByteDance CloudWeGo technical experts said, “We have received a lot of feedback from the community. For example, many users call for Protobuf. In response to this feedback, we plan to implement Kitex performance optimizations for Protobuf support. We welcome you to submit issues and PRs to CloudWeGo. We’ve also set up customized support for enterprises and organizations to use Kitex and Netpoll, and hope that CloudWeGo will truly become a universal, available open-source solution to microservices communication and governance in the future.”\nRegarding “open source”, ByteDance CloudWeGo technology experts have a clear vision: “Completing KPIs is not the purpose of this open source project.” A healthy open-source model focuses on open sharing, co-growth, and long-termism. CloudWeGo recognizes individual participation, community values, and the sense of belonging brought by open source community.\"\n“As a beneficiary and participant of the open source project, ByteDance also hopes to become a promoter and leader of the open source project. It hopes to gift excellent internal practices to the open source community, build and enrich the open source ecosystem in the infrastructure field together with the community, and provide wider and better choices for developers and enterprises for their technology selection.” ByteDance CloudWeGo technology experts said, “We embrace the open source culture, listen to community feedback, actively meet user’s needs, provide Chinese and English documentations, and develop guidelines quickly, to facilitate and support community developers to understand CloudWeGo and participate in contributions.”\nProject address: https://github.com/cloudwego\nInterviewees: ByteDance CloudWeGo technical experts (Guangming Luo, Rui Yang, Ziang Ma).\nReference link: https://www.infoq.cn/article/9ixlu4kjapg3ufhymm3j\n","categories":"","description":"This blog introduces the open-source background, advantages, limitations and goals of CloudWeGo from an external perspective through interviews.","excerpt":"This blog introduces the open-source background, advantages, …","ref":"/blog/2022/03/25/an-article-to-learn-about-bytedance-microservices-middleware-cloudwego/","tags":"","title":"An Article to Learn About ByteDance Microservices Middleware CloudWeGo"},{"body":"Bugfix  [#383 ] fix(generic): detect circular dependency in thrift IDL when using generic call. [#359 ] fix(tool): fix streaming import missing in protobuf combine service. [#363 ] fix(client): fix a bug that sequence ID of oneway requests are not encoded and lower the loss rate of oneway requests. [#367 ] fix(generic/tool): combine services may have duplicate loading of the same service.  Optimise  [#362 ] optimize(diagnosis): lbcache is global, it doesn’t need register ProbeFunc for diagnosis. [#374 ] optimize(rpcinfo): RPCInfo.To().Tag() use instance tag instead of remoteinfo tag firstly. [#355 ] optimize(connpool): adjust minMaxIdleTimeout to 2s. [#354 ] optimize(hook): adding locks to onServerStart and onShutdown, acquire the corresponding lock when doing some read and write operations like RegisterStartHook and range in server.Run(). [#331 ] optimize(discovery): add error definition ErrInstanceNotFound which is used in the service discovery module.  Refactor  [#352 ] refactor(event): delete additional atomic operations and replace them with a normal operation. [#343 ] refactor(loadbalancer): merge BuildWeightedVirtualNodes function into buildVirtualNodes function, make it easier to maintain.  Chore  [#376 ] chore: upgrade choleraehyq/pid for Go 1.18.  Docs  [#364 ] docs: update readme with new blog.  ","categories":"","description":"","excerpt":"Bugfix  [#383 ] fix(generic): detect circular dependency in thrift IDL …","ref":"/blog/2022/03/24/kitex-release-v0.2.1/","tags":"","title":"Kitex Release v0.2.1"},{"body":"Bugfix  [#383 ] 修复(generic)：在泛化调用的时候检查 IDL 是否有循环依赖。 [#359 ] 修复(tool)：修复 protobuf CombineService 缺失 streaming 引用的问题。 [#363 ] 修复(client)：修复 oneway 请求的 sequence ID 没有被编码的问题以及降低 oneway 调用的丢包率。 [#367 ] 修复(generic/tool)：修复 CombineServices 可能存在多次加载同一个 service 问题。  Optimise  [#362 ] 优化(diagnosis)：lbcaches 是全局的，无需为每个 client 注册 ProbeFunc 用于诊断查询。 [#374 ] 优化(rpcinfo)：RPCInfo.To().Tag() 优先使用服务发现的 instance tag 而不是 remoteinfo tag。 [#355 ] 优化(连接池)：修改默认的连接池最小空闲等待时间为 2s。 [#354 ] 优化(hook)：为 onServerStart和 onShutdown添加资源锁，当做一些如RegisterStartHook和 server.Run中的 range之类的读写操作时请求对应的资源锁。 [#331 ] 优化(discovery)：增加「实例不存在」错误定义。  Refactor  [#352 ] 重构(event)：删除额外的原子操作并用普通赋值操作替换。 [#343 ] 重构(loadbalancer)：将 buildWeightedVirtualNodes 函数合入 buildVirtualNodes 函数中，成为一个函数。  Chore  [#376 ] 升级依赖 choleraehyq/pid 以兼容Go 1.18。  Docs  [#364 ] 更新 README 到新博客的链接。  ","categories":"","description":"","excerpt":"Bugfix  [#383 ] 修复(generic)：在泛化调用的时候检查 IDL 是否有循环依赖。 [#359 ] 修复(tool)：修 …","ref":"/zh/blog/2022/03/24/kitex-v0.2.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.2.1 版本发布"},{"body":"Feature  Feat(grpc): support options to set the internal params of gRPC Feat(kerror): add new func WithCauseAndExtraMsg for basicError Feat(rpcinfo): add FreezeRPCInfo to support asynchronous context usage Feat(codec): default codec supports size limit  Bugfix  Fix(remotecli): fix bug that released connections may be reused Fix(generic): generic call supports extended services Fix(generic): fix generic call oneway flag  Optimise  Optimize(retry): improve retry success rate when do failure retry  Chore  Chore: upgrade netpoll to v0.2.0 Chore:add third party license  ","categories":"","description":"","excerpt":"Feature  Feat(grpc): support options to set the internal params of …","ref":"/blog/2022/02/24/kitex-release-v0.2.0/","tags":"","title":"Kitex Release v0.2.0"},{"body":"Feature  Feat(grpc): gRPC 相关配置支持通过 options 来设置，并且为了兼容旧版本默认窗口大小调整为 64K Feat(kerror): 为 basicError 添加新的 error 封装 func WithCauseAndExtraMsg Feat(rpcinfo): 添加 FreezeRPCInfo 以支持异步 context 使用 Feat(codec): 默认编解码器支持限定包体积大小  Bugfix  Fix(remotecli): 修复重置的连接可能被复用的问题 Fix(generic): 修复泛化调用的客户端不能使用继承的 service 的方法的问题 Fix(generic): 修复泛化调用 client 侧判断 Oneway 不准确的问题  Optimise  Optimize(retry): 提高异常重试的重试成功率   如果超时的请求先于重试的请求返回，可能会导致重试请求也失败；同时也可以避免超时请求不必要的解码处理。\n Chore  Chore: 升级 netpoll 的版本至 v0.2.0 Chore: 添加第三方库的license  ","categories":"","description":"","excerpt":"Feature  Feat(grpc): gRPC 相关配置支持通过 options 来设置，并且为了兼容旧版本默认窗口大小调整为 64K …","ref":"/zh/blog/2022/02/24/kitex-v0.2.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.2.0 版本发布"},{"body":"Improvement  Feat: on connect callback Feat: new conn api - Until Feat: support dialing without timeout  Fix  Fix: trigger close callback if only set the onConnect callback Fix: add max node size to prevent OOM Fix: FDOperator.reset() not reset op.OnWrite Fix: Write panic when conn Close Fix: unit tests may fail  Chore  docs: update readme  ","categories":"","description":"","excerpt":"Improvement  Feat: on connect callback Feat: new conn api - Until …","ref":"/blog/2022/02/22/netpoll-release-v0.2.0/","tags":"","title":"Netpoll Release v0.2.0"},{"body":"Improvement  Feat: 添加 OnConnect 回调 Feat: 新增 Until API Feat: 支持不带 timeout 的 dial  Fix  Fix: 修复当只设置了 onConnect 回调时，不会触发 close callback 的 bug Fix: 添加最大节点限制，避免异常情况下的 OOM 问题 Fix: 修复 reset operator 时，没有 reset OnWrite 的问题 Fix: 修复连接关闭时，写 panic 的问题 Fix: 修复单测失败问题  Chore  docs: 更新 readme  ","categories":"","description":"","excerpt":"Improvement  Feat: 添加 OnConnect 回调 Feat: 新增 Until API Feat: …","ref":"/zh/blog/2022/02/22/netpoll-v0.2.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Netpoll v0.2.0 版本发布"},{"body":"Improvement  Optimize(log): don’t print timeout log in rpctimeout middleware Optimize(log): adjust default log level to info Optimize(gRPC): lock the sendAt avoid grpc bdp data race  Bugfix  Fix(client-connection): fix a connection leaking bug that happens when clients fail at Send Fix(timeout): fix TimeoutAdjust won’t work when set in middleware builder  Tool  Fix(tool): fix protobuf handler arguments name   kitex will generate a stream type named “{{.ServiceName}}{{.Name}}Server” for each streaming server, but in handler.go kitex use “{{.ServiceName}}{{.RawName}}Server” as stream name.\n Chore  Style: remove unnecessary type conversions  ","categories":"","description":"","excerpt":"Improvement  Optimize(log): don’t print timeout log in rpctimeout …","ref":"/blog/2022/01/18/kitex-release-v0.1.4/","tags":"","title":"Kitex Release v0.1.4"},{"body":"功能优化  在 rpctimeout 的 middleware 的输出日志中过滤掉超时日志 调整默认日志级别为 Info 给 sentAt 变量加锁，避免单测出现 DATA RACE，实际上不会有并发问题  Bug 修复  修复客户端编码失败时连接会泄漏的问题 修复 middleware builder 中设置 TimeoutAdjust 不生效的问题  工具  修复 protobuf 的 handler 参数名   kitex 会给每个 stream server 生成一个名为 “{{.ServiceName}}{{.Name}}Server” 的 stream 类型， 但是在 handler.go 中使用的是 “{{.ServiceName}}{{.RawName}}Server\n Chore  删除不必要的类型转换  ","categories":"","description":"","excerpt":"功能优化  在 rpctimeout 的 middleware 的输出日志中过滤掉超时日志 调整默认日志级别为 Info 给 sentAt  …","ref":"/zh/blog/2022/01/18/kitex-v0.1.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.1.4 版本发布"},{"body":"Overview Fixed connection leak when client encoding failed\nSeverity Level Low\nDescription Fixed connection leak when client encoding failed\nSolution When client encoding fails, the connection is released\nAffected Components kitex-v0.1.3\nCVE None\nReferences  https://github.com/cloudwego/kitex/pull/315  ","categories":"","description":"Connection Leaking","excerpt":"Connection Leaking","ref":"/security/safety-bulletin/detail/cloudwego-sa-2022-1/","tags":"","title":"CloudWeGo-SA-2022-1"},{"body":"简介 修复客户端编码失败时连接会泄漏的问题\n严重级别 Low\n描述 修复客户端编码失败时连接会泄漏的问题\n解决办法 当客户端编码失败时，释放连接\n影响组件 kitex-v0.1.3\nCVE 无\n参考链接  https://github.com/cloudwego/kitex/pull/315  ","categories":"","description":"Connection Leaking","excerpt":"Connection Leaking","ref":"/zh/security/safety-bulletin/detail/cloudwego-sa-2022-1/","tags":"","title":"CloudWeGo-SA-2022-1"},{"body":"Feature  Transmit the Base from client to server for getting the caller info in JSON generic  Bugfix  Fix(grpc): fix metric missing method tag in streaming Fix(generic): fix the incompatible modification about base64 binary in the JSON and HTTP generic Fix(grpc): fix the bug of grpc flow control, which brings the problem of continuous timeout  CI  Add scenario tests  Chore  update the ROADMAP  ","categories":"","description":"","excerpt":"Feature  Transmit the Base from client to server for getting the …","ref":"/blog/2021/12/30/kitex-release-v0.1.3/","tags":"","title":"Kitex Release v0.1.3"},{"body":"功能优化  JSON 泛化调用场景，向服务端传递 Base 信息，从而服务端可获取 Caller 等信息  Bug 修复  修复 streaming 的 metric 上报（server侧）丢失 method 信息的问题 修复 JSON 和 HTTP 泛化中 base64 和 binary 的不兼容改动 修复 gRPC 流控相关的问题，该问题会导致 client 侧出现持续超时  CI  增加场景测试  Chore  更新了 ROADMAP  ","categories":"","description":"","excerpt":"功能优化  JSON 泛化调用场景，向服务端传递 Base 信息，从而服务端可获取 Caller 等信息  Bug …","ref":"/zh/blog/2021/12/30/kitex-v0.1.3-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.1.3 版本发布"},{"body":"Hotfix  Fix some gRPC request bugs which are involved by v0.1.0 Fix mistake gRPC method path when no package definition in IDL  Dependency Change  Chore: upgrade netpoll-http2 to fix the problem about large request package (\u003e4K) in streaming  Chore  Chore: use GitHub’s PULL_REQUEST_TEMPLATE to create a PR  ","categories":"","description":"","excerpt":"Hotfix  Fix some gRPC request bugs which are involved by v0.1.0 Fix …","ref":"/blog/2021/12/22/kitex-release-v0.1.2/","tags":"","title":"Kitex Release v0.1.2"},{"body":"Hotfix  修复 v0.1.0 gRPC 请求优化引入的部分问题 修复 IDL 中未定义 package 时，gRPC 的方法信息错误问题  依赖更新  更新 netpoll-http2 依赖，解决 streaming 场景下大包（\u003e4K）请求报错的问题  杂项  使用 GitHub 的 PR 模板，强制开发者提交 PR 时填写相关描述  ","categories":"","description":"","excerpt":"Hotfix  修复 v0.1.0 gRPC 请求优化引入的部分问题 修复 IDL 中未定义 package 时，gRPC 的方法信息错误问 …","ref":"/zh/blog/2021/12/22/kitex-v0.1.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.1.2 版本发布"},{"body":"Feature Generic Call  Support combined services Export SetSeqID and add GetSeqID for binary generic call of server side Support close generic client to avoid memory leak  Log  Use key=value style in log messages Use klog as global log in some logs Use the global default logger across kitex Print detail loginfo by ctx Pass service info to go func which is used to output for troubleshooting  Option  Add NewThriftCodecDisableFastMode to disable FastWrite/Read Add server option - WithReusePort Default rpc timeout = 0  Proxy  Proxy add ContextHandler interface to support passing initialization context to mwBuilder Register Dump in lbcache to diagnosis Pass RPCConfig to proxy.Config  Improvement  Reduce heap allocation Optimize mux performance Recycle grpc codec buffer by close linkbuffer Distinguish ErrRPCFinish in cost info of backup request Move mux.ShardQueue to netpoll, rename sharedMap to shardMap Add container length encoding guard in fast api  Bugfix  Enable server error handle middleware Adjust Balancer initialization in lbcache Init TraceCtl when it is nil (only affect unit test) Set default rpctimeout and disable timeout logic if rpctimeout == 0 Defaultlogger wrong calldepth Rename BackwardProxy to ReverseProxy Avoid nil panic in grpc keepalive Fix hidden dangers about grpc Fix exception missing in void method Fix mistake dump info when instances change.  Docs  Fix link in readme_zh Remove docs; maintain cloudwego.io only  Netpoll API Change  Adapt netpoll.Writer.Append API  Dependency Change  github.com/cloudwego/netpoll: v0.0.4 -\u003e v0.1.2  ","categories":"","description":"","excerpt":"Feature Generic Call  Support combined services Export SetSeqID and …","ref":"/blog/2021/12/13/kitex-release-v0.1.0/","tags":"","title":"Kitex Release v0.1.0"},{"body":"功能 泛化调用  IDL 解析支持多 Service 暴露 SetSeqID 方法便于二进制泛化场景 server 侧使用 泛化 client 支持关闭，规避内存泄漏问题  日志  修改日志风格，使用 “key=value” 列出信息 使用 klog 作为全局的日志输出工具 使用全局的 default logger 日志打印更多 context 信息，例如 logId，方便问题排查 go func 传入服务信息用于 recover panic 后输出关键信息方便问题排查  Option  增加 NewThriftCodecDisableFastMode 方法，来关闭 FastWrite 和 FastRead Kitex server 支持端口复用 默认 RPC 超时设置为 0（在后续 PR 中，revert 了该变更）  Proxy  Proxy 增加 ContextHandler 接口用于传递初始化ctx给 mwbuilder 注册 lbcache 的 Dump 给 diagnosis，用于问题诊断 将 PRCConfig 传递给 proxy.Config  优化  减少了对象的堆分配 优化多路复用性能 优化 grpc 编解码性能，通过 Release 时释放(Close) LinkBuffer 在计算 backup request 的消耗(cost)时，区分 ErrRPCFinish 多路复用分片队列逻辑移动至 netpoll/mux，并重命名分片字典 优化Fast api中容器类型的长度编码逻辑  Bug 修复  修复 server 端 WithErrorHandler 配置不生效问题 调整 lbcache 中的 Balancer 初始化逻辑 修复 TraceCtl 可能为 nil 的问题(仅影响单测) 设置默认的 rpc timeout, 并支持设置 WithRPCTimeout(0) 来关闭超时中间件 修复 default logger 使用错误的 call depth 重命名 BackwardProxy 为 ReverseProxy 修复 grpc 场景下的 panic 修复 grpc 场景下的潜在风险（keepalive 超时导致 panic） 修复 void 方法中的异常缺失 修复实例变更时 dump 信息不正确问题。  文档  修复失效的中文链接 将全部 doc 移至官网 cloudwego.io  Netpoll API Change:  适应 netpoll.Writer.Append 的 API 改动，返回值从 2个 变为 1个  依赖变化  github.com/cloudwego/netpoll: v0.0.4 -\u003e v0.1.2  ","categories":"","description":"","excerpt":"功能 泛化调用  IDL 解析支持多 Service 暴露 SetSeqID 方法便于二进制泛化场景 server …","ref":"/zh/blog/2021/12/13/kitex-v0.1.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.1.0 版本发布"},{"body":"Hotfix  check args in LinkBuffer API  ","categories":"","description":"","excerpt":"Hotfix  check args in LinkBuffer API  ","ref":"/blog/2021/12/13/netpoll-release-v0.1.2/","tags":"","title":"Netpoll Release v0.1.2"},{"body":"Bug 修复:  LinkBuffer 增加了空值校验  ","categories":"","description":"","excerpt":"Bug 修复:  LinkBuffer 增加了空值校验  ","ref":"/zh/blog/2021/12/13/netpoll-v0.1.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Netpoll v0.1.2 版本发布"},{"body":"Improvement  enhance mux shard queue  Bugfix  book never reset readnode  Chore  update readme  ","categories":"","description":"","excerpt":"Improvement  enhance mux shard queue  Bugfix  book never reset …","ref":"/blog/2021/12/09/netpoll-release-v0.1.1/","tags":"","title":"Netpoll Release v0.1.1"},{"body":"优化:  优化了多路复用下，分片队列的性能  Bug 修复:  修复了 book 方法在多路复用下的 bug  文档  修正了一些大小写和语法问题，并更新了链接  ","categories":"","description":"","excerpt":"优化:  优化了多路复用下，分片队列的性能  Bug 修复:  修复了 book 方法在多路复用下的 bug  文档  修正了一些大小写和语 …","ref":"/zh/blog/2021/12/09/netpoll-v0.1.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Netpoll v0.1.1 版本发布"},{"body":"Improvement  add mux.ShardQueue to support connection multiplexing input at a single LinkBuffer Node to improve performance fix waitReadSize logic bug and enhance input trigger reduce timeout issues when waitRead and inputAck have competition unify and simplify conn locks  Bugfix  ensure EventLoop object will not be finalized before serve return  Chore  update readme update issue templates  Breaking Change  remove WriteBuffer() returned parameter n  ","categories":"","description":"","excerpt":"Improvement  add mux.ShardQueue to support connection multiplexing …","ref":"/blog/2021/12/01/netpoll-release-v0.1.0/","tags":"","title":"Netpoll Release v0.1.0"},{"body":"功能:  增加了分片队列，用于支持连接多路复用 优化方案：尽可能的维护单节点 LinkBuffer 来减少 copy 优化方案：修复了 waitReadSize 的 bug，并优化了 input trigger 效率 优化方案：减少了 waitRead 和 inputAck 冲突时产生的超时错误 逻辑简化：简化了连接状态机  Bug 修复:  修复了 eventLoop 提前 GC 的 bug  文档  更新 README，将 Performance 部分移动至 netpoll-benchmark 项目 更新了 reference，添加了官网信息，移除了 change log  重大变更  WriteBuffer 返回值由 (n int, err error) 改为 (err error)  ","categories":"","description":"","excerpt":"功能:  增加了分片队列，用于支持连接多路复用 优化方案：尽可能的维护单节点 LinkBuffer 来减少 copy 优化方案： …","ref":"/zh/blog/2021/12/01/netpoll-v0.1.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Netpoll v0.1.0 版本发布"},{"body":" On September 8, 2021, ByteDance announced the launch of CloudWeGo open source project. CloudWeGo is a set of microservice middleware developed by ByteDance with high performance, strong scalability and stability. It focuses on microservice communication and governance, and meets the demands of different services in various scenarios. CloudWeGo currently has 4 Repos: Kitex, Netpoll, Thriftgo and netpoll-http2, featuring the RPC framework – Kitex and the network library – Netpoll.\n Recently, ByteDance Service Framework Team officially announced the open source of CloudWeGo. It includes the Golang microservice RPC framework – Kitex, which has been deeply used in Douyin and Toutiao.\nThis article aims to share the scenarios and technical issues that developers need to know when stress testing Kitex. These guides will help users adjust and optimize Kitex to better match their business needs, and maximize Kitex’s performance in real RPC scenarios. Users can also refer to the official stress test project – kitex-benchmark for more details.\nThe Characteristics of Microservice Scenario Kitex was born in ByteDance’s large-scale microservices architecture practice. The scenario it is aimed at is naturally a microservices scenario. Therefore, the following will first introduce the characteristics of microservices, so that developers can understand Kitex’s design thinking in depth.\n RPC Communication Model  The communication between microservices is usually based on PingPong model. So, in addition to the conventional throughput performance index, developers also need to consider the average latency of each RPC.\n Complex Call Chain  An RPC call often requires multiple microservices to collaborate, and downstream services have their own dependencies, so the entire call chain will be a complex network structure.\nIn this kind of complex call chains, the latency fluctuation of one intermediate node may be transmitted to the entire chain，resulting in an overall timeout. When there are many nodes on the chain, even if the fluctuation probability of each node is very low, the timeout probability that eventually converges on the chain will be magnified. Therefore, the latency fluctuation of a single service, notably P99, is also a key indicator that has a significant impact on online services.\n Size of Data Package  Although the size of transmitted data packages depends on the actual business scenario, the internal statistics of ByteDance found that most online requests are small packages (\u003c2KB). So we focused on optimizing the performance in the small data package scenarios while taking the large package scenarios into account.\nStress Test for Microservice Scenarios Determine Stress Test Objects Measuring the performance of an RPC framework requires consideration from two perspectives: Client and Server. In large-scale business architectures, upstream clients are not necessarily using the same frameworks as downstream, and same goes to the downstream services scheduled by developers. The situation becomes more complicated when Service Mesh is involved.\nSome stress test projects often generate performance data for the entire framework by mixing Client and Server processes, which is likely to be inconsistent with the actual online operation.\nIf you want to stress test Server, you should give Client as many resources as possible to push Server to its limit, and vice versa. If both Client and Server are only provided 4-core CPUs for stress tests, it will be impossible for developers to determine the performance data is referring to either Client or Server. Thus, the test result will not have practical value for online services.\nAlignment of Connection Model Conventional RPCs have three major connection models:\n Short connection: Each request creates a new connection and closes the connection immediately after the return is received. Persistent connection pool: A single connection can process only one complete request \u0026 return at once. Connection multiplexing: A single connection can process multiple requests \u0026 returns asynchronously at the same time.  Each type of connection model is not absolutely good or bad, it depends on the actual usage scenario. Although connection multiplexing generally performs the best, the application must rely on the protocol being able to support package serial numbers, and some older framework services may not support multiplexing calls.\nIn order to ensure maximum compatibility, Kitex initially used short connections on the Client side by default, while other mainstream open source frameworks used connection multiplexing by default. It resulted in large performance data deviations for some users when stress testing with default configuration.\nLater, in order to accommodate the common scenario of open source users, Kitex supported persistent connection by default in v0.0.2.\nAlignment of Serialization Strategy For RPC frameworks, regardless of service governance, the computation overhead is mainly generated in serialization and deserialization.\nKitex uses the Go protobuf library to serialize Protobuf. And for serialization of Thrift, Kitex has specific performance optimization, which is introduced in the blog post on our official web.\nMost of the current open source frameworks support Protobuf in preference, and some built-in Protobuf are actually gogo/protobuf versions with performance optimizations. However, gogo/protobuf is currently at risk of maintenance absence. Therefore, due to maintainability concerns, we decided to use the official protobuf library only. Certainly, we will plan to optimize Protobuf in the future.\nUse Exclusive CPU Although multiple processes would usually utilize the CPU capability at the same time for online applications. But in stress test scenarios, both Client and Server processes are extremely busy. Sharing the CPU will result in a large number of context switching, which makes the output data less reliable and prone to large fluctuations.\nTherefore, we recommend that the Client and Server processes should be isolated on different CPUs or different exclusive machines. If you want to further avoid the impact of other processes, you can add the nice -n -20 command to adjust the scheduling priority of the stress testing process.\nIn addition, if possible, using physical machines makes the test results more precise and reproducible compared to using virtual machines on cloud platforms.\nPerformance Data Demonstration On the premise of meeting the above requirements, we compared the stress test results of multiple frameworks using Protobuf. The stress test source code can be found in kitex-benchmark repo. When Server is fully loaded, P99 Latency of Kitex in connection pool mode is the lowest of all frameworks. In multiplexing mode, Kitex also performs well in each indicator.\nConfiguration\n Client 16 CPUs，Server 4 CPUs 1KB Request Package Size, Echo Scenario  Reference Data\n KITEX: Connection Pool Model (Default Setting) KITEX-MUX: Connection Multiplexing Connection Multiplexing for all other Frameworks  Summary Each mainstream Golang open source RPC framework actually has its own focus in terms of design goals: some focus on generality, some on scenarios with light business logic like Redis, some on throughput performance, and some on P99 latency.\nIn the daily iteration of ByteDance’s business, it is common for a feature to cause one indicator to rise and another indicator to decline. Therefore, Kitex was more inclined to solve various problems in large-scale microservice scenarios at the beginning of its design.\nSince the launch of Kitex, we have received a large amount of self-testing data from our users. We appreciate the community for their attention and support. We also encourage developers to use the testing guide provided in this article, and select appropriate tools for their own scenarios. For more questions, please make an Issue on GitHub.\nPertinent Links  CloudWeGo Official Website: https://www.cloudwego.io Kitex: https://github.com/cloudwego/kitex Netpoll: https://github.com/cloudwego/netpoll kitex-benchmark: https://github.com/cloudwego/kitex-benchmark netpoll-benchmark: https://github.com/cloudwego/netpoll-benchmark Go Protobuf Library: https://github.com/golang/protobuf Thriftgo：https://github.com/cloudwego/thriftgo  ","categories":"","description":"This blog describes how to use Kitex for performance testing and how to analyze the test results to help users tune Kitex with real RPC scenarios to better match business needs and maximize performance.","excerpt":"This blog describes how to use Kitex for performance testing and how …","ref":"/blog/2021/11/24/getting-started-with-kitexs-practice-performance-testing-guide/","tags":"","title":"Getting Started With Kitex's Practice: Performance Testing Guide"},{"body":"日前，字节跳动服务框架团队正式开源 CloudWeGo ，在抖音、今日头条均有深度应用的 Golang 微服务 RPC 框架 Kitex 也包含在其中。\n本文旨在分享开发者在压测 Kitex 时需要了解的场景和技术问题。这些建议有助于用户更好地结合真实 RPC 场景对 Kitex 进行调优，使之更贴合业务需要、发挥最佳性能。用户也可以参考官方提供的压测项目 kitex-benchmark 了解更多细节。\n微服务场景的特点 Kitex 诞生于字节跳动大规模微服务架构实践，面向的场景自然是微服务场景，因此下面会先介绍微服务的特点，方便开发者深入理解 Kitex 在其中的设计思考。\n  RPC 通信模型\n微服务间的通信通常以 PingPong 模型为主，所以除了常规的吞吐性能指标外，每次 RPC 的平均时延也是开发者需要考虑的点。\n  复杂的调用链路\n一次 RPC 调用往往需要多个微服务协作完成，而下游服务又会有其自身依赖，所以整个调用链路会是一个复杂的网状结构。 在这种复杂调用关系中，某个中间节点出现的延迟波动可能会传导到整个链路上，导致整体超时。当链路上的节点足够多时，即便每个节点的波动概率很低，最终汇聚到链路上的超时概率也会被放大。 所以单一服务的延迟波动 —— 即 P99 延迟指标，也是一个会对线上服务产生重大影响的关键指标。\n  包体积大小\n虽然一个服务通信包的大小取决于实际业务场景，但在字节跳动的内部统计中，我们发现线上请求大多以小包（\u003c2KB）为主，所以在兼顾大包场景的同时，也重点优化了小包场景下的性能。\n  针对微服务场景进行压测 确定压测对象 衡量一个 RPC 框架的性能需要从两个视角分别去思考：Client 视角与 Server 视角。在大规模的业务架构中，上游 Client 不见得使用的也是下游的框架，而开发者调用的下游服务也同样如此，如果再考虑到 Service Mesh 的情况就更复杂了。\n一些压测项目通常会把 Client 和 Server 进程混部进行压测，然后得出整个框架的性能数据，这其实和线上实际运行情况很可能是不符的。\n如果要压测 Server，应该给 Client 尽可能多的资源，把 Server 压到极限，反之亦然。如果 Client 和 Server 都只给了 4 核 CPU 进行压测，会导致开发者无法判断最终得出来的性能数据是哪个视角下的，更无法给线上服务做实际的参考。\n对齐连接模型 常规 RPC 的连接模型主要有三种：\n 短连接：每次请求都创建新连接，得到返回后立即关闭连接 长连接池：单个连接同时只能处理一次完整请求与返回 连接多路复用：单个连接可以同时异步处理多个请求与返回  每类连接模型没有绝对好坏，取决于实际使用场景。连接多路复用虽然一般来说性能相对最好，但应用上必须依赖协议能够支持包序列号，且一些老框架服务可能也并不支持多路复用的方式调用。\nKitex 最早为保证最大程度的兼容性，在 Client 端默认使用了短连接，而其他主流开源框架默认使用连接多路复用，这导致一些用户在使用默认配置压测时，出现了比较大的性能数据偏差。\n后来为了契合开源用户的常规使用场景，Kitex 在 v0.0.2 中也加入了默认使用长连接的设置。\n对齐序列化方式 对于 RPC 框架来说，不考虑服务治理的话，计算开销主要都集中在序列化与反序列化中。\nKitex 对于 Protobuf 的序列化使用的是官方的 Protobuf 库，对于 Thrift 的序列化，则专门进行了性能优化，这方面的内容在官网博客中有介绍。\n当前开源框架大多优先支持 Protobuf，而部分框架内置使用的 Protobuf 其实是做了许多性能优化的 gogo/protobuf 版本，但由于 gogo/protobuf 当前有失去维护的风险，所以出于可维护性角度考虑，我们依然决定只使用官方的 Protobuf 库，当然后续我们也会计划对 Protobuf 进行优化。\n使用独占 CPU 虽然线上应用通常是多个进程共享 CPU，但在压测场景下，Client 与 Server 进程都处于极端繁忙的状况，如果同时还共享 CPU 会导致大量上下文切换，从而使得数据缺乏可参考性，且容易产生前后很大波动。\n所以我们建议是将 Client 与 Server 进程隔离在不同 CPU 或者不同独占机器上进行。如果还想要进一步避免其他进程产生影响，可以再加上 nice -n -20 命令调高压测进程的调度优先级。\n另外如果条件允许，相比云平台虚拟机，使用真实物理机会使得测试结果更加严谨与具备可复现性。\n性能数据参考 在满足上述要求的前提下，我们对多个框架使用 Protobuf 进行了压测对比，压测代码在 kitex-benchmark 仓库。在充分压满 Server 的目标下，Kitex 在连接池模式下的 P99 Latency 在所有框架中最低。而在多路复用模式下，Kitex 在各指标上也都具有更加明显的优势。\n配置：\n Client 16 CPUs，Server 4 CPUs 1KB 请求大小，Echo 场景  参考数据：\n KITEX：连接池模式（默认模式） KITEX-MUX：多路复用模式 其他框架均使用多路复用模式  结语 在当前主流的 Golang 开源 RPC 框架中，每个框架其实在设计目标上都各有侧重：有些框架侧重于通用性，有些侧重于类似 Redis 这种轻业务逻辑的场景，有些侧重于吞吐性能，而有些则更侧重 P99 时延。\n字节跳动的业务在日常迭代中，常常会出现因某个 feature 导致一个指标上升，另一个指标下降的情况，因此 Kitex 在设计之初就更倾向于解决大规模微服务场景下各种问题。\nKitex 发布后，我们接到了大量来自用户的自测数据，感谢社区对我们的关注和支持，也欢迎广大开发者基于本文提供的测试指南，针对自己的实际场景选择合适的工具。更多问题，请在 GitHub 上提 Issue 交流。\n相关链接   Kitex: https://github.com/cloudwego/kitex\n  Netpoll: https://github.com/cloudwego/netpoll\n  kitex-benchmark: https://github.com/cloudwego/kitex-benchmark\n  netpoll-benchmark: https://github.com/cloudwego/netpoll-benchmark\n  官方 Protobuf 库: https://github.com/golang/protobuf\n  Thriftgo: https://github.com/cloudwego/thriftgo\n  ","categories":"","description":"本文介绍了如何使用 Kitex 进行性能测试，以及如何分析测试结果，有助于用户更好地结合真实 RPC 场景对 Kitex 进行调优，使之更贴合业务需要、发挥最佳性能。","excerpt":"本文介绍了如何使用 Kitex 进行性能测试，以及如何分析测试结果，有助于用户更好地结合真实 RPC 场景对 Kitex 进行调优，使之更贴 …","ref":"/zh/blog/2021/11/24/rpc-%E6%A1%86%E6%9E%B6-kitex-%E5%AE%9E%E8%B7%B5%E5%85%A5%E9%97%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E5%8D%97/","tags":"","title":"RPC 框架 Kitex 实践入门：性能测试指南"},{"body":"Improvement:  Use shard rings to reduce lock overhead in connpool. Fill upstream information to rpcinfo from TTheader, for printing useful log when decode error happened. Move unlink uds operation to CreateListener. Replace sync.Mutex by sync.RWMutex of event.go and ring_single.go.  Bugfix:  Fix netpollmux shard index overflow. Remove reflection of WithCircuitBreaker option arguments to prevent data-race. Fix rpc finished error may happen small probability in failure retry scenario \u0026\u0026 add sample check for retry circuit breaking. Fix a test case mistake in endpoint_test.go. Modify longconn variable name to conn.  Tool:  Kitex codegen tool supports passing through thrift-go plugin arguments.  Docs:  Use a link to the the kitex-benchmark repository to replace the performance section in README.  Dependency Change:  github.com/tidwall/gjson: v1.8.0 -\u003e v1.9.3  ","categories":"","description":"","excerpt":"Improvement:  Use shard rings to reduce lock overhead in connpool. …","ref":"/blog/2021/11/05/kitex-release-v0.0.8/","tags":"","title":"Kitex Release v0.0.8"},{"body":"优化  使用分片 ring 减少连接池的锁开销。 装填 TTHeader 中的上游服务信息到 rpcinfo 中，用于在 decode 出错时输出来源信息。 Unlink uds 调整至 CreateListener 中。 event.go 和 ring_single.go 中的 Mutex 改为 RWMutex。  Bug 修复  修复 netpollmux shard index 溢出的问题。 移除 WithCircuitBreaker option 里对参数的反射，避免 data-race。 在重试场景下， 修复 rpc finish 错误导致的小概率失败的问题，并且加上了熔断 sample 的校验。 修复 endpoint_test.go 中的一处单测错误。 修改 conn_wrapper.go 中 longconn 变量命名为 conn.。  生成工具  代码生成工具支持透传thrift-go插件参数。  文档  将 README 中的性能结果改为引用 kitex-benchmark 仓库的数据。  依赖变化  github.com/tidwall/gjson: v1.8.0 -\u003e v1.9.3  ","categories":"","description":"","excerpt":"优化  使用分片 ring 减少连接池的锁开销。 装填 TTHeader 中的上游服务信息到 rpcinfo 中，用于在 decode 出错 …","ref":"/zh/blog/2021/11/05/kitex-v0.0.8-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.0.8 版本发布"},{"body":"Feature:  Add default ErrorHandler to wrap remote error when no ErrorHandler is specified. Backward metainfo is supported. JSON generic call is supported. Usage guide: link.  Improvement:  Use new netpoll API to improve throughput and reduce latency for mux. Backward and forward metainfo is supported for mux. Client will use RPCTimeout middleware when necessary. Add validity verification of idle connection in ConnectionPool. QPS limiter token will be reset when QPS limit updates. Reduce the deviation of QPS Limiter.  Bugfix:  Fix WithExitWaitTime won’t set exit wait time correctly. Fix goroutine leak when update interval of QPS limiter. Use actual listen address to build registry info.  Tool:  Fix code generating error when no stream method in protobuf file.  Docs:  English is available for README and all other documents. Guide for generic call. English | 中文 Landscape and Roadmap in README.  Dependency Change:  github.com/cloudwego/netpoll: v0.0.3 -\u003e v0.0.4 github.com/bytedance/gopkg: v0.0.0-20210709064845-3c00f9323f09 -\u003e v0.0.0-20210910103821-e4efae9c17c3  ","categories":"","description":"","excerpt":"Feature:  Add default ErrorHandler to wrap remote error when no …","ref":"/blog/2021/09/26/kitex-release-v0.0.5/","tags":"","title":"Kitex Release v0.0.5"},{"body":"功能:  增加默认的 ErrorHandler 封装 Error（用户指定会被覆盖）。 metainfo 支持反向传递。 支持了 JSON 泛化调用，使用指南可参考：Kitex 泛化调用使用指南。  优化:  多路复用场景下使用了新的 netpoll API 来改善吞吐和延迟。 多路复用场景下支持 metainfo 的正向和反向传递。 Client 会在需要的时候默认使用 RPCTimeout 中间件。 连接池配置增加全局空闲连接和单实例空闲连接合法性校验。 当更新 QPS 最大限制时会重置计数器。 减小 QPS 限流的误差。  Bug 修复:  修复 WithExitWaitTime 没有正确设置退出等待时间的问题。 修复更新 QPS 限制器更新间隔时，协程泄漏的问题。 服务注册使用真实监听的地址。  工具:  修复了当 protobuf 文件只有 unary 方法时，生成出错的问题。  文档:  提供了英文版的README和其他文档。 补充了泛化调用手册： English | 中文。 README 中增加了 landsapce 和 roadmap。  依赖变化:  github.com/cloudwego/netpoll: v0.0.3 -\u003e v0.0.4 github.com/bytedance/gopkg: v0.0.0-20210709064845-3c00f9323f09 -\u003e v0.0.0-20210910103821-e4efae9c17c3  ","categories":"","description":"","excerpt":"功能:  增加默认的 ErrorHandler 封装 Error（用户指定会被覆盖）。 metainfo 支持反向传递。 支持了 JSON  …","ref":"/zh/blog/2021/09/26/kitex-v0.0.5-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.0.5 版本发布"},{"body":"Preface Kitex is the next generation high-performance and extensible Go RPC framework developed by ByteDance Service Framework Team. Compared with other RPC frameworks, in addition to its rich features for service governance, it has the following characteristics: integrated with the self-developed network library - Netpoll; supports multiple Message Protocols (Thrift, Protobuf) and Interactive Models (Ping-Pong, Oneway, Streaming); provides a more flexible and extensible code generator.\nCurrently, Kitex has been widely used by the major lines of business in ByteDance, and statistics shows that the number of service access is up to 8K. We’ve been continuously improving Kitex’s performance since its launch. This article will share our work on optimizing Netpoll and serialization.\nOptimization of the Network Library - Netpoll Netpoll, the self-developed network library based on Epoll. Compared with the previous version and the go net library, its performance has been significantly improved. Test results indicated that compared with the last version (2020.05), the latest version (2020.12) has ↑30% throughput capacity, ↓25% AVG latency, and ↓67% TP99 . Its performance is far better than the Go Net library. Below, we’ll share two solutions that can significantly improve its performance.\nOptimizing Scheduling Delays When Calling “epoll_wait” When Netpoll was newly released, it encountered the problem of low AVG latency but high TP99. Through our research and analysis on “epoll_wait”, we found that such a problem could be mitigated by integrating “polling” and “event trigger”. With such improvements in scheduling strategy, the latency can be reduced considerably.\nLet’s have a look at the “syscall.EpollWait” method provided by Go first:\nfunc EpollWait(epfd int, events []EpollEvent, msec int) (n int, err error) Three parameters are provided here, they represent “epoll fd”, “callback events”, and “milliseconds to wait” respectively. Only “msec” is dynamic.\nNormally, we would set “msec = -1” when we are actively calling “EpollWait”, as we want to wait for the event infinitely. In fact, many open-source net libraries were also using it in this way. But our research showed that setting “msec =-1” was not the optimal solution.\nThe kernel source (below) of “epoll_wait” shows that setting “msec = -1” arises extra “fetch_events” checks than setting “msec = 0”, and therefore consumes more time.\nstatic int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout) { ... if (timeout \u003e 0) { ... } else if (timeout == 0) { ... goto send_events; } fetch_events: ... if (eavail) goto send_events; send_events: ... The Benchmark shows that when an event is triggered, setting “msec = 0” is about 18% faster than setting “msec = -1”. Thus, when triggering complex events, setting “msec = 0” is obviously a better choice.\n   Benchmark time/op bytes/op     BenchmarkEpollWait, msec=0 270 ns/op 0 B/op   BenchmarkEpollWait, msec=-1 328 ns/op 0 B/op   EpollWait Delta -17.68% ~    However, setting “msec = 0” would lead to infinite polling when no event is triggered, consumes lots of resources.\nTaking the previously mentioned factors into account, it’s preferred to set “msec = 0” when an event is triggered and “msec = -1” when no event is triggered to reduce polling. The pseudocode is demonstrated as follows:\nvar msec = -1 for { n, err = syscall.EpollWait(epfd, events, msec) if n \u003c= 0 { msec = -1 continue } msec = 0 ... } Nevertheless, our experiments have proved that the improvement is insignificant. Setting “msec = 0” merely reduces the delay of a single call by 50ns, which is not a considerable improvement. If we want to further reduce latency, adjustment must be made in Go runtime scheduling. Thus, let’s further explore this issue: In the pseudocode above, setting “msec= -1” with no triggered event, and “continue” directly will immediately execute “EpollWait” again. Since there is no triggered event while “msec = -1”, the current “goroutine” will block and be switched by “P” passively. However, it is less efficient, and we can save time if we actively switch “goroutine” for “P” before “continue”. So we modified the above pseudocode as follows:\nvar msec = -1 for { n, err = syscall.EpollWait(epfd, events, msec) if n \u003c= 0 { msec = -1 runtime.Gosched() continue } msec = 0 ... } The test results of the modified code showed that throughput ↑12% and TP99 ↓64%. The latency was significantly reduced.\nUtilizing “unsafe.Pointer” Through further study of “epoll_wait”, we find that the “syscall.EpollWait” published by Go and the “epollwait” used by “runtime” are two different versions, as they use different “EpollEvent”. They are demonstrated as follows:\n// @syscall type EpollEvent struct { Events uint32 Fd int32 Pad int32 } // @runtime type epollevent struct { events uint32 data [8]byte // unaligned uintptr } As we can see, the “epollevent” used by “runtime” is the original structure defined by “epoll” at system layer. The published version encapsulates it and splits “epoll_data(epollevent.data)” into two fixed fields: “Fd” and “Pad”. For “runtime”, in its source code we found the following logic:\n*(**pollDesc)(unsafe.Pointer(\u0026ev.data)) = pd pd := *(**pollDesc)(unsafe.Pointer(\u0026ev.data)) Obviously, “runtime” uses “epoll_data(\u0026ev.data)” to store the pointer of the corresponding structure (pollDesc) of “fd” directly. Thus, when an event is triggered, the “struct” object can be found directly with the corresponding logic being executed. However, the external version can only obtain the encapsulated “fd” parameters. So it needs to introduce additional “Map” to manipulate the “struct” object, and the performance will be diminished.\nTherefore, we abandoned “syscall.EpollWait” and designed our own “EpollWait” call by referring to “runtime”. We also use “unsafe.Pointer” to access “struct” objects. The test results showed that our “EpollWait” call contributed to ↑10% throughput and ↓10% TP99, which has significantly improved efficiency.\nSerialization/Deserialization Optimization of Thrift Serialization refers to the process of converting a data structure or object into a binary or textual form. Deserialization is the opposite process. A serialization protocol needs to be agreed during RPC communication. The serialization process is executed before the client sends requests. The bytes are transmitted to the server over the network, and the server will logic-process the bytes to complete an RPC request. Thrift supports “Binary”, “Compact”, and “JSON” serialization protocols. Since “Binary” is the most common protocol used in Bytedance, we will only discuss about “Binary” protocol.\n“Binary” protocol is “TLV” (“Type”, “Length”, “Value”) encoded, that is, each field is described using “TLV” structure. It emphasizes that the “Value” can also be a “TLV” structure, where the “Type” and “Length” are fixed in length, and the length of “Value” is determined by the input value of “Length”. The TLV coding structure is simple, clear, and scalable. However, since it requires the input of “Type” and “Length”, there is extra memory overhead incurred. It wastes considerable memory especially when most fields are in base types.\nThe performance of serialization and deserialization can be optimized from two dimensions - “time” \u0026 “space”. To be compatible with the existing “binary” protocols, optimization in “space” seems to be infeasible. Improvement can only be made in “time”, it includes:\n Reduce the frequency of operations on memory, notably memory allocation and copying. Try to pre-allocate memory to reduce unnecessary time consumption. Reduce the frequency of function calls by adjusting code structure or using “inline” etc.  Research on Serialization Strategy Based on “go_serialization_benchmarks”, we investigated a number of serialization schemes that performed well to guide the optimization of our serialization strategy.\nAnalysis of “protobuf”, “gogoprotobuf”, and “Cap ‘n Proto” has provided us the following results:\n Considering I/O, the transmitted data is usually compressed in size during network transmission. “protobuf” uses “Varint” encoding and has good data compression capabilities in most scenarios. “gogoprotobuf” uses precomputation to reduce memory allocations and copies during serialization. Thus, it eliminates the cost of system calls, locks and GC arisen from memory allocations. “Cap ‘n Proto” directly operates buffer, which also reduces memory allocations and copies. In addition, it also designs “struct pointer” in a way that processes fixed-length data and non-fixed-length data separately, which enables fast processing for fixed-length data.  For compatibility reasons, it is impossible to change the existing “TLV” encoding format, so data compression is not feasible. But finding 2 and 3 are inspiring to our optimization work, and in fact we have taken a similar approach.\nApproaches Reducing Operations on Memory Buffer management\nBoth serialization and deserialization involve copying data from one piece of memory to another. It involves memory allocation and memory copying. Avoiding memory operations can reduce unnecessary overhead such as system calls, locks, and GC.\nIn fact, Kitex has provided “LinkBuffer” for buffer management purposes. “LinkBuffer” is designed with a linked structure and consists of multiple blocks, among which blocks are memory chunks with a fixed size. Object pool is constructed to maintain unoccupied block and support block multiplexing, thus, reduce memory usage and GC.\nInitially we simply used “sync.Pool” to multiplex the “LinkBufferNode” of netpoll, but it didn’t significantly contribute to multiplexing in large data package scenarios (large nodes can’t be reclaimed or it would cause memory leaking). At present, we have changed our strategy to maintain a group of “sync.Pool”, and the buffer size in each chunk is different. When new blocks are created, it is obtained from the pool with the closest size to the required size, so that the memory can be multiplexed as much as possible. And the test results also proved that it contributed to significant improvement in terms of memory allocation and GC.\nCopy-free String / Binary\nFor some services, such as video-related services, during its request or return processes, large-size “Binary” data will be arisen, representing the processed video or image data. Meanwhile, some services will return large-size “String” data (such as full-text information, etc.). In this scenario, all the hot spots we see through the flame graph are on the copies of the data. So we thought, can we reduce the frequency of such copies?\nThe answer is positive. Since our underlying buffer is a linked list, it is easy to insert a node in the middle of the list.\nThus, we have taken a similar approach, when a “string” or “binary” data exists during serialization processes. First, split the node’s buffer into two segments and then insert the buffer of the “string” / “binary” objects in the middle correspondingly. This avoids the copy of large “string” / “binary” .\nFurthermore, a copy will occur if we convert a string to “[]byte” using “[]byte(string)”. Because “string” is immutable and “[]byte” is mutable in Golang language. “unsafe” is needed if you don’t want to copy during the conversion:\nfunc StringToSliceByte(s string) []byte { l := len(s) return *(*[]byte)(unsafe.Pointer(\u0026reflect.SliceHeader{ Data: (*(*reflect.StringHeader)(unsafe.Pointer(\u0026s))).Data, Len: l, Cap: l, })) } The meaning of this demonstrated code is to take the address of the string first, and then give it a slice byte header, so that the “string” can be converted into “[]byte” without copying the data. Note that the resulting “[]byte” is not writable, or the behavior is undefined.\nPre-Calculation\nSome services support transmissions of large data package, which incurs considerable serialization / deserialization overhead. Generally, large packages are associated with the large size of the container type. If the buffer can be pre-calculated, some O(n) operations can be reduced to O(1), and further reduce the frequency of function calls. In the case of large data packages, the number of memory allocation can also be greatly reduced, bringing considerable benefits.\n  Base types\n If the container element is defined as base type (bool, byte, i16, i32, i64, double), the total size can be pre-calculated during serialization as its size is fixed, and enough buffer can be allocated at once. The number of “malloc” operations of O(n) can be reduced to O(1), thus greatly reducing the frequency of “malloc” operations. Similarly, the number of “next” operations can be reduced during deserialization.    Rearrangement of “Struct” Fields\n The above optimizations are valid only for container elements that are defined as base types. Can they be optimized for “struct” elements? The answer is yes. If there are fields of base type in “struct”, we can pre-calculate the size of these fields, then allocate buffer for these fields in advance during serialization and write these fields in the first order. We can also reduce the frequency of “malloc”.    Size calculation\n The optimization mentioned above is for base types. If you first iterate over all the fields of the request during serialization, you can calculate the size of the entire request, allocate buffer in advance, and directly manipulate buffer during serialization and deserialization, so that the optimization effect can be achieved for non-base types. Define a new “codec” interface:    type thriftMsgFastCodec interface { BLength() int // count length of whole req/resp  FastWrite(buf []byte) int FastRead(buf []byte) (int, error) }  Change the “Marshal” and “Unmarshal” interfaces accordingly:  func (c thriftCodec) Marshal(ctx context.Context, message remote.Message, out remote.ByteBuffer) error { ... if msg, ok := data.(thriftMsgFastCodec); ok { msgBeginLen := bthrift.Binary.MessageBeginLength(methodName, thrift.TMessageType(msgType), int32(seqID)) msgEndLen := bthrift.Binary.MessageEndLength() buf, err := out.Malloc(msgBeginLen + msg.BLength() + msgEndLen)// malloc once  if err != nil { return perrors.NewProtocolErrorWithMsg(fmt.Sprintf(\"thrift marshal, Malloc failed: %s\", err.Error())) } offset := bthrift.Binary.WriteMessageBegin(buf, methodName, thrift.TMessageType(msgType), int32(seqID)) offset += msg.FastWrite(buf[offset:]) bthrift.Binary.WriteMessageEnd(buf[offset:]) return nil } ... } func (c thriftCodec) Unmarshal(ctx context.Context, message remote.Message, in remote.ByteBuffer) error { ... data := message.Data() if msg, ok := data.(thriftMsgFastCodec); ok \u0026\u0026 message.PayloadLen() != 0 { msgBeginLen := bthrift.Binary.MessageBeginLength(methodName, msgType, seqID) buf, err := tProt.next(message.PayloadLen() - msgBeginLen - bthrift.Binary.MessageEndLength()) // next once  if err != nil { return remote.NewTransError(remote.PROTOCOL_ERROR, err.Error()) } _, err = msg.FastRead(buf) if err != nil { return remote.NewTransError(remote.PROTOCOL_ERROR, err.Error()) } err = tProt.ReadMessageEnd() if err != nil { return remote.NewTransError(remote.PROTOCOL_ERROR, err.Error()) } tProt.Recycle() return err } ... }  Modify the generated code accordingly:  func (p *Demo) BLength() int { l := 0 l += bthrift.Binary.StructBeginLength(\"Demo\") if p != nil { l += p.field1Length() l += p.field2Length() l += p.field3Length() ... } l += bthrift.Binary.FieldStopLength() l += bthrift.Binary.StructEndLength() return l } func (p *Demo) FastWrite(buf []byte) int { offset := 0 offset += bthrift.Binary.WriteStructBegin(buf[offset:], \"Demo\") if p != nil { offset += p.fastWriteField2(buf[offset:]) offset += p.fastWriteField4(buf[offset:]) offset += p.fastWriteField1(buf[offset:]) offset += p.fastWriteField3(buf[offset:]) } offset += bthrift.Binary.WriteFieldStop(buf[offset:]) offset += bthrift.Binary.WriteStructEnd(buf[offset:]) return offset } Optimizing Thrift Encoding with SIMD “list\u003ci64/i32\u003e” is widely used in the company to carry the ID list, and the encoding method of “list\u003ci64/i32\u003e” is highly consistent with the rule of vectorization. Thus, we use SIMD to optimize the encoding process of list\u003ci64/i32\u003e.\nWe implement “avx2” to improve the encoding process, and the improved results are significant. When dealing with large amounts of data, the performance can be improved by 6 times for i64 and 12 times for i32. In the case of small data volume, the improvement is more obvious, which achieves 10 times for i64 and 20 times for I32.\nReducing Function Calls inline\nThe purpose of “inline” is to expand a function call during its compilation and replace it with the implementation of the function. It improves program performance by reducing the overhead of the function call.\n“inline” can’t be implemented on all functions in Go. Run the process with the argument - (gflags=\"-m\") to display the functions that are inlined. The following conditions cannot be inlined:\n A function containing a loop; Functions that include: closure calls, select, for, defer, coroutines created by the go keyword; For Functions over a certain length, by default when parsing the AST, Go applies 80 nodes. Each node consumes one unit of inline budget. For example, a = a + 1 contains five nodes: AS, NAME, ADD, NAME, LITERAL. When the overhead of a function exceeds this budget, it cannot be inlined.  You can specify the intensity (go 1.9+) of the compiler’s inlined code by specifying “-l” at compile time. But it is not recommended, as in our test scenario, it is buggy and does not work:\n// The debug['l'] flag controls the aggressiveness. Note that main() swaps level 0 and 1, making 1 the default and -l disable. Additional levels (beyond -l) may be buggy and are not supported. // 0: disabled // 1: 80-nodes leaf functions, oneliners, panic, lazy typechecking (default) // 2: (unassigned) // 3: (unassigned) // 4: allow non-leaf functions Although using “inline” can reduce the overhead of function calls, it may also lead to lower CPU cache hit rate due to code redundancy. Therefore, excessive usage of “inline” should not be blindly pursued, and specific analysis should be carried out based on “profile” results.\ngo test -gcflags='-m=2' -v -test.run TestNewCodec 2\u003e\u00261 | grep \"function too complex\" | wc -l 48 go test -gcflags='-m=2 -l=4' -v -test.run TestNewCodec 2\u003e\u00261 | grep \"function too complex\" | wc -l 25 As you can see, from the output above, increasing the inline intensity does reduce the “function too complex”. Following are the benchmark results:\n   Benchmark time/op bytes/op allocs/op     BenchmarkOldMarshal-4 309 µs ± 2% 218KB 11   BenchmarkNewMarshal-4 310 µs ± 3% 218KB 11    It reveals that turning on the highest level of inlining intensity does eliminate many functions that cannot be inlined due to “function too complex”, but the test results show that the improvement is insignificant.\nTesting Results We built benchmarks to compare performance before and after optimization, and here are the results. Testing Environment: Go 1.13.5 darwin/amd64 on a 2.5 GHz Intel Core i7 16GB\nSmall Data Size\nData size: 20KB\n   Benchmark time/op bytes/op allocs/op     BenchmarkOldMarshal-4 138 µs ± 3% 25.4KB 19   BenchmarkNewMarshal-4 29 µs ± 3% 26.4KB 11   Marshal Delta -78.97% 3.87% -42.11%   BenchmarkOldUnmarshal-4 199 µs ± 3% 4720 1360   BenchmarkNewUnmarshal-4 94µs ± 5% 4700 1280   Unmarshal Delta -52.93% -0.24% -5.38%    Large Data Size\nData size: 6MB\n   Benchmark time/op bytes/op allocs/op     BenchmarkOldMarshal-4 58.7ms ± 5% 6.96MB 3350   BenchmarkNewMarshal-4 13.3ms ± 3% 6.84MB 10   Marshal Delta -77.30% -1.71% -99.64%   BenchmarkOldUnmarshal-4 56.6ms ± 3% 17.4MB 391000   BenchmarkNewUnmarshal-4 26.8ms ± 5% 17.5MB 390000   Unmarshal Delta -52.54% 0.09% -0.37%    Copy-free Serialization In some services with large request and response data, the cost of serialization and deserialization is high. There are two ways for optimization:\n Implement the optimization strategy on serialization and deserialization as described earlier. Scheduling by copy-free serialization.  Research on Copy-free Serilization RPC through copy-free serialization, which originated from the “Cap ‘n Proto” project of Kenton Varda. “Cap ‘n Proto” provides a set of data exchange formats and corresponding codec libraries.\nIn essence, “Cap ‘n Proto” creates a bytes slice as buffer, and all read \u0026 write operations on data structures are directly operated on buffer. After reading \u0026 writing, information contained by the buffer is added to the head and can be sent directly. And the peer end can read it after receiving it. Since there is no Go structure as an intermediate storage, serialization and deserialization are not required.\nTo briefly summarize the characteristics of “Cap ‘n Proto”:\n All data is read and written to a contiguous memory. The serialization operation is preceded. “Get/Set” data and encoding process in parallel. In the data exchange format, pointer (“offset” at the data memory) mechanism is used to store data at any location in the contiguous memory, so that data in the structure can be read and written in any order.  Fixed-size fields of a structure are rearranged so that they are stored in contiguous memory. Fields with indeterminate size of a structure (e.g. list), are represented by a fixed-size pointer that stores information including the location of the data.    First of all, “Cap ‘n Proto” has no Go language structure as an intermediate carrier, which can reduce a copy. Then, “Cap ‘n Proto” operates on a contiguous memory, and the read and write of coded data can be completed at once. Because of these two reasons, Cap ‘n Proto has excellent performance.\nHere are the benchmarks of “Thrift” and “Cap ‘n Proto” for the same data structure. Considering that “Cap ‘n Proto” presets the codec operation, we compare the complete process including data initialization. That is, structure data initialization + (serialization) + write buffer + read from buffer + (deserialization) + read from structure.\nstructMyTest{1:i64Num,2:AnoAno,3:list\u003ci64\u003eNums,// 长度131072 大小1MB }structAno{1:i64Num,}   Benchmark Iter time/op bytes/op alloc/op     BenchmarkThriftReadWrite 172 6855840 ns/op 3154209 B/op 545 allocs/op   BenchmarkCapnpReadWrite 1500 844924 ns/op 2085713 B/op 9 allocs/op   ReadWrite Delta / -87.68% -33.88% -98.35%    (deserialization) + read data, depending on the size of data package,“Cap ‘n Proto” performance is about 8-9 times better than “Thrift”. Write data + (serialization), depending on the size of data package, “Cap ‘n Proto” performance is approximately 2-8 times better than “Thrift”. Overall performance of “Cap ‘n Proto” is approximately 4-8 times better than “Thrift”.\nPreviously, we discussed the advantages of “Cap ‘n Proto”. We will then summarize some problems existing in “Cap ‘n Proto”:\n One problem with the contiguous memory of Cap ‘n Proto is that when the data of variable size is resized, and the required space is larger than the original space, the space of the original data can only be reallocated later. As a result, the original space becomes a hole that cannot be removed. This problem gets worse as the call link is resized, and can only be solved with strict constraints throughout the link: avoid resizing variable size fields, and when resize is necessary, rebuild a structure and make a deep copy of the data. “Cap ‘n Proto” has no Go language structure as an intermediate carrier, so all fields can only be read and written through the interface, resulting in poor user experience.  Thrift Protocol‘s Compatible Copy-free Serialization In order to support copy-free serialization better and more efficiently, “Cap ‘n Proto” uses a self-developed codec format, but it is difficult to be implemented in the current environment where “Thrift” and “ProtoBuf” are dominant. In order to achieve the performance of copy-free serialization with protocol compatibility, we started the exploration of copy-free serialization that is compatible with “Thrift” protocol.\n“Cap ‘n Proto” is a benchmark for copy-free serialization, so let’s see if the optimizations on “Cap ‘n Proto” can be applied to Thrift:\n Nature is the core of copy-free serialization, which does not use Go structure as intermediate carriers to reduce one copy. This optimization is not about a particular protocol and can be applied to any existing protocol (So it’s naturally compatible with the Thrift protocol), but the user experience of “Cap ‘n Proto” reflects that it needs to be carefully polished. “Cap ‘n Proto” is operated on a contiguous memory. The read \u0026 write of the encoded data can be completed at once. “Cap ‘n Proto” can operate on contiguous memory because there is a pointer mechanism that allows data to be stored anywhere, allowing fields to be written in any order without affecting decoding. However, it is very likely to leave a hole in the resize due to misoperation on contiguous memory. Besides, “Thrift” has no pointer alike mechanism, so it has stricter requirements on data layout. Here are two ways to approach such problems:  Insist on operating in contiguous memory, while imposing strict regulations on users’ usage: 1. Resize operation must rebuild the data structure; 2. When a structure is nested, there are strict requirements on the order in which the fields are written (we can think of it as unfolding a nested structure from the outside in, and being written in the same order) . In addition, due to TLV encoding such as Binary, when writing begins for each nesting, it requires declaration (such as “StartWriteFieldX”). Operating not entirely in contiguous memory, alterable fields are allocated a separate piece of memory. Since memory is not completely contiguous, the write operation can’t complete the output at once. In order to get closer to the performance of writing data at once, we adopted a linked buffer scheme. On the one hand, when the variable field resize occurs, only one node of the linked buffer is replaced, and there is no need to reconstruct the structure like “Cap ‘n Proto”. On the other hand, there is no need to clarify the actual structure like “Thrift” when the output is needed, just write the buffer on the link.    To summarize what we have determined previously: 1. Do not use Go structure as the intermediate carrier, directly operate the underlying memory through the interface, and complete the codec at the same time of “Get/Set”. 2. Data is stored through a linked buffer.\nThen let’s take a look at the remaining issues:\n Degradation of the user experience caused by not using Go structures.  Solution: Improve the user experience of “Get/Set” interface and make it as easy to use as the Go structure.   Binary Format of “Cap ‘n Proto” is designed specifically for copy-free serialization scenarios, and although decoding is performed once for every Get, the decoding costs are minimal. The “Thrift” protocol (taking “Binary” as an example) has no mechanism that is similar to pointer. When there are multiple fields of variable size or nesting, they must be resolved sequentially instead of directly calculating the offset to get the field data location. Moreover, the cost of sequential resolution for each Get is too high.  Solution: In addition to recording the structure’s buffer nodes, we also add an index that records the pointer to the buffer node at the beginning of each field with unfixed size. The following is the ultimate performance comparison test between the current copy-free serialization scheme and “FastRead/Write” under the condition of 4 cores:       Package Size Type QPS TP90 TP99 TP999 CPU     1KB Non-serialization 70,700 1 ms 3 ms 6 ms /    FastWrite/FastRead 82,490 1 ms 2 ms 4 ms /   2KB Non-serialization 65,000 1 ms 4 ms 9 ms /    FastWrite/FastRead 72,000 1 ms 2 ms 8 ms /   4KB Non-serialization 56,400 2 ms 5 ms 10 ms 380%    FastWrite/FastRead 52,700 2 ms 4 ms 10 ms 380%   32KB Non-serialization 27,400 / / / /    FastWrite/FastRead 19,500 / / / /   1MB Non-serialization 986 53 ms 56 ms 59 ms 260%    FastWrite/FastRead 942 55 ms 59 ms 62 ms 290%   10MB Non-serialization 82 630 ms 640 ms 645 ms 240%    FastWrite/FastRead 82 630 ms 640 ms 640 ms 270    Summary of the test results:\n In small data package scenario, performance of non-serialization is poorer - about 85% of FastWrite/FastRead’s performance. In large data package scenario, the performance of non-serialization is better. When processing packages larger than 4K, the performance of non-serialization is 7%-40% better compared with “FastWrite/FastRead”.  Postscript Hope the above sharing can be helpful to the community. At the same time, we are trying to share memory-based IPC, io_uring, TCP zero copy, RDMA, etc., to better improve Kitex performance. And we will also focus on improving the communication scenarios of the same device and container. Welcome to join us and contribute to Go ecology together!\nReference  https://github.com/alecthomas/go_serialization_benchmarks https://capnproto.org/ Intel C++ Compiler Classic Developer Guide and Reference  ","categories":"","description":"This blog introduces the performance optimization practice of Bytedance Go RPC framework Kitex, which includes Netpoll, Thrift, serialization and so on.","excerpt":"This blog introduces the performance optimization practice of …","ref":"/blog/2021/09/23/performance-optimization-on-kitex/","tags":"","title":"Performance Optimization on Kitex"},{"body":"前言 Kitex 是字节跳动框架组研发的下一代高性能、强可扩展性的 Go RPC 框架。除具备丰富的服务治理特性外，相比其他框架还有以下特点： 集成了自研的网络库 Netpoll；支持多消息协议（Thrift、Protobuf）和多交互方式（Ping-Pong、Oneway、 Streaming）；提供了更加灵活可扩展的代码生成器。\n目前公司内主要业务线都已经大范围使用 Kitex，据统计当前接入服务数量多达 8k。Kitex 推出后，我们一直在不断地优化性能，本文将分享我们在 Netpoll 和 序列化方面的优化工作。\n自研网络库 Netpoll 优化 自研的基于 epoll 的网络库 —— Netpoll，在性能方面有了较为显著的优化。测试数据表明，当前版本(2020.12) 相比于上次分享时(2020.05)，吞吐能力 ↑30%，延迟 AVG ↓25%，TP99 ↓67%，性能已远超官方 net 库。以下，我们将分享两点显著提升性能的方案。\nepoll_wait 调度延迟优化 Netpoll 在刚发布时，遇到了延迟 AVG 较低，但 TP99 较高的问题。经过认真研究 epoll_wait，我们发现结合 polling 和 event trigger 两种模式，并优化调度策略，可以显著降低延迟。\n首先我们来看 Go 官方提供的 syscall.EpollWait 方法：\nfunc EpollWait(epfd int, events []EpollEvent, msec int) (n int, err error) 这里共提供 3 个参数，分别表示 epoll 的 fd、回调事件、等待时间，其中只有 msec 是动态可调的。\n通常情况下，我们主动调用 EpollWait 都会设置 msec=-1，即无限等待事件到来。事实上不少开源网络库也是这么做的。但是我们研究发现，msec=-1 并不是最优解。\nepoll_wait 内核源码(如下) 表明，msec=-1 比 msec=0 增加了 fetch_events 检查，因此耗时更长。\nstatic int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout) { ... if (timeout \u003e 0) { ... } else if (timeout == 0) { ... goto send_events; } fetch_events: ... if (eavail) goto send_events; send_events: ... Benchmark 表明，在有事件触发的情况下，msec=0 比 msec=-1 调用要快 18% 左右，因此在频繁事件触发场景下，使用 msec=0 调用明显是更优的。\n   Benchmark time/op bytes/op     BenchmarkEpollWait, msec=0 270 ns/op 0 B/op   BenchmarkEpollWait, msec=-1 328 ns/op 0 B/op   EpollWait Delta -17.68% ~    而在无事件触发的场景下，使用 msec=0 显然会造成无限轮询，空耗大量资源。\n综合考虑后，我们更希望在有事件触发时，使用 msec=0 调用，而在无事件时，使用 msec=-1 来减少轮询开销。伪代码如下：\nvar msec = -1 for { n, err = syscall.EpollWait(epfd, events, msec) if n \u003c= 0 { msec = -1 continue } msec = 0 ... } 那么这样就可以了吗？事实证明优化效果并不明显。\n我们再做思考：\nmsec=0 仅单次调用耗时减少 50ns，影响太小，如果想要进一步优化，必须要在调度逻辑上做出调整。\n进一步思考：\n上述伪代码中，当无事件触发，调整 msec=-1 时，直接 continue 会立即再次执行 EpollWait，而由于无事件，msec=-1，当前 goroutine 会 block 并被 P 切换。 但是被动切换效率较低，如果我们在 continue 前主动为 P 切换 goroutine，则可以节约时间。因此我们将上述伪代码改为如下：\nvar msec = -1 for { n, err = syscall.EpollWait(epfd, events, msec) if n \u003c= 0 { msec = -1 runtime.Gosched() continue } msec = 0 ... } 测试表明，调整代码后，吞吐量 ↑12%，TP99 ↓64%，获得了显著的延迟收益。\n合理利用 unsafe.Pointer 继续研究 epoll_wait，我们发现 Go 官方对外提供的 syscall.EpollWait 和 runtime 自用的 epollwait 是不同的版本，即两者使用了不同的 EpollEvent。以下我们展示两者的区别：\n// @syscall type EpollEvent struct { Events uint32 Fd int32 Pad int32 } // @runtime type epollevent struct { events uint32 data [8]byte // unaligned uintptr } 我们看到，runtime 使用的 epollevent 是系统层 epoll 定义的原始结构；而对外版本则对其做了封装，将 epoll_data(epollevent.data) 拆分为固定的两字段：Fd 和 Pad。 那么 runtime 又是如何使用的呢？在源码里我们看到这样的逻辑：\n*(**pollDesc)(unsafe.Pointer(\u0026ev.data)) = pd pd := *(**pollDesc)(unsafe.Pointer(\u0026ev.data)) 显然，runtime 使用 epoll_data(\u0026ev.data) 直接存储了 fd 对应结构体(pollDesc)的指针，这样在事件触发时，可以直接找到结构体对象，并执行相应逻辑。 而对外版本则由于只能获得封装后的 Fd 参数，因此需要引入额外的 Map 来增删改查结构体对象，这样性能肯定相差很多。\n所以我们果断抛弃了 syscall.EpollWait，转而仿照 runtime 自行设计了 EpollWait 调用，同样采用 unsafe.Pointer 存取结构体对象。测试表明，该方案下 吞吐量 ↑10%，TP99 ↓10%，获得了较为明显的收益。\nThrift 序列化/反序列化优化 序列化是指把数据结构或对象转换成字节序列的过程，反序列化则是相反的过程。RPC 在通信时需要约定好序列化协议，client 在发送请求前进行序列化， 字节序列通过网络传输到 server，server 再反序列进行逻辑处理，完成一次 RPC 请求。Thrift 支持 Binary、Compact 和 JSON 序列化协议。目前公司内部使用的基本都是 Binary，这里只介绍 Binary 协议。\nBinary 采用 TLV 编码实现，即每个字段都由 TLV 结构来描述，TLV 意为：Type 类型， Length 长度，Value 值，Value 也可以是个 TLV 结构，其中 Type 和 Length 的长度固定，Value 的长度则由 Length 的值决定。 TLV 编码结构简单清晰，并且扩展性较好，但是由于增加了 Type 和 Length，有额外的内存开销，特别是在大部分字段都是基本类型的情况下有不小的空间浪费。\n序列化和反序列的性能优化从大的方面来看可以从空间和时间两个维度进行优化。从兼容已有的 Binary 协议来看，空间上的优化似乎不太可行，只能从时间维度进行优化，包括：\n  减少内存操作次数，包括内存分配和拷贝，尽量预分配内存，减少不必要的开销；\n  减少函数调用次数，比如可调整代码结构和 inline 等手段进行优化；\n  调研 根据 go_serialization_benchmarks 的压测数据，我们找到了一些性能卓越的序列化方案进行调研，希望能够对我们的优化工作有所启发。\n通过对 protobuf、gogoprotobuf 和 Cap’n Proto 的分析，我们得出以下结论：\n  网络传输中出于 IO 的考虑，都会尽量压缩传输数据，protobuf 采用了 Varint 编码在大部分场景中都有着不错的压缩效果；\n  gogoprotobuf 采用预计算方式，在序列化时能够减少内存分配次数，进而减少了内存分配带来的系统调用、锁和 GC 等代价；\n  Cap’n Proto 直接操作 buffer，也是减少了内存分配和内存拷贝（少了中间的数据结构），并且在 struct pointer 的设计中把固定长度类型数据和非固定长度类型数据分开处理，针对固定长度类型可以快速处理；\n  从兼容性考虑，不可能改变现有的 TLV 编码格式，因此数据压缩不太现实，但是 2 和 3 对我们的优化工作是有启发的，事实上我们也是采取了类似的思路。\n思路 减少内存操作 buffer 管理\n无论是序列化还是反序列化，都是从一块内存拷贝数据到另一块内存，这就涉及到内存分配和内存拷贝操作，尽量避免内存操作可以减少不必要的系统调用、锁和 GC 等开销。\n事实上 Kitex 已经提供了 LinkBuffer 用于 buffer 的管理，LinkBuffer 设计上采用链式结构，由多个 block 组成，其中 block 是大小固定的内存块，构建对象池维护空闲 block，由此复用 block，减少内存占用和 GC。\n刚开始我们简单地采用 sync.Pool 来复用 netpoll 的 LinkBufferNode，但是这样仍然无法解决对于大包场景下的内存复用（大的 Node 不能回收，否则会导致内存泄漏）。 目前我们改成了维护一组 sync.Pool，每组中的 buffer size 都不同，新建 block 时根据最接近所需 size 的 pool 中去获取，这样可以尽可能复用内存，从测试来看内存分配和 GC 优化效果明显。\nstring / binary 零拷贝\n对于有一些业务，比如视频相关的业务，会在请求或者返回中有一个很大的 Binary 二进制数据代表了处理后的视频或者图片数据，同时会有一些业务会返回很大的 String（如全文信息等）。 这种场景下，我们通过火焰图看到的热点都在数据的 copy 上，那我们就想了，我们是否可以减少这种拷贝呢？\n答案是肯定的。既然我们底层使用的 Buffer 是个链表，那么就可以很容易地在链表中间插入一个节点。\n我们就采用了类似的思想，当序列化的过程中遇到了 string 或者 binary 的时候， 将这个节点的 buffer 分成两段，在中间原地插入用户的 string / binary 对应的 buffer，这样可以避免大的 string / binary 的拷贝了。\n这里再介绍一下，如果我们直接用 []byte(string) 去转换一个 string 到 []byte 的话实际上是会发生一次拷贝的，原因是 Go 的设计中 string 是 immutable 的但是 []byte 是 mutable 的， 所以这么转换的时候会拷贝一次；如果要不拷贝转换的话，就需要用到 unsafe 了：\nfunc StringToSliceByte(s string) []byte { l := len(s) return *(*[]byte)(unsafe.Pointer(\u0026reflect.SliceHeader{ Data: (*(*reflect.StringHeader)(unsafe.Pointer(\u0026s))).Data, Len: l, Cap: l, })) } 这段代码的意思是，先把 string 的地址拿到，再拼装上一个 slice byte 的 header，这样就可以不拷贝数据而将 string 转换成 []byte 了，不过要注意这样生成的 []byte 不可写，否则行为未定义。\n预计算\n线上存在某些服务有大包传输的场景，这种场景下会引入不小的序列化 / 反序列化开销。一般大包都是容器类型的大小非常大导致的，如果能够提前计算出 buffer，一些 O(n) 的操作就能降到 O(1)，减少了函数调用次数，在大包场景下也大量减少了内存分配的次数，带来的收益是可观的。\n  基本类型\n 如果容器元素为基本类型（bool, byte, i16, i32, i64, double）的话，由于基本类型大小固定，在序列化时是可以提前计算出总的大小，并且一次性分配足够的 buffer，O(n) 的 malloc 操作次数可以降到 O(1)，从而大量减少了 malloc 的次数，同理在反序列化时可以减少 next 的操作次数。    struct 字段重排\n  上面的优化只能针对容器元素类型为基本类型的有效，那么对于元素类型为 struct 的是否也能优化呢？答案是肯定的。\n  沿用上面的思路，假如 struct 中如果存在基本类型的 field，也可以预先计算出这些 field 的大小，在序列化时为这些 field 提前分配 buffer，写的时候也把这些 field 顺序统一放到前面写，这样也能在一定程度上减少 malloc 的次数。\n    一次性计算\n 上面提到的是基本类型的优化，如果在序列化时，先遍历一遍 request 所有 field，便可以计算得到整个 request 的大小，提前分配好 buffer，在序列化和反序列时直接操作 buffer，这样对于非基本类型也能有优化效果。    定义新的 codec 接口：\n  type thriftMsgFastCodec interface { BLength() int // count length of whole req/resp  FastWrite(buf []byte) int FastRead(buf []byte) (int, error) }  在 Marshal 和 Unmarshal 接口中做相应改造：  func (c thriftCodec) Marshal(ctx context.Context, message remote.Message, out remote.ByteBuffer) error { ... if msg, ok := data.(thriftMsgFastCodec); ok { msgBeginLen := bthrift.Binary.MessageBeginLength(methodName, thrift.TMessageType(msgType), int32(seqID)) msgEndLen := bthrift.Binary.MessageEndLength() buf, err := out.Malloc(msgBeginLen + msg.BLength() + msgEndLen)// malloc once  if err != nil { return perrors.NewProtocolErrorWithMsg(fmt.Sprintf(\"thrift marshal, Malloc failed: %s\", err.Error())) } offset := bthrift.Binary.WriteMessageBegin(buf, methodName, thrift.TMessageType(msgType), int32(seqID)) offset += msg.FastWrite(buf[offset:]) bthrift.Binary.WriteMessageEnd(buf[offset:]) return nil } ... } func (c thriftCodec) Unmarshal(ctx context.Context, message remote.Message, in remote.ByteBuffer) error { ... data := message.Data() if msg, ok := data.(thriftMsgFastCodec); ok \u0026\u0026 message.PayloadLen() != 0 { msgBeginLen := bthrift.Binary.MessageBeginLength(methodName, msgType, seqID) buf, err := tProt.next(message.PayloadLen() - msgBeginLen - bthrift.Binary.MessageEndLength()) // next once  if err != nil { return remote.NewTransError(remote.PROTOCOL_ERROR, err.Error()) } _, err = msg.FastRead(buf) if err != nil { return remote.NewTransError(remote.PROTOCOL_ERROR, err.Error()) } err = tProt.ReadMessageEnd() if err != nil { return remote.NewTransError(remote.PROTOCOL_ERROR, err.Error()) } tProt.Recycle() return err } ... }  生成代码中也做相应改造：  func (p *Demo) BLength() int { l := 0 l += bthrift.Binary.StructBeginLength(\"Demo\") if p != nil { l += p.field1Length() l += p.field2Length() l += p.field3Length() ... } l += bthrift.Binary.FieldStopLength() l += bthrift.Binary.StructEndLength() return l } func (p *Demo) FastWrite(buf []byte) int { offset := 0 offset += bthrift.Binary.WriteStructBegin(buf[offset:], \"Demo\") if p != nil { offset += p.fastWriteField2(buf[offset:]) offset += p.fastWriteField4(buf[offset:]) offset += p.fastWriteField1(buf[offset:]) offset += p.fastWriteField3(buf[offset:]) } offset += bthrift.Binary.WriteFieldStop(buf[offset:]) offset += bthrift.Binary.WriteStructEnd(buf[offset:]) return offset } 使用 SIMD 优化 Thrift 编码 公司内广泛使用 list\u003ci64/i32\u003e 类型来承载 ID 列表，并且 list\u003ci64/i32\u003e 的编码方式十分符合向量化的规律，于是我们用了 SIMD 来优化 list\u003ci64/i32\u003e 的编码过程。\n我们使用了 avx2，优化后的结果比较显著，在大数据量下针对 i64 可以提升 6 倍性能，针对 i32 可以提升 12 倍性能；在小数据量下提升更明显，针对 i64 可以提升 10 倍，针对 i32 可以提升 20 倍。\n减少函数调用 inline\ninline 是在编译期间将一个函数调用原地展开，替换成这个函数的实现，它可以减少函数调用的开销以提高程序的性能。\n在 Go 中并不是所有函数都能 inline，使用参数-gflags=\"-m\"运行进程，可显示被 inline 的函数。以下几种情况无法内联：\n  包含循环的函数；\n  包含以下内容的函数：闭包调用，select，for，defer，go 关键字创建的协程；\n  超过一定长度的函数，默认情况下当解析 AST 时，Go 申请了 80 个节点作为内联的预算。每个节点都会消耗一个预算。比如，a = a + 1 这行代码包含了 5 个节点：AS, NAME, ADD, NAME, LITERAL。当一个函数的开销超过了这个预算，就无法内联。\n  编译时通过指定参数-l可以指定编译器对代码内联的强度（go 1.9+），不过这里不推荐大家使用，在我们的测试场景下是 buggy 的，无法正常运行：\n// The debug['l'] flag controls the aggressiveness. Note that main() swaps level 0 and 1, making 1 the default and -l disable. Additional levels (beyond -l) may be buggy and are not supported. // 0: disabled // 1: 80-nodes leaf functions, oneliners, panic, lazy typechecking (default) // 2: (unassigned) // 3: (unassigned) // 4: allow non-leaf functions 内联虽然可以减少函数调用的开销，但是也可能因为存在重复代码，从而导致 CPU 缓存命中率降低，所以并不能盲目追求过度的内联，需要结合 profile 结果来具体分析。\ngo test -gcflags='-m=2' -v -test.run TestNewCodec 2\u003e\u00261 | grep \"function too complex\" | wc -l 48 go test -gcflags='-m=2 -l=4' -v -test.run TestNewCodec 2\u003e\u00261 | grep \"function too complex\" | wc -l 25 从上面的输出结果可以看出，加强内联程度确实减少了一些\"function too complex\"，看下 benchmark 结果：\n   Benchmark time/op bytes/op allocs/op     BenchmarkOldMarshal-4 309 µs ± 2% 218KB 11   BenchmarkNewMarshal-4 310 µs ± 3% 218KB 11    上面开启最高程度的内联强度，确实消除了不少因为“function too complex”带来无法内联的函数，但是压测结果显示收益不太明显。\n测试结果 我们构建了基准测试来对比优化前后的性能，下面是测试结果。\n环境：Go 1.13.5 darwin/amd64 on a 2.5 GHz Intel Core i7 16GB\n小包\ndata size: 20KB\n   Benchmark time/op bytes/op allocs/op     BenchmarkOldMarshal-4 138 µs ± 3% 25.4KB 19   BenchmarkNewMarshal-4 29 µs ± 3% 26.4KB 11   Marshal Delta -78.97% 3.87% -42.11%   BenchmarkOldUnmarshal-4 199 µs ± 3% 4720 1360   BenchmarkNewUnmarshal-4 94µs ± 5% 4700 1280   Unmarshal Delta -52.93% -0.24% -5.38%    大包\ndata size: 6MB\n   Benchmark time/op bytes/op allocs/op     BenchmarkOldMarshal-4 58.7ms ± 5% 6.96MB 3350   BenchmarkNewMarshal-4 13.3ms ± 3% 6.84MB 10   Marshal Delta -77.30% -1.71% -99.64%   BenchmarkOldUnmarshal-4 56.6ms ± 3% 17.4MB 391000   BenchmarkNewUnmarshal-4 26.8ms ± 5% 17.5MB 390000   Unmarshal Delta -52.54% 0.09% -0.37%    无拷贝序列化 在一些 request 和 response 数据较大的服务中，序列化和反序列化的代价较高，有两种优化思路：\n  如前文所述进行序列化和反序列化的优化\n  以无拷贝序列化的方式进行调用\n  调研 通过无拷贝序列化进行 RPC 调用，最早出自 Kenton Varda 的 Cap’n Proto 项目，Cap’n Proto 提供了一套数据交换格式和对应的编解码库。\nCap’n Proto 本质上是开辟一个 bytes slice 作为 buffer ，所有对数据结构的读写操作都是直接读写 buffer，读写完成后， 在头部添加一些 buffer 的信息就可以直接发送，对端收到后即可读取，因为没有 Go 语言结构体作为中间存储，所有无需序列化这个步骤，反序列化亦然。\n简单总结下 Cap’n Proto 的特点：\n  所有数据的读写都是在一段连续内存中\n  将序列化操作前置，在数据 Get/Set 的同时进行编解码\n  在数据交换格式中，通过 pointer（数据存储位置的 offset）机制，使得数据可以存储在连续内存的任意位置，进而使得结构体中的数据可以以任意顺序读写\n 对于结构体的固定大小字段，通过重新排列，使得这些字段存储在一块连续内存中 对于结构体的不定大小字段（如 list），则通过一个固定大小的 pointer 来表示，pointer 中存储了包括数据位置在内的一些信息    首先 Cap’n Proto 没有 Go 语言结构体作为中间载体，得以减少一次拷贝，然后 Cap’n Proto 是在一段连续内存上进行操作，编码数据的读写可以一次完成，因为这两个原因，使得 Cap' Proto 的性能表现优秀。\n下面是相同数据结构下 Thrift 和 Cap’n Proto 的 Benchmark，考虑到 Cap’n Proto 是将编解码操作前置了，所以对比的是包括数据初始化在内的完整过程，即结构体数据初始化+（序列化）+写入 buffer +从 buffer 读出+（反序列化）+从结构体读出数据。\nstructMyTest{1:i64Num,2:AnoAno,3:list\u003ci64\u003eNums,// 长度131072 大小1MB }structAno{1:i64Num,}   Benchmark Iter time/op bytes/op alloc/op     BenchmarkThriftReadWrite 172 6855840 ns/op 3154209 B/op 545 allocs/op   BenchmarkCapnpReadWrite 1500 844924 ns/op 2085713 B/op 9 allocs/op   ReadWrite Delta / -87.68% -33.88% -98.35%    （反序列化）+读出数据，视包大小，Cap’n Proto 性能大约是 Thrift 的 8-9 倍。写入数据+（序列化），视包大小，Cap’n Proto 性能大约是 Thrift 的 2-8 倍。整体性能 Cap' Proto 性能大约是 Thrift 的 4-8 倍。\n前面说了 Cap’n Proto 的优势，下面总结一下 Cap’n Proto 存在的一些问题：\n  Cap’n Proto 的连续内存存储这一特性带来的一个问题：当对不定大小数据进行 resize ，且需要的空间大于原有空间时，只能在后面重新分配一块空间，导致原来数据的空间成为了一个无法去掉的 hole 。 这个问题随着调用链路的不断 resize 会越来越严重，要解决只能在整个链路上严格约束：尽量避免对不定大小字段的 resize ，当不得不 resize 的时候，重新构建一个结构体并对数据进行深拷贝。\n  Cap’n Proto 因为没有 Go 语言结构体作为中间载体，使得所有的字段都只能通过接口进行读写，用户体验较差。\n  Thrift 协议兼容的无拷贝序列化 Cap’n Proto 为了更好更高效地支持无拷贝序列化，使用了一套自研的编解码格式，但在现在 Thrift 和 ProtoBuf 占主流的环境中难以铺开。为了能在协议兼容的同时获得无拷贝序列化的性能，我们开始了 Thrift 协议兼容的无拷贝序列化的探索。\nCap’n Proto 作为无拷贝序列化的标杆，那么我们就看看 Cap’n Proto 上的优化能否应用到 Thrift 上：\n  自然是无拷贝序列化的核心，不使用 Go 语言结构体作为中间载体，减少一次拷贝。此优化点是协议无关的，能够适用于任何已有的协议，自然也能和 Thrift 协议兼容，但是从 Cap’n Proto 的使用上来看，用户体验还需要仔细打磨一下。\n  Cap’n Proto 是在一段连续内存上进行操作，编码数据的读写可以一次完成。Cap’n Proto 得以在连续内存上操作的原因：有 pointer 机制，数据可以存储在任意位置，允许字段可以以任意顺序写入而不影响解码。 但是一方面，在连续内存上容易因为误操作，导致在 resize 的时候留下 hole，另一方面，Thrift 没有类似于 pointer 的机制，故而对数据布局有着更严格的要求。这里有两个思路：\n 坚持在连续内存上进行操作，并对用户使用提出严格要求：1. resize 操作必须重新构建数据结构 2. 当存在结构体嵌套时，对字段写入顺序有着严格要求（可以想象为把一个存在嵌套的结构体从外往里展开，写入时需要按展开顺序写入）， 且因为 Binary 等 TLV 编码的关系，在每个嵌套开始写入时，需要用户主动声明（如 StartWriteFieldX）。 不完全在连续内存上操作，局部内存连续，可变字段则单独分配一块内存，既然内存不是完全连续的，自然也无法做到一次写操作便完成输出。为了尽可能接近一次写完数据的性能，我们采取了一种链式 buffer 的方案， 一方面当可变字段 resize 时只需替换链式 buffer 的一个节点，无需像 Cap’n Proto 一样重新构建结构体，另一方面在需要输出时无需像 Thrift 一样需要感知实际的结构，只要把整个链路上的 buffer 写入即可。    先总结下目前确定的两个点：1. 不使用 Go 语言结构体作为中间载体，通过接口直接操作底层内存，在 Get/Set 时完成编解码 2. 通过链式 buffer 存储数据\n然后让我们看下目前还有待解决的问题：\n  不使用 Go 语言结构体后带来的用户体验劣化\n 解决方案：改善 Get/Set 接口的使用体验，尽可能做到和 Go 语言结构体同等的易用    Cap’n Proto 的 Binary Format 是针对无拷贝序列化场景专门设计的，虽然每次 Get 时都会进行一次解码，但是解码代价非常小。而 Thrift 的协议（以 Binary 为例），没有类似于 pointer 的机制， 当存在多个不定大小字段或者存在嵌套时，必须顺序解析而无法直接通过计算偏移拿到字段数据所在的位置，而每次 Get 都进行顺序解析的代价过于高昂。\n 解决方案：我们在表示结构体的时候，除了记录结构体的 buffer 节点，还加了一个索引，里面记录了每个不定大小字段开始的 buffer 节点的指针。 下面是目前的无拷贝序列化方案与 FastRead/Write，在 4 核下的极限性能对比测试：       包大小 类型 QPS TP90 TP99 TP999 CPU     1KB 无序列化 70,700 1 ms 3 ms 6 ms /    FastWrite/FastRead 82,490 1 ms 2 ms 4 ms /   2KB 无序列化 65,000 1 ms 4 ms 9 ms /    FastWrite/FastRead 72,000 1 ms 2 ms 8 ms /   4KB 无序列化 56,400 2 ms 5 ms 10 ms 380%    FastWrite/FastRead 52,700 2 ms 4 ms 10 ms 380%   32KB 无序列化 27,400 / / / /    FastWrite/FastRead 19,500 / / / /   1MB 无序列化 986 53 ms 56 ms 59 ms 260%    FastWrite/FastRead 942 55 ms 59 ms 62 ms 290%   10MB 无序列化 82 630 ms 640 ms 645 ms 240%    FastWrite/FastRead 82 630 ms 640 ms 640 ms 270%    测试结果概述：\n  小包场景，无序列化性能表现较差，约为 FastWrite/FastRead 的 85%。\n  大包场景，无序列化性能表现较好，4K 以上的包较 FastWrite/FastRead 提升 7%-40%。\n  后记 希望以上的分享能够对社区有所帮助。同时，我们也在尝试 share memory-based IPC、io_uring、tcp zero copy 、RDMA 等，更好地提升 Kitex 性能；重点优化同机、同容器的通讯场景。欢迎各位感兴趣的同学加入我们，共同建设 Go 语言生态！\n参考资料   https://github.com/alecthomas/go_serialization_benchmarks\n  https://capnproto.org/\n  Intel® C++ Compiler Classic Developer Guide and Reference\n  ","categories":"","description":"本文介绍了字节跳动 Go RPC 框架 Kitex 的性能优化实践，包括 Netpoll、Thrift、序列化等方面的优化。","excerpt":"本文介绍了字节跳动 Go RPC 框架 Kitex 的性能优化实践，包括 Netpoll、Thrift、序列化等方面的优化。","ref":"/zh/blog/2021/09/23/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-go-rpc-%E6%A1%86%E6%9E%B6-kitex-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/","tags":"","title":"字节跳动 Go RPC 框架 Kitex 性能优化实践"},{"body":"Improvement:  Support TCP_NODELAY by default Read \u0026\u0026 write in a single loop Return real error for nocopy rw Change default number of loops policy Redefine EventLoop.Serve arg: Listener -\u003e net.Listener Add API to DisableGopool Remove reading lock Blocking conn flush API  Bugfix:  Set leftover wait read size  ","categories":"","description":"","excerpt":"Improvement:  Support TCP_NODELAY by default Read \u0026\u0026 write in a single …","ref":"/blog/2021/09/16/netpoll-release-v0.0.4/","tags":"","title":"Netpoll Release v0.0.4"},{"body":"优化:  默认支持 TCP_NODELAY 支持在一个循环中读写 返回 nocopy rw 的真实错误 更改了循环策略的默认数量 重新定义了 EventLoop.Serve arg: Listener -\u003e net.Listener 在 DisableGopool 中增加了API 删除了读锁 连接 Flush API 调整为阻塞的  Bug 修复:  设置剩余待读取大小。  ","categories":"","description":"","excerpt":"优化:  默认支持 TCP_NODELAY 支持在一个循环中读写 返回 nocopy rw …","ref":"/zh/blog/2021/09/16/netpoll-v0.0.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Netpoll v0.0.4 版本发布"},{"body":"Background ByteDance is proud to announce the launch of open source software CloudWeGo. Focusing on microservice communication and governance, it offers high performance, strong extensibility, and high reliability which enables quick construction of an enterprise-level cloud native architecture.\nByteDance uses Golang as its main development language, and supports the reliable communication of tens of thousands of Golang microservices. We are experienced in microservices after practicing under massive traffic, and so we decided to offer open source software in order to enrich the community’s ecology.\nWe have built the CloudWeGo project to gradually open source the internal microservices system and try to make the projects friendly to external users, and our internal projects will also use this open source project as a library for iterative development. CloudWeGo will follow a key principle of maintaining one set of code internally and externally, iterating them as a whole. As we needed to migrate our internal users to open source libraries transparently, we did not initially pursue any publicity. However, it has been gratifying to see Kitex gain 1.2k stars and Netpoll gain 700+ stars within one month organically.\nCloudWeGo is not only an external open source project, but also a real ultra-large-scale enterprise-level practice project.\nWe look forward to enriching the Golang product system of the cloud native community through CloudWeGo and helping other companies to build cloud-native architectures in a rapid and convenient way. We also hope to attract developers in the open source community, to maintain and improve this project together, provide support for multiple scenarios, and enrich product capabilities.\nBecause the projects under CloudWeGo depend on many internal basic tool libraries, we also open source the basic Golang tool libraries used internally, and maintain them in bytedance/gopkg.\nCloudWeGo To begin with, the two main projects included within CloudWeGo are the Kitex RPC framework and the Netpoll network library. We chose not to publicise these projects prematurely, to ensure our open source technologies were ready and had sufficient verification upon launch.\nKitex Kitex [kaɪt’eks] is a high-performance and strong-extensibility Golang RPC framework used in Bytedance. Before Kitex, the internal Golang framework was Kite, which was strongly coupled with Thrift - the code generation part of which covered intricate logic in the code.\nDue to these factors, it was difficult to optimize the framework from the network model or codec level.\nAdding new features will inevitably lead to more bloated code and would have hindered the iteration process. Instead we designed a new framework, Kitex, to address these concerns. Although Kitex is a new framework, it has been applied online internally for more than a year. At present, more than 50% of Golang microservices in Bytedance use Kitex.\nFeatures of Kitex include:\n High Performance  Kitex integrates Netpoll, a high-performance network library which offers significant performance advantage over go net. Kitex also makes some optimizations on the codec of Thrift, details of which can be found here. Users can also refer to this website for performance results.\n Extensibility  Kitex employs a modular design and provides many interfaces with default implementation for users to customize. Users can then extend or inject them into Kitex to fulfill their needs. Please refer to the official doc for the extensibility of Kitex. For their network library, developers can freely choose other network libraries aside from netpoll.\n Multi-message Protocol  Regarding the RPC message protocol, Kitex supports Thrift, Kitex Protobuf and gRPC by default. For Thrift, it supports two binary protocols, Buffered and Framed. Kitex Protobuf is a Kitex custom Protobuf messaging protocol with a protocol format similar to Thrift. The gRPC message protocol enables Kitex to interact with gRPC. Additionally, Kitex allows developers to extend their own messaging protocols.\n Multi-transport Protocol  The transport protocol encapsulates the message protocol for RPC communication and is able to transparently transmit meta-information used for service governance. Kitex supports two transport protocols, TTHeader and HTTP2. TTHeader can be used in conjunction with Thrift and Kitex Protobuf. At present, HTTP2 is mainly used in combination with the gRPC protocol, and will support Thrift in the future.\n Multi-message Type  Kitex supports PingPong, One-way, and Bidirectional Streaming. Among them, One-way currently only supports Thrift protocol, two-way Streaming only supports gRPC, and Kitex will support Thrift’s two-way Streaming in the future.\n Service Governance  Kitex integrates service governance modules such as service registry, service discovery, load balancing, circuit breaker, rate limiting, retry, monitoring, tracing, logging, diagnosis, etc. Most of these modules have been provided with default extensions, and users can make their choice of modules to integrate.\n Code Generation  Kitex has built-in code generation tools that support generating Thrift, Protobuf, and scaffold code. The original Thrift code is generated by Thriftgo, which is now open sourced. Kitex’s optimization of Thrift is supported by Kitex Tool as a plugin. Protobuf code is generated by Kitex as an official protoc plugin. Currently, Protobuf IDL parsing and code generation are not separately supported.\nNetpoll Netpoll is a high-performance, non-blocking I/O networking framework which focuses on RPC scenarios, developed by ByteDance.\nRPC is usually heavy on processing logic, including business logic and codec, and therefore cannot handle I/O serially like Redis. However, Go’s standard library net is designed for blocking I/O APIs, so that the RPC framework can only follow the One Conn One Goroutine design. It increases cost for context switching due to a large number of goroutines under high concurrency. Moreover, net.Conn has no API to check Alive, so it is difficult to make an efficient connection pool for the RPC framework, because there may be a large number of failed connections in the pool.\nOn the other hand, the open source community currently lacks Go network libraries that focus on RPC scenarios. Similar repositories such as evio and gnet are focused on scenarios like Redis and Haproxy.\nNetpoll has been designed to solve these problems. It draws inspiration from the design of evio and netty, achieves excellent performance and is more suitable for microservice architecture. Netpoll also provides a number of Features. Developers are recommended to use Netpoll as the network library of the RPC framework.\nThriftgo Thriftgo is an implementation of thrift compiler in go language that supports complete syntax and semantic checking of Thrift IDL.\nCompared with the official Golang code generation by Apache Thrift, Thriftgo made some bug fixes and supports a plugin mechanism. Users can customize the generated code according to their needs.\nThriftgo is the code generation tool of Kitex. CloudWeGo will soon opensource thrift-gen-validator, a plugin of Thriftgo that supports IDL Validator and is used for field verification, which is not provide by Thrift. With the IDL Validator, developers do not need to implement code verification logic by themselves.\nAlthough Thriftgo currently only supports the generation of Golang Thrift code, it is positioned to support Thrift code generation in various languages. If there is a need in future, we will also consider supporting code generation for other programming languages. At the same time, we will try to contribute Thriftgo to the Apache Thrift community.\nMaintenance A complete microservice system builds upon a basic cloud ecosystem. No matter how the microservices are developed; based on the public cloud, a private cloud or your own infrastructure, additional services (including service governance platform, monitoring, tracing, service registry and discovery, configuration and service mesh etc) and some customized standards are needed to provide better service governance. At Bytedance we have complete internal services to support the microservice system, but these services cannot be open source in the short term. So, how will CloudWeGo maintain a set of code internally and externally, and iterate them as a whole?\nProjects in CloudWeGo are not coupled with the internal ecology. For example, Netpoll is directly migrated to open source libraries, and our internal dependencies are adjusted to open source libraries.\nKitex’s code is split into two parts, including the core of Kitex which has been migrated to the open source library, and the encapsulated internal library which will provide transparent upgrades for internal users.\nFor open source users who use Kitex, they can also extend Kitex and integrate Kitex into their own microservice system. We hope, and expect, that more developers will contribute their own extensions to kitex-contrib, providing help and convenience for more users.\nFuture directions  Open source other internal projects  We will continue to open source other internal projects, such as HTTP framework Hertz, shared memory-based IPC communication library ShmIPC and others, to provide more support for microservice scenarios.\n Open source verified and stable features  The main projects of CloudWeGo provide support for internal microservices of Bytedance. New features are usually verified internally, and we will gradually open source them when they are relatively mature, such as the integration of ShmIPC, no serialization, and no code generation.\n Combine internal and external needs and iterate  After launching open source software, in addition to supporting internal users we also hope that CloudWeGo can provide good support for external users and help everyone quickly build their own microservice system. As such, we will iterate based on the needs of both internal and external users.\nFollowing initial feedback, users have shown a stronger demand for Protobuf. Although Kitex supports multiple protocols, the internal RPC communication protocol of Bytedance is Thrift. Protobuf, Kitex Protobuf or compatibility with gRPC is supported only to fulfill the needs of a small number of internal users, so performance [for Protobuf] has not been optimized yet. In terms of code generation, we have not made any optimizations, and currently utilize Protobuf’s official binary directly.\nGogo/protobuf is an excellent open source library that optimizes Protobuf serialization performance based on generated code, but unfortunately the library is currently out of maintenance, which is why Kitex did not choose gogo. In order to meet the growing needs of developers, we are planning to carry out Kitex’s performance optimization for Protobuf support.\nYou are welcome to submit issues and PRs to build CloudWeGo together. We are excited for more developers to join, and also look forward to CloudWeGo helping more and more companies quickly build cloud-native architectures. If any corporate customers want to employ CloudWeGo in your internal projects, we can provide technical support. Feel free to raise an issue in Github if you have any questions.\n","categories":"","description":"ByteDance now offers open source through CloudWeGo！","excerpt":"ByteDance now offers open source through CloudWeGo！","ref":"/blog/2021/09/13/cloudwego-open-source-announcement/","tags":"","title":"CloudWeGo Open Source Announcement"},{"body":"开源背景 CloudWeGo 是一套由字节跳动开源的、以 Go 语言为核心的、可快速构建企业级云原生架构的中间件集合，专注于微服务通信与治理，具备高性能、可扩展、高可靠的特点。\n字节跳动内部使用 Golang 作为主要的业务开发语言，我们支持着数万个 Golang 微服务的可靠通信，经过数量众多的微服务和海量流量的验证，我们已经有了较为成熟的微服务最佳实践，于是考虑将内部的实践开源出去丰富社区生态。 但微服务相关的项目较多，每个项目单独开源对外部用户并不友好，为了更好地让大家聚焦于微服务，我们以 CloudWeGo 作为项目名，逐步将内部微服务体系的项目开源，内外统一使用开源库，各项目以开源库为主进行迭代。\n内外维护一套代码，统一迭代演进，是我们开源前明确的原则，但毕竟涉及到代码库的调整，我们要保证内部用户尽可能无感知的迁移到开源库，本着对内部和开源用户负责的态度，我们要先确认内部可以平滑过渡，所以开源时并未对外宣传。 让我们欣慰的是，在未宣传的情况下，一个月内 Kitex 收获了 1.2k stars，Netpoll 收获了700+ stars。\nCloudWeGo 不仅仅是一个对外的开源项目，也是一个真实的超大规模企业级实践项目。\n我们希望通过 CloudWeGo 丰富云原生社区的 Golang 产品体系，助力其他企业快速构建云原生架构，也希望吸引外部开发者共建，促进面向多元场景支持的演进，丰富产品能力。\n因为 CloudWeGo 下的项目会依赖很多内部的基础工具库，我们也推动将内部常用的 Golang 基础工具库开源出去，统一在 bytedance/gopkg 维护。\nCloudWeGo 开源项目 CloudWeGo 第一批以 Kitex RPC 框架和 Netpoll 网络库为主开源四个项目。Kitex 和 Netpoll 开源前我们发布过两篇文章 字节跳动 Go RPC 框架 Kitex 性能优化实践 和 字节跳动在 Go 网络库上的实践 分享我们的实践，文章发布后大家都在关注我们什么时候开源，因为我们希望将成熟的实践开源出去，所以没有过早的推动开源。\nKitex Kitex 是字节跳动内部的 Golang 微服务 RPC 框架，具有高性能、强可扩展的主要特点。在 Kitex 之前内部的 Golang 框架是 Kite，但 Kite 与 Thrift 深度耦合、生成代码逻辑重， 很难从网络模型或编解码层面改造优化，继续支持新特性势必会造成代码越发臃肿迭代受阻问题，于是我们针对曾经的痛点设计了新的框架 Kitex。虽然 Kitex 是新框架，但已经在线上应用一年多，目前字节内部超过 50% 的 Golang 微服务使用 Kitex。\n以下简述 Kitex 的一些特性：\n  高性能：网络传输模块 Kitex 默认集成了自研的网络库 Netpoll，性能相较使用 go net 有显著优势；除了网络库带来的性能收益，Kitex 对 Thrift 编解码也做了优化，详见 优化实践。关于性能数据可参考 kitex-benchmark。\n  扩展性：Kitex 设计上做了模块划分，提供了较多的扩展接口以及默认的扩展实现，使用者也可以根据需要自行定制扩展，更多扩展能力参见 文档。Kitex 也并未耦合 Netpoll，开发者也可以选择其它网络库扩展使用。\n  消息协议：RPC 消息协议默认支持 Thrift、Kitex Protobuf、gRPC。Thrift 支持 Buffered 和 Framed 二进制协议；Kitex Protobuf 是 Kitex 自定义的 Protobuf 消息协议，协议格式类似 Thrift；gRPC 是对 gRPC 消息协议的支持，可以与 gRPC 互通。除此之外，使用者也可以扩展自己的消息协议。\n  传输协议：传输协议封装消息协议进行 RPC 互通，传输协议可以额外透传元信息，用于服务治理，Kitex 支持的传输协议有 TTHeader、HTTP2。TTHeader 可以和 Thrift、Kitex Protobuf 结合使用；HTTP2 目前主要是结合 gRPC 协议使用，后续也会支持 Thrift。\n  多消息类型：支持 PingPong、Oneway、双向 Streaming。其中 Oneway 目前只对 Thrift 协议支持，双向 Streaming 只对 gRPC 支持，后续会考虑支持 Thrift 的双向 Streaming。\n  服务治理：支持服务注册/发现、负载均衡、熔断、限流、重试、监控、链路跟踪、日志、诊断等服务治理模块，大部分均已提供默认扩展，使用者可选择集成。\n  Kitex 内置代码生成工具，可支持生成 Thrift、Protobuf 以及脚手架代码。原生的 Thrift 代码由本次一起开源的 Thriftgo 生成，Kitex 对 Thrift 的优化由 Kitex Tool 作为插件支持。Protobuf 代码由 Kitex 作为官方 protoc 插件生成 ，目前暂未单独支持 Protobuf IDL 的解析和代码生成。\n  Netpoll Netpoll 是字节跳动内部的 Golang 高性能、I/O 非阻塞的网络库，专注于 RPC 场景。\nRPC 通常有较重的处理逻辑（业务逻辑、编解码），耗时长，不能像 Redis 一样采用串行处理(必须异步)。而 Go 的标准库 net 设计了 BIO(Blocking I/O) 模式的 API， 为了保证异步处理，RPC 框架设计上需要为每个连接都分配一个 goroutine，这在空闲连接较多时，产生大量的空闲 goroutine，增加调度开销。 此外，net.Conn 没有提供检查连接活性的 API，很难设计出高效的连接池，池中的失效连接无法及时清理，复用低效。\n开源社区目前缺少专注于 RPC 方案的 Go 网络库。类似的项目如：evio , gnet 等，均面向 Redis, Haproxy 这样的场景。\n因此 Netpoll 应运而生，它借鉴了 evio 和 Netty 的优秀设计，具有出色的 性能，更适用于微服务架构。 同时，Netpoll 还提供了一些 特性，推荐在 RPC 框架中作为底层网络库。\nThriftgo Thriftgo 是 Go 语言实现的 Thrift IDL 解析和代码生成器，支持完善的 Thrift IDL 语法和语义检查，相较 Apache Thrift 官方的 Golang 生成代码，Thriftgo 做了一些问题修复且支持插件机制，用户可根据需求自定义生成代码。\nKitex 的代码生成工具就是 Thriftgo 的插件，CloudWeGo 近期也会开源另一个 Thriftgo 的插件 thrift-gen-validator，支持 IDL Validator，用于字段值校验，解决开发者需要自行实现代码校验逻辑的负担，弥补 Thrift 缺失的能力。\nThriftgo 目前虽然仅支持生成 Golang Thrift 代码，但其定位是可支持各语言的 Thrift 代码生成，未来如果有需求，我们也会考虑生成其他语言的代码，同时我们也将尝试将其回馈至 Apache Thrift 社区。\nNetpoll-http2 Netpoll-http2 是基于 Golang 标准库 golang.org/x/net/http2 的源码替换 go net 为 Netpoll，目前用于 Kitex 对 gRPC 协议的支持，对 HTTP2 有需求的外部开发者也可以使用此库。\n内外版本维护 完整的微服务体系离不开基础的云生态，无论在公有云、私有云还是基于自己的基础设施开发微服务，都需要搭建额外的服务以很好的支持微服务的治理，比如治理平台、监控、链路跟踪、注册/发现、配置中心、服务网格等， 而且还存在一些定制的规范。字节跳动自然也有完善的内部服务支持微服务体系，但这些服务短期还无法开源，那 CloudWeGo 如何内外维护一套代码，统一迭代呢？\nCloudWeGo 下与内部生态没有耦合的项目，如 Netpoll，直接迁移到开源库，内部依赖调整为开源库。\n而需要集成治理能力融入微服务体系的 Kitex 则基于其扩展性，将内外部的代码做了拆分，Kitex 的核心代码迁移到开源库，内部库封装一层壳保证内部用户无感知升级。 集成内部治理特性的模块则作为 Kitex 的扩展保留在内部库，同时对于一些新的特性也会优先在内部库支持，稳定后迁移到开源库。\n对于使用 Kitex 的开源用户，同样可以对 Kitex 进行扩展，将 Kitex 融入自己的微服务体系中，也希望开发者能贡献自己的扩展到 kitex-contrib，为更多用户提供便利。\n未来展望 继续开源其他内部项目\n 我们会继续开源其他内部项目，如 HTTP 框架 Hertz、基于共享内存的 IPC 通信库 ShmIPC 等，提供更多场景的微服务需求支持。  逐步开源经验证的、稳定的特性\n CloudWeGo 的主要项目均为字节内部微服务提供支持，新的特性通常会在内部验证，相对成熟后我们会逐步开源出去，比如对 ShmIPC 的集成、无序列化、无生成代码的支持等等。  结合内外部用户需求，持续迭代\n  CloudWeGo 开源后除向内部提供支持外，我们也希望 CloudWeGo 能为外部用户提供良好的支持，帮助大家快速搭建自己的微服务体系，所以我们会面向内外部用户迭代。\n  就开源一个月的反馈看，大家对 Protobuf 的诉求较为强烈。坦诚来说 Kitex 虽然支持多协议，但字节内部 RPC 通信协议是 Thrift，对 Protobuf 无论是 Kitex Protobuf 还是兼容 gRPC 更多的是支持少部分内部用户的需求， 所以暂时未开展性能优化，生成代码也是直接使用 Protobuf 官方的二进制（gogo/protobuf 是基于生成代码优化 Protobuf 序列化性能的优秀开源库， 但很遗憾该库目前是停止维护状态，所以 Kitex 并未选择 gogo），但鉴于大家强烈的诉求，我们会计划开展 Kitex 对 Protobuf 支持的性能优化。\n  欢迎大家向 CloudWeGo 提交 issue 和 PR 共建 CloudWeGo，我们诚心期待更多的开发者加入，也期待 CloudWeGo 助力越来越多的企业快速构建云原生架构。如果企业客户想内部试用，我们可以排期提供专项技术支持和交流，欢迎入群咨询。\n  ","categories":"","description":"字节跳动宣布正式开源内部微服务中间件 CloudWeGo","excerpt":"字节跳动宣布正式开源内部微服务中间件 CloudWeGo","ref":"/zh/blog/2021/09/07/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%BC%80%E6%BA%90%E5%86%85%E9%83%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6-cloudwego/","tags":"","title":"字节跳动开源内部微服务中间件 CloudWeGo"},{"body":"Improvement:  Make transMetaHandler executed before customized boundHandlers to ensure the customized boundHandlers could get metainfo. TransError uses internal error typeID if exist.  Bugfix:  Not reset stats level when clear RPCInfo in netpollmux to fix metric missing bug when use netpollmux. Remove stale addresses in long pool. Add an EOF condition to eliminate a redundant warning. Modify error types check of service circuit breaker to fix the bug that fuse cannot be triggered.  Tool:  Adjust protobuf generated code of unary to support both Kitex Protobuf and gRPC. Upgrade version of thriftgo to fix golint style. Fix typo in thrift generated code. Fix a bug that streaming generated code missing transport option.  Docs:  Add Golang setup section and Golang version requirement Some docs are updated. Add some English documents.  Dependency Change:  Thriftgo: v0.0.2-0.20210726073420-0145861fcd04 -\u003e v0.1.2 Netpoll: v0.0.2 -\u003e v0.0.3  ","categories":"","description":"","excerpt":"Improvement:  Make transMetaHandler executed before customized …","ref":"/blog/2021/08/26/kitex-release-v0.0.4/","tags":"","title":"Kitex Release v0.0.4"},{"body":"优化:  transMetaHandler 在自定义 boundHandlers 之前执行，保证自定义 boundHandlers 可以拿到 RPCInfo 信息。 TransError 暴露封装 error 的 typeID 用于支持自定义 Error 回传错误码。  Bug 修复:  复用 RPCInfo 不对 stats level 重置， 以修复在使用 netpollmux 时 metric 丢失问题。 清理不存在节点的连接池。 Streaming 中增加 Netpoll EOF 错误判断来清除冗余的 warning 日志。 修改熔断错误统计类型，非 Ignorable 错误类型均做熔断统计，以修复开源版本熔断无法正确生效和内部版本在开启mesh后重试熔断无法生效问题。  工具:  调整了 Protobuf unary 方法的生成代码，来同时支持 Kitex Protobuf 和 gRPC。 升级了 thriftgo 版本来修复 golint。 修复了生成代码中的错误。 修复了流生成的代码缺少传输选项的错误。  文档:  添加了 Golong 配置部分的文档以及 Golang 版本要求。 更新了一些现有文档。 添加了一些英文文档。  依赖变化:  Thriftgo: v0.0.2-0.20210726073420-0145861fcd04 -\u003e v0.1.2 Netpoll: v0.0.2 -\u003e v0.0.3  ","categories":"","description":"","excerpt":"优化:  transMetaHandler 在自定义 boundHandlers 之前执行，保证自定义 boundHandlers …","ref":"/zh/blog/2021/08/26/kitex-v0.0.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.0.4 版本发布"},{"body":"Bugfix:  Prevent connection pool from being overridden.  ","categories":"","description":"","excerpt":"Bugfix:  Prevent connection pool from being overridden.  ","ref":"/blog/2021/08/01/kitex-release-v0.0.3/","tags":"","title":"Kitex Release v0.0.3"},{"body":"Bug 修复:  防止连接池被覆盖。  ","categories":"","description":"","excerpt":"Bug 修复:  防止连接池被覆盖。  ","ref":"/zh/blog/2021/08/01/kitex-v0.0.3-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.0.3 版本发布"},{"body":"Improvement:  Kitex now disables all stats to improve performance when no tracer is provided. The Kitex client now will reuse connections by default.  Bugfix:  A nil-pointer bug in lbcache has been fixed. A data-race issue in the retry(backup request) is fixed.  Tool:  The kitex tool no longer generates a default config file. The kitex tool now uses the latest API of thriftgo which fixes several bad corner cases in code generation. The kitex tool now checks the existence of the go command instead of assuming it. Thanks to @anqiansong  Docs:   We have updated some documentations in this version.\n  Several lint issues and typos are fixed thanks to @rleungx @Huangxuny1 @JeffreyBool.\n  ","categories":"","description":"","excerpt":"Improvement:  Kitex now disables all stats to improve performance when …","ref":"/blog/2021/07/30/kitex-release-v0.0.2/","tags":"","title":"Kitex Release v0.0.2"},{"body":"优化：  Kitex 在没有 tracer 时关闭 stats 分阶段耗时采集，避免无 Trace 时额外的性能消耗。 Kitex client 默认使用连接池。  Bug 修复:  修复了一个 lbcache 中 nil-pointer 的错误。 修复了一个 retry 重试（Backup Request）中的 data race 问题。  工具:  Kitex 工具去掉默认生成的配置文件。 Kitex 工具现在使用最新的 thriftgo API 以避免老版 API 在生成代码时的几个边角案例。 Kitex 工具现在会检查代码中是否包含 go 命令，不再假设它的存在。感谢 @anqiansong 的贡献。  文档:  我们在这个版本中更新了一些文档。 我们修改了一些拼写错误和错别字。感谢 @rleungx @Huangxuny1 @JeffreyBool 的贡献。  ","categories":"","description":"","excerpt":"优化：  Kitex 在没有 tracer 时关闭 stats 分阶段耗时采集，避免无 Trace 时额外的性能消耗。 Kitex …","ref":"/zh/blog/2021/07/30/kitex-v0.0.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.0.2 版本发布"},{"body":"Kitex project initialization.\n","categories":"","description":"","excerpt":"Kitex project initialization.\n","ref":"/blog/2021/07/12/kitex-release-v0.0.1/","tags":"","title":"Kitex Release v0.0.1"},{"body":"Kitex 项目初始化。\n","categories":"","description":"","excerpt":"Kitex 项目初始化。\n","ref":"/zh/blog/2021/07/12/kitex-v0.0.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/","tags":"","title":"Kitex v0.0.1 版本发布"},{"body":" This article is excerpted from the ByteDance Architecture Practice series.\n“ByteDance Architecture Practice” is a series of articles produced by the technical teams and experts from the ByteDance Architecture Team, to share the team’s practical experience and lessons learnt from the development of infra-architecture, for the purpose of enhancing communication and growth of the developers.\nAs an important part of R\u0026D system, RPC framework carries almost all service traffics. This paper will briefly introduce the design and practice of the ByteDance in-house developed network library – Netpoll, as well as the problems and solutions that arise during our practices. This article can be used as a reference to help the tech-community’s further practices and experiments.\n Preface As an important part of the R\u0026D system, RPC framework carries almost all service traffics. As Golang is used more and more widely in ByteDance, the business has higher requirements on its framework. However, the “Go net” library cannot provide sufficient performance and control to support the business, notably inability to perceive the connection state, low utilization due to the large number of connections, and inability to control the number of goroutines. In order to take full control of the network layer, it’s necessary to make some exploration prospectively, and finally empower the business. The Service Framework Team launched a new self-developed network library – “Netpoll” based on “epoll”, and developed a new-generation Golang framework – “Kitex” based on “Netpoll”.\nSince there are many articles discussing the principles of “epoll”, this article will briefly introduce the design of “Netpoll” only. We’ll then try to review some of our practices regarding “Netpoll”. Finally, we’ll share a problem we encountered during our practices and how we solved it. In the meantime, we welcome more peers who are interested in Golang and Go framework to join us!\nDesign of the New Network Library Reactor - Event Monitoring and the Core of Scheduling The core of “Netpoll” is the event monitoring scheduler – “Reactor”, which uses “epoll” to monitor the “File Descriptor (fd)” of the connection and triggers the read, write and close events on the connection through the callback mechanism.  Server - MainReactor \u0026 SubReactor Implementation Netpoll combines Reactors in a 1: N master-slave pattern:\n “MainReactor” mainly manages the “Listener”, and is responsible for monitoring ports and establishing new connections. The “SubReactor” manages the “Connection”, listens all assigned connections, and submits all triggered events to the goroutine pool for processing. “Netpoll” supports “NoCopy RPC” by introducing active memory management in I/O tasks and providing an “NoCopy” invocation interface to the upper layer. Add a goroutine pool to centrally process I/O tasks, reduce the number of goroutines and scheduling overhead.   Client - Shares the Capability of Reactor SubReactor is shared between the client and server. Netpoll implements “Dialer” and provides the function for establishing connections. On the client, similar to “net.Conn”, Netpoll provides underlying support for “write -\u003e wait read callback”.  Nocopy Buffer Why Nocopy Buffer? As mentioned earlier, the way epoll is triggered affects the design of I/O and buffer, which can be generally divided into two approaches:\n Level Trigger (LT). It is necessary to complete I/O actively after the event is triggered, and provides buffers directly to the upper code. Edge Trigger (ET). You can choose to manage the event notification only (e.g. go net), with the upper layer code for I/O completion and buffers management.  Both ways have their advantages and disadvantages. “Netpoll” adopts the first strategy, which has better timeliness and higher fault tolerance rate. Active I/O can centralize memory usage and management, provide nocopy operation, and reduce GC. In fact, some popular open-source network libraries, such as “easygo”, “evio”, “gnet”, etc. are also designed in this way.\nHowever, using LT also brings another problem, namely the additional concurrency overhead caused by the underlying active I/O and the concurrent buffer operations by the upper code. For example, there are concurrent read and write when I/O read(data)/write(buffer) and the upper code reads the buffer, vice versa. In order to ensure data correctness and avoid lock contention, existing open-source network libraries usually adopt synchronous processing of buffer (“easygo”, “evio”) or provide a copy of buffer to the upper layer code (“gnet”), which are not suitable for business processing or have considerable copy overhead.\nOn the other hand, common buffer libraries such as “bytes”, “bufio”, and “ringbuffer” have problems such as “growth” requiring copy of data from the original array; capacity can only be expanded but can’t be reduced; occupying a large amount of memory etc. Therefore, we hope to introduce a new form of buffer to solve the two problems above.\nThe Design and Advantages of Nocopy Buffer Nocopy Buffer is implemented based on linked-list of array. As shown in the figure below, we abstract []byte array into blocks and combine blocks into Nocopy Buffer in the form of a linked list. Meanwhile, reference counting mechanism, Nocopy API and object pool are introduced.   Nocopy Buffer has the following advantages over some common buffer libraries like “bytes”, “bufio”, and “ringbuffer”:\n Read and write in parallel without lock, and supports stream read/write with nocopy  Read and write operate the head pointer and tail pointer separately without interfering with each other.   Efficient capacity expansion and reduction  For capacity expansion, you can add new blocks directly after the tail pointer without copying the original array. For capacity reduction, the head pointer directly releases the used block node to complete the capacity reduction. Each block has an independent reference count, and when the freed block is no longer referenced, the block node is actively reclaimed.   Flexible slicing and splicing of buffer (the characteristic of linked list)  Support arbitrary read slicing (nocopy), and the upper layer code can process data stream slicing in parallel with nocopy by reference counting GC, regardless of the lifecycle. Support arbitrary splicing (nocopy). Buffer write supports splicing block after the tail pointer, without copy, and ensuring that data is written only once.   Nocopy Buffer is pooled to reduce GC  Treat each []byte array as a block node, and build an object pool to maintain free blocks, thus reuse blocks, reduce memory footprint and GC. Based on the Nocopy Buffer, we implemented Nocopy Thrift, so that the codec process allocates zero memory with zero copy.    Connection Multiplexing RPC calling is usually in the form of short connection or persistent connection pool, and each call is bound to one connection. Therefore, when the scale of upstream and downstream is large, the number of existing connections in the network increases in the speed of MxN, which brings huge scheduling pressure and computing overhead, and makes service governance difficult. Therefore, we want to introduce a mechanism for “parallel processing of calls on a single persistent connection” to reduce the number of connections in the network. This mechanism is called connection multiplexing.\nThere are some existing open-source connection multiplexing solutions. But they are limited by code level constraints. They all require copy buffer for data subcontracting and merging, resulting in poor performance. Nocopy Buffer, with its flexible slicing and splicing, well supports data subcontracting and merging with nocopy, making it possible to achieve high-performance connection multiplexing schemes.\nThe design of Netpoll-based connection multiplexing is shown in the figure below. We abstract the Nocopy Buffer(and its sharding) into virtual connections, so that the upper layer code retains the same calling experience as “net.Conn”. At the same time, the data on the real connection can be flexibly allocated to the virtual connection through protocol subcontracting in the underlying code. Or send virtual connection data through protocol encoding.  \nThe connection multiplexing scheme contains the following core elements:\n The virtual connection  It is essentially a “Nocopy Buffer”, designed to replace real connections and avoid memory copy. The upper-layer service logic/codec is executed on the virtual connection, and the upper-layer logic can be executed in parallel asynchronously and independently.   Shared map  Shared locking is introduced to reduce the lock intensity. The Sequence ID is used to mark the request on the caller side and the shared lock is used to store the callback corresponding to the ID. After receiving the response data, find the corresponding callback based on the sequence ID and execute it.   Data subcontracting and encoding  How to identify the complete request-response data package is the key to make the connection multiplexing scheme feasible, so the protocol needs to be introduced. The “Thrift Header Protocol” is used to check the data package integrity through the message header, and sequence ids are used to mark the corresponding relations between request and response.    ZeroCopy “ZeroCopy” refers to the ZeroCopy function provided by Linux. In the previous chapter, we discussed nocopy of the service layer. But as we know, when we call the “sendmsg” system-call to send a data package, actually there is still a copy of the data, and the overhead of such copies is considerable when the data packages are large. For example, when the data package has the size of 100M, we can see the following result:   The previous example is merely the overhead of tcp package sending. In our scenario, most services are connected to the “Service Mesh”. Therefore, there are three copies in a package sending: Service process to kernel, kernel to sidecar, sidecar to kernel. This makes the CPU usage caused by copying especially heavy for services demanding large package transactions, as shown in the following figure:   To solve this problem, we chose to use the ZeroCopy API provided by Linux (send is supported after 4.14; receive is supported after 5.4). But this introduces an additional engineering problem: the ZeroCopy send API is incompatible with the original call method and does not coexist well. Here’s how ZeroCopy Send works: After the service process calls “sendmsg”, “sendmsg” records the address of the “iovec” and returns it immediately. In this case, the service process cannot release the memory, and needs to wait for the kernel to send a signal indicating that an “iovec” has been successfully sent before it can be released via “epoll”. Since we don’t want to change the way the business side uses it, we need to provide a synchronous sending and receiving interface to the upper layer, so it is difficult to provide both ZeroCopy and non-Zerocopy abstraction based on the existing API. Since ZeroCopy has performance degradation in small package scenarios, this is not the default option.\nThus, the ByteDance Service Framework Team collaborated with the ByteDance Kernel Team. The Kernel Team provided the synchronous interface: when “sendmsg” is called, the kernel listens and intercepts the original kernel callback to the service, and doesn’t let “sendmsg” return values until the callback is complete. This allows us to easily plug in “ZeroCopy send” without changing the original model. Meanwhile, the ByteDance Kernel Team also implements ZeroCopy based on Unix domain socket, which enables zero-copy communication between service processes and Mesh sidecar.\nAfter using “ZeroCopy send”, we can see that the kernel is no longer occupied by copy through perf:   In terms of CPU usage, ZeroCopy can save half the cpu of non-ZeroCopy in large package scenarios.\nDelay Caused By Go Scheduling  PS: This problem has been fixed in the new version of Netpoll. The solution is to set EpollWait timeout parameter to 0 and actively give up the execution right to optimize the goroutine scheduling to improve the efficiency.\n In our practice, we found that although our newly written “Netpoll” outperformed the “Go net” library in terms of avg delay, it was generally higher than the “Go net” library in terms of p99 and max delay, and the spikes would be more obvious, as shown in the following figure (Go 1.13, Netpoll + multiplexing in blue, Netpoll + persistent connection in green, Go net library + persistent connection in yellow):  \nWe tried many ways to improve it, but the outcomes were unsatisfactory. Finally, we locate that the delay was not caused by the overhead of “Netpoll” itself, but by the scheduling of Go, for example:\n In “Netpoll”, the “SubReactor” itself is also a “goroutine”, which is affected by scheduling and cannot be guaranteed to be executed immediately after the “EpollWait” callback, so there would be a delay here. At the same time, since the “SubReactor” used to handle I/O events and the “MainReactor” used to handle connection listening are “goroutines” themselves, it is actually impossible to ensure that these reactors can be executed in parallel under multi-kernel conditions. Even in the most extreme cases, these reactors may be under the same P, and eventually become sequential execution, which cannot take full advantage of multi-kernel; After “EpollWait callback”, I/O events are processed serially in the “SubReactor”, so the last event may have a long tail problem. In connection multiplexing scenarios, since each connection is bound to a “SubReactor”, the delay is entirely dependent on the scheduling of the “SubReactor”, resulting in more pronounced spikes. Because Go has specific improvements for the net library in runtime, the net library will not have the above situation. At the same time, the net library is also a “goroutine-per-connection” model, so it ensures that requests can be executed in parallel without interfering with each other.  For the above problems, we have two solutions at present:\n Modify the Go runtime source code, register a callback in the Go runtime, call EpollWait each time, and pass the fd to the callback execution; Work with the ByteDance Kernel Team to support simultaneous batch read/write of multiple connections to solve sequential problems. In addition, in our tests, Go 1.14 reduces the latency slightly lower and smoother, but the max QPS that can be achieved is lower. I hope our ideas can provide some references to peers in the industry who also encountered this problem.  Postscript We hope the above sharing can be helpful to the community. At the same time, we are accelerating the development of “Netpoll” and “Kitex” – a new framework based on “Netpoll”. You are welcome to join us and build Golang ecology together!\nReference  http://man7.org/linux/man-pages/man7/epoll.7.html https://golang.org/src/runtime/proc.go https://github.com/panjf2000/gnet https://github.com/tidwall/evio  ","categories":"","description":"This blog introduces the design and practice of Bytedance self-developed network library Netpoll as well as the actual problems and solutions, hope to provide you with some reference.","excerpt":"This blog introduces the design and practice of Bytedance …","ref":"/blog/2020/05/24/bytedance-practices-on-go-network-library/","tags":"","title":"ByteDance Practices on Go Network Library"},{"body":" 本文选自“字节跳动基础架构实践”系列文章。\n“字节跳动基础架构实践”系列文章是由字节跳动基础架构部门各技术团队及专家倾力打造的技术干货内容，和大家分享团队在基础架构发展和演进过程中的实践经验与教训，与各位技术同学一起交流成长。\n 前言 RPC 框架作为研发体系中重要的一环，承载了几乎所有的服务流量。随着公司内 Go 语言使用越来越广，业务对框架的要求越来越高，而 Go 原生 net 网络库却无法提供足够的性能和控制力，如无法感知连接状态、连接数量多导致利用率低、无法控制协程数量等。 为了能够获取对于网络层的完全控制权，同时先于业务做一些探索并最终赋能业务，框架组推出了全新的基于 epoll 的自研网络库 —— Netpoll，并基于其之上开发了字节内新一代 Golang 框架 Kitex。\n由于 epoll 原理已有较多文章描述，本文将仅简单介绍 Netpoll 的设计；随后，我们会尝试梳理一下我们基于 Netpoll 所做的一些实践；最后，我们将分享一个我们遇到的问题，以及我们解决的思路。同时，欢迎对于 Go 语言以及框架感兴趣的同学加入我们！\n新型网络库设计 Reactor - 事件监听和调度核心 Netpoll 核心是 Reactor 事件监听调度器，主要功能为使用 epoll 监听连接的文件描述符（fd），通过回调机制触发连接上的 读、写、关闭 三种事件。\nServer - 主从 Reactor 实现 Netpoll 将 Reactor 以 1:N 的形式组合成主从模式。\n MainReactor 主要管理 Listener，负责监听端口，建立新连接； SubReactor 负责管理 Connection，监听分配到的所有连接，并将所有触发的事件提交到协程池里进行处理。 Netpoll 在 I/O Task 中引入了主动的内存管理，向上层提供 NoCopy 的调用接口，由此支持 NoCopy RPC。 使用协程池集中处理 I/O Task，减少 goroutine 数量和调度开销。  Client - 共享 Reactor 能力 client 端和 server 端共享 SubReactor，Netpoll 同样实现了 dialer，提供创建连接的能力。client 端使用上和 net.Conn 相似，Netpoll 提供了 write -\u003e wait read callback 的底层支持。\nNocopy Buffer 为什么需要 Nocopy Buffer ? 在上述提及的 Reactor 和 I/O Task 设计中，epoll 的触发方式会影响 I/O 和 buffer 的设计，大体来说分为两种方式：\n 采用水平触发(LT)，则需要同步的在事件触发后主动完成 I/O，并向上层代码直接提供 buffer。 采用边沿触发(ET)，可选择只管理事件通知(如 go net 设计)，由上层代码完成 I/O 并管理 buffer。  两种方式各有优缺，Netpoll 采用前者策略，水平触发时效性更好，容错率高，主动 I/O 可以集中内存使用和管理，提供 nocopy 操作并减少 GC。事实上一些热门开源网络库也是采用方式一的设计，如 easygo、evio、gnet 等。\n但使用 LT 也带来另一个问题，即底层主动 I/O 和上层代码并发操作 buffer，引入额外的并发开销。比如：I/O 读数据写 buffer 和上层代码读 buffer 存在并发读写，反之亦然。 为了保证数据正确性，同时不引入锁竞争，现有的开源网络库通常采取 同步处理 buffer(easygo, evio) 或者将 buffer 再 copy 一份提供给上层代码(gnet) 等方式，均不适合业务处理或存在 copy 开销。\n另一方面，常见的 bytes、bufio、ringbuffer 等 buffer 库，均存在 growth 需要 copy 原数组数据，以及只能扩容无法缩容，占用大量内存等问题。因此我们希望引入一种新的 Buffer 形式，一举解决上述两方面的问题。\nNocopy Buffer 设计和优势 Nocopy Buffer 基于链表数组实现，如下图所示，我们将 []byte 数组抽象为 block，并以链表拼接的形式将 block 组合为 Nocopy Buffer，同时引入了引用计数、nocopy API 和对象池。\nNocopy Buffer 相比常见的 bytes、bufio、ringbuffer 等有以下优势：\n 读写并行无锁，支持 nocopy 地流式读写  读写分别操作头尾指针，相互不干扰。   高效扩缩容  扩容阶段，直接在尾指针后添加新的 block 即可，无需 copy 原数组。 缩容阶段，头指针会直接释放使用完毕的 block 节点，完成缩容。每个 block 都有独立的引用计数，当释放的 block 不再有引用时，主动回收 block 节点。   灵活切片和拼接 buffer (链表特性)  支持任意读取分段(nocopy)，上层代码可以 nocopy 地并行处理数据流分段，无需关心生命周期，通过引用计数 GC。 支持任意拼接(nocopy)，写 buffer 支持通过 block 拼接到尾指针后的形式，无需 copy，保证数据只写一次。   Nocopy Buffer 池化，减少 GC  将每个 []byte 数组视为 block 节点，构建对象池维护空闲 block，由此复用 block，减少内存占用和 GC。基于该 Nocopy Buffer，我们实现了 Nocopy Thrift，使得编解码过程内存零分配零拷贝。    连接多路复用 RPC 调用通常采用短连接或者长连接池的形式，一次调用绑定一个连接，那么当上下游规模很大的情况下，网络中存在的连接数以 MxN 的速度扩张，带来巨大的调度压力和计算开销，给服务治理造成困难。 因此，我们希望引入一种 “在单一长连接上并行处理调用” 的形式，来减少网络中的连接数，这种方案即称为 “连接多路复用”。\n当前业界也存在一些开源的连接多路复用方案，掣肘于代码层面的束缚，这些方案均需要 copy buffer 来实现数据分包和合并，导致实际性能并不理想。 而上述 Nocopy Buffer 基于其灵活切片和拼接的特性，很好的支持了 nocopy 的数据分包和合并，使得实现高性能连接多路复用方案成为可能。\n基于 Netpoll 的连接多路复用设计如下图所示，我们将 Nocopy Buffer(及其分片) 抽象为虚拟连接，使得上层代码保持同 net.Conn 相同的调用体验。 与此同时，在底层代码上通过协议分包将真实连接上的数据灵活的分配到虚拟连接上；或通过协议编码合并发送虚拟连接数据。\n连接多路复用方案包含以下核心要素：\n  虚拟连接\n 实质上是 Nocopy Buffer，目的是替换真正的连接，规避内存 copy。 上层的业务逻辑/编解码 均在虚拟连接上完成，上层逻辑可以异步独立并行执行。    Shared map\n 引入分片锁来减少锁力度。 在调用端使用 sequence id 来标记请求，并使用分片锁存储 id 对应的回调。 在接收响应数据后，根据 sequence id 来找到对应回调并执行。    协议分包和编码\n 如何识别完整的请求响应数据包是连接多路复用方案可行的关键，因此需要引入协议。 这里采用 thrift header protocol 协议，通过消息头判断数据包完整性，通过 sequence id 标记请求和响应的对应关系。    ZeroCopy 这里所说的 ZeroCopy，指的是 Linux 所提供的 ZeroCopy 的能力。上一章中我们说了业务层的零拷贝，而众所周知，当我们调用 sendmsg 系统调用发包的时候， 实际上仍然是会产生一次数据的拷贝的，并且在大包场景下这个拷贝的消耗非常明显。以 100M 为例，perf 可以看到如下结果：\n这还仅仅是普通 tcp 发包的占用，在我们的场景下，大部分服务都会接入 Service Mesh，所以在一次发包中，一共会有 3 次拷贝：业务进程到内核、内核到 sidecar、sidecar 再到内核。 这使得有大包需求的业务，拷贝所导致的 cpu 占用会特别明显，如下图：\n为了解决这个问题，我们选择了使用 Linux 提供的 ZeroCopy API（在 4.14 以后支持 send；5.4 以后支持 receive）。但是这引入了一个额外的工程问题：ZeroCopy send API 和原先调用方式不兼容，无法很好地共存。 这里简单介绍一下 ZeroCopy send 的工作方式：业务进程调用 sendmsg 之后，sendmsg 会记录下 iovec 的地址并立即返回，这时候业务进程不能释放这段内存，需要通过 epoll 等待内核回调一个信号表明某段 iovec 已经发送成功之后才能释放。 由于我们并不希望更改业务方的使用方法，需要对上层提供同步收发的接口，所以很难基于现有的 API 同时提供 ZeroCopy 和非 ZeroCopy 的抽象；而由于 ZeroCopy 在小包场景下是有性能损耗的，所以也不能将这个作为默认的选项。\n于是，字节跳动框架组和字节跳动内核组合作，由内核组提供了同步的接口：当调用 sendmsg 的时候，内核会监听并拦截内核原先给业务的回调，并且在回调完成后才会让 sendmsg 返回。 这使得我们无需更改原有模型，可以很方便地接入 ZeroCopy send。同时，字节跳动内核组还实现了基于 unix domain socket 的 ZeroCopy，可以使得业务进程与 Mesh sidecar 之间的通信也达到零拷贝。\n在使用了 ZeroCopy send 后，perf 可以看到内核不再有 copy 的占用：\n从 cpu 占用数值上看，大包场景下 ZeroCopy 能够比非 ZeroCopy 节省一半的 cpu。\nGo 调度导致的延迟问题分享  PS: 该问题在新版本的 Netpoll 中已经修复，修复方法是通过 EpollWait Timeout 为 0 并且通过主动让出执行权，在 Goroutine 调度上做优化从而改善延迟。\n 在我们实践过程中，发现我们新写的 Netpoll 虽然在 avg 延迟上表现胜于 Go 原生的 net 库，但是在 p99 和 max 延迟上要普遍略高于 Go 原生的 net 库， 并且尖刺也会更加明显，如下图（Go 1.13，蓝色为 Netpoll + 多路复用，绿色为 Netpoll + 长连接，黄色为 net 库 + 长连接）：\n我们尝试了很多种办法去优化，但是收效甚微。最终，我们定位出这个延迟并非是由于 Netpoll 本身的开销导致的，而是由于 go 的调度导致的，比如说：\n 由于在 Netpoll 中，SubReactor 本身也是一个 goroutine，受调度影响，不能保证 EpollWait 回调之后马上执行，所以这一块会有延迟； 同时，由于用来处理 I/O 事件的 SubReactor 和用来处理连接监听的 MainReactor 本身也是 goroutine，所以实际上很难保证在多核情况之下，这些 Reactor 能并行执行； 甚至在最极端情况之下，可能这些 Reactor 会挂在同一个 P 下，最终变成了串行执行，无法充分利用多核优势； 由于 EpollWait 回调之后，SubReactor 内是串行处理 I/O 事件的，导致排在最后的事件可能会有长尾问题； 在连接多路复用场景下，由于每个连接绑定了一个 SubReactor，故延迟完全取决于这个 SubReactor 的调度，导致尖刺会更加明显。  由于 Go 在 runtime 中对于 net 库有做特殊优化，所以 net 库不会有以上情况；同时 net 库是 goroutine-per-connection 的模型，所以能确保请求能并行执行而不会相互影响。\n对于以上这个问题，我们目前解决的思路有两个：\n 修改 Go runtime 源码，在 Go runtime 中注册一个回调，每次调度时调用 EpollWait，把获取到的 fd 传递给回调执行； 与字节跳动内核组合作，支持同时批量读/写多个连接，解决串行问题。另外，经过我们的测试，Go 1.14 能够使得延迟略有降低同时更加平稳，但是所能达到的极限 QPS 更低。希望我们的思路能够给业界同样遇到此问题的同学提供一些参考。  后记 希望以上的分享能够对社区有所帮助。同时，我们也在加速建设 Netpoll 以及基于 Netpoll 的新框架 Kitex。欢迎各位感兴趣的同学加入我们，共同建设 Go 语言生态！\n参考资料  http://man7.org/linux/man-pages/man7/epoll.7.html https://golang.org/src/runtime/proc.go https://github.com/panjf2000/gnet https://github.com/tidwall/evio  ","categories":"","description":"本文将简单介绍字节跳动自研网络库 Netpoll 的设计及实践；以及我们实际遇到的问题和解决思路，希望能为大家提供一些参考。","excerpt":"本文将简单介绍字节跳动自研网络库 Netpoll 的设计及实践；以及我们实际遇到的问题和解决思路，希望能为大家提供一些参考。","ref":"/zh/blog/2020/05/24/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%9C%A8-go-%E7%BD%91%E7%BB%9C%E5%BA%93%E4%B8%8A%E7%9A%84%E5%AE%9E%E8%B7%B5/","tags":"","title":"字节跳动在 Go 网络库上的实践"},{"body":"  #td-cover-block-0 { background-image: url(/about/featured-background_hu32328cd19520b83601287ce1c2b24452_94020_960x540_fill_catmullrom_bottom_2.png); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/about/featured-background_hu32328cd19520b83601287ce1c2b24452_94020_1920x1080_fill_catmullrom_bottom_2.png); } }  About A leading practice for building enterprise cloud native middleware.       CloudWeGo is an open-source middleware set launched by ByteDance that can be used to quickly build enterprise-class cloud native architectures. It contains many components, including the RPC framework Kitex, the HTTP framework Hertz, the basic network library Netpoll, thrfitgo, etc. By combining the community's excellent open source products, developers can quickly build a complete set of microservices systems. For more ecosystem，please refer kitex-contrib and hertz-contrib.     Kitex Next generation high performance, highly scalable Golang RPC framework.\n     Hertz High-performance, high-usability, extensible HTTP framework for Go. It's designed to simplify building microservices for developers.\n     Netpoll High-performance NIO (Non-blocking I/O) network library, focusing on RPC scenarios.\n     Thriftgo A thrift compiler implemented by Golang supports plug-in mechanism.\n    ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/about/","tags":"","title":"About"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the blog section. It has two categories: News and Releases. …","ref":"/blog/","tags":"","title":"Blog"},{"body":"  #td-cover-block-0 { background-image: url(/featured-background_hu32328cd19520b83601287ce1c2b24452_94020_960x540_fill_catmullrom_top_2.png); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/featured-background_hu32328cd19520b83601287ce1c2b24452_94020_1920x1080_fill_catmullrom_top_2.png); } }  Welcome to CloudWeGo A leading practice for building enterprise cloud native middleware!\n Get Started    Github           Why CloudWeGo? CloudWeGo is an open-source middleware set launched by ByteDance that can be used to quickly build enterprise-class cloud native architectures. The common characteristics of CloudWeGo projects are high performance, high scalability, high reliability and focus on microservices communication and governance.       Open  Fully open source, community neutral, compatible with the community open source ecology, pluggable components, CloudWeGo components and other open source components can be integrated or replaced with each other     Industry-standard  Contains the components needed to build an enterprise-class cloud-native architecture, allowing users to focus more on business development, meet the current and future needs of user scenarios, and experience the refinement of large-scale scenarios     Cloud Native  Quickly build a cloud-native microservice system and develop more reliable, scalable and easy-to-maintain cloud-native applications.       Projects Kitex Next generation high performance, highly scalable Golang RPC framework.\n  Hertz Next generation high performance, highly scalable Golang HTTP framework.\n  Netpoll High-performance NIO (Non-blocking I/O) network library, focusing on RPC scenarios.\n  Thriftgo A thrift compiler implemented by Golang supports plug-in mechanism.\n  Volo A high-performance and strong-extensibility Rust RPC framework.\n  Monoio A thread-per-core Rust runtime with io_uring/epoll/kqueue.\n  Motore Async middleware abstraction powered by GAT and TAIT.\n  Pilota A thrift and protobuf implementation in pure rust with high performance and extensibility.\n  Sonic A blazingly fast JSON serializing \u0026 deserializing library, accelerated by JIT and SIMD.\n  Frugal A very fast dynamic Thrift serializer \u0026 deserializer based on just-in-time compilation.\n  Fastpb A faster Protobuf serializer \u0026 deserializer.\n  Cwgo CloudWeGo All in one Code Generator.\n       \"Over the past three years, Bytedance has witnessed rapid growth in the number and scale of its microservices. In 2018, we had about 7,000-8,000 online microservices, and by May of 2021, the number had exceeded 50,000. Now, we have decided to open source these technologies to help more developers. \"  — Service Framework Team, ByteDance       Created by   Used by                   CloudWeGo enriches the CNCF CLOUD NATIVE Landscape.       Docs  Kitex Hertz Volo Netpoll Motore Pilota   Projects  Kitex Hertz Volo Netpoll Motore Pilota   Contact Us  Email: conduct@cloudwego.io Slack        ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/","tags":"","title":"CloudWeGo"},{"body":"  #td-cover-block-0 { background-image: url(/zh/featured-background_hu32328cd19520b83601287ce1c2b24452_94020_960x540_fill_catmullrom_top_2.png); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh/featured-background_hu32328cd19520b83601287ce1c2b24452_94020_1920x1080_fill_catmullrom_top_2.png); } }  欢迎使用 CloudWeGo 构建企业级云原生中间件的领先实践！\n 开始    Github           为什么选 CloudWeGo? CloudWeGo 是一套由字节跳动开源的、可快速构建企业级云原生微服务架构的中间件集合。CloudWeGo 项目共同的特点是高性能、高扩展性、高可靠，专注于微服务通信与治理。       开放  技术栈全面开源共建、保持社区中立、兼容社区开源生态，组件可插拔，CloudWeGo 组件与其它开源组件可互相集成或替换。    企业级  包含构建企业级云原生架构所需的各个组件，让用户更加专注于业务开发，满足用户场景的现状和未来需求，经历过大规模场景的锤炼。    云原生  基于 CloudWeGo 可快速搭建云原生微服务体系，快速开发更具可靠性、扩展性、易维护的云原生应用。      项目 Kitex 下一代高性能、强可扩展的 Golang RPC 框架。\n  Hertz 下一代高性能、强可扩展的 Golang HTTP 框架。\n  Netpoll 高性能、I/O非阻塞的网络框架，专注于 RPC 场景。\n  Thriftgo Go 语言实现的 Thrift 编译器，支持插件机制，支持完整的 Thrift IDL 语法和完善的语义检查。\n  Volo 高性能、强可扩展的 Rust RPC 框架。\n  Monoio 基于 io_uring/epoll/kqueue 和 thread-per-core 模型的 Rust Runtime。\n  Motore 基于 GAT 和 TAIT 的异步中间件抽象。\n  Pilota 一个在纯 Rust 中具有高性能和可扩展性的 Thrift 和 Protobuf 实现。\n  Sonic 非常快的由 JIT 和 SIMD 加速的 JSON 序列化和反序列化库。\n  Frugal 基于 JIT 编译的高性能动态 Thrift 编解码器。\n  Fastpb 非常快的 Protobuf 序列化和反序列化库。\n  Cwgo CloudWeGo All in one 代码生成工具.\n       \"近三年来，字节跳动的微服务数量和规模迎来快速发展。2018 年，我们的在线微服务数大约是 7000-8000，到 2021 年五月份，这一数字已经突破 5 万。现在我们决定把这些技术开源出来，帮助更多开发者。\"  — 字节跳动服务框架团队       出品方   谁在用                   CloudWeGo 丰富了 CNCF 云原生生态.       文档  Kitex Hertz Volo Netpoll Motore Pilota   项目  Kitex Hertz Volo Netpoll Motore Pilota   联系我们  邮箱：conduct@cloudwego.io 加入 Slack        ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/zh/","tags":"","title":"CloudWeGo"},{"body":"  Welcome to CloudWeGo Community CloudWeGo is an open source project that anyone in the community can use, improve, and enjoy. We'd love you to join us! Here's a few ways to find out what's happening and get involved.\n    Develop and Contribute If you want to get more involved by contributing to CloudWeGo, join us here:\n  GitHub:  Development takes place here!   Slack:  Join our CloudWeGo Slack Channel    You can find out how to contribute to these docs in our Contribution Guidelines.  ","categories":"","description":"","excerpt":"  Welcome to CloudWeGo Community CloudWeGo is an open source project …","ref":"/community/","tags":"","title":"Community"},{"body":"  #td-cover-block-0 { background-image: url(/cooperation/featured-background_hu12e647f8638b137fcd0c7539335f6f57_163512_960x540_fill_catmullrom_bottom_2.png); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/cooperation/featured-background_hu12e647f8638b137fcd0c7539335f6f57_163512_1920x1080_fill_catmullrom_bottom_2.png); } }  谁在使用CloudWeGo  CloudWeGo 项目介绍小蓝书     CloudWeGo 用户实践案例分享\n      CloudWeGo 是一套由字节跳动开源的、可快速构建企业级云原生架构的中间件集合，专注于微服务通信与治理，具备高性能、高扩展性、高可靠的特点，满足不同业务在不同场景的诉求。 此外，CloudWeGo 也重视与云原生生态的集成，支持对接主流注册中心、Prometheus 监控以及 OpenTelemetry \u0026 OpenTracing 链路追踪等。 目前 CloudWeGo 已经在诸多企业和相关业务落地，涉及到电商、证券、游戏、企业软件、基础架构等诸多领域，详见下面案例介绍。 华兴证券在混合云原生架构下的 Kitex 实践  华兴证券是 CloudWeGo 企业用户，使用 Kitex 框架完成混合云部署下的跨机房调用。完成搭建针对 Kitex 的可观测性系统，以及在 K8s 同集群和跨集群下使用 Kitex 的落地实践。 了解更多   Kitex 在森马电商场景的落地实践  近些年电商行业高速发展，森马电商线上业务激增，面临着高并发、高性能的业务场景需求。森马正式成为 CloudWeGo 的企业用户，通过使用 Kitex 接入 Istio，极大地提高了对高并发需求的处理能力。 了解更多   飞书管理后台平台化改造的演进史  飞书管理后台是飞书套件专为企业管理员提供的信息管理平台，通过引入 Kitex 泛化调用对飞书管理后台进行平台化改造，提供一套统一的标准和通用服务，实现了飞书管理后台作为企业统一数字化管理平台的愿景。 了解更多        document.getElementById(\"file_download_bluebook\").addEventListener(\"click\", function(){ gtag('event', 'file_download_bluebook', { \"event_name\": \"file_download_bluebook\", }); })  ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/cooperation/","tags":"","title":"Cooperation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/search/","tags":"","title":"Search Results"},{"body":"This is the security section. It has two categories: vulnerability-reporting and safety-bulletin.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the security section. It has two categories: …","ref":"/security/","tags":"","title":"Security"},{"body":"  #td-cover-block-0 { background-image: url(/zh/about/featured-background_hu32328cd19520b83601287ce1c2b24452_94020_960x540_fill_catmullrom_bottom_2.png); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh/about/featured-background_hu32328cd19520b83601287ce1c2b24452_94020_1920x1080_fill_catmullrom_bottom_2.png); } }  关于 一套可快速构建企业级云原生架构的最佳实践！\n      CloudWeGo 是一套可快速构建企业级云原生微服务架构的中间件集合。 它包含许多组件：Golang RPC 框架 Kitex，HTTP 框架 Hertz，Rust RPC 框架 Volo，网络库 Netpoll，Go 语言 Thrift 编译器 Thriftgo 等等。 通过结合社区优秀的开源产品和生态，可以快速搭建一套完善的云原生微服务体系。 更多生态能力对接，请参考 kitex-contrib 和 hertz-contrib。     Kitex 下一代高性能、强可扩展的 Golang RPC 框架。\n     Hertz 高易用性、高性能、高扩展性的 Golang 微服务 HTTP 框架，旨在为开发人员简化构建微服务。      Netpoll 高性能、I/O非阻塞的网络框架，专注于 RPC 场景。      Thriftgo Go 语言实现的 thrift 编译器，支持插件机制，支持完整的 thrift IDL 语法和完善的语义检查。\n    ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/zh/about/","tags":"","title":"关于"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the blog section. It has two categories: News and Releases. …","ref":"/zh/blog/","tags":"","title":"博客"},{"body":"This is the security section. It has two categories: vulnerability-reporting and safety-bulletin.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the security section. It has two categories: …","ref":"/zh/security/","tags":"","title":"安全"},{"body":"  #td-cover-block-0 { background-image: url(/zh/cooperation/featured-background_hu12e647f8638b137fcd0c7539335f6f57_163512_960x540_fill_catmullrom_bottom_2.png); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh/cooperation/featured-background_hu12e647f8638b137fcd0c7539335f6f57_163512_1920x1080_fill_catmullrom_bottom_2.png); } }  谁在使用CloudWeGo  CloudWeGo 项目介绍小蓝书     CloudWeGo 用户实践案例分享\n      CloudWeGo 是一套由字节跳动开源的、可快速构建企业级云原生架构的中间件集合，专注于微服务通信与治理，具备高性能、高扩展性、高可靠的特点，满足不同业务在不同场景的诉求。 此外，CloudWeGo 也重视与云原生生态的集成，支持对接主流注册中心、Prometheus 监控以及 OpenTelemetry \u0026 OpenTracing 链路追踪等。 目前 CloudWeGo 已经在诸多企业和相关业务落地，涉及到电商、证券、游戏、企业软件、基础架构等诸多领域，详见下面案例介绍。 华兴证券在混合云原生架构下的 Kitex 实践  华兴证券是 CloudWeGo 企业用户，使用 Kitex 框架完成混合云部署下的跨机房调用。完成搭建针对 Kitex 的可观测性系统，以及在 K8s 同集群和跨集群下使用 Kitex 的落地实践。 了解更多   Kitex 在森马电商场景的落地实践  近些年电商行业高速发展，森马电商线上业务激增，面临着高并发、高性能的业务场景需求。森马正式成为 CloudWeGo 的企业用户，通过使用 Kitex 接入 Istio，极大地提高了对高并发需求的处理能力。 了解更多   飞书管理后台平台化改造的演进史  飞书管理后台是飞书套件专为企业管理员提供的信息管理平台，通过引入 Kitex 泛化调用对飞书管理后台进行平台化改造，提供一套统一的标准和通用服务，实现了飞书管理后台作为企业统一数字化管理平台的愿景。 了解更多        document.getElementById(\"file_download_bluebook\").addEventListener(\"click\", function(){ gtag('event', 'file_download_bluebook', { \"event_name\": \"file_download_bluebook\", }); })  ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: …","ref":"/zh/cooperation/","tags":"","title":"案例"},{"body":"社区模块，当前包含以下几部分：\n","categories":"","description":"","excerpt":"社区模块，当前包含以下几部分：\n","ref":"/zh/community/","tags":"","title":"社区"}]